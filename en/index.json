[{"categories":["Programming-Languages"],"content":"An introduction of the Applicative Functor, including the motivations, the meaing of \u003c*\u003e, etc","date":"2024-10-20","objectID":"/en/why-applicative-functor/","series":null,"tags":["Haskell"],"title":"Why Applicative Functor","uri":"/en/why-applicative-functor/"},{"categories":["Programming-Languages"],"content":" Info I assume that you have a good understanding of Functor before reading this article. ","date":"2024-10-20","objectID":"/en/why-applicative-functor/:0:0","series":null,"tags":["Haskell"],"title":"Why Applicative Functor","uri":"/en/why-applicative-functor/#"},{"categories":["Programming-Languages"],"content":" Why Applicative FunctorThere is a crucial question before we delve into the Applicative Functor: Why do we still need the Applicative Functor when we already have Functor? The signature of fmap function in Functor is a -\u003e b -\u003e f a -\u003e f b. So we can only use regular unary function a -\u003e b as a mapping function. What if we want to use a mapping function with multiple arguments? For example, we may want to use (+) :: a -\u003e a -\u003e a as the mapping function, then what we will get? haskell ghci\u003e let a = fmap (+) [1,2,3] ghci\u003e :t a a :: Num a =\u003e [a -\u003e a] Info The Unary function is a function that only has one single argument From the output of ghci, we can see each value in the Functor becomes a function a -\u003e a. Given that every function in Haskell is a currying function, we can figure out how it works. Each value in the List Functor becomes the first argument of (+). You may imagine the List Functor will be haskell [\\x -\u003e 1 + x, \\x -\u003e 2 + x, \\x -\u003e 3 + x] -- or, more simpler [(1+), (2+), (3+)] So we should have no problem using 1 as the second argument of (+). haskell ghci\u003e fmap ($ 1) a [2,3,4] -- 2 = 1 + 1 -- 3 = 2 + 1 -- 4 = 3 + 1 Note Conclusion: If the mapping function f contains two arguments, then fmap f x will make each value within Functor x become a function. If you understand the above example, I‚Äôm sure that you know how to get Just (1+) using fmap haskell ghci\u003e let justF = fmap (+) $ Just 1 ghci\u003e :t justF justF :: Num a =\u003e Maybe (a -\u003e a) Now imagine that we have a value of Just 2 haskell ghci\u003e :t Just 2 Just 2 :: Num a =\u003e Maybe a Then, can we combine Just (1+) and Just 2 somehow and get Just (1+2) = Just 3? After all, it should be a natural thing to do. You will find that we can‚Äôt directly use fmap to achieve this. The reason is that the fmap can only use a regular unary function a -\u003e b as the mapping function. However, the function now lives in a Functor (that is, Maybe (a -\u003e a) instead of a -\u003e a). If such an operator exists (denoted as magicOperator), we can derive its signature haskell magicOperator :: Maybe (a -\u003e b) -\u003e Maybe a -\u003e Maybe b If we abstract Maybe with a general type constructor f haskell magicOperator :: f (a -\u003e b) -\u003e f a -\u003e f b Congratulations! You just derive the \u003c*\u003e operator in Applicative Functor. Tip Although we can‚Äôt use fmap directly here, we can combine it with pattern matching to achieve the same goal. haskell apply Nothing _ = Nothing apply (Just f) Nothing = Nothing apply (Just f) (Just v) = fmap f (Just v) However, other Functor types don‚Äôt necessarily support extraction using pattern matching like this :( Previously, we only considered the scenario where the mapping function has one argument. Now let‚Äôs consider the scenario with n arguments. Let the mapping function be represented as g, and its type signature is haskell g :: t1 -\u003e t2 -\u003e t3 -\u003e ... -\u003e tn -\u003e t Let‚Äôs assume that we have a bunch of Functors xi, where each xi has the type f ti. Since Haskell functions are all curried, we can start by deriving from fmap g x1 haskell -- Note that -- 1. fmap :: (a -\u003e b) -\u003e f a -\u003e f b -- 2. g :: t1 -\u003e t2 -\u003e t3 -\u003e ... -\u003e tn -\u003e t -- 3. x1 :: f t1 fmap g x1 :: f (t2 -\u003e t3 -\u003e ... -\u003e tn -\u003e t) Let‚Äôs continue to derive the type of fmap g x1 x2. And we will be stuck here because the types just don‚Äôt match! haskell fmap g x1 :: f (t2 -\u003e t3 -\u003e ... -\u003e tn -\u003e t) x2 :: f t2 Apparently, we should use \u003c*\u003e here, and the equation should be like haskell fmap g x1 \u003c*\u003e x2 \u003c*\u003e x3 \u003c*\u003e x4 \u003c*\u003e ... \u003c*\u003e xn -- or, more simpler g \u003c$\u003e x1 \u003c*\u003e x2 \u003c*\u003e x3 \u003c*\u003e x4 \u003c*\u003e ... \u003c*\u003e xn Note Conclusion: We need the Applicative Functor because we need to use \u003c*\u003e to apply a function within a Functor on a value within another Functor. The \u003c*\u003e is kind of function application ","date":"2024-10-20","objectID":"/en/why-applicative-functor/:1:0","series":null,"tags":["Haskell"],"title":"Why Applicative Functor","uri":"/en/why-applicative-functor/#why-applicative-functor"},{"categories":["Programming-Languages"],"content":" What is Applicative Functor Warning In addition to the following definitions, the Applicative Functor should also satisfy Applicative Laws Now we know how \u003c*\u003e works, let‚Äôs see the definition of Applicative Functor. haskell class (Functor f) =\u003e Applicative f where pure :: a -\u003e f a (\u003c*\u003e) :: f (a -\u003e b) -\u003e f a -\u003e f b Let‚Äôs focus on the pure function. The type a -\u003e f a indicates that the pure function just put a value a into the Applicative Functor. The most intuitive application may be putting a function into an Applicative Functor. In the aforementioned example, we have haskell fmap g x1 \u003c*\u003e x2 \u003c*\u003e x3 \u003c*\u003e x4 \u003c*\u003e ... \u003c*\u003e xn -- or, more simpler g \u003c$\u003e x1 \u003c*\u003e x2 \u003c*\u003e x3 \u003c*\u003e x4 \u003c*\u003e ... \u003c*\u003e xn We can use the pure function and rewrite the equation. haskell pure g \u003c*\u003e x1 \u003c*\u003e x2 \u003c*\u003e x3 \u003c*\u003e x4 \u003c*\u003e ... \u003c*\u003e xn The \u003c*\u003e was derived earlier by ourselves, and its meaning is already clear, so we won‚Äôt go into detail here. Let‚Äôs see a concrete example of Applicative Functor. The Maybe type is an Applicative Functor haskell instance Applicative Maybe where pure = Just (Just f) \u003c*\u003e (Just x) = Just (f x) _ \u003c*\u003e _ = Nothing ","date":"2024-10-20","objectID":"/en/why-applicative-functor/:2:0","series":null,"tags":["Haskell"],"title":"Why Applicative Functor","uri":"/en/why-applicative-functor/#what-is-applicative-functor"},{"categories":["Programming-Languages"],"content":" $, \u003c$\u003e, \u003c*\u003eLet‚Äôs compare three similar but different operators that all represent function application haskell ($) :: (a -\u003e b) -\u003e a -\u003e b (\u003c$\u003e) :: Functor f =\u003e (a -\u003e b) -\u003e f a -\u003e f b (\u003c*\u003e) :: Applicative f =\u003e f (a -\u003e b) -\u003e f a -\u003e f b Where ($) is a navie function application, which can apply a regular unary function on a regular value. However, we usually write f x instead of f $ x \u003c$\u003e is the infix form of fmap function, which can apply a regular unary function on a Functor. \u003c*\u003e is the function application operator of Applicative Functor, which can lift a regular unary function into Applicative Functor and apply it on an Applicative Functor ","date":"2024-10-20","objectID":"/en/why-applicative-functor/:3:0","series":null,"tags":["Haskell"],"title":"Why Applicative Functor","uri":"/en/why-applicative-functor/#--"},{"categories":["Programming-Languages"],"content":" Wrap-upThis article discusses why, in addition to Functor, we also need Applicative Functor. In my opinion, the greatest utility of Applicative Functor is that we can easily lift any ordinary function into an Applicative Functor and then use \u003c*\u003e for function application. ","date":"2024-10-20","objectID":"/en/why-applicative-functor/:4:0","series":null,"tags":["Haskell"],"title":"Why Applicative Functor","uri":"/en/why-applicative-functor/#wrap-up"},{"categories":["Vim-Neovim","Git"],"content":"A introduction of using vim-fugitive in Neovim, which summarize the workflows","date":"2024-10-11","objectID":"/en/my-workflow-of-using-vim-fugitive-in-neovim/","series":null,"tags":["Git"],"title":"My workflows of using vim-fugitive in Neovim","uri":"/en/my-workflow-of-using-vim-fugitive-in-neovim/"},{"categories":["Vim-Neovim","Git"],"content":" IntroRecently, while using Git with Neovim, I noticed that my workflow isn‚Äôt as smooth as I‚Äôd like it to be. I tend to exit Neovim, and then type git commands in the terminal. Before committing code changes, I usually check the diff information using delta. To cut down the number of keystrokes, I‚Äôve also enabled the Oh My Zsh‚Äôs git plugin, so I can use a bunch of shortcuts like ga = git add and gcmsg = git commit -m The main reason for the lack of smoothness is I often find myself switching between Neovim and the terminal, like this. flowchart i(Edit code) ---\u003e|Exit Neovim| j(Use git diff to see diff information) ---\u003e k(The code need to re-edit) k ---\u003e|Open Neovim| i That‚Äôs when I recalled vim-fugitive, which had been sitting in my plugin list. I recall its GitHub page saying it‚Äôs ‚Äúso awesome, it should be illegal‚Äù, but I never really looked into it. So after diving into it today, here‚Äôs a summary of the workflow I founded. ","date":"2024-10-11","objectID":"/en/my-workflow-of-using-vim-fugitive-in-neovim/:1:0","series":null,"tags":["Git"],"title":"My workflows of using vim-fugitive in Neovim","uri":"/en/my-workflow-of-using-vim-fugitive-in-neovim/#intro"},{"categories":["Vim-Neovim","Git"],"content":" Workflows","date":"2024-10-11","objectID":"/en/my-workflow-of-using-vim-fugitive-in-neovim/:2:0","series":null,"tags":["Git"],"title":"My workflows of using vim-fugitive in Neovim","uri":"/en/my-workflow-of-using-vim-fugitive-in-neovim/#workflows"},{"categories":["Vim-Neovim","Git"],"content":" PreliminaryMost of the git commands you used in the terminal can be replaced with :Git .... For example, the git blame‚Äôs corresponding command in vim-fugitive is :Git blame. You can shorten :Git to just :G. ","date":"2024-10-11","objectID":"/en/my-workflow-of-using-vim-fugitive-in-neovim/:2:1","series":null,"tags":["Git"],"title":"My workflows of using vim-fugitive in Neovim","uri":"/en/my-workflow-of-using-vim-fugitive-in-neovim/#preliminary"},{"categories":["Vim-Neovim","Git"],"content":" Git statusTo show the status of files in a git repo is quite simple, you just need to use text :G The output should be like text Head: main Merge: origin/main Help: g? Untracked (1) ? foo.py Staged (1) A bar.py Unpushed to origin/main (1) 7c08152 add .gitignore There is a status code before each file. '' unmodified M modified T file type changed A added D deleted R renamed c copied U updated but unmerged ? untracked ! ignored ","date":"2024-10-11","objectID":"/en/my-workflow-of-using-vim-fugitive-in-neovim/:2:2","series":null,"tags":["Git"],"title":"My workflows of using vim-fugitive in Neovim","uri":"/en/my-workflow-of-using-vim-fugitive-in-neovim/#git-status"},{"categories":["Vim-Neovim","Git"],"content":" Git add \u0026 git commitLet‚Äôs use the previous example again. If we want to add foo.py to the staging area, place the cursor over foo.py and press s text Head: main Merge: origin/main Help: g? Untracked (1) ? foo.py Staged (1) A bar.py Unpushed to origin/main (1) 7c08152 add .gitignore The change will be text Head: main Merge: origin/main Help: g? Staged (2) A bar.py A foo.py Unpushed to origin/main (1) 7c08152 add .gitignore To undo the staging process is quite easy and intuitive, just press u Finally, after modifying the file, move the cursor over the file and press cc (Hint: cc = git commit). You will see a buffer pop up and you can edit the commit message. After saving the code changes will be committed. In addition, here are some other commonly used commands ca,ca = git commit --amend ce,ca = git commit --amend --no-edit cw, reword the last commit message Place the cursor over the untracked file, and press I. You will find that the status code of this file becomes A. Essentially, this helps us execute git add --intent-to-add. The benefit of git add --intent-to-add is that now we can see the diff for the untracked files1, which is something regular git add can‚Äôt do. The former corresponds to Changes not staged for commit in git status, while the latter corresponds to Changes to be committed. You can verify this by running git status ","date":"2024-10-11","objectID":"/en/my-workflow-of-using-vim-fugitive-in-neovim/:2:3","series":null,"tags":["Git"],"title":"My workflows of using vim-fugitive in Neovim","uri":"/en/my-workflow-of-using-vim-fugitive-in-neovim/#git-add--git-commit"},{"categories":["Vim-Neovim","Git"],"content":" See Git diffTo see the git diff in the following buffer text Head: main Merge: origin/main Help: g? Staged (2) A bar.py A foo.py Unpushed to origin/main (1) 7c08152 add .gitignore If the code change is small, you may just place the cursor over the target file and press =. And the output will be like Tip Press = again to hide the diff information. text Head: main Merge: origin/main Help: g? Staged (2) A bar.py A foo.py @@ -0,0 +1,2 @@ +def main(): + print(\"Please enter a integer\") Unpushed to origin/main (1) 7c08152 add .gitignore However, usually, your code change will be huge. Then a side-by-side view may be more appropriate. To do this, you just need to replace = with dv Tip Besides viewing the git diff using dv, you can also edit the file content as you with ","date":"2024-10-11","objectID":"/en/my-workflow-of-using-vim-fugitive-in-neovim/:2:4","series":null,"tags":["Git"],"title":"My workflows of using vim-fugitive in Neovim","uri":"/en/my-workflow-of-using-vim-fugitive-in-neovim/#see-git-diff"},{"categories":["Vim-Neovim","Git"],"content":" Git logTo see the git log, just type text :G log The output should be like text commit 23ffed83d3ac5b3b7de37ecb29b55e5cf35b5f65 Author: MartinLwx \u003c*****************\u003e Date: Thu Oct 10 22:07:02 2024 +0800 add bar.py commit 7c081527a2dbadafbaf7907c5b547afc9e725ac9 Author: MartinLwx \u003c*****************\u003e Date: Thu Oct 10 22:05:54 2024 +0800 add .gitignore Place your cursor over the target commit and press o, and the details will be shown in another buffer. Tip Use ]] and [[ to quickly move among commits ","date":"2024-10-11","objectID":"/en/my-workflow-of-using-vim-fugitive-in-neovim/:2:5","series":null,"tags":["Git"],"title":"My workflows of using vim-fugitive in Neovim","uri":"/en/my-workflow-of-using-vim-fugitive-in-neovim/#git-log"},{"categories":["Vim-Neovim","Git"],"content":" Git blameThis may be my favorite feature because it‚Äôs just so convenient and intuitive. The output of :G blame is text 23ffed83 1 (MartinLwx 2024-10-10 22:07:02 +0800 1) def main(): 23ffed83 2 (MartinLwx 2024-10-10 22:07:02 +0800 2) print(\"Please enter a integer\") You can see clearly who should be blamed if a line goes wrong for some reason. What‚Äôs more, we can interact with this buffer. For example, we can press o to see the details of a specific commit. ","date":"2024-10-11","objectID":"/en/my-workflow-of-using-vim-fugitive-in-neovim/:2:6","series":null,"tags":["Git"],"title":"My workflows of using vim-fugitive in Neovim","uri":"/en/my-workflow-of-using-vim-fugitive-in-neovim/#git-blame"},{"categories":["Vim-Neovim","Git"],"content":" Split code change into multiple commitsMany times, after you‚Äôve made multiple code changes, completing several features or bug fixes, you forget to commit along the way. So how do you split different code changes into separate commits? (After all, it‚Äôs a good practice to have one commit to do one thing at a time) Let‚Äôs assume the code of foo.py is python def main(): print(\"Please enter a integer\") And we add the following code changes. All we want to do is split the if, elif, else three cases into three commits. python def main(): i = input(\"Please enter a integer\") if i == 0: print(\"i == 0\") elif i == 1: print(\"i == 1\") else: print(\"i not in [0, 1]\") Place the cursor over foo.py and press = to see the diff information. text Head: main Push: origin/main Help: g? Unstaged (1) M foo.py @@ -1,2 +1,8 @@ def main(): i = input(\"Please enter a integer\") + if i == 0: + print(\"i == 0\") + elif i == 1: + print(\"i == 1\") + else: + print(\"i not in [0, 1]\") Unpushed to * (3) d2d951f add foo.py 23ffed8 add bar.py 7c08152 add .gitignore Now use V to select the following 2 lines. text + if i == 0: + print(\"i == 0\") And then, press s to stage the partial code change text Head: main Push: origin/main Help: g? Unstaged (1) M foo.py @@ -2,3 +2,7 @@ def main(): i = input(\"Please enter a integer\") if i == 0: print(\"i == 0\") + elif i == 1: + print(\"i == 1\") + else: + print(\"i not in [0, 1]\") Staged (1) M foo.py Unpushed to * (3) d2d951f add foo.py 23ffed8 add bar.py 7c08152 add .gitignore Finally, use cc to commit. text Head: main Push: origin/main Help: g? Unstaged (1) M foo.py @@ -2,3 +2,7 @@ def main(): i = input(\"Please enter a integer\") if i == 0: print(\"i == 0\") + elif i == 1: + print(\"i == 1\") + else: + print(\"i not in [0, 1]\") Unpushed to * (4) c46474f add i == 0 d2d951f add foo.py 23ffed8 add bar.py 7c08152 add .gitignore The above output indicates that we have successfully added a new commit c46474f Tip Use ]c and [c to quickly move among different hunk We just need to do this multiple times :) ","date":"2024-10-11","objectID":"/en/my-workflow-of-using-vim-fugitive-in-neovim/:2:7","series":null,"tags":["Git"],"title":"My workflows of using vim-fugitive in Neovim","uri":"/en/my-workflow-of-using-vim-fugitive-in-neovim/#split-code-change-into-multiple-commits"},{"categories":["Vim-Neovim","Git"],"content":" Git rebase -igit rebase -i is another feature I commonly use. Here, we can try to combine the three commits we just split. text 68081e9 add else branch f9dfc93 add i == 1 c46474f add i == 0 First, use :G log to show the commit history text commit 68081e928ad8dbbafc8e20ebefaeb7f3dad968bf Author: MartinLwx \u003c****************\u003e Date: Thu Oct 10 23:10:14 2024 +0800 add else branch commit f9dfc93d9846a3cec6220b0f91b8e4a84dcb9367 Author: MartinLwx \u003c****************\u003e Date: Thu Oct 10 22:57:04 2024 +0800 add i == 1 commit c46474f9cf8c34071fa95f797e94ffc75b1ee3e2 Author: MartinLwx \u003c****************\u003e Date: Thu Oct 10 22:55:03 2024 +0800 add i == 0 And then, place the cursor over the corresponding commit of add i == 0, and press ri (HintÔºöri = rebase -i). Then modify the code as I do text r c46474f add i == 0 s f9dfc93 add i == 1 s 68081e9 add else branch After rebasing, the commit history should be like text Head: main Push: origin/main Help: g? Unpushed to * (4) c814dce merge 3 commits d2d951f add foo.py 23ffed8 add bar.py 7c08152 add .gitignore ","date":"2024-10-11","objectID":"/en/my-workflow-of-using-vim-fugitive-in-neovim/:2:8","series":null,"tags":["Git"],"title":"My workflows of using vim-fugitive in Neovim","uri":"/en/my-workflow-of-using-vim-fugitive-in-neovim/#git-rebase--i"},{"categories":["Vim-Neovim","Git"],"content":" Resolve merge conflictsFinally, let‚Äôs learn how to resolve the merge conflicts when we merge two branches using vim-fugitive. Suppose on another branch called feature, the foo.py file looks like this. text def main(): i = input(\"Please enter a integer\") if i == 0: i = i + 1 else: i = i + 2 We can type the following command in main branch. text :G merge feature Now the output of :G should be like text Head: main Push: origin/main Help: g? Unstaged (1) U foo.py Staged (1) U foo.py Unpushed to * (6) 21055dc add else branch f9dfc93 add i == 1 c46474f add i == 0 d2d951f add foo.py 23ffed8 add bar.py 7c08152 add .gitignore What we need to focus on are the files in Unstaged, which need to be modified to resolve merge conflicts. To make resolving conflicts easier, move the cursor over the file and press dv, and you‚Äôll see the three buffers open. The leftmost buffer contains the code on the main branch The middle buffer contains the conflicting code The rightmost buffer contains the code on the feature branch After resolving the conflicts in the middle buffer, use :Gwrite to save the changes and add the file to the staging area However, sometimes you may just want to use the code from one specific branch. In this case, modifying the conflict in the middle can be cumbersome and pointless. Instead, you can directly move to the left or right buffer (depending on which branch‚Äôs code you want) and use :Gwrite! to save and stage it. In either case, you‚Äôll ultimately need to use cc to commit, and the branch will be successfully merged. text Head: main Push: origin/main Help: g? Unpushed to * (8) d23d66e Merge branch 'feature' 6ad1330 nonsense update 21055dc add else branch f9dfc93 add i == 1 c46474f add i == 0 d2d951f add foo.py 23ffed8 add bar.py 7c08152 add .gitignore ","date":"2024-10-11","objectID":"/en/my-workflow-of-using-vim-fugitive-in-neovim/:2:9","series":null,"tags":["Git"],"title":"My workflows of using vim-fugitive in Neovim","uri":"/en/my-workflow-of-using-vim-fugitive-in-neovim/#resolve-merge-conflicts"},{"categories":["Vim-Neovim","Git"],"content":" Wrap-upThis is the workflow I‚Äôve discovered with vim-fugitive, and I‚Äôve been using it for a while. For me, I‚Äôve found that the previous feeling of discomfort has disappeared. I feel that using Git in Neovim has become much more efficient because I no longer need to frequently switch contexts between Neovim and the Terminal. And frequent context switching will reduce productivity2 https://stackoverflow.com/questions/24329051/what-does-git-add-intent-to-add-or-n-do-and-when-should-it-be-used¬†‚Ü©Ô∏é https://www.software.com/devops-guides/context-switching¬†‚Ü©Ô∏é ","date":"2024-10-11","objectID":"/en/my-workflow-of-using-vim-fugitive-in-neovim/:3:0","series":null,"tags":["Git"],"title":"My workflows of using vim-fugitive in Neovim","uri":"/en/my-workflow-of-using-vim-fugitive-in-neovim/#wrap-up"},{"categories":["Program-Analysis"],"content":"A simple introduction of Tree-sitter, which focus on its Query","date":"2024-09-07","objectID":"/en/tree-sitter-and-its-query/","series":null,"tags":["Compiler","Program-Analysis"],"title":"Tree-sitter and its Query","uri":"/en/tree-sitter-and-its-query/"},{"categories":["Program-Analysis"],"content":" IntroTree-sitter is a parser generator, that is, we can leverage it to generate a specific parser. In addition to that, it also offers other functionality. For example, we can write a Query using S-expression, which will do the pattern matching on the AST. Before we delve into this feature, let‚Äôs talk about some backgrounds ","date":"2024-09-07","objectID":"/en/tree-sitter-and-its-query/:1:0","series":null,"tags":["Compiler","Program-Analysis"],"title":"Tree-sitter and its Query","uri":"/en/tree-sitter-and-its-query/#intro"},{"categories":["Program-Analysis"],"content":" S-expression Info If you once wrote Lisp (or its dialects, such as Scheme and Racket), you should be familiar with the S-expression We can define a S-expression recursively, the definition is A S-expression can be x, where x is an atom A S-expression is not empty and follows the form of (S1 S2 ... Sn), where each Si is a S-expression The definition of a tree in data structure is also recursive, so we can use a S-expression to represent the tree. For example python + / \\ 1 - / \\ 2 3 The AST of 1 + (2 - 3) $\\uparrow$, which has the following S-expression representation. lisp (+ 1 (- 2 3)) In this situation, the first S-expression in () is the parent node, and the others are its children. ","date":"2024-09-07","objectID":"/en/tree-sitter-and-its-query/:2:0","series":null,"tags":["Compiler","Program-Analysis"],"title":"Tree-sitter and its Query","uri":"/en/tree-sitter-and-its-query/#s-expression"},{"categories":["Program-Analysis"],"content":" AST in Tree-sitterThe Tree-sitter supports many programming languages. For each programming language, there is a GitHub repository called tree-sitter-*, where * represents the programming language. For example, Python‚Äôs corresponding GitHub repository is tree-sitter-python. You may find a specific file called grammar.js in such a repository. This file defines the grammar of the programming language. Let‚Äôs take tree-sitter-python for an example, the grammar shows the syntax of for-loop is js for_statement: $ =\u003e seq( optional('async'), 'for', field('left', $._left_hand_side), 'in', field('right', $._expressions), ':', field('body', $._suite), field('alternative', optional($.else_clause)), ), If you have some compiler background, it‚Äôs easy to infer the syntax of for-loop in Python is python [async] for \u003cleft\u003e in \u003cright\u003e: \u003cbody\u003e [\u003celse_clause\u003e] Tip The [] means it‚Äôs optional, and the \u003c\u003e means they can be further expanded. After knowing how the AST is defined, we want to know how to generate an AST for a code snippet using the parser produced by Tree-sitter. We can install tree-sitter in the local machine. If you are using the Mac, you can use homebrew sh $ brew install tree-sitter $ tree-sitter init-config Then, we need to clone the tree-sitter-* GitHub repository we want to use. After cloning this repo, we can run the following commands (take tree-sitter-python for an example) sh $ git clone git@github.com:tree-sitter/tree-sitter-python.git $ tree-sitter generate # generate a parser in src/parser.c Tip If you want to use the tree-sitter CLI tool anywhere, then you need to Use the tree-sitter init-config command to find where the config file is in your OS Open this config file and check the parse-directories attribute Copy your tree-sitter-* GitHub repository to one of the folder Now, in the root directory of tree-sitter-python, we can generate the AST. Before that, let‚Äôs just write a simple Python code snippet. python def sum(x: int, y: int) -\u003e int: return x + y sum(1, 2) Then, we can use the following command to parse this code snippet. The output should be like lisp (module [0, 0] - [5, 0] (function_definition [0, 0] - [1, 16] name: (identifier [0, 4] - [0, 7]) parameters: (parameters [0, 7] - [0, 23] (typed_parameter [0, 8] - [0, 14] (identifier [0, 8] - [0, 9]) type: (type [0, 11] - [0, 14] (identifier [0, 11] - [0, 14]))) (typed_parameter [0, 16] - [0, 22] (identifier [0, 16] - [0, 17]) type: (type [0, 19] - [0, 22] (identifier [0, 19] - [0, 22])))) return_type: (type [0, 27] - [0, 30] (identifier [0, 27] - [0, 30])) body: (block [1, 4] - [1, 16] (return_statement [1, 4] - [1, 16] (binary_operator [1, 11] - [1, 16] left: (identifier [1, 11] - [1, 12]) right: (identifier [1, 15] - [1, 16]))))) (expression_statement [4, 0] - [4, 9] (call [4, 0] - [4, 9] function: (identifier [4, 0] - [4, 3]) arguments: (argument_list [4, 3] - [4, 9] (integer [4, 4] - [4, 5]) (integer [4, 7] - [4, 8]))))) The [x1, y1] - [x2, y2] here denotes the range of the source code for a specific AST node. That is, row x1 to row x2 and column y1 to column y2. Note that the index starts from 0 and it is right exclusive. Tip There is an online Playground on the official website. You can just try it! ","date":"2024-09-07","objectID":"/en/tree-sitter-and-its-query/:3:0","series":null,"tags":["Compiler","Program-Analysis"],"title":"Tree-sitter and its Query","uri":"/en/tree-sitter-and-its-query/#ast-in-tree-sitter"},{"categories":["Program-Analysis"],"content":" Basic Query SyntaxHere comes the main topic of this post. How to find the AST nodes you want to match? Just use the Query feature. The Query is just a S-expression. For example, if we want to find the function definition in Python code, we can write lisp (function_definition) In addition to that, the Tree-sitter also enables us to capture the matched source code and save it in a variable. We just need to put @variable_name after the specific S-expression. lisp (function_definition) @func Tip If you are using the online Playground, you can see the matched source code is highlighted. Tip There are two types of AST nodes in Tree-sitter. The first one is named AST node, and the other one is anonymous AST node. The syntax of named AST nodes is field_name: S-expression. Usually, we want to restrict the matched AST nodes. For example, we want to match an AST node only when it has specific children. We can do this by just adding the field: prefix. The following Query will find Python functions that have type hints for return value. lisp (function_definition return_type: (type)) @has_return_type_func Similarly, we can only match an AST node when it does not have specific children. We just need to add ! before a field. The following Query will find Python functions which does not have type hints for the return value. lisp (function_definition !return_type) @no_return_type_func What about the anonymous AST nodes? We specific the expected string directly without using the (). Let‚Äôs say we want to find binary operations which do addition lisp (binary_operator operator: \"+\") @add_op Tip The anonymous AST nodes won‚Äôt be shown in the AST. Then how can we know how to write the Query? The answer is hidden in the grammar.js file. I referred to these lines when I wrote the above Query. ","date":"2024-09-07","objectID":"/en/tree-sitter-and-its-query/:4:0","series":null,"tags":["Compiler","Program-Analysis"],"title":"Tree-sitter and its Query","uri":"/en/tree-sitter-and-its-query/#basic-query-syntax"},{"categories":["Program-Analysis"],"content":" Advanced Query SyntaxNow let‚Äôs take a step further, the Query supports regex expression natively. All of *, ?, +, [abc] are supported. Just consider the following Python code. python arr1 = [] arr2 = [1] arr3 = [1, 2] We want to extract all the integers within all Python lists. However, the number of integers varies in different lists. That is exactly what * did in regex expression lisp ((integer) (\",\" (integer))*)@int_list Besides, the Query supports the . mark. The functionality will change depending on the location of . If . appears before the first children (denoted by S2), then the S2 must be the first children of the parent node (denoted by S1). If we want to extract all the first elements in all Python lists, we can write lisp (list . (integer) @first_int) If . appears after the last children (denoted by Sn), then the Sn must be the last children of the parent node (denoted by S1). If we want to extract all the last elements in all Python lists, we can write lisp (list (integer) @last_int .) Things get more complicated when the elements within a Python list have different types. For example python arr1 = [] arr2 = [None] arr3 = [1, 2, \"90\"] Now we can not just use (integer) to match the elements. What we need is a special mark that denotes any possibility. That is what _ did in Python code, the Query just borrows it. lisp (list (_) @last_int .) Tip The (_) can match any named AST nodes, and the _ can match both named AST nodes and anonymous AST nodes. ","date":"2024-09-07","objectID":"/en/tree-sitter-and-its-query/:5:0","series":null,"tags":["Compiler","Program-Analysis"],"title":"Tree-sitter and its Query","uri":"/en/tree-sitter-and-its-query/#advanced-query-syntax"},{"categories":["Program-Analysis"],"content":" More Advanced Query SyntaxLet‚Äôs dive deeper into the Query feature. Using @variable_name to capture the matched source code is indeed useful. If we can apply some condition to control if the match is considered legal, it would be much better! Luckily, the Tree-sitter offers this functionality called predicate :) The predicate is also a S-expression, and the syntax is (S1 S2 S3) S1: It can be any of #eq?, #not-eq?, #any-eq?, #any-not-eq?, #match?, #not-match?, #any-match?, #any-not-match?, #any-of?, #not-any-of?. The functionality is indicated by its name. S2: It must be a @variable_name S3: It can be a @variable_name, or a string (for *eq?), a regex expression (for *match?), or candidates (for *-of?). The candidates do not need to be parenthesized. Info The eq? is a function in Lisp and its dialects Now, let‚Äôs use the predicate to extract the last element only when it is a string and it is equal to \"90\". The Query would be like lisp (list (string) @last_str (#eq? @last_str \"90\") .) ","date":"2024-09-07","objectID":"/en/tree-sitter-and-its-query/:6:0","series":null,"tags":["Compiler","Program-Analysis"],"title":"Tree-sitter and its Query","uri":"/en/tree-sitter-and-its-query/#more-advanced-query-syntax"},{"categories":["Program-Analysis"],"content":" BindingsPreviously, we used the CLI command and the online Playground to demonstrate the ideas. Can we use other programming languages to do the same thing? Of course, we can. The Tree-sitter provides us with many programming languages bindings Let‚Äôs use the Python binding. First, we need to install some packages sh $ pip install tree-sitter $ pip install tree-sitter-python Then we can start to write Python code. After generating the Parser, we can exploit the parser to parse Python code. python import tree_sitter_python as tspython from tree_sitter import Language, Parser PY_LANGUAGE = Language(tspython.language()) code = \"\"\"def sum(x: int, y: int) -\u003e int: return x + y sum(1, 2) \"\"\" parser = Parser(PY_LANGUAGE) tree = parser.parse(bytes(code, encoding=\"utf8\")) Now tree is the AST. Let‚Äôs check the root_node (module) to see if the result is right python parser = Parser(PY_LANGUAGE) tree = parser.parse(bytes(code, encoding=\"utf8\")) root_node = tree.root_node print(root_node.type) # module print(root_node.start_point) # Point(row=0, column=0) print(root_node.end_point) # Point(row=5, column=0) We can see from the output that the result is aligned with the previous result lisp (module [0, 0] - [5, 0] ... ;; omit Now we can write a Query, which will extract the function‚Äôs arguments with type hints. python query = PY_LANGUAGE.query( \"\"\"(typed_parameter (identifier)@name type: (type (identifier)@val))\"\"\" ) captures = query.captures(root_node) for arg_name, arg_type in zip(captures[\"name\"], captures[\"val\"]): print(f\"{str(arg_name.text)}: {str(arg_type.text)}\") ","date":"2024-09-07","objectID":"/en/tree-sitter-and-its-query/:7:0","series":null,"tags":["Compiler","Program-Analysis"],"title":"Tree-sitter and its Query","uri":"/en/tree-sitter-and-its-query/#bindings"},{"categories":["Program-Analysis"],"content":" Wrap-upTree-sitter is a powerful parser generator. I use its Query feature heavily to do program analysis. The information extracted from the AST can be further analyzed. Compared to another parse generator (like ANTLR), I prefer Tree-sitter because it is easier to use in my opinion. This may be related to my background, I once learned Scheme and Racket because of my interest. I am quite familiar with writing a S-expression :) ","date":"2024-09-07","objectID":"/en/tree-sitter-and-its-query/:8:0","series":null,"tags":["Compiler","Program-Analysis"],"title":"Tree-sitter and its Query","uri":"/en/tree-sitter-and-its-query/#wrap-up"},{"categories":null,"content":" Who am II am MartinLwx, a machine learning engineer and software engineer with a passion for natural language processing (NLP), software engineering, and programming languages/analysis. The name MartinLwx is a blend of my English name (Martin) and my Chinese name (Weixin Lin). In March 2024, I received my Master‚Äôs degree from College of Computer Science and Technology, Zhejiang University, China. After graduation, I joined a tech company where I continue to work at the intersection of AI4SE (AI for software engineering) and SE4AI (Software engineering for AI), pushing boundaries in both fields. ","date":"2024-09-07","objectID":"/en/about/:1:0","series":null,"tags":null,"title":"About Me","uri":"/en/about/#who-am-i"},{"categories":null,"content":" About this siteThe website was launched in 2021 with the following goals: To dive deep into technical details I am passionate about To learn by teaching and sharing knowledge with others ","date":"2024-09-07","objectID":"/en/about/:2:0","series":null,"tags":null,"title":"About Me","uri":"/en/about/#about-this-site"},{"categories":["Programming-Languages"],"content":"A simple tutorial for dataclass feature proposed in Python 3.7 (syntax and semantics)","date":"2024-08-17","objectID":"/en/learn-to-use-dataclass-in-python/","series":null,"tags":["Python"],"title":"Learn to Use @dataclass in Python","uri":"/en/learn-to-use-dataclass-in-python/"},{"categories":["Programming-Languages"],"content":" IntroI like Python‚Äôs tuple, which allows us to quickly bundle together values of different types as a single entity and manage them in an intuitive and easy-to-use way. However, I find that once the tuple has many fields, I‚Äôm forced to add a comment to indicate the meaning of each field. For example, python t = (3, 4, 3.5) # (x, y, value) Then, I can jump to this definition and check the comment to see each field‚Äôs meaning. But indeed, this brings a lot of inconvenience, once the code becomes longer it‚Äôs not easy to locate that specific line of code. So I would write a class, which allows me to reference a field by name instead of by position. The naive way contains boilerplate template, including __init__, __repr__ , etc. The topic today is dataclass, which saves us from writing such a boilerplate template. Tip To learn a programming language feature, you just need to learn three important questions: What‚Äôs the syntax? What‚Äôs the semantic? What‚Äôs the usage? ","date":"2024-08-17","objectID":"/en/learn-to-use-dataclass-in-python/:1:0","series":null,"tags":["Python"],"title":"Learn to Use @dataclass in Python","uri":"/en/learn-to-use-dataclass-in-python/#intro"},{"categories":["Programming-Languages"],"content":" Syntax python from dataclasses import dataclass @dataclass class Point: x: int y: int value: float = 0.0 The example above defines a Point class, which contains 3 fields: coordinates (x, y) and the corresponding value (the default value is 0). We can draw some conclusions here: The dataclass is a python decorator For instance variables of class, we must add the type hints. The default value is optional. ","date":"2024-08-17","objectID":"/en/learn-to-use-dataclass-in-python/:2:0","series":null,"tags":["Python"],"title":"Learn to Use @dataclass in Python","uri":"/en/learn-to-use-dataclass-in-python/#syntax"},{"categories":["Programming-Languages"],"content":" SemanticSo How could this be helpful? python ... # omitted foo = Point(3, 4, 3.5) # __init__ bar = Point(3, 4, 3.5) # __init__ print(foo) # __repr__ print(foo.x) # named reference print(foo == bar) # __eq__ So, we can clearly see the @dataclass decorator helps us implementing __init__, __repr__, __eq__, and we can reference a specific field by name The @dataclass decorator will add fields with type hints to Class‚Äôs __annotations__ (in the declaration order) python print(Point.__annotations__) # {'x': \u003cclass 'int'\u003e, 'y': \u003cclass 'int'\u003e, 'value': \u003cclass 'float'\u003e} To summarize, the semantics are: The @dataclass decorator will generate some dunder method for us, including __init__, __repr__, __eq__. If you implement these methods by yourself, then your implementation will take precedence. The fields with type hints will become the arguments of generated functions, in the declaration order. Take __init__ as an example, the generated method is as follows: python class Point: ... def __init__(self, x: int, y: int, value: float = 0.0): self.x = x self.y = y self.value = value ","date":"2024-08-17","objectID":"/en/learn-to-use-dataclass-in-python/:3:0","series":null,"tags":["Python"],"title":"Learn to Use @dataclass in Python","uri":"/en/learn-to-use-dataclass-in-python/#semantic"},{"categories":["Programming-Languages"],"content":" Advanced UsageThe aforementioned syntax and semantics are enough for basic usage. However, the dataclass is much more powerful than you might think. It enables us to control the generation behaviors in general, as well as the behavior of each field The @dataclass is a decorator, that is, a kind of special function. We can control the generation behaviors by modifying the parameters. The most important arguments in my opinion are as follows (I also show the default settings) python @dataclass( init=true, # generate __init__ method repr=true, # generate __repr__ method # default format: \u003cclassname\u003e(field1=..., field2=..., ...) eq=true, # compare dataclasses like tuples order=false, # generate __lt/lt/gt/ge__ methods frozen=false, # if true, assigning to fields will generate an exception ) Take order as an example, we wish the Point is comparable: first by comparing the coordinates (x, y) and then by comparing the value python from dataclasses import dataclass @dataclass(order=True) class Point: x: int y: int value: float foo = Point(3, 4, 3.5) # __init__ bar = Point(3, 4, 4.5) # __init__ print(foo \u003c bar) # __eq__ To control each field‚Äôs behavior, we need to use the field in the dataclass library. It also has many arguments, you may refer to the official documentation, I will only talk about some important arguments in my opinion default, default_factory, we use one of the arguments to set the default values. The former directly sets a default value, while the latter specifies a constructor without arguments (For example, list, set, etc.) repr, should we generate the string representation for this field? Let‚Äôs say now we change the value field to values, that is, we want each coordinate to hold a list of values python from dataclasses import dataclass, field @dataclass class Point: x: int y: int value: list[float] = field(default_factory=list) foo = Point(3, 4, [3.5, 4.5, 5.5]) # __init__ print(foo.__annotations__) Finally, let‚Äôs talk about the inheritance scenario. The data class decorated by @dataclass is also a data class, we can inherit another data class as we wish. What if both of them contain fields with the same name? For example python from dataclasses import dataclass @dataclass class A: x: int = 1 y: int = 2 z: int = 5 @dataclass class B(A): x: int = 3 y: int = 4 foo = B() print(foo) # B(x=3, y=4, z=5) It works like this1: Using MRO to decide the visit order, that is, starting from Object class and collecting fields Finally, add the data class‚Äôs fields and merge the result. If multiple fields have the same name, the latter will override the earlier ones. ","date":"2024-08-17","objectID":"/en/learn-to-use-dataclass-in-python/:4:0","series":null,"tags":["Python"],"title":"Learn to Use @dataclass in Python","uri":"/en/learn-to-use-dataclass-in-python/#advanced-usage"},{"categories":["Programming-Languages"],"content":" FAQ","date":"2024-08-17","objectID":"/en/learn-to-use-dataclass-in-python/:5:0","series":null,"tags":["Python"],"title":"Learn to Use @dataclass in Python","uri":"/en/learn-to-use-dataclass-in-python/#faq"},{"categories":["Programming-Languages"],"content":" How to differentiate instance variables and class variables in the data classUse type hints to distinguish between instance variables and class variables, where the type of a class variable is typing.ClassVar python from typing import ClassVar from dataclasses import dataclass, field @dataclass class Point: x: int y: int value: list[float] = field(default_factory=list) a_class_variable: ClassVar[int] = 3 a_point = Point(3, 4) print(Point.a_class_variable) ","date":"2024-08-17","objectID":"/en/learn-to-use-dataclass-in-python/:5:1","series":null,"tags":["Python"],"title":"Learn to Use @dataclass in Python","uri":"/en/learn-to-use-dataclass-in-python/#how-to-differentiate-instance-variables-and-class-variables-in-the-data-class"},{"categories":["Programming-Languages"],"content":" vs namedtuple1 @dataclass collections.namedtuple Different types but have same fields‚Äô value(e.g. Point3D(2017, 6, 2) == Date(2017, 6, 2)) ‚ùå ‚úÖ Set default value for a field ‚úÖ ‚ùå Control each field‚Äôs behavior (__init__, __repr__, etc) ‚úÖ ‚ùå Merge fields by inheritance ‚úÖ ‚ùå ","date":"2024-08-17","objectID":"/en/learn-to-use-dataclass-in-python/:5:2","series":null,"tags":["Python"],"title":"Learn to Use @dataclass in Python","uri":"/en/learn-to-use-dataclass-in-python/#vs-namedtuple"},{"categories":["Programming-Languages"],"content":" Wrap-upPython‚Äôs @dataclass can let‚Äôs use describe a data class in declarative way. We only need to describe each field‚Äôs type, default value, etc. The @dataclass can generate some useful methods automatically for us. The mental model might be: data class = mutable namedtuple with default value üëç ","date":"2024-08-17","objectID":"/en/learn-to-use-dataclass-in-python/:6:0","series":null,"tags":["Python"],"title":"Learn to Use @dataclass in Python","uri":"/en/learn-to-use-dataclass-in-python/#wrap-up"},{"categories":["Programming-Languages"],"content":" Refs PEP 557 ‚Äì Data Classes¬†‚Ü©Ô∏é¬†‚Ü©Ô∏é ","date":"2024-08-17","objectID":"/en/learn-to-use-dataclass-in-python/:7:0","series":null,"tags":["Python"],"title":"Learn to Use @dataclass in Python","uri":"/en/learn-to-use-dataclass-in-python/#refs"},{"categories":["Software-Engineering"],"content":"A tutorial about automating deployment of Hugo blog using GitHub Actions","date":"2024-07-29","objectID":"/en/use-github-actions-to-automate-hugo-build/","series":null,"tags":["CI/CD","GitHub"],"title":"Use Github Actions to automate Hugo blog deployment","uri":"/en/use-github-actions-to-automate-hugo-build/"},{"categories":["Software-Engineering"],"content":" IntroRecently I started learning the GitHub Actions, a feature provided by GitHub that can be used to automate a series of steps. In the process of software development, the most common use of this feature may be the building process. For static-typed programming languages such as C/C++, we are usually required to write the build scripts. The build process involves environment preparation, dependencies download, and build execution. However, automating software builds with GitHub Actions is not the focus of this post. As I was learning this feature, I thought about how I could put it into practice and realized I could use it to automate the build and deployment of my Hugo blog :) ","date":"2024-07-29","objectID":"/en/use-github-actions-to-automate-hugo-build/:1:0","series":null,"tags":["CI/CD","GitHub"],"title":"Use Github Actions to automate Hugo blog deployment","uri":"/en/use-github-actions-to-automate-hugo-build/#intro"},{"categories":["Software-Engineering"],"content":" BackgroundMy Hugo blog uses two Git repositories Public repository: martinlwx.github.io - contains the generated static website. Private repository - Contains the configurations of the Hugo blog and the original posts in Markdown format. In the root folder, there is a ./public subfolder that points to the aforementioned public repo (as a git submodule). The relationship can be illustrated in the following figure: flowchart LR private(\"Private repo\") --\u003e|git push| public(\"Public repo: martinlwx.github.io\") Warning If you don‚Äôt use Algolia, you don‚Äôt need to upload index.json The process of publishing a post involves writing the post, generating the static website using Hugo, and uploading index.json file using atomic-algolia to Algolia. To simplify this process, I wrote a shell script. sh #!/bin/bash echo \"Deploying hugo website...\" # delete all the files in public folder rm -rf public/* # build the website hugo -t DoIt # upload index.json node push_algolia_json.js # deploy the website msg=\"rebuild site on $(date)\" echo \"$msg\" cd public || exit git add . git commit -m \"$msg\" git push # backup private repo cd .. || exit git add . git commit -m \"backup hugo on $(date)\" git push echo \"Git push successfully!\" Then, I can build and deploy my Hugo blog with one single command sh $ bash deploy.sh ","date":"2024-07-29","objectID":"/en/use-github-actions-to-automate-hugo-build/:2:0","series":null,"tags":["CI/CD","GitHub"],"title":"Use Github Actions to automate Hugo blog deployment","uri":"/en/use-github-actions-to-automate-hugo-build/#background"},{"categories":["Software-Engineering"],"content":" The concepts in GitHub ActionsThere are many concepts in GitHub Actions, such as Workflow, Event, Job, Action, and Step. A Workflow can contain one or more Jobs, and each Job consists of multiple Steps. Each Step can run shell commands, execute shell scripts, or run actions. Here, actions can be regarded as pre-written scripts by others, typically used for complex and repetitive operations. By reusing others‚Äô actions, we significantly reduce the effort required to write Workflows. Workflows are usually triggered by pre-set Events, which include git-related events like git push, receiving pull requests, etc. Once triggered, the workflow will start running. The diagram below illustrates this process. timeline Event: push : pull request : ... Job1 : Step 1. Run action : Step 2. Run action : Step 3. Run action : Step 4. Run action : ... Job2: Step 1. Run action : Step 2. Run action : Step 3. Run action : Step 4. Run action : ... The workflow can be described as a YAML file, which will be managed with other files in our git repo. The detailed syntax can be found on this official page ","date":"2024-07-29","objectID":"/en/use-github-actions-to-automate-hugo-build/:3:0","series":null,"tags":["CI/CD","GitHub"],"title":"Use Github Actions to automate Hugo blog deployment","uri":"/en/use-github-actions-to-automate-hugo-build/#the-concepts-in-github-actions"},{"categories":["Software-Engineering"],"content":" Writing a YAML file Info I assume that you have a basic understanding of GitHub Actions syntax, as this is not the focus of this article :) Now, I will try to convert the aforementioned shell script into a YAML file (named build_and_deploy.yaml) yaml name: hugo-deploy on: push: branches: - master jobs: build-and-deploy: runs-on: ubuntu-latest steps: - name: Check out this repo uses: actions/checkout@v4 with: submodules: 'recursive' fetch-depth: 0 - name: Install Hugo CLI uses: peaceiris/actions-hugo@v3 with: hugo-version: 'latest' extended: true - name: Install node.js uses: actions/setup-node@v4 with: node-version: 'latest' - name: Install atomic-algolia run: npm install atomic-algolia - name: Build the website with the DoIt theme run: hugo -t DoIt - name: Upload index.json for search run: node push_algolia_json.js - name: Deploy uses: peaceiris/actions-gh-pages@v4 with: deploy_key: ${{ secrets.HUGO_PRIVATE_KEY }} external_repository: Martinlwx/martinlwx.github.io publish_branch: main publish_dir: ./public The actions/checkout action can be used to clone our git repository and its submodules. In my private repo, I have 2 git repositories: DoIt, my Hugo theme public ‰ªìÂ∫ì We need to clone the git submodules recursively, which is why we use the submodules: true setting. Additionally, the fetch-depth: 0 setting ensures that all commits are cloned during the process. The next step is installing Hugo itself. Although the official Hugo document provides a detailed implementation, I found it somewhat cumbersome. So I did some research and found actions-hugo, which can download Hugo for us and is easy to use. I set hugo-version: 'latest' to ensure it always uses the latest Hugo. Since DoIt use features like admonition, we also need to set extended: true, which means using the extended version of Hugo. Warning If you don‚Äôt use Algolia, you don‚Äôt need to install node.js, install atomic-algolia, and upload index.json The installation of node.js is similar. We can just leverage the actions written by others. After installing node.js, we can use npm to install atomic-algolia Before uploading the index.json file, we need to ensure that the index.json is up-to-date. So, we run hugo -t DoIt first Now we can run node push_algolia_json.js. If you are curious about how to write push_algolia_json.js, you can check atomic-algolia Finally, we come to the most complex part - deploying the Hugo Blog. The author of actions-hugo also offers another action called actions-gh-pages to simplify the deployment. However, the complexity arises from the repositories themselves. As mentioned earlier, I have 2 repositories. I first build the Hugo Blog in the private repository and then deploy it to the public repository. According to the README.md in actions-gh-pages, we need to set the external_repository attribute, which points to the public repository. Because this action involves two repositories, we also need to set deploy_key, which means we need to generate a paired ssh-key. The following diagram illustrates this idea. flowchart LR private(\"` Private repo (use the *private* ssh-key as a *secret*) `\") --\u003e|peaceiris/actions-gh-pages@v4| public(\"` Public repo (use the *public* ssh-key as a *deploy key*) `\") First, let‚Äôs generate paired ssh-key by the following command sh # replace with your email here. $ ssh-keygen -t ed25519 -C martinlwx@163.com -f \"hugo\" In the current directory, you will see there are hugo and hugo.pub files Open the public repository, click Settings -\u003e Deploy keys -\u003e Add deploey key, and copy and paste the content of hugo.pub. Note that you should enable Allow Write Access. Open the private repository, click Settings -\u003e Secrets and variables -\u003e Actions -\u003e Manage repository secret, and copy and paste the content of hugo. Remember the title you set because we will need to reference it in the ${{ secrets.xxx }}. I set the title to HUGO_PRIVATE_KEY, so I can use ${{ secrets.HUGO_PRIVATE_KEY }} in the deploy_key. The remaining configurations I","date":"2024-07-29","objectID":"/en/use-github-actions-to-automate-hugo-build/:4:0","series":null,"tags":["CI/CD","GitHub"],"title":"Use Github Actions to automate Hugo blog deployment","uri":"/en/use-github-actions-to-automate-hugo-build/#writing-a-yaml-file"},{"categories":["Software-Engineering"],"content":" Wrap-upAfter setting up the pipeline, I realized my workload seemed to have increased. What used to be done with just bash deploy.sh now requires me to manually git add and git commit‚Äîthough this is partly because the previous commit messages were generated by a command. Nonetheless, I‚Äôve learned how to use GitHub Actions, and automating the deployment of my Hugo blog has been an interesting CI/CD practice. I hope this article helps you, the reader, in some way :) ","date":"2024-07-29","objectID":"/en/use-github-actions-to-automate-hugo-build/:5:0","series":null,"tags":["CI/CD","GitHub"],"title":"Use Github Actions to automate Hugo blog deployment","uri":"/en/use-github-actions-to-automate-hugo-build/#wrap-up"},{"categories":["Programming-Languages"],"content":"A simple introduction of tail call and tail call optimization","date":"2024-03-22","objectID":"/en/tail-call-and-tail-call-optimization/","series":null,"tags":["OCaml","Programming-Languages","Performance-Engineering"],"title":"Tail call and Tail-call Optimization (TCO)","uri":"/en/tail-call-and-tail-call-optimization/"},{"categories":["Programming-Languages"],"content":" Tail call \u0026 Tail-recursionAssume that function A calls function B. We call function A Caller and function B Callee. The tail call refers to when the Caller only needs to wait for the return value of the Callee, as everything else has already been completed1. If this is a recursive function call(e.g. the Caller and Callee are the same function), then the function is said to be tail-recursive. ","date":"2024-03-22","objectID":"/en/tail-call-and-tail-call-optimization/:1:0","series":null,"tags":["OCaml","Programming-Languages","Performance-Engineering"],"title":"Tail call and Tail-call Optimization (TCO)","uri":"/en/tail-call-and-tail-call-optimization/#tail-call--tail-recursion"},{"categories":["Programming-Languages"],"content":" Tail-call Optimization (TCO)According to the mechanism of the function call, a stack frame will be created to store some useful information such as the return address. What if the function call is a tail-call? Could you find any optimization chance? By the definition of tail call, we know that the Caller has done everything and just needs to keep waiting. Most of the information of the Caller is no longer needed. Then we can reuse the stack frame of the Caller instead of creating a new one. That‚Äôs exactly what the tail call optimization (TCO) does2 The benefit of TCO is that the overhead of creating new stack frames is avoided. We can safely use tail-recursion without worrying about the famous stack overflow issue, as long as the programming language supports TCO, and it‚Äôs enabled. ","date":"2024-03-22","objectID":"/en/tail-call-and-tail-call-optimization/:1:1","series":null,"tags":["OCaml","Programming-Languages","Performance-Engineering"],"title":"Tail call and Tail-call Optimization (TCO)","uri":"/en/tail-call-and-tail-call-optimization/#tail-call-optimization-tco"},{"categories":["Programming-Languages"],"content":" Make recursion tail-recursion Info I use OCaml to demonstrate the ideas because it supports TCO. To get the benefits of TCO, we need to learn how to rewrite any naive recursion function to a tail-recursion. One of the popular ways is the accumulator pattern. Steps to follow3 Create a helper function which usually has two parameters The data to be processed The accumulated value The base case of the helper function is: returning the accumulated value The base case of the original recursive function changes to calling the helper function Let‚Äôs use a classic recursive function which calculates the factorial as an example. First, create a new project with dune sh $ dune init project tco Then we can easily write a naive recursive function in ./tco/bin/main.ml` as follows ocaml let rec factorial n = match n with 0 | 1 -\u003e 1 | n -\u003e n * factorial (n - 1) It‚Äôs obvious that this function is not tail-recursive. The reason is that we still need to multiply the return value of factorial (n - 1) by n. Now we can rewrite this function to a tail-recursive function using the accumulator pattern. ocaml let factorial_tco n = let rec helper cur acc = match cur with | 0 | 1 -\u003e acc (* Return the accumulated value *) | cur -\u003e (helper [@tailcall]) (cur - 1) (acc * cur) in helper n 1 (* Call the helper function *) Tip We can use the [@tailcall] annotation to ensure a function call is a tail call, otherwise, the compiler will throw a warning. To benchmark the two implementations, we can use the core_bench tool. Let‚Äôs first install the required packages sh $ opam install core_bench After the installation, we need to change the configuration file ./tco/bin/dune lisp (executable (public_name tco) (name main) (libraries tco core core_bench core_unix.command_unix)) Now, we can add the performance testing code in ./tco/bin/main.ml as follows ocaml open Core open Core_bench let rec factorial n = match n with | 0 | 1 -\u003e 1 | n -\u003e n * factorial (n - 1) let factorial_tco n = let rec helper cur acc = match cur with | 0 | 1 -\u003e acc | cur -\u003e (helper [@tailcall]) (cur - 1) (acc * cur) in helper n 1 (* Benchmark *) let bench () = Bench.make_command [ Bench.Test.create ~name:\"factorial\" (fun () -\u003e factorial 10000); Bench.Test.create ~name:\"factorial_tco\" (fun () -\u003e factorial_tco 10000); ] |\u003e Command_unix.run let _ = bench () Build then run sh $ dune build $ dune exec tco The output of performance testing in my MacBook M3 Air is: text Estimated testing time 20s (2 benchmarks x 10s). Change using '-quota'. ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ Name ‚îÇ Time/Run ‚îÇ Percentage ‚îÇ ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îÇ factorial ‚îÇ 40.42us ‚îÇ 100.00% ‚îÇ ‚îÇ factorial_tco ‚îÇ 10.06us ‚îÇ 24.90% ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò The performance gain of TCO is quite impressive üöÄ Warning The exact values of the output may vary depending on the hardware. However, the performance gain should be obvious. The deeper the recursion is, the more performance you will gain. You can change the 10000 to other values to explore the differences. ","date":"2024-03-22","objectID":"/en/tail-call-and-tail-call-optimization/:2:0","series":null,"tags":["OCaml","Programming-Languages","Performance-Engineering"],"title":"Tail call and Tail-call Optimization (TCO)","uri":"/en/tail-call-and-tail-call-optimization/#make-recursion-tail-recursion"},{"categories":["Programming-Languages"],"content":" Wrap-upIn my opinion, the TCO stores the accumulated value in a specific parameter which avoids the overhead of creating new stack frames. We gain the performance boost but lose the beauty of recursion. I would suggest that only try to rewrite recursive functions to tail-recursive functions as needed. ","date":"2024-03-22","objectID":"/en/tail-call-and-tail-call-optimization/:3:0","series":null,"tags":["OCaml","Programming-Languages","Performance-Engineering"],"title":"Tail call and Tail-call Optimization (TCO)","uri":"/en/tail-call-and-tail-call-optimization/#wrap-up"},{"categories":["Programming-Languages"],"content":" Refs Tail Recursion | Coursera¬†‚Ü©Ô∏é Accumulators for Tail Recursion | Coursera¬†‚Ü©Ô∏é Perspective on Tail Recursion | Coursera¬†‚Ü©Ô∏é ","date":"2024-03-22","objectID":"/en/tail-call-and-tail-call-optimization/:4:0","series":null,"tags":["OCaml","Programming-Languages","Performance-Engineering"],"title":"Tail call and Tail-call Optimization (TCO)","uri":"/en/tail-call-and-tail-call-optimization/#refs"},{"categories":["Vim-Neovim"],"content":"Learn to use text-object in vim/neovim","date":"2024-03-03","objectID":"/en/learn-to-use-text-objects-in-vim/","series":null,"tags":["Vim-Neovim"],"title":"Learn to use text-object in Vim\u0026Neovim","uri":"/en/learn-to-use-text-objects-in-vim/"},{"categories":["Vim-Neovim"],"content":" IntroYou probably do not know what the text-object is in Vim/Neovim. However, you may use it in your daily life. For instance, When you are writing code, you may want to change the arguments of a function. Take the following code as an example, let‚Äôs say you want to change the function call to bar(3, 2, 1), and the cursor currently stays on the , python def foo(): ... res = bar(1, 2, 3) # ^ # The position of your cursor(on `,`) ... How will you achieve this goal? If you are familiar with Vim/Neovim, you will likely instinctively type ci) or ci(, and then you can quickly type in the new arguments. The i( or i) here are so-called text-object. Warning Bad practice: Use F( to jump to previous ( and then use x to delete char one by one ","date":"2024-03-03","objectID":"/en/learn-to-use-text-objects-in-vim/:1:0","series":null,"tags":["Vim-Neovim"],"title":"Learn to use text-object in Vim\u0026Neovim","uri":"/en/learn-to-use-text-objects-in-vim/#intro"},{"categories":["Vim-Neovim"],"content":" Built-in text-object Tip Check :h text-objects for more information Simply put, text-object is a textual entity corresponding to a certain area of text, and this area of text contains structure within it. Therefore, they can be treated as a single text-object, which brings convenience to many operations. The built-in text-object is represented as two-letter combinations: The first letter is either i or a i refers to text-object itself, and a also contains the next/previous whitespace or paired symbols(e.g. {}, (), ...) Mnemonic: i = (i)nside, a = (a)round The second letter has two possibilities One of the paired symbols Paired symbols: {}, (), [], '', \"\", \u003ctag\u003e\u003c/tag\u003e. Note that \u003ctag\u003e\u003c/tag\u003e is represented as t. For example, if you want to delete the foobar in \u003ctag\u003efoobar\u003c/tag\u003e, you can put the cursor within the tag and type dit e.g. a{ = (around) {, it contains all the text within {}(inclusive) (w)ord, (s)entences, (p)aragraphs Each one of them can be used with i or a - iw, aw, is, as, ip, ap ","date":"2024-03-03","objectID":"/en/learn-to-use-text-objects-in-vim/:2:0","series":null,"tags":["Vim-Neovim"],"title":"Learn to use text-object in Vim\u0026Neovim","uri":"/en/learn-to-use-text-objects-in-vim/#built-in-text-object"},{"categories":["Vim-Neovim"],"content":" Syntax-aware text-objectPreviously, we mentioned that the text-object is structured in some way. It reminds me of the code, which is highly structured text. Occasionally, we want to delete the entire function body and rewrite it. If the function body is enclosed in {}, then typically we can use ci{ to accomplish this task. However, care must be taken regarding the cursor‚Äôs position to ensure the {} of the function body is closet to the cursor, which can be somewhat annoying. Example The function body in Rust is enclosed in {}. To delete the entire function body and rewrite it, we can place the cursor on the i in if, and then type ci{ rust fn fib(n: i32) -\u003e i32 { // The position of your cursor(on `i`) // v if n == 1 || n == 2 { 1 } else { fib(n - 1) + fib(n-2) } } But what if the function body is not enclosed in {}? For example, the Python code uses indentation to recognize the function body. python def fib(n: int): if n == 1 or n == 2: return 1 return fib(n - 1) + fib(n - 2) Is there a special text-object that corresponds to the function body considering that the code is highly structured? That is what the magic plugin - nvim-treesitter-textobjects does for us. By analyzing the syntax of code, it defines various text-object such as functions, classes, loops, etc. Warning Check my commit to see the changes and how I organize my configuration files. Your file structure may not be the same, but you get the idea :) If you also use lazy.nvim, put the followinglines in your plugin list. lua require(\"lazy\").setup({ ... { \"nvim-treesitter/nvim-treesitter-textobjects\", dependencies = \"nvim-treesitter/nvim-treesitter\", config = function() require(\"config.nvim-treesitter-textobjects\") end, }, ... }) Create a new file nvim-treesitter-textobjects.lua and edit(Most of the code has been omitted by me, the complete file is located here): lua local is_ok, configs = pcall(require, \"nvim-treesitter.configs\") if not is_ok then return end configs.setup({ textobjects = { select = { ... keymaps = { -- outer: outer part -- inner: inner part [\"af\"] = \"@function.outer\", [\"if\"] = \"@function.inner\", [\"ac\"] = \"@class.outer\", [\"ic\"] = \"@class.inner\", [\"al\"] = \"@loop.outer\", [\"il\"] = \"@loop.inner\", }, include_surrounding_whitespace = true, }, }, ... }) Based on my personal needs, I add 6 text-object(af, if, ac, ic, al, il) to operate on function, class, and loop. You can find syntax-aware text-object in the official README.md file. Now we can use dif to delete the entire function body in any position within the function body :) ","date":"2024-03-03","objectID":"/en/learn-to-use-text-objects-in-vim/:3:0","series":null,"tags":["Vim-Neovim"],"title":"Learn to use text-object in Vim\u0026Neovim","uri":"/en/learn-to-use-text-objects-in-vim/#syntax-aware-text-object"},{"categories":["Vim-Neovim"],"content":" Wrap-upThe text-object organizes the text into objects, allowing us to operate them conveniently. With the help of nvim-treesitter-textobjects, we can operate on various programming language constructsüç∫ ","date":"2024-03-03","objectID":"/en/learn-to-use-text-objects-in-vim/:4:0","series":null,"tags":["Vim-Neovim"],"title":"Learn to use text-object in Vim\u0026Neovim","uri":"/en/learn-to-use-text-objects-in-vim/#wrap-up"},{"categories":["Vim-Neovim"],"content":"Neovim Setup for OCaml","date":"2024-01-23","objectID":"/en/neovim-setup-for-ocaml/","series":null,"tags":["Vim-Neovim","OCaml"],"title":"Neovim Setup for OCaml","uri":"/en/neovim-setup-for-ocaml/"},{"categories":["Vim-Neovim"],"content":" Info Updates: 2024-09-14. If an LSP contains a Formatter, then we don‚Äôt need to install the corresponding Formatter on our own. ","date":"2024-01-23","objectID":"/en/neovim-setup-for-ocaml/:0:0","series":null,"tags":["Vim-Neovim","OCaml"],"title":"Neovim Setup for OCaml","uri":"/en/neovim-setup-for-ocaml/#"},{"categories":["Vim-Neovim"],"content":" IntroIn previous post, I elaborated on how to set up Neovim from scratch. However, I didn‚Äôt answer the following questions: What if an LSP does not support formatting, how to configure Neovim to support a third-party code formatting tool? How to change configuration files when adding a new programming language? Recently I was learning OCaml, I thought it would be a good chance to answer the questions. Info I assume you have already read my previous post, so I will omit some details here. ","date":"2024-01-23","objectID":"/en/neovim-setup-for-ocaml/:1:0","series":null,"tags":["Vim-Neovim","OCaml"],"title":"Neovim Setup for OCaml","uri":"/en/neovim-setup-for-ocaml/#intro"},{"categories":["Vim-Neovim"],"content":" Install OCaml Info If you are not using a Mac, you may refer to the official instructions for more details. It is quite handy to install OCaml on a Mac with Homebrew. sh $ brew install opam According to the output of Homebrew, we need to perform additional configurations and modify ~/.zshrc(for Zsh users) or ~/.bashrc(for Bash users). sh $ opam init # press `y` to confirm To make the modifications work, run the following command in your terminal sh $ source ~/.zshrc # $ source ~/.bashrc # if you use bash Finally, we can use this command to check if everything goes right sh $ opam switch The output will be like text # switch compiler description -\u003e 5.0.0 ocaml-base-compiler.5.0.0 5.0.0 default ocaml.4.14.0 default Similar to IPython for Python, the OCaml offers a REPL tool called utop. We can install this to practice programming OCaml sh $ opam install utop dune Just try the utop REPL yourself :) sh $ utop The output would be like text ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ Welcome to utop version 2.13.1 (using OCaml version 5.0.0)! ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò Type #utop_help for help about using utop. ‚îÄ( 10:33:26 )‚îÄ\u003c command 0 \u003e‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ{ counter: 0 }‚îÄ utop # ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇAfl_instrument‚îÇAlias_analysis‚îÇAllocated_const‚îÇAnnot‚îÇApplicative‚îÇArch‚îÇArg‚îÇArg_helper‚îÇArray‚îÇArrayLabels‚îÇAsmgen‚îÇAsmlibrarian‚îÇAsmlink‚îÇAsmpackager‚îÇAssert_failure‚îÇAst_helper‚îÇAst_inva‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ","date":"2024-01-23","objectID":"/en/neovim-setup-for-ocaml/:2:0","series":null,"tags":["Vim-Neovim","OCaml"],"title":"Neovim Setup for OCaml","uri":"/en/neovim-setup-for-ocaml/#install-ocaml"},{"categories":["Vim-Neovim"],"content":" OCaml LSP configurations Info If you follow my previous post, then the file hierarch of your setup will be like text nvim ‚îú‚îÄ‚îÄ init.lua ‚îî‚îÄ‚îÄ lua ‚îú‚îÄ‚îÄ colorscheme.lua ‚îú‚îÄ‚îÄ config ‚îÇ¬†‚îî‚îÄ‚îÄ nvim-cmp.lua ‚îú‚îÄ‚îÄ keymaps.lua ‚îú‚îÄ‚îÄ lsp.lua ‚îú‚îÄ‚îÄ options.lua ‚îî‚îÄ‚îÄ plugins.lua Previously, we leveraged mason.nvim to set up LSPs. To add a new LSP for a specific programming language, we can also use this. Steps to follow: Open Neovim and type :Mason, found ocaml-lsp in the (2) LSP section. Press i when the cursor stays on the line. Open the configurations file for LSP(lsp.lua in my configurations), add the following lua code lua ... -- rest of the configurations lspconfig.ocamllsp.setup({ on_attach = on_attach, }) Warning You may have your configuration files and do not follow my previous post. So adding the aforementioned Lua code may not work for you. However, you can check the full configuration here to understand how it works and adapt to your configurations. After modifying lsp.lua, we can restart Neovim to make the configurations take effect. Warning Similar to rust-analyzer, we can only use ocaml-lsp in a project but not a single file. Now you can create a new dune project to see if LSP works. ","date":"2024-01-23","objectID":"/en/neovim-setup-for-ocaml/:3:0","series":null,"tags":["Vim-Neovim","OCaml"],"title":"Neovim Setup for OCaml","uri":"/en/neovim-setup-for-ocaml/#ocaml-lsp-configurations"},{"categories":["Vim-Neovim"],"content":" OCaml Formatter configurationsThe ocaml-lsp LSP does not support formatting OCaml code. If you try to format an OCaml code, you will get an error message: text [LSP] Format request failed, no matching language servers. Now, I will talk about how to set up a formatter for OCaml. You may have noticed that the Mason tool also offers Linter and Formatter. The formatter for OCaml is ocamlformat. So We can install it just like we install an LSP. However, ocamlformat is a CLI tool which can not be integrated into Neovim. Luckily, we have none-ls plugin, which can expose linter, formatter, and other CLI tools as LSP for Neovim. Info none-ls.nvim is maintained by the community because its predecessor null-ls.nvim has been archived To make it easier, we can use the mason-null-ls.nvim plugin, developed by the same author of mason.nvim. Open plugins.lua file and append these Lua codes. After saving the changes and restarting Neovim you should see lazy.nvim is installing these plugins. lua ... -- rest of the configurations require(\"lazy\").setup({ -- Add hooks to LSP to support Linter \u0026\u0026 Formatter { \"jay-babu/mason-null-ls.nvim\", event = { \"BufReadPre\", \"BufNewFile\" }, dependencies = { \"williamboman/mason.nvim\", \"nvimtools/none-ls.nvim\", }, config = function() -- Note: -- the default search path for `require` is ~/.config/nvim/lua -- use a `.` as a path seperator -- the suffix `.lua` is not needed require(\"config.mason-null-ls\") end, }, ... -- rest of the configurations }) Then, create a new file called mason-null-ls.lua in config folder and put the following code lua local mason_ok, mason = pcall(require, \"mason\") if not mason_ok then return end local null_ls_ok, null_ls = pcall(require, \"null-ls\") if not null_ls_ok then return end local mason_null_ls_ok, mason_null_ls = pcall(require, \"mason-null-ls\") if not mason_null_ls_ok then return end mason.setup() mason_null_ls.setup({ -- A list of sources to install if they're not already installed. -- This setting has no relation with the `automatic_installation` setting. ensure_installed = {}, -- Run `require(\"null-ls\").setup`. -- Will automatically install masons tools based on selected sources in `null-ls`. -- Can also be an exclusion list. -- Example: `automatic_installation = { exclude = { \"rust_analyzer\", \"solargraph\" } }` automatic_installation = false, -- Sources found installed in mason will automatically be set up for null-ls. automatic_setup = true, handlers = { -- Hint: see https://github.com/nvimtools/none-ls.nvim/blob/main/doc/BUILTIN_CONFIG.md -- to see what sources are available -- Hint: see https://github.com/jose-elias-alvarez/null-ls.nvim/blob/main/doc/BUILTIN_CONFIG.md -- to check what we can configure for each source ocamlformat = function(source_name, methods) null_ls.register(null_ls.builtins.formatting.ocamlformat.with({ -- Add more arguments to a source's defaults -- Default: { \"--enable-outside-detected-project\", \"--name\", \"$FILENAME\", \"-\" } -- Type `ocamlformat --help` in your terminal to check more args extra_args = { \"--if-then-else\", \"vertical\" }, })) end, }, }) null_ls.setup() Tip When you set automatic_setup = true, the mason-null-ls will help you configure the installed formatter automatically. If you want to configure a specific formatter, you should make some changes in handlers. FAQsÔºö How to find the default configurations of a formatter? See here How to configure handlers? See here How to know other configurations of a formatter? See the official formatter page. For example, In the README file of the ocamlformat, it says we can type ocamlformat --help to see more options. Finally, we also need to change the lsp.lua file. The original liens related to code formmating looks like this: lua ... -- rest of the configurations vim.keymap.set(\"n\", \"\u003cspace\u003ef\", function() vim.lsp.buf.format({ async = true }) end, bufopts) ... -- rest of the configurations Now we are using none-ls to do formatting. So we need to set the filter argument as follows lua ... -- rest of the ","date":"2024-01-23","objectID":"/en/neovim-setup-for-ocaml/:4:0","series":null,"tags":["Vim-Neovim","OCaml"],"title":"Neovim Setup for OCaml","uri":"/en/neovim-setup-for-ocaml/#ocaml-formatter-configurations"},{"categories":["Vim-Neovim"],"content":" Wrap-upNow let‚Äôs summarize how to set up Neovim for a new programming language. If you also use mason.nvim, mason-lspconfig, none-ls.nvim and mason-null-ls.nvim, you can follow the instructions to setup: Read the official pages and install the programming language‚Äôs environment on your machine. Open Neovim, type :Mason, and install the corresponding LSP. Refer to the official LSP pages and check if the LSP contains a built-in Formatter. If the answer is no, just use :Mason to install one. Open the lsp.lua file and configure LSP If you install Formatter by yourself, open the mason-null-ls.lua file to configure handlers For things that are not clearly stated in this post, you can view my dotfiles configurations repo to learn more information. ","date":"2024-01-23","objectID":"/en/neovim-setup-for-ocaml/:5:0","series":null,"tags":["Vim-Neovim","OCaml"],"title":"Neovim Setup for OCaml","uri":"/en/neovim-setup-for-ocaml/#wrap-up"},{"categories":["ML-DL"],"content":"A simple introduction to the KV Cache used in the LLM inference optimization","date":"2023-10-12","objectID":"/en/llm-inference-optimization-kv-cache/","series":null,"tags":["NLP","Deep-Learning"],"title":"LLM inference optimization - KV Cache","uri":"/en/llm-inference-optimization-kv-cache/"},{"categories":["ML-DL"],"content":" BackgroundThe secret behind LLM is that it will generate tokens one by one based on all the previous tokens. Let‚Äôs assume that we have already generated $t$ tokens, denoted by $x_{1:t}$. In the next iteration, the LLM will generate $x_{1:t+1}$. Note that the first $t$ tokens are the same. $$x_{1:t+1}=\\text{LLM}(x_{1:t})$$ The next iteration is similar. $$x_{1:t+2}=\\text{LLM}(x_{1:t+1})$$ In summary, in each iteration, we will use the output of the previous round as a new input for the LLM. Generally, this process will continue until the output reaches the maximum length we predefined or the LLM itself generates a special token, signifying the completion of the generating process. ","date":"2023-10-12","objectID":"/en/llm-inference-optimization-kv-cache/:1:0","series":null,"tags":["NLP","Deep-Learning"],"title":"LLM inference optimization - KV Cache","uri":"/en/llm-inference-optimization-kv-cache/#background"},{"categories":["ML-DL"],"content":" Demystify the KV Cache The inference process of the LLM is easy to understand, but this simple implementation has a drawback - there is significant amount of redundant computationüßê Simply overserving two consecutive inference calculations is sufficient to understand why the redundant computations are present For example $$ x_{1:t+1}=\\text{LLM}(x_{1:t}) $$ The input of the LLM is $x_{1:t}$. Let‚Äôs focus on the last token $x_t$, whose query vector will undergo dot product computation with the key vectors generated by each of the preceding tokens, including itself. $$\\mathbf q_{t}^T\\mathbf k_{1},\\mathbf q_{t}^T\\mathbf k_{2},‚Ä¶,\\mathbf q_{t}^T\\mathbf k_{t}$$ The next step is $$ x_{1:t+2}=\\text{LLM}(x_{1:t+1}) $$ The input of the LLM is $x_{1:t+1}$. The last token $x_{t+1}$ will also undergo dot product computation with the key vectors generated by each of the preceding tokens, including itself. $$\\mathbf q_{t+1}^T\\mathbf k_{1},\\mathbf q_{t+1}^T\\mathbf k_{2},‚Ä¶,\\mathbf q_{t+1}^T\\mathbf k_{t+1}$$ What about the $x_t$ token? $$\\mathbf q_{t}^T\\mathbf k_{1},\\mathbf q_{t}^T\\mathbf k_{2},‚Ä¶,\\mathbf q_{t}^T\\mathbf k_{t}$$ We can see that the computations are redundant compared to the previous round. The same logic applies to tokens before $x_t$. We need to recalculate all the key vectors and value vectors for $x_{1:t}$, even though the values of these vectors actually remain unchangedüßê. ü§î What if we cached all the key vectors and value vectors for all preceding tokens? We won‚Äôt need to compute these again and again. That‚Äôs what exactly the KV Cache does. After applying the KV Cache, in each round except the first one, we only need to focus on the last input token. We will compute its query, key, and value vectors and use these 3 new vectors to perform a self-attention operation with all the cached key/value vectors of preceding tokens. I drew a simple picture to show what happened we when used the KV Cache to speed up the inference process. Consider that the LLM generates 4 tokens starting from scratch, where the blue part represents the values that are cached, and the red part indicates what‚Äôs not cached ","date":"2023-10-12","objectID":"/en/llm-inference-optimization-kv-cache/:2:0","series":null,"tags":["NLP","Deep-Learning"],"title":"LLM inference optimization - KV Cache","uri":"/en/llm-inference-optimization-kv-cache/#demystify-the-kv-cache"},{"categories":["ML-DL"],"content":" The performance of the KV CacheThe principle behind accelerating inference with the KV Cache is as follows: in the self-attention layer, instead of performing the matrix multiplication $\\mathbf Q\\mathbf K^T$ in each iteration, we only need to perform vector-matrix multiplication between the query vector $\\mathbf q$ of the last token of each input and $\\mathbf K$, and then we update the KV Cache. Incorporating the KV Cache allows the inference process of LLM to be viewed as two stages In the first iteration, the KV Cache is empty, so we need to compute all the key, query, and value vectors for these tokens, and we will cache the key/value vectors. For every subsequent iteration, you only need to compute the key, query, and value vector for the new token and update the KV Cache. Then, what‚Äôs the price of the KV Cache? The main cost is that it will increase the GPU memory usage. You can find a memory usage comparison of enabling or disabling the KV Cache here. I will put some summarization below. Enable the KV Cache - 2 * hidden_size * num_layers * decoder_length Disable the KV Cache - 2 * hidden_size * 1 * decoder_length ","date":"2023-10-12","objectID":"/en/llm-inference-optimization-kv-cache/:3:0","series":null,"tags":["NLP","Deep-Learning"],"title":"LLM inference optimization - KV Cache","uri":"/en/llm-inference-optimization-kv-cache/#the-performance-of-the-kv-cache"},{"categories":["ML-DL"],"content":" KV Cache APIHuggingface provides an API called model.generate. It has a parameter called use_cache, which is set to True by default1. ","date":"2023-10-12","objectID":"/en/llm-inference-optimization-kv-cache/:4:0","series":null,"tags":["NLP","Deep-Learning"],"title":"LLM inference optimization - KV Cache","uri":"/en/llm-inference-optimization-kv-cache/#kv-cache-api"},{"categories":["ML-DL"],"content":" Ref GenerationConfig¬†‚Ü©Ô∏é ","date":"2023-10-12","objectID":"/en/llm-inference-optimization-kv-cache/:5:0","series":null,"tags":["NLP","Deep-Learning"],"title":"LLM inference optimization - KV Cache","uri":"/en/llm-inference-optimization-kv-cache/#ref"},{"categories":["ML-DL"],"content":"An introduction of the LoRA fine-tuning","date":"2023-09-14","objectID":"/en/lora-finetuning/","series":null,"tags":["Paper","Internal","Deep-Learning"],"title":"LoRA fine-tuning","uri":"/en/lora-finetuning/"},{"categories":["ML-DL"],"content":" What‚Äôs LoRA Since the era of LLM(large language model) arrived, fine-tuning LLM has become a challenge because the LLM models are extremely large, making it difficult to perform full fine-tuning. There are mainly two approaches: freeze the entire LLM and perform prompt tuning or In-context Learning; freeze the entire LLM but inserting trainable modules. Today, I will introduce the LoRA(Low-Rank Adaptation), which corresponds to the latter technical approach. This is a work proposed by the Microsoft team1 The idea behind LoRA is quite simple. If you are familiar with deep learning, you should know that the parameters are updated by the gradient descent. Let‚Äôs consider a weight matrix $\\mathbf W_0\\in\\mathcal{R}^{d\\times d}$(the subscript 0 here means it‚Äôs the initial value), we can use $\\Delta \\mathbf W$ to denote the relative change to the initial value when it has been trained. After training, the parameters of this matrix will be $$\\mathbf W_0+\\Delta \\mathbf W$$ The problem that LoRA aims to solve is whether it is possible to determine the $\\Delta \\mathbf W$ without altering $\\mathbf W_0$ and with minimal computation cost. This is achievable because researchers have found that the intrinsic rank of a learned LLM model is low. Therefore, the authors hypothesize that the weight change($\\Delta \\mathbf W$) during model adaption also has a low intrinsic rank, which allows us to perform a low-rank decomposition of $\\Delta\\mathbf W$. Experimental results have shown that this assumption holds, and LoRA fine-tuning achieves promising results1. The low-rank decomposition is as follows $$\\Delta \\mathbf W=\\mathbf B\\mathbf A$$ where $\\mathbf B\\in\\mathcal{R}^{d\\times r}$Ôºå$\\mathbf A\\in\\mathcal{R}^{r\\times d}$, the matrix $\\mathbf B$ is initialized with zero and the matrix $\\mathbf A$ is initialized with a random Gaussian. This ensures that at the beginning of training, the LoRA module has no impact on the original model. If the input is $\\mathbf x$, then the computation will be $$\\mathbf W_0\\mathbf x+\\frac{\\alpha}{r}\\Delta \\mathbf W\\mathbf x=\\mathbf W_0\\mathbf x+\\frac{\\alpha}{r}\\mathbf B\\mathbf A\\mathbf x$$ The $\\alpha$ here is a scaling factor, and $r$ is the value of low-rank During training, only $\\mathbf B$ and $\\mathbf A$ are updated by the gradient descent. During inference, we can combine $\\mathbf W_0$ with $\\mathbf B\\mathbf A$ just like the LoRA module does not exist. It is a significant advantage of LoRA: it does not introduce inference latencyüëç Additionally, we can calculate the change in the number of learnable parameters when using LoRA. $$ (\\mathbf W_0+\\frac{\\alpha}{r}\\Delta\\mathbf W)\\mathbf x=\\mathbf W_0\\mathbf x+\\frac{\\alpha}{r}\\Delta \\mathbf W\\mathbf x=\\mathbf W_0\\mathbf x+\\frac{\\alpha}{r}\\mathbf B\\mathbf A\\mathbf x $$ The learnable parameters we need to train are significantly reduced because $r¬´d$, which makes LoRA a parameter-efficient fine-tuning method. üëç Two questions remaining - where should LoRA be applied in the transformer architecture? what is the optimal value for r? In section 7.1 of the paper, the authors found that applying LoRA to both the $\\mathbf W_q$ and $\\mathbf W_v$ yields the best result1 In section 7.2 of the paper, the authors discovered that increasing r does not always lead to significant improvements. and the values around 4 ~ 8 work well, which suggest that a low-rank adaptation matrix is sufficient1 ","date":"2023-09-14","objectID":"/en/lora-finetuning/:1:0","series":null,"tags":["Paper","Internal","Deep-Learning"],"title":"LoRA fine-tuning","uri":"/en/lora-finetuning/#whats-lora"},{"categories":["ML-DL"],"content":" How to use LoRAThe Huggingface has a library called peft which supports LoRA fine-tuning and many other fine-tuning techniques. The README.md file in this repo explains how to use LoRA fine-tuning. We simply need to configure the parameters using LoraConfig, and then use get_peft_model to transform the model, making it ready for subsequent training. python from transformers import AutoModelForCausalLM from peft import get_peft_config, get_peft_model, LoraConfig, TaskType model_name_or_path = \"facebook/opt-350m\" peft_config = LoraConfig( task_type=TaskType.CAUSAL_LM, r=8, lora_alpha=32, lora_dropout=0.1, ) model = AutoModelForCausalLM.from_pretrained(model_name_or_path) model = get_peft_model(model, peft_config) model.print_trainable_parameters() # output: trainable params: 786,432 # || all params: 331,982,848 # || trainable%: 0.2368893467652883 After training, we can save the model by using model.save_pretrained(output_dir), where output_dir means the path to save. If we check the output_dir folder, you will find that we only saved the incremental PEFT weights rather than the whole model weights sh output_dir ‚îú‚îÄ‚îÄ README.md ‚îú‚îÄ‚îÄ adapter_config.json ‚îî‚îÄ‚îÄ adapter_model.bin To load the model and the LoRA module, we can leverage this magic API :) python from peft import AutoPeftModelForCausalLM peft_model_name_or_path = \"./output_dir\" model = AutoPeftModelForCausalLM.from_pretrained(peft_model_name_or_path) ","date":"2023-09-14","objectID":"/en/lora-finetuning/:2:0","series":null,"tags":["Paper","Internal","Deep-Learning"],"title":"LoRA fine-tuning","uri":"/en/lora-finetuning/#how-to-use-lora"},{"categories":["ML-DL"],"content":" The source code of LoRA I omit some irrelevant parts of the source code for brevity. The code below is from the peft 0.5.0 The core of the LoRA fine-tuning implementation is the LoraModel class python class LoraModel(BaseTuner): def __init__(self, model, config, adapter_name) -\u003e None: super().__init__(model, config, adapter_name) ... It can be seen from the code that LoraModel inherits from the BaseTuner class, and it just calls the constructor of BaseTuner python class BaseTuner(nn.Module, ABC): def __init__(self, model, peft_config, adapter_name) -\u003e None: super().__init__() self.model = model self.inject_adapter(self.model, adapter_name) self.model.peft_config = self.peft_config Let‚Äôs focus on the inject_adapter method python class BaseTuner(nn.Module, ABC): def inject_adapter(self, model: nn.Module, adapter_name: str): peft_config = self.peft_config[adapter_name] is_target_modules_in_base_model = False key_list = [key for key, _ in model.named_modules()] peft_config = self._prepare_adapter_config(peft_config, model_config) for key in key_list: if not self._check_target_module_exists(peft_config, key): continue is_target_modules_in_base_model = True parent, target, target_name = _get_submodules(model, key) optionnal_kwargs = { \"loaded_in_8bit\": getattr(model, \"is_loaded_in_8bit\", False), \"loaded_in_4bit\": getattr(model, \"is_loaded_in_4bit\", False), \"current_key\": key, } self._create_and_replace( peft_config, adapter_name, target, target_name, parent, **optionnal_kwargs, ) self._mark_only_adapters_as_trainable() if self.peft_config[adapter_name].inference_mode: for n, p in self.model.named_parameters(): if adapter_name in n: p.requires_grad = False The inject_adapter just iterates all modules and checks which one we want to modify by the name of the module. The key here is the _create_and_replace method python class LoraModel(BaseTuner): def _create_and_replace( self, lora_config, adapter_name, target, target_name, parent, **optionnal_kwargs, ): bias = hasattr(target, \"bias\") and target.bias is not None kwargs = { \"r\": lora_config.r, \"lora_alpha\": lora_config.lora_alpha, \"lora_dropout\": lora_config.lora_dropout, \"fan_in_fan_out\": lora_config.fan_in_fan_out, \"init_lora_weights\": lora_config.init_lora_weights, } kwargs[\"loaded_in_8bit\"] = optionnal_kwargs.pop(\"loaded_in_8bit\", False) kwargs[\"loaded_in_4bit\"] = optionnal_kwargs.pop(\"loaded_in_4bit\", False) kwargs[\"bias\"] = bias if isinstance(target, LoraLayer) and isinstance(target, torch.nn.Conv2d): ... else: new_module = self._create_new_module( lora_config, adapter_name, target, **kwargs ) self._replace_module(parent, target_name, new_module, target) We are interested in how LoRA changes the nn.Linear module, so we should dive into the _create_new_module method python class LoraModel(BaseTuner): def _create_new_module(lora_config, adapter_name, target, **kwargs): if loaded_in_8bit and isinstance(target, bnb.nn.Linear8bitLt): ... else: if isinstance(target, torch.nn.Linear): in_features, out_features = target.in_features, target.out_features elif isinstance(target, Conv1D): ... else: ... new_module = Linear( adapter_name, in_features, out_features, bias=bias, **kwargs ) return new_module First, we copy the in_features and out_features attributes of the nn.Linear module, and then we create a new Linear module. We can find the Linear module definition in the same file python class Linear(nn.Linear, LoraLayer): def __init__( self, adapter_name: str, in_features: int, out_features: int, r: int = 0, lora_alpha: int = 1, lora_dropout: float = 0.0, fan_in_fan_out: bool = False, is_target_conv_1d_layer: bool = False, **kwargs, ): init_lora_weights = kwargs.pop(\"init_lora_weights\", True) nn.Linear.__init__(self, in_features, out_features, **kwargs) LoraLayer.__init__(self, in_features=in_features, out_features=out_features) # Freezing the pre-trained weight matrix self.weight.requires_grad = False nn.Linear.reset_parameters(self) self.update_layer(adapter_name, r, lora_alpha, lora_dro","date":"2023-09-14","objectID":"/en/lora-finetuning/:3:0","series":null,"tags":["Paper","Internal","Deep-Learning"],"title":"LoRA fine-tuning","uri":"/en/lora-finetuning/#the-source-code-of-lora"},{"categories":["ML-DL"],"content":" Refs LoRA: Low-Rank Adaptation of Large Language Models¬†‚Ü©Ô∏é¬†‚Ü©Ô∏é¬†‚Ü©Ô∏é¬†‚Ü©Ô∏é ","date":"2023-09-14","objectID":"/en/lora-finetuning/:4:0","series":null,"tags":["Paper","Internal","Deep-Learning"],"title":"LoRA fine-tuning","uri":"/en/lora-finetuning/#refs"},{"categories":["Algorithm"],"content":"An introduction of an algorithm to handle the next lexicographical permutation problem","date":"2023-09-06","objectID":"/en/the-next-lexicographical-permutation-problem/","series":null,"tags":["Algorithm"],"title":"The next lexicographical permutation problem","uri":"/en/the-next-lexicographical-permutation-problem/"},{"categories":["Algorithm"],"content":" IntroOccasionally, you may want to get the next/prev lexicographical permutation of a sequence. How would you do that? If you are a C++ programmer, you are probably familiar with the next_permutation1 and prev_permutation2 APIs. However, Python does not provide the counterparts. So the topic today is how to do this in Python. Since the solutions of prev lexicographical permutation and the next lexicographical permutation are very similar, let us focus on the next lexicographical permutation problem. ","date":"2023-09-06","objectID":"/en/the-next-lexicographical-permutation-problem/:1:0","series":null,"tags":["Algorithm"],"title":"The next lexicographical permutation problem","uri":"/en/the-next-lexicographical-permutation-problem/#intro"},{"categories":["Algorithm"],"content":" AlgorithmWhat may surprise you is that someone came up with a solution to this problem in the 14th century3. Assume the sequence is a. The following steps show how to get the next lexicographical permutation Find the largest index k such that a[k] \u003c a[k + 1]. If no such index exists, the permutation is the last permutation Find the largest index l greater than k such that a[k] \u003c a[l] Swap the value of a[k] with that of a[l] Reverse the sequence from a[k + 1] up to and including the final element a[n] That is how you get the next lexicographical permutation. But why this is correct? Now let‚Äôs dive into the details to figure out this. ","date":"2023-09-06","objectID":"/en/the-next-lexicographical-permutation-problem/:2:0","series":null,"tags":["Algorithm"],"title":"The next lexicographical permutation problem","uri":"/en/the-next-lexicographical-permutation-problem/#algorithm"},{"categories":["Algorithm"],"content":" Algorithm explainedLet‚Äôs forget this algorithm and try to imagine how would you solve the next lexicographical permutation problem. If you are familiar with the backtracing algorithm, you might try to enumerate all possible permutations and try to find the specific one. However, the time complexity is awful which is $O(N!)$. That brings us to the following question Q1 - What are the characteristics of generating the next lexicographical permutation problem during backtracking? Let‚Äôs use a simple example [1, 2, 3, 4] and enumerate its permutations in lexicographical order. Python [[1, 2, 3, 4], [1, 2, 4, 3], [1, 3, 2, 4], [1, 3, 4, 2], [1, 4, 2, 3], [1, 4, 3, 2], [2, 1, 3, 4], ... # omit [4, 3, 2, 1]] What makes [2, 1, 3, 4] the next lexicographical permutation of [1, 4, 3, 2]? Could you spot any patterns? More specifically, why did the value of the first position change from 1 to 2? What‚Äôs the characteristics of [1, 4, 3, 2]? The answer is: 4, 3, 2 is the longest non-increasing suffix(LNIS). Does this rule apply to any situation? Let‚Äôs see another example, [1, 2, 4, 3] -\u003e [1, 3, 2, 4]. We can see that the LNIS of [1, 2, 4, 3] is [4, 3], and the second position changes from 2 to 3. Let‚Äôs line these up to make it more clear Python [1, 4, 3, 2] ^ # LNIS [2, 1, 3, 4] ^ # change this [1, 2, 4, 3] ^ # LNIS [1, 3, 2, 4] ^ # change this So we can conclude - Find the start position j of LNIS in the sequence and try to increase the value in position j - 1. This explains the step 1 of the aforementioned algorithm. If you are not convinced by the above observation, then you can try to understand this from the backtracing perspective. When will we increase the value of position j - 1? When we have already enumerated all the permutations of a[j:] and returns from the recursive function call. The a[j:] subsequence would be in non-increasing order since we try to set the value of each position in lexicographical order. Python indices: 0, 1, 2, ..., j - 1, j, ..., n - 1 # a[j - 1] \u003c a[j] A1 - To generate the next lexicographical permutation, we will always try to increase the previous position of LNIS For the convenience of subsequent discussion, we call the position on the left of the LNIS found earlier as pivot (that is, j - 1 in front). So now comes the second question Q2 - How to change the value of a[pivot]? We are concerned about the next lexicographical permutation, so we want to make a[pivot] slightly bigger. But how can we find the next greater value of a[pivot]? The answer is: this element is located in a[pivot + 1:], that is, we need to find a position whose value is bigger than a[pivot], and this value should be as small as possible. Do not forget that a[pivot+1:] is the LNIS, which means that we can search `a[pivot + 1:] from right to left. This explains the step 2 of the aforementioned algorithm. A2 - Search a[pivot + 1:] from right to left whose value is bigger than a[pivot] and this value should be as small as possible. Let‚Äôs denote the index of this value as r Now there are only two remaining steps to explain, and they are related Q3 - Why should we swap a[pivot] and a[r], then reverse the a[pivot + 1:] suffix? Theoretically speaking, after we modify the value of a[pivot], the part of a[pivot + 1:] also needs to be modified, so the question is how to modify it. From the backtracing perspective, a[pivot + 1] should start from the smallest lexicographical order, that is, a[pivot + 1:] should be in non-decreasing order. Interestingly, the swap operation does not change the order of a[pivot + 1:], which means the a[pivot + 1:] is still in non-increasing order. To make it in non-decreasing order, we just need to reverse this part. This explains the step 3 \u0026 4 of this algorithm A3 - The swap operation does not change the order of a[pivot + 1:]. We reverse a[pivot + 1:] to make it in non-decreasing order ","date":"2023-09-06","objectID":"/en/the-next-lexicographical-permutation-problem/:3:0","series":null,"tags":["Algorithm"],"title":"The next lexicographical permutation problem","uri":"/en/the-next-lexicographical-permutation-problem/#algorithm-explained"},{"categories":["Algorithm"],"content":" CodeThe Leetcode offers a practice, you can examine your understanding there. I would suggest that try to implement this on your own at first and then check my code if needed :) Python class Solution: def nextPermutation(self, nums: List[int]) -\u003e None: # Step 1. Find the rightmost i s.t. a[i] \u003e a[i - 1] # and set pivot to i - 1 pivot = -1 for i in reversed(range(len(nums))): if i - 1 \u003e= 0 and nums[i] \u003e nums[i - 1]: pivot = i - 1 break if pivot == -1: nums.reverse() return # Step 2. Find the rightmost value s.t. a[i] \u003e a[pivot] for i in reversed(range(len(nums))): if nums[i] \u003e nums[pivot]: nums[i], nums[pivot] = nums[pivot], nums[i] break # Step 3. Reverse the (pivot, len(nums)) part left, right = pivot + 1, len(nums) - 1 while left \u003c right: nums[left], nums[right] = nums[right], nums[left] left += 1 right -= 1 return None ","date":"2023-09-06","objectID":"/en/the-next-lexicographical-permutation-problem/:4:0","series":null,"tags":["Algorithm"],"title":"The next lexicographical permutation problem","uri":"/en/the-next-lexicographical-permutation-problem/#code"},{"categories":["Algorithm"],"content":" Wrap upThe key to understanding the algorithm of the next lexicographical permutation problem is the backtracing algorithm(in my humble opinion). I hope you find this post helpful :) ","date":"2023-09-06","objectID":"/en/the-next-lexicographical-permutation-problem/:5:0","series":null,"tags":["Algorithm"],"title":"The next lexicographical permutation problem","uri":"/en/the-next-lexicographical-permutation-problem/#wrap-up"},{"categories":["Algorithm"],"content":" Refs std::next_permutation¬†‚Ü©Ô∏é std::prev_permutation¬†‚Ü©Ô∏é Permutation-Wiki¬†‚Ü©Ô∏é ","date":"2023-09-06","objectID":"/en/the-next-lexicographical-permutation-problem/:6:0","series":null,"tags":["Algorithm"],"title":"The next lexicographical permutation problem","uri":"/en/the-next-lexicographical-permutation-problem/#refs"},{"categories":["NLP"],"content":"An introduction of the BPE tokenizer","date":"2023-08-24","objectID":"/en/the-bpe-tokenizer/","series":null,"tags":["NLP"],"title":"BPE Tokenization Demystified: Implementation and Examples","uri":"/en/the-bpe-tokenizer/"},{"categories":["NLP"],"content":" A taxonomy of tokenization methodsIn NLP, one crux of problems is - how to tokenize the text. There are three methods available: Char-level Word-level Subword-level Let‚Äôs talk about the Char-level tokenizer. That is, we tokenize the text into a char stream. For instance, highest -\u003e h, i, g, h, e, s, t. One advantage of the Char-level tokenizer is that the size of Vocab won‚Äôt be that large. The size of Vocab is equal to the size of the alphabet. So you probably won‚Äôt meet the infamous Out-of-vocabulary(OOV) problem. However, the downside is that the char itself does not convey too much information, and we will get too many tokens after tokenizing. Try to imagine that a simple word highest will give us 7 tokensüò® The Word-level tokenizer is slightly better. In the Word-level tokenizer, we usually divide text into individual words using whitespace or punctuation marks. so the number of tokens after tokenizing won‚Äôt be too high. For instance, Today is a good day -\u003e Today, is, a, good, day. However, the Word-level tokenizer is not perfect. In English, the words high, higher, highest are semantically similar, with the latter two being comparative forms, but Word-level tokenization would treat them as three separate words. ü§îÔ∏è Is there a better way such that we most likely avoid the OOV problem, have a reasonable number of tokens after tokenizing, and also consider compound words, tense variations, etc.? This is where subword level tokenization comes into play. Using the same example as before, a subword tokenizer will most likely tokenize it as high, er, high, est. Therefore, the subword level tokenization involves representing a word using multiple subwords. The method I‚Äôm introducing today, BPE (Byte-Pair Encoding), belongs to the subword level category. There is one subtle thing to think about - What does the byte in the byte pair mean? We know that every char is 1 byte if we are using the ASCII encoding. However, what if we are using utf-8 encoding? A char may be 1 ~ 4 bytes. ü§îÔ∏è So, if BPE is applied to utf-8 text, what does a byte pair refer to? Thus, I feel there‚Äôs a bit of ambiguity here. Therefore, a better way to understand it might be that a byte pair is essentially a char pair, where char here refers to a utf-8 character. ","date":"2023-08-24","objectID":"/en/the-bpe-tokenizer/:1:0","series":null,"tags":["NLP"],"title":"BPE Tokenization Demystified: Implementation and Examples","uri":"/en/the-bpe-tokenizer/#a-taxonomy-of-tokenization-methods"},{"categories":["NLP"],"content":" BPE training phaseNow let‚Äôs figure out how the BPE tokenizer got trained. Let‚Äôs assume that we have some documents $D={d_1,d_2,‚Ä¶}$ For each $d$, we will transform the documents into word list in some way. For instance, you may choose to split the document by whitespace to get words Count the word freq for each word $w$ in $D$, and we can also get the alphabet of $D$ as the initial vocab(plus the \u003c/w\u003e). The alphabet contains all the unique utf-8 char in all documents $D$ For each word, transform the word into a utf-8 char list. We call it a split. For example, highest -\u003e h, i, g, h, e, s, t Append \u003c/w\u003e to each utf-8 list. e.g. highest -\u003e h, i, g, h, e, s, t, \u003c/w\u003e Repeat the following steps until any one of the two conditions is met: 1) Vocab reaches the upper limit. 2) Reach the maximum number of iterations Find the most frequent pair, add it to a merge table, and add the merged result to the vocab Update all splits of all words. For example, the most frequent pair may be (h, i) in our previous example, then we will add hi to the Vocab and change the split highest -\u003e hi, g, h, e, s, t, \u003c/w\u003e You may have 3 puzzles: Why word frequency? Because we want to find the most frequent pair easily Why append \u003c/w\u003e? Because we want to reconstruct the input later, we use \u003c/w\u003e to mark that it is the end of a word What if we have multiple pairs with the same frequency? How to handle this may vary in different implementations, but shouldn‚Äôt have much impact in my opinion. üí° You can observe that when the BPE algorithm merges the most frequently occurring pair, it doesn‚Äôt cross over words. ","date":"2023-08-24","objectID":"/en/the-bpe-tokenizer/:1:1","series":null,"tags":["NLP"],"title":"BPE Tokenization Demystified: Implementation and Examples","uri":"/en/the-bpe-tokenizer/#bpe-training-phase"},{"categories":["NLP"],"content":" How to use a trained BPE?After we trained a BPE tokenizer, we will obtain a merge table and a vocab. Assuming that we now need to tokenize the text s Use the same method as during training, start by splitting s into individual words, with each word further divided into utf-8 char. Remember to append \u003c/w\u003e in each split Iterate through the merge table and check if each merge rule can be applied to update the split of each word. üí° An important detail here is that the merge rules we extracted are sorted in descending order of frequency. Thus, by sequentially traversing the merge table, we are implicitly incorporating the notion of prioritizing the merging of the most frequently occurring pairs. ","date":"2023-08-24","objectID":"/en/the-bpe-tokenizer/:1:2","series":null,"tags":["NLP"],"title":"BPE Tokenization Demystified: Implementation and Examples","uri":"/en/the-bpe-tokenizer/#how-to-use-a-trained-bpe"},{"categories":["NLP"],"content":" BPE exampleLet‚Äôs use a motivating example to see how BPE got trained. Let‚Äôs say the corpus is python corpus = [\"highest\", \"higher\", \"lower\", \"lowest\", \"cooler\", \"coolest\"] We do not need to compute the word frequency here in that each word appears exactly once. First, let‚Äôs transformer each word into utf-8 chars and append \u003c/w\u003e python { \"highest\": [\"h\", \"i\", \"g\", \"h\", \"e\", \"s\", \"t\", \"\u003c/w\u003e\"], \"higher\": [\"h\", \"i\", \"g\", \"h\", \"e\", \"r\", \"\u003c/w\u003e\"], \"lower\": [\"l\", \"o\", \"w\", \"e\", \"r\", \"\u003c/w\u003e\"], \"lowest\": [\"l\", \"o\", \"w\", \"e\", \"s\", \"t\", \"\u003c/w\u003e\"], \"cooler\": [\"c\", \"o\", \"o\", \"l\", \"e\", \"r\", \"\u003c/w\u003e\"], \"collest\": [\"c\", \"o\", \"o\", \"l\", \"e\", \"s\", \"t\", \"\u003c/w\u003e\"], } We can find that the most frequently occurring pair is (e, s). Thus, we use this merge rule to update the splits. Note that we can also choose (e, r) because they have the same frequency python { \"highest\": [\"h\", \"i\", \"g\", \"h\", \"es\", \"t\", \"\u003c/w\u003e\"], \"higher\": [\"h\", \"i\", \"g\", \"h\", \"e\", \"r\", \"\u003c/w\u003e\"], \"lower\": [\"l\", \"o\", \"w\", \"e\", \"r\", \"\u003c/w\u003e\"], \"lowest\": [\"l\", \"o\", \"w\", \"es\", \"t\", \"\u003c/w\u003e\"], \"cooler\": [\"c\", \"o\", \"o\", \"l\", \"e\", \"r\", \"\u003c/w\u003e\"], \"collest\": [\"c\", \"o\", \"o\", \"l\", \"es\", \"t\", \"\u003c/w\u003e\"], } This time, the most frequently occurring pair is (es, t). We follow the same procedure and update the splits python { \"highest\": [\"h\", \"i\", \"g\", \"h\", \"est\", \"\u003c/w\u003e\"], \"higher\": [\"h\", \"i\", \"g\", \"h\", \"e\", \"r\", \"\u003c/w\u003e\"], \"lower\": [\"l\", \"o\", \"w\", \"e\", \"r\", \"\u003c/w\u003e\"], \"lowest\": [\"l\", \"o\", \"w\", \"est\", \"\u003c/w\u003e\"], \"cooler\": [\"c\", \"o\", \"o\", \"l\", \"e\", \"r\", \"\u003c/w\u003e\"], \"collest\": [\"c\", \"o\", \"o\", \"l\", \"est\", \"\u003c/w\u003e\"], } The most frequently occurring is (est, \u003c/w\u003e) python { \"highest\": [\"h\", \"i\", \"g\", \"h\", \"est\u003c/w\u003e\"], \"higher\": [\"h\", \"i\", \"g\", \"h\", \"e\", \"r\", \"\u003c/w\u003e\"], \"lower\": [\"l\", \"o\", \"w\", \"e\", \"r\", \"\u003c/w\u003e\"], \"lowest\": [\"l\", \"o\", \"w\", \"est\u003c/w\u003e\"], \"cooler\": [\"c\", \"o\", \"o\", \"l\", \"e\", \"r\", \"\u003c/w\u003e\"], \"collest\": [\"c\", \"o\", \"o\", \"l\", \"est\u003c/w\u003e\"], } The most frequently occurring is (e, r) python { \"highest\": [\"h\", \"i\", \"g\", \"h\", \"est\u003c/w\u003e\"], \"higher\": [\"h\", \"i\", \"g\", \"h\", \"er\", \"\u003c/w\u003e\"], \"lower\": [\"l\", \"o\", \"w\", \"er\", \"\u003c/w\u003e\"], \"lowest\": [\"l\", \"o\", \"w\", \"est\u003c/w\u003e\"], \"cooler\": [\"c\", \"o\", \"o\", \"l\", \"er\", \"\u003c/w\u003e\"], \"collest\": [\"c\", \"o\", \"o\", \"l\", \"est\u003c/w\u003e\"], } The most frequently occurring is (er, \u003c/w\u003e) python { \"highest\": [\"h\", \"i\", \"g\", \"h\", \"est\u003c/w\u003e\"], \"higher\": [\"h\", \"i\", \"g\", \"h\", \"er\u003c/w\u003e\"], \"lower\": [\"l\", \"o\", \"w\", \"er\u003c/w\u003e\"], \"lowest\": [\"l\", \"o\", \"w\", \"est\u003c/w\u003e\"], \"cooler\": [\"c\", \"o\", \"o\", \"l\", \"er\u003c/w\u003e\"], \"collest\": [\"c\", \"o\", \"o\", \"l\", \"est\u003c/w\u003e\"], } I believe the example above is quite clear enough. We can find that the BPE tokenizer finds two meaningful suffixes er and est :) ","date":"2023-08-24","objectID":"/en/the-bpe-tokenizer/:1:3","series":null,"tags":["NLP"],"title":"BPE Tokenization Demystified: Implementation and Examples","uri":"/en/the-bpe-tokenizer/#bpe-example"},{"categories":["NLP"],"content":" BPE tokenizer in HuggingfaceThe API provided by the Huggingface is quite simple. You may notice that it uses Char in the class name, which confirms what I mentioned earlier. python from tokenizers import CharBPETokenizer # Instantiate tokenizer tokenizer = CharBPETokenizer() tokenizer.train_from_iterator( corpus, vocab_size=17, min_frequency=2, ) ","date":"2023-08-24","objectID":"/en/the-bpe-tokenizer/:1:4","series":null,"tags":["NLP"],"title":"BPE Tokenization Demystified: Implementation and Examples","uri":"/en/the-bpe-tokenizer/#bpe-tokenizer-in-huggingface"},{"categories":["NLP"],"content":" Implemene a BPE tokenizerThe best way to understand how an algorithm works is to always try to implement one. Here I implement a BPE class which follows the algorithm described earlier. If you initialize with debug=True, you can observe how the entire BPE update process works First, let‚Äôs check the constructor and the train method python from collections import defaultdict, Counter from pprint import pprint class BPE: def __init__( self, corpus: list[str], vocab_size: int, max_iter: int | None = None, debug: bool = False, ): self.corpus = corpus self.vocab_size = vocab_size self.vocab = [] self.word_freq = Counter() self.splits = {} # e.g. highest: [high, est\u003c/w\u003e] self.merges = {} # e.g. [high, est\u003c/w\u003e]: highest self.max_iter = max_iter self.debug = debug def train(self): \"\"\"Train a BPE Tokenizer\"\"\" # count the word frequency for document in self.corpus: # split each document in corpus by whitespace words = document.split() self.word_freq += Counter(words) # initialize the self.splits for word in self.word_freq: self.splits[word] = list(word) + [\"\u003c/w\u003e\"] if self.debug: print(f\"Init splits: {self.splits}\") alphabet = set() for word in self.word_freq: alphabet |= set(list(word)) alphabet.add(\"\u003c/w\u003e\") self.vocab = list(alphabet) self.vocab.sort() cnt = 0 while len(self.vocab) \u003c self.vocab_size: if self.max_iter and cnt \u003e= self.max_iter: break # find the most frequent pair pair_freq = self.get_pairs_freq() if len(pair_freq) == 0: print(\"No pair available\") break pair = max(pair_freq, key=pair_freq.get) self.update_splits(pair[0], pair[1]) if self.debug: print(f\"Updated splits: {self.splits}\") self.merges[pair] = pair[0] + pair[1] self.vocab.append(pair[0] + pair[1]) if self.debug: print( f\"Most frequent pair({max(pair_freq.values())} times) \" f\"is : {pair[0]}, {pair[1]}. Vocab size: {len(self.vocab)}\" ) cnt += 1 The implementations of the key functions are as follows python ... def update_splits(self, lhs: str, rhs: str): \"\"\"If we see lhs and rhs appear consecutively, we merge them\"\"\" for word, word_split in self.splits.items(): new_split = [] cursor = 0 while cursor \u003c len(word_split): if ( word_split[cursor] == lhs and cursor + 1 \u003c len(word_split) and word_split[cursor + 1] == rhs ): new_split.append(lhs + rhs) cursor += 2 else: new_split.append(word_split[cursor]) cursor += 1 self.splits[word] = new_split # if word_split != new_split: # print(f\"old: {word_split}\") # print(f\"new: {new_split}\") def get_pairs_freq(self) -\u003e dict: \"\"\"Compute the pair frequency\"\"\" pairs_freq = defaultdict(int) for word, freq in self.word_freq.items(): split = self.splits[word] for i in range(len(split)): if i + 1 \u003c len(split): pairs_freq[(split[i], split[i + 1])] += freq return pairs_freq Now we can implement a tokenize method python ... def tokenize(self, s: str) -\u003e list[str]: splits = [list(t) + [\"\u003c/w\u003e\"] for t in s.split()] for lhs, rhs in self.merges: for idx, split in enumerate(splits): new_split = [] cursor = 0 while cursor \u003c len(split): if ( cursor + 1 \u003c len(split) and split[cursor] == lhs and split[cursor + 1] == rhs ): new_split.append(lhs + rhs) cursor += 2 else: new_split.append(split[cursor]) cursor += 1 assert \"\".join(new_split) == \"\".join(split) splits[idx] = new_split return sum(splits, []) Try to tokenize the corpus mentioned earlier using our hand crafted BPE tokenizer python bpe = BPE(corpus, vocab_size=17, debug=False) bpe.train() bpe.tokenize(\" \". join(corpus)) The output is: python ['h', 'i', 'g', 'h', 'est\u003c/w\u003e', 'h', 'i', 'g', 'h', 'er\u003c/w\u003e', 'l', 'o', 'w', 'er\u003c/w\u003e', 'l', 'o', 'w', 'est\u003c/w\u003e', 'c', 'o', 'o', 'l', 'er\u003c/w\u003e', 'c', 'o', 'o', 'l', 'est\u003c/w\u003e'] ü§îÔ∏è This indicates that our implementation is correct, and thanks to \u003c/w\u003e, we can see the word boundaries between words and even reconstruct the original input. ","date":"2023-08-24","objectID":"/en/the-bpe-tokenizer/:1:5","series":null,"tags":["NLP"],"title":"BPE Tokenization Demystified: Implementation and Examples","uri":"/en/the-bpe-tokenizer/#implemene-a-bpe-tokenizer"},{"categories":["NLP"],"content":" Wrap upThe BPE tokenize is simple and practical, but when you delve into its implementation, you will encounter several details. However, it‚Äôs precisely by engaging with these intricacies that your understanding of BPE becomes more profound. Let‚Äôs also talk about some limitations of BPE. For instance, you will notice that we are using whitespace to split text, which works for whitespaced language. However, for languages like Chinese, spaces don‚Äôt define word boundaries, which makes things more complex and calls for a better tokenizing method. ","date":"2023-08-24","objectID":"/en/the-bpe-tokenizer/:1:6","series":null,"tags":["NLP"],"title":"BPE Tokenization Demystified: Implementation and Examples","uri":"/en/the-bpe-tokenizer/#wrap-up"},{"categories":["NLP"],"content":"An simple introduction of TF-IDF model","date":"2023-08-16","objectID":"/en/an-introduction-of-tf-idf-model/","series":null,"tags":["NLP","Machine-Learning"],"title":"TF-IDF model","uri":"/en/an-introduction-of-tf-idf-model/"},{"categories":["NLP"],"content":" What is the TF-IDF modelIn previous post, we talked about the bag-of-word model, which has many limitations. Today we take a step further to see if we can try to fix one of the limitations - Each word has the same importance. üí° The crux of the problem - How to define the word importance? One idea is: The more frequently a word appears within a single document, the more important it is for that document. For instance, in an article discussing dogs, the word ‚Äúdog‚Äù is likely to appear frequently, reflecting the document‚Äôs main topic. But what if a word appears very frequently in all documents? For example, the word ‚Äúof‚Äù may appear quite often in every document, can we say ‚Äúof‚Äù is important? Clearly, that‚Äôs not the case. So we have a clue here: If a word has a high frequency in every document, probably it‚Äôs not significant and does not convey too much information. Therefore, a reasonable solution should consider a word‚Äôs frequency within a single document but also take into account its frequency crossing multiple documents. TF-IDF balances these two aspects. In summary, the intuition behind TF-IDF is - Similar documents may use similar words, while the importance of different words should vary. ","date":"2023-08-16","objectID":"/en/an-introduction-of-tf-idf-model/:1:0","series":null,"tags":["NLP","Machine-Learning"],"title":"TF-IDF model","uri":"/en/an-introduction-of-tf-idf-model/#what-is-the-tf-idf-model"},{"categories":["NLP"],"content":" TF-IDF in detailTF-IDF = Term frequency(TF) + Inverse document frequency(IDF). Let‚Äôs break it into two parts ","date":"2023-08-16","objectID":"/en/an-introduction-of-tf-idf-model/:2:0","series":null,"tags":["NLP","Machine-Learning"],"title":"TF-IDF model","uri":"/en/an-introduction-of-tf-idf-model/#tf-idf-in-detail"},{"categories":["NLP"],"content":" TFThe TF can be seen as a function of document $d$ and word $w$, and the equation is: $$\\text{TF}(w, d)=\\frac{\\text{frequency of}\\ w\\ \\text{in}\\ d}{\\text{word counts of } d}$$ That is, we just need to calculate the frequency of word $w$ in the document $d$, and then divide it by the total number of words in $d$. üêõ In Scikit-Learn, the computation of TF is a bit different. It doesn‚Äôt involve dividing by the total number of words in the document. The purpose of dividing is to normalize the $\\text{TF}(w, d)$ values within the document $d$, making them add up to one. In Scikit-Learn, this normalization process is performed after the TF-IDF calculation. We will demonstrate this with an example later. ","date":"2023-08-16","objectID":"/en/an-introduction-of-tf-idf-model/:2:1","series":null,"tags":["NLP","Machine-Learning"],"title":"TF-IDF model","uri":"/en/an-introduction-of-tf-idf-model/#tf"},{"categories":["NLP"],"content":" IDFThe goal of IDF is to reduce the importance of some common words that appear in each document. Therefore, the IDF is a function involving the word $w$ and the $corpus$. $$ \\text{IDF}(w, corpus)=log\\ \\frac{\\text{document count of }corpus}{1+\\text{count of document which contains }w} $$ We add one in the denominator to avoid division by 0. ü§îÔ∏è The $corpus$ is gennerally fixed. So it can be treated as a constant. In that case, IDF can be considered as something that‚Äôs only related to the word $w$ üí° Note the $log$ here. Are we using $log_2$, $log_{10}$ or $ln$? Different frameworks might have variations. Scikit-Learn use $ln$ üêõ In Scikit-Learn, the calculation of IDF differs from the equations mentioned above. By default, Scikit-Learn uses the following formula1: $$ \\text{IDF}(w, corpus)=log\\ \\frac{1 + \\text{document count of }corpus}{1+\\text{count of document which contains }w} + 1 $$ ü§îÔ∏è In my opinion, the modification made by Scikit-Learn ensures that $\\text{IDF}(w)$ cannot be less than 1. In the origin equation, if a word $w$ appears in each document within the corpus, $\\text{IDF}(w)$ could be a negative value. Therefore, Scikit-Learn‚Äôs modification seems more practical. It provides a more intuitive comparison of the IDF values for different words. ","date":"2023-08-16","objectID":"/en/an-introduction-of-tf-idf-model/:2:2","series":null,"tags":["NLP","Machine-Learning"],"title":"TF-IDF model","uri":"/en/an-introduction-of-tf-idf-model/#idf"},{"categories":["NLP"],"content":" TF-IDF$$ \\text{TF-IDF}(w, d, corpus)=\\text{TF}(w, d) * \\text{IDF}(d, corpus) $$ ","date":"2023-08-16","objectID":"/en/an-introduction-of-tf-idf-model/:2:3","series":null,"tags":["NLP","Machine-Learning"],"title":"TF-IDF model","uri":"/en/an-introduction-of-tf-idf-model/#tf-idf"},{"categories":["NLP"],"content":" The TF-IDF in Scikit-LearnIt‚Äôs trivial to implement the TF-IDF algorithm. However, probably you will just use the well-established APIs provided by Scikit-Learn. Here, we will delve into how to calculate TF-IDF in Scikit-Learn. Let‚Äôs proceed by continuing to use the official example from Scikit-Learn: python toy_corpus = [ 'This is the first document.', 'This is the second second document.', 'And the third one.', 'Is this the first document?', ] tokenized_toy_corpus = [ ['this', 'is', 'the', 'first', 'document'], ['this', 'is', 'the', 'second', 'second', 'document'], ['and', 'the', 'third', 'one'], ['is', 'this', 'the', 'first', 'document'] ] Let‚Äôs retrieve the TF-IDF matrix using the APIs python from sklearn.feature_extraction.text import TfidfVectorizer # set norm=None for comparison vectorizer = TfidfVectorizer(norm=None) X = vectorizer.fit_transform(toy_corpus) We can access the TF-IDF matrix using X.toarray() (Note that I set norm=None in the code snippet) and document first is one second the third this document1 0.0 1.22314 1.51082 1.22314 0.0 0.0 1.0 0.0 1.22314 document2 0.0 1.22314 0.0 1.22314 0.0 3.83258 1.0 0.0 1.22314 document3 1.91629 0.0 0.0 0.0 1.91629 0.0 1.0 1.91629 0.0 document4 0.0 1.22314 1.51082 1.22314 0.0 0.0 1.0 0.0 1.22314 Let me also put the bag-of-word matrix here: and document first is one second the third this document1 0 1 1 1 0 0 1 0 1 document2 0 1 0 1 0 2 1 0 1 document3 1 0 0 0 1 0 1 1 0 document4 0 1 1 1 0 0 1 0 1 ü§îÔ∏è Comparing these two matrices, we can find that the word importance of document and first inside the document1 has changed. The TF-IDF value for document is 1.22314, while the TF-IDF value for first is 1.51082, due to the unequal presence of these words in the corpus. However, the bag-of-word model fails to recognize this and considers both of them as having an importance of 1 We can retrieve the IDF value of each word by accessing the idf_ attribute python print(vectorizer.idf_) # [1.91629073 1.22314355 1.51082562 1.22314355 1.91629073 # 1.91629073 1. 1.91629073 1.22314355] ü§îÔ∏è If we multiply this IDF vector by the matrix output of the bag-of-word model(note that the IDF vector will be broadcasted), you would obtain the TF-IDF matrix calculated by Scikit-Learn. This confirms what we mentioned earlier: Scikit-Learn directly uses the output of the bag-of-word model as TF. Scikit-Learn‚Äôs IDF calculation differs from the standard approach. ","date":"2023-08-16","objectID":"/en/an-introduction-of-tf-idf-model/:3:0","series":null,"tags":["NLP","Machine-Learning"],"title":"TF-IDF model","uri":"/en/an-introduction-of-tf-idf-model/#the-tf-idf-in-scikit-learn"},{"categories":["NLP"],"content":" Implement TF-IDF manuallyWe assume that each document within the corpus is tokenized, and we use the TF-IDF definition of Scikit-Learn üêõ The code below is not optimized, just for demonstration :) python import math def TF(word: str, tokenized_document: list[str]) -\u003e float: return tokenized_document.count(word) def IDF(word: str, tokenized_corpus: list[list[str]]) -\u003e float: doc_count_contains_word = 0 for doc in tokenized_corpus: if word in doc: doc_count_contains_word += 1 return math.log((1 + len(tokenized_corpus)) / (1 + doc_count_contains_word)) + 1 def TF_IDF( word: str, tokenized_document: list[str], tokenized_corpus: list[list[str]] ) -\u003e float: return TF(word, tokenized_document) * IDF(word, tokenized_corpus) ","date":"2023-08-16","objectID":"/en/an-introduction-of-tf-idf-model/:4:0","series":null,"tags":["NLP","Machine-Learning"],"title":"TF-IDF model","uri":"/en/an-introduction-of-tf-idf-model/#implement-tf-idf-manually"},{"categories":["NLP"],"content":" Wrap upIn this post, we investigate how TF-IDF has brought improvements to the bag-of-word model: by additionally considering a word‚Äôs frequency across all documents to adjust its importance. Through the analysis of official example in Scikit-Learn, we have also validated that, the importance of words are now different. This stands as a noteworthy enhancement to the bag-of-word model. From an implementation perspective, the calculation of TF-IDF only requires traversing the corpus once. During the traversal, a few additional variables are maintained: the count of how many documents each word appears in, the total number of processed documents, etc. You may take a look at the source code of the Dictionary class in Gensim for more details. ","date":"2023-08-16","objectID":"/en/an-introduction-of-tf-idf-model/:5:0","series":null,"tags":["NLP","Machine-Learning"],"title":"TF-IDF model","uri":"/en/an-introduction-of-tf-idf-model/#wrap-up"},{"categories":["NLP"],"content":" Refs TF-IDF term weighting¬†‚Ü©Ô∏é ","date":"2023-08-16","objectID":"/en/an-introduction-of-tf-idf-model/:6:0","series":null,"tags":["NLP","Machine-Learning"],"title":"TF-IDF model","uri":"/en/an-introduction-of-tf-idf-model/#refs"},{"categories":["NLP"],"content":"An introduction of bag-of-word model","date":"2023-08-11","objectID":"/en/an-introduction-of-bag-of-word-model/","series":null,"tags":["NLP","Machine-Learning","AI4SE"],"title":"Bag-of-Word model","uri":"/en/an-introduction-of-bag-of-word-model/"},{"categories":["NLP"],"content":" What is the bag-of-word model?In NLP, we need to represent each document as a vector because machine learning can only accept input as numbers. That is, we want to find a magic function that: $$ f(\\text{document}) = vector $$ Today‚Äôs topic is bag-of-word(BoW) model, which can transform a document into a vector representation. üí° Although the BoW model is outdated in 2023, I still encourage you to learn from the history and think about some essential problems: What is the motivation? What are the pros and cons? How can we make it better? üí° Note that I may use word and token interchangeably ","date":"2023-08-11","objectID":"/en/an-introduction-of-bag-of-word-model/:1:0","series":null,"tags":["NLP","Machine-Learning","AI4SE"],"title":"Bag-of-Word model","uri":"/en/an-introduction-of-bag-of-word-model/#what-is-the-bag-of-word-model"},{"categories":["NLP"],"content":" Motivation \u0026 intuitionBefore we dive into the details, I want to give you an intuition why BoW may work - Similar documents may use similar words You may object to this intuition and show some good counterexamples, and I agree with your point. That‚Äôs why we need more powerful models rather than BoW :) ","date":"2023-08-11","objectID":"/en/an-introduction-of-bag-of-word-model/:1:1","series":null,"tags":["NLP","Machine-Learning","AI4SE"],"title":"Bag-of-Word model","uri":"/en/an-introduction-of-bag-of-word-model/#motivation--intuition"},{"categories":["NLP"],"content":" BoW model in detailIn BoW, you need to do two things: Create a vocabulary. Each token in the vocab is assigned a unique id (usually, it will start from 0). The length of the BoW vector will be equal to the size of the vocab For each document in the corpus, identify words that are not currently present in the existing vocabulary, and subsequently incorporate these words into the vocabulary list. After constructing a BoW model, we can use it to transform any document into a vector representation. The procedure is simple, we just count the occurrences of each word in the document. Note that we only consider vocab words and ignore the out-of-vocabulary(OOV) words. Let‚Äôs use a toy example to illustrate this idea1 python toy_corpus = [ 'This is the first document.', 'This is the second second document.', 'And the third one.', 'Is this the first document?', ] Remove punctuation, then tokenize with spaces, and also convert all the words to lowercase. After preprocessing, we can obtain: python tokenized_toy_corpus = [ ['this', 'is', 'the', 'first', 'document'], ['this', 'is', 'the', 'second', 'second', 'document'], ['and', 'the', 'third', 'one'], ['is', 'this', 'the', 'first', 'document'] ] To simplify matters, let‚Äôs encompass all words within the corpus and incorporate them into our vocabulary. python flatten_list_as_set = set(sum(tokenized_toy_corpus, start=[])) print(f\"the toy vocab size: {len(flatten_list_as_set)}\") the toy vocab size: 9 üí° A nice trick to flatten this list :D Now, let‚Äôs assign a unique token id to each word in the vocab python toy_token2id = {} for token in sorted(flatten_list_as_set): toy_token2id[token] = len(toy_token2id) print(toy_token2id) { 'and': 0, 'document': 1, 'first': 2, 'is': 3, 'one': 4, 'second': 5, 'the': 6, 'third': 7, 'this': 8 } The vocab size is 9, then we know we can represent each document as a vector with a length 9 by counting the words Let‚Äôs manually implement this to see if we understand the ideas python BoW_matrix = [] for document in tokenized_toy_corpus: temp = [0] * 9 for token in document: temp[toy_token2id[token]] += 1 BoW_matrix.append(temp) print(BoW_matrix) [ [0, 1, 1, 1, 0, 0, 1, 0, 1], [0, 1, 0, 1, 0, 2, 1, 0, 1], [1, 0, 0, 0, 1, 0, 1, 1, 0], [0, 1, 1, 1, 0, 0, 1, 0, 1] ] The numbers may not be so intuitive, let‚Äôs add more information to make this better. If you check the answer1, that‚Äôs exactly what we calculated and document first is one second the third this document1 0 1 1 1 0 0 1 0 1 document2 0 1 0 1 0 2 1 0 1 document3 1 0 0 0 1 0 1 1 0 document4 0 1 1 1 0 0 1 0 1 Here comes the question: How to read this? Each row is a BoW vector of the corresponding document. Take the 2nd row as an example, it means the document2 has: document * 1 is * 1 second * 2 the * 1 this * 1 Recall that the tokenized document2 is ['this', 'is', 'the', 'second', 'second', 'document'], which is aligned with the vector representation Now you know how to interpret the BoW matrix. :D üßê You might have observed that there are so many 0 in this matrix. Indeed, the BoW matrix tends to be sparse. That‚Äôs one of the limitations of BoW python from sklearn.metrics.pairwise import cosine_similarity We can use the inner product to measure the similarity between two vectors. Recall our tokenized_toy_corpus python tokenized_toy_corpus = [ ['this', 'is', 'the', 'first', 'document'], ['this', 'is', 'the', 'second', 'second', 'document'], ['and', 'the', 'third', 'one'], ['is', 'this', 'the', 'first', 'document'] ] Now, let‚Äôs say the query is the last document - ['is', 'this', 'the', 'first', 'document'], which document has the highest similarity except the query? We as humans can find this at a glance. The first document should be the answer. Let‚Äôs check if the machine can figure out this: python print( cosine_similarity([BoW_matrix[3]], [BoW_matrix[0]]), cosine_similarity([BoW_matrix[3]], [BoW_matrix[1]]), cosine_similarity([BoW_matrix[3]], [BoW_matrix[2]]), ) [[1.]] [[0.63245553]] [[0.2236068]] The machine agrees ","date":"2023-08-11","objectID":"/en/an-introduction-of-bag-of-word-model/:1:2","series":null,"tags":["NLP","Machine-Learning","AI4SE"],"title":"Bag-of-Word model","uri":"/en/an-introduction-of-bag-of-word-model/#bow-model-in-detail"},{"categories":["NLP"],"content":" Beyond the toy exampleThe toy example is not quite exciting in my opinion. So I use a real-world dataset - CodeSearchNet to play the BoW model. The CodeSearchNet contains various functions from many programming languages, I just pick the Python code to analyze. You are free to investigate another programming language :) python from datasets import load_dataset from gensim import corpora def process_data(partition: str) -\u003e list[str]: \"\"\" Get data from the datasets library from huggingface. Only keep the `whole_func_string` column Arg --- `partition`: train/validation/test Return ----- return a list of python functions \"\"\" raw_datasets = load_dataset(\"code_search_net\", \"python\") return raw_datasets[partition][\"whole_func_string\"] This may take a while depending on your network condition(941MB) python # use the test dataset to speed up the process corpus = process_data(\"test\") Let‚Äôs see a simple example python print(corpus[0]) def get_vid_from_url(url): \"\"\"Extracts video ID from URL. \"\"\" return match1(url, r'youtu\\.be/([^?/]+)') or \\ match1(url, r'youtube\\.com/embed/([^/?]+)') or \\ match1(url, r'youtube\\.com/v/([^/?]+)') or \\ match1(url, r'youtube\\.com/watch/([^/?]+)') or \\ parse_query_param(url, 'v') or \\ parse_query_param(parse_query_param(url, 'u'), 'v') Different from the English text, the programming language has well-defined grammar(context-free grammar). So we can tokenize the source code by a lexer. I use the built-in tokenize module to achieve this Feel free to skip this function if you can‚Äôt understand how a lexer works. The reason behind using a lexer is to make the tokenization process more accurate :) python import ast from io import BytesIO import tokenize def get_token_stream(code: str) -\u003e list[str]: \"\"\" Tokenize the source code and return a token stream Note that the following token type will be removed: - COMMENT - NEWLINE - NL - INDENT - DEDENT - ENCODING - STRING \"\"\" # see https://docs.python.org/3/library/token.html useless_token_type = { tokenize.COMMENT, tokenize.NEWLINE, tokenize.NL, # non-terminating newline tokenize.INDENT, tokenize.DEDENT, tokenize.ENCODING, tokenize.STRING, } parse_tree = ast.parse(code) origin_tokens = tokenize.tokenize(BytesIO(code.encode(\"utf-8\")).readline) token_as_strlist = [ token.string for token in origin_tokens if token.type not in useless_token_type ] return token_as_strlist Two things to notice are: We remove all strings, including docstring, f-string, comment, etc. We do not tokenize the variable name or function name using camelCase or snake_case convention First, let‚Äôs use get_token_stream to tokenize each function within this dataset. Note that the dataset contains Python2 code, which can‚Äôt be processed by the auxiliary function I have crafted. Consequently, I choose to remove the Python2 code. python from tqdm.auto import tqdm py2_cnt, py3_cnt = 0, 0 new_corpus = [] codes = [] for code in tqdm(corpus): try: codes.append(get_token_stream(code)) new_corpus.append(code) py3_cnt += 1 except SyntaxError: py2_cnt += 1 print(f\"Python2: {py2_cnt}, Python3: {py3_cnt}\") corpus = new_corpus Let‚Äôs make sure the get_token_stream function works correctly python print(codes[0]) [ 'def', 'get_vid_from_url', '(', 'url', ')', ':', 'return', 'match1', '(', 'url', ',', ')', 'or', 'match1', '(', 'url', ',', ')', 'or', 'match1', '(', 'url', ',', ')', 'or', 'match1', '(', 'url', ',', ')', 'or', 'parse_query_param', '(', 'url', ',', ')', 'or', 'parse_query_param', '(', 'parse_query_param', '(', 'url', ',', ')', ',', ')', '' ] Now, we can leverage the API provided by the Gensim to create a vocabulary python from gensim import corpora dictionary = corpora.Dictionary(codes) print(dictionary) Dictionary\u003c77242 unique tokens: ['', '(', ')', ',', ':']...\u003e That‚Äôs a huge dictionary. Let‚Äôs see if we can optimize this. ü§îÔ∏è Usually, we are not interested in tokens that only appear once in our corpus. So we can remove them python once_ids = [ token_id for token_id, doc_freq in dictionary.dfs.items() if doc_","date":"2023-08-11","objectID":"/en/an-introduction-of-bag-of-word-model/:2:0","series":null,"tags":["NLP","Machine-Learning","AI4SE"],"title":"Bag-of-Word model","uri":"/en/an-introduction-of-bag-of-word-model/#beyond-the-toy-example"},{"categories":["NLP"],"content":" Wrap upNow, let‚Äôs summarize some limitations of BoW. You may have figured out some of them by yourself: Loss of word order information. The cat chased the dog is different from The dog chased the cat No semantic information. BoW treats each word as an independent entity The BoW vector is a high-dimensional sparse vector. It is computationally expensive and the size depends on your vocab size Each word has the same importance. Some words may be more informative Does not handle out-of-vocabulary problems. What if a document contains many OOV tokens? ‚Ä¶ The BoW model has so many drawbacks that you probably only would see it in tutorials for educational purposes. In light of these limitations, more advanced models like Word2Vec, GloVe, and transformer-based architectures (e.g., BERT, GPT) have been developed to overcome these drawbacks and provide better representations of text. ","date":"2023-08-11","objectID":"/en/an-introduction-of-bag-of-word-model/:3:0","series":null,"tags":["NLP","Machine-Learning","AI4SE"],"title":"Bag-of-Word model","uri":"/en/an-introduction-of-bag-of-word-model/#wrap-up"},{"categories":["NLP"],"content":" Refs CountVectorizer¬†‚Ü©Ô∏é¬†‚Ü©Ô∏é ","date":"2023-08-11","objectID":"/en/an-introduction-of-bag-of-word-model/:4:0","series":null,"tags":["NLP","Machine-Learning","AI4SE"],"title":"Bag-of-Word model","uri":"/en/an-introduction-of-bag-of-word-model/#refs"},{"categories":["ML-DL"],"content":"A introduction of a cool trick to calculate partial derivatives in machine learning","date":"2023-07-26","objectID":"/en/a-trick-to-calculating-partial-derivatives-in-ml/","series":null,"tags":["Deep-Learning","Machine-Learning"],"title":"A trick to calculating partial derivatives in machine learning","uri":"/en/a-trick-to-calculating-partial-derivatives-in-ml/"},{"categories":["ML-DL"],"content":" IntroYou may have difficulties when trying to calculate the partial derivatives in machine learning like me. Even though I found a good reference cookbook that could be used to derive the gradients, I still got confused. Today, I want to share a practical technique I recently learned from this video: when calculating partial derivatives in machine learning, you can treat everything as if it were a scalar and then make the shapes match Disclaimer: Calculating the partial derivatives using this trick DO NOT guarantee that the gradients are correct. The dimensions may match but the gradients could be wrong. Therefore, it is essential to perform gradient checking to ensure correctness ","date":"2023-07-26","objectID":"/en/a-trick-to-calculating-partial-derivatives-in-ml/:1:0","series":null,"tags":["Deep-Learning","Machine-Learning"],"title":"A trick to calculating partial derivatives in machine learning","uri":"/en/a-trick-to-calculating-partial-derivatives-in-ml/#intro"},{"categories":["ML-DL"],"content":" Application üí° Uppercase bold letters represent matrices, while non-bold letters represent scalars ","date":"2023-07-26","objectID":"/en/a-trick-to-calculating-partial-derivatives-in-ml/:2:0","series":null,"tags":["Deep-Learning","Machine-Learning"],"title":"A trick to calculating partial derivatives in machine learning","uri":"/en/a-trick-to-calculating-partial-derivatives-in-ml/#application"},{"categories":["ML-DL"],"content":" Backpropagation in matrix formIn my previous post, I try to derive the backpropagation equations in the scalar form because it‚Äôs much easier to understand. However, if you ever try to implement the forward propagation or the backpropagation, you‚Äôll find that everything is done in matrix form. That is why it‚Äôs essential to understand how the matrix form of backpropagation works. Now, I will use the technique mentioned earlier to derive it For simplicity, let‚Äôs ignore the bias term and only consider the weight term Consider a simple $L$ layers MLP, where $\\mathbf Z^l$ represents the output of layer $l$. We also use $\\mathbf Z$ to represent the input. Thus, we have: $$\\mathbf Z^0=\\mathbf X$$ Here, $\\mathbf X\\in\\mathcal{R}^{m\\times d}$, where $m$ is the number of samples, and $d$ is the length of each features for each sample The output of the model $f_\\theta$ is $$f_\\theta(\\mathbf X)=\\mathbf Z^{L}$$ Here, $\\theta$ represents the learnable parameters of this model The relationship between any continuous layers is: $$\\mathbf Z^{l+1}=\\sigma_{l+1}(\\mathbf Z^l\\mathbf W^{l+1}),l=0,‚Ä¶,L-1$$ Here, $\\sigma_{l+1}$ is the activate function of layer $l+1$ The shapes: $$\\mathbf Z^l\\in\\mathcal{R}^{m\\times n_l}$$ $$\\mathbf W^{l+1} \\in \\mathcal R^{n_l\\times n_{l+1}}$$ Here, $n_l$ represents the number of neurons in layer $l$ We want to determine the gradient of the loss $J$ with respect to any learnable parameter in the model. This gradient is essential for using gradient a descent algorithm to update the learnable parameters. Specifically, let‚Äôs consider that we want to calculate the gradient of $\\mathbf{W}^l$. $$ \\frac{\\partial J}{\\partial \\mathbf W^l}=\\frac{\\partial J}{\\partial\\mathbf Z^{L}}\\cdot \\frac{\\partial \\mathbf Z^{L}}{\\partial\\mathbf Z^{L-1}}\\cdot ‚Ä¶\\cdot \\frac{\\partial \\mathbf Z^{l+1}}{\\partial\\mathbf Z^{l}}\\cdot\\frac{\\partial \\mathbf Z^{l}}{\\partial\\mathbf W^l} $$ ü§îÔ∏è What if we also want to calculate the gradient with respect to $\\mathbf W^{l-1}$? $$ \\frac{\\partial J}{\\partial \\mathbf W^{l-1}}=\\frac{\\partial J}{\\partial\\mathbf Z^{L}}\\cdot \\frac{\\partial \\mathbf Z^{L}}{\\partial\\mathbf Z^{L-1}}\\cdot ‚Ä¶\\cdot \\frac{\\partial \\mathbf Z^{l+1}}{\\partial\\mathbf Z^{l}} \\cdot \\frac{\\partial \\mathbf Z^{l}}{\\partial\\mathbf Z^{l-1}}\\cdot\\frac{\\partial \\mathbf Z^{l-1}}{\\partial\\mathbf W^{l-1}} $$ One thing to notice is that - both equations share some common components. So we can introduce an additional notation $\\mathbf G^l$ which represents the gradient of $\\mathbf Z^l$ $$\\mathbf G^{l}=\\frac{\\partial J}{\\partial \\mathbf Z^{l}}$$ Now, let‚Äôs try to figure out the relationship between $\\mathbf G^l$ and $\\mathbf G^{l+1}$ $$ \\begin{equation} \\begin{aligned} \\mathbf G^{l} \u0026=\\frac{\\partial J}{\\partial \\mathbf Z^{l+1}}\\cdot\\frac{\\partial \\mathbf Z^{l+1}}{\\partial \\mathbf Z^l} \\\\\\ \u0026=\\mathbf G^{l+1}\\cdot \\frac{\\partial \\mathbf Z^{l+1}}{\\partial \\mathbf Z^l} \\\\\\ \u0026=\\mathbf G^{l+1}\\cdot \\frac{\\partial \\sigma_{l+1}(\\mathbf Z^{l}\\mathbf W^{l+1})}{\\partial \\mathbf Z^{l}\\mathbf W^{l+1}}\\cdot\\frac{\\partial \\mathbf Z^{l}\\mathbf W^{l+1}}{\\partial \\mathbf Z^l} \\\\\\ \u0026=\\mathbf G^{l+1}\\cdot \\sigma‚Äô(\\mathbf Z^{l}\\mathbf W^{l+1})\\cdot \\mathbf W^{l+1}\\ (cheat) \\end{aligned} \\end{equation} $$ In the last line above, we are calculating the derivatives as if they were scalars. Now let‚Äôs try to make the shapes match. Let‚Äôs first examine the shapes of each component: $$\\mathbf G^{l+1}\\in\\mathcal{R}^{m\\times n_{l+1}}$$ $$\\sigma_{l+1}‚Äô(\\mathbf Z^{l}\\mathbf W^{l+1})\\in\\mathcal{R}^{m\\times n_{l+1}}$$ $$ \\mathbf W^{l+1}\\in\\mathcal{R}^{n_l\\times n_{l+1}} $$ We want to get a matrix with the shape $m\\times n_l$, because $$\\mathbf G^l\\in\\mathcal{R}^{m\\times n_l}$$ So we can derive this $$\\mathbf G^{l}=\\Big (\\mathbf G^{l+1}\\odot\\sigma_{l+1}‚Äô(\\mathbf Z^{l}\\mathbf W^{l+1})\\Big )(\\mathbf{W}^{l+1})^T=\\Big (\\mathbf G^{l+1}\\odot\\sigma_{l+1}‚Äô(\\mathbf Z^{l+1})\\Big )(\\mathbf{W}^{l+1})^T$$ Now, let‚Äôs get back to what we originally intended to do - computing the gradient with respect to $\\mathbf{W}^l","date":"2023-07-26","objectID":"/en/a-trick-to-calculating-partial-derivatives-in-ml/:2:1","series":null,"tags":["Deep-Learning","Machine-Learning"],"title":"A trick to calculating partial derivatives in machine learning","uri":"/en/a-trick-to-calculating-partial-derivatives-in-ml/#backpropagation-in-matrix-form"},{"categories":["ML-DL"],"content":" The gradient of a linear regression modelPreviously in this post I need to derive this equation $$ \\begin{aligned} \\frac{\\partial}{\\partial \\theta}\\ J(w,b) \u0026= \\frac{\\partial}{\\partial \\theta}\\ \\frac{1}{2m}(\\mathbf X\\theta - \\vec{y})^T(\\mathbf X\\theta - \\vec{y}) \\\\\\ \\end{aligned} $$ With this cool trick, we can derive like this $$ \\begin{equation} \\begin{aligned} \\frac{\\partial}{\\partial \\theta}\\ J(w,b) \u0026= \\frac{\\partial}{\\partial \\theta}\\ \\frac{1}{2m}(\\mathbf X\\theta - \\vec{y})^T(\\mathbf X\\theta - \\vec{y}) \\\\\\ \u0026= \\frac{1}{2m}\\frac{\\partial(\\ \\mathbf X\\theta - \\vec{y})^T(\\mathbf X\\theta - \\vec{y}) }{\\partial (\\mathbf X\\theta-\\vec y)}\\cdot \\frac{\\partial (\\mathbf X\\theta-\\vec y)}{\\partial \\theta}\\\\\\ \u0026= \\frac{1}{2m}\\cdot2(\\mathbf X\\theta-\\vec y)\\cdot\\mathbf X\\ (cheat) \\end{aligned} \\end{equation} $$ Note the shapes here $$(\\mathbf X\\theta-\\vec y)\\in\\mathcal{R}^{m\\times 1}$$ $$\\mathbf X\\in\\mathcal{R}^{m\\times(n+1)}$$ We want a vector whose shape is equal to $(n+1)\\times 1$ $$\\theta\\in\\mathcal{R}^{(n+1)\\times 1}$$ Let‚Äôs make the shapes match: $$\\frac{1}{m}\\mathbf X^T(\\mathbf X\\theta-\\vec y)$$ ","date":"2023-07-26","objectID":"/en/a-trick-to-calculating-partial-derivatives-in-ml/:2:2","series":null,"tags":["Deep-Learning","Machine-Learning"],"title":"A trick to calculating partial derivatives in machine learning","uri":"/en/a-trick-to-calculating-partial-derivatives-in-ml/#the-gradient-of-a-linear-regression-model"},{"categories":["ML-DL"],"content":" Key takeawayThis trick is practical but not rigorous. After mastering this technique, the process of formula derivation in machine learning may become much easier. However, don‚Äôt forget to use gradient checking technique to ensure correctness :) ","date":"2023-07-26","objectID":"/en/a-trick-to-calculating-partial-derivatives-in-ml/:3:0","series":null,"tags":["Deep-Learning","Machine-Learning"],"title":"A trick to calculating partial derivatives in machine learning","uri":"/en/a-trick-to-calculating-partial-derivatives-in-ml/#key-takeaway"},{"categories":["ML-DL","Internal"],"content":"A simple introduction of strides format used by Pytorch","date":"2023-07-14","objectID":"/en/how-to-reprensent-a-tensor-or-ndarray/","series":null,"tags":["Internal","Pytorch","Deep-Learning"],"title":"Demystifying Pytorch's Strides Format","uri":"/en/how-to-reprensent-a-tensor-or-ndarray/"},{"categories":["ML-DL","Internal"],"content":" IntroEven though I have been using Numpy and Pytorch for a long time, I never really knew how they implemented the underlying tensors and why they are so efficient. Recently, while studying the course Deep Learning Systems, I finally got the opportunity to try implementing tensors on my own. After going through the process, my understanding of tensors is much better üßê As a Pytorch user, is it necessary to understand the underlying tensor storage mechanism? I believe it is essential. In most cases, understanding the underlying principles helps you grasp higher-level concepts better. For example, understanding the tensor storage mechanism can help you answer the following questions: Does broadcasting involve copying arrays? What does contiguous do in Pytorch, and why is this function needed? ","date":"2023-07-14","objectID":"/en/how-to-reprensent-a-tensor-or-ndarray/:1:0","series":null,"tags":["Internal","Pytorch","Deep-Learning"],"title":"Demystifying Pytorch's Strides Format","uri":"/en/how-to-reprensent-a-tensor-or-ndarray/#intro"},{"categories":["ML-DL","Internal"],"content":" Row-major and column-majorLet‚Äôs start with a simple 2D array, A 2D array occupies a contiguous location in memory, but how it is stored, whether using row-major or column-major, may vary. Let‚Äôs say we have a 2D array A whose size is $2\\times 3$ python [[0.2949, 0.9608, 0.0965], [0.5463, 0.4176, 0.8146]] If we use row-major, then the memory layout(denoted as A_in_row) would be: python [0.2949, 0.9608, 0.0965, 0.5463, 0.4176, 0.8146] To access (i, j) when using row-major, the equations says: python A[i][j] = A_in_row[i * A.shape[1] + j] If we use column-major, then the memory layout(denoted as A_in_col) would be: python [0.2949, 0.5463, 0.9608, 0.4176, 0.0965, 0.8146] To access (i, j) when using column-major, the equations says: python A[i][j] = A_in_col[j * A.shape[0] + i] ","date":"2023-07-14","objectID":"/en/how-to-reprensent-a-tensor-or-ndarray/:2:0","series":null,"tags":["Internal","Pytorch","Deep-Learning"],"title":"Demystifying Pytorch's Strides Format","uri":"/en/how-to-reprensent-a-tensor-or-ndarray/#row-major-and-column-major"},{"categories":["ML-DL","Internal"],"content":" Strides format Note: I will use continuous/contiguous/compact interchangeably. At the low level, tensors can be stored either by rows or columns. Both Numpy and PyTorch adopt the approach of storing tensors by rows. Regardless of the tensor‚Äôs dimension, the underlying storage always occupies continuous memory space. Now, the question arises: How do we access the data at the desired positions? The answer is strides format. We may regard the strides format as a generalization version of the two previous indexing formats. Let‚Äôs consider a tensor of $N$ dimensions(0-based), and its underlying storage is represented as A_internal. If we want to access A[i0][i1][i2]..., the indexing is done as follows: python A[i0][i1][i2]... = A_internal[ stride_offset + i0 * A.strides[0] + i1 * A.strides[1] + i2 * A.strides[2] + ... + in-1 * A.strides[n-1] ] The strides format has two components: offset - the offset of the tensor relative to the underlying storage strides array, whose length is equal to the number of dimensions of the tensor. strides[i] indicates how many ‚Äúelements‚Äù need to be skipped in memory to move ‚Äúone unit‚Äù in the $i$-th dimension of the tensor For example, considering the earlier example of a 2D array, if we interpret it using the strides format python A[i][j] = A_in_row[ 0 + i * A.shape[1] + j * 1 ] For a 2D array of size (A.shape[0], A.shape[1]), its offset is 0, and the strides array is [A.shape[1], 1](row-major). ü§îÔ∏è This means that moving ‚Äúone unit‚Äù in the first dimension requires skipping A.shape[1] elements in the underlying memory, where A.shape[1] is the length of each row I made this image to give you better intuition :) üßê How to obtain the strides array for an $N$ dimensional tensor? Let‚Äôs say we want to calculate strides[k] for the $k$-th dimension. We know the semantic of strides[k] is the elements to skip in the underlying memory to moving ‚Äúone unit‚Äù in the $k$-th dimension, If the memory layout of the tensor is continuous, then the answer would be the product of $k+1,k+2,‚Ä¶, N-1$. If $k=N-1$, then strides[N - 1] = 1 The mathematical formula is as follows: $$strides[k]=\\prod_{i=k+1}^{N-1}shape[i]$$ üí° It is important to reiterate that the above formula holds only when the tensor‚Äôs underlying memory layout is contiguous. ","date":"2023-07-14","objectID":"/en/how-to-reprensent-a-tensor-or-ndarray/:3:0","series":null,"tags":["Internal","Pytorch","Deep-Learning"],"title":"Demystifying Pytorch's Strides Format","uri":"/en/how-to-reprensent-a-tensor-or-ndarray/#strides-format"},{"categories":["ML-DL","Internal"],"content":" Why stridesÔºüAfter understanding the strides format. The next question would be: Why do we need the strides format and what benefits it brings? The most significant advantage is that many tensor operations can be performed in a zero-copy manner. By using the strides format, the concepts of ‚Äúunderlying storage‚Äù and ‚Äúviews‚Äù are separated. Now let‚Äôs talk about some common tensor operations ","date":"2023-07-14","objectID":"/en/how-to-reprensent-a-tensor-or-ndarray/:4:0","series":null,"tags":["Internal","Pytorch","Deep-Learning"],"title":"Demystifying Pytorch's Strides Format","uri":"/en/how-to-reprensent-a-tensor-or-ndarray/#why-strides"},{"categories":["ML-DL","Internal"],"content":" print_internal functionBefore we start to investigate the tensor operations, we need to write a helper function such that we can get the underlying storage. Pytorch provides us with the data_ptr API, which will return the address of the first element of a tensor. Then, by using the storage().nbytes() method provided by PyTorch, we can determine the amount of memory space the tensor‚Äôs underlying storage occupies(in bytes)1. Additionally, the dtype attribute of the tensor informs us about the size of each element. For example, torch.float32 occupies 4 bytes Finally, we can use the ctypes.string_at(address, size=-1) function to read the tensor as a C-style string (buffer), and torch.frombuffer can be used to create a tensor from this buffer. Putting it all together, we can write this helper function called print_internal: python def print_internal(t: torch.Tensor): print( torch.frombuffer( ctypes.string_at(t.data_ptr(), t.storage().nbytes()), dtype=t.dtype ) ) Now we create a tensor t with dimension (1, 2, 3, 4) and observe its underlying representation. The subsequent operations and explanations will be based on this tensor t python torch.arange(0, 24).reshape(1, 2, 3, 4) print(t) # tensor([[[[ 0, 1, 2, 3], # [ 4, 5, 6, 7], # [ 8, 9, 10, 11]], # [[12, 13, 14, 15], # [16, 17, 18, 19], # [20, 21, 22, 23]]]]) print(t.stride()) # (24, 12, 4, 1) print_internal(t) # tensor([0, 1, 2, 3, # 4, 5, 6, 7, # 8, 9, 10, 11, # 12, 13, 14, 15, # 16, 17, 18, 19, # 20, 21, 22, 23]) By using the formula we previously talked about, we know the strides of t should be (2 * 3 * 4, 3 * 4, 4, 1), that is, (24, 12, 4, 1). The t.stride() will give us the strides array maintained by Pytorch. Indeed, it gives us the answer which is exactly what we expected. ","date":"2023-07-14","objectID":"/en/how-to-reprensent-a-tensor-or-ndarray/:4:1","series":null,"tags":["Internal","Pytorch","Deep-Learning"],"title":"Demystifying Pytorch's Strides Format","uri":"/en/how-to-reprensent-a-tensor-or-ndarray/#print_internal-function"},{"categories":["ML-DL","Internal"],"content":" permute operationsSuppose we rearrange the dimensions with permute, how does strides change? python print(t.stride()) # (24, 12, 4, 1) print(t.permute((1, 2, 3, 0)).is_contiguous()) # True print(t.permute((1, 2, 3, 0)).stride()) # (12, 4, 1, 24) print(t.permute((0, 2, 3, 1)).is_contiguous()) # False print(t.permute((0, 2, 3, 1)).stride()) # (24, 4, 1, 12) print(t.permute((1, 0, 3, 2)).is_contiguous()) # False print(t.permute((1, 0, 3, 2)).stride()) # (12, 24, 1, 4) print_internal(t.permute((1, 2, 3, 0))) # tensor([0, 1, 2, 3, # 4, 5, 6, 7, # 8, 9, 10, 11, # 12, 13, 14, 15, # 16, 17, 18, 19, # 20, 21, 22, 23]) As indicated by these examples, the permute operation will not change offset. However, the permute operation will usually make the underlying storage incompact. Although we can use the new_shape after permuting to re-calculate the strides array, a better way would be just permute the original strides array. The output of print_internal indicates that the permute operation is lazy2. ","date":"2023-07-14","objectID":"/en/how-to-reprensent-a-tensor-or-ndarray/:4:2","series":null,"tags":["Internal","Pytorch","Deep-Learning"],"title":"Demystifying Pytorch's Strides Format","uri":"/en/how-to-reprensent-a-tensor-or-ndarray/#permute-operations"},{"categories":["ML-DL","Internal"],"content":" broadcast_to operationBroadcast_to operation is an interesting operation. Before knowing the internals, you might think that broadcasting involves copying along the corresponding dimensions. However, there is no copying under the hood. Pytorch just change the strides array. More specifically, Pytorch will set stride[k] = 0 if its size is one before broadcasting3. Let‚Äôs try to do broadcasting along the first dimension of tensor t and observe how the shape and strides will change python print(t.broadcast_to((2, 2, 3, 4)).is_contiguous()) # False print(t.broadcast_to((2, 2, 3, 4)).shape) # torch.Size([2, 2, 3, 4]) print(t.stride()) # (24, 12, 4, 1) print(t.broadcast_to((2, 2, 3, 4)).stride()) # (0, 12, 4, 1) print_internal(t.broadcast_to((2, 2, 3, 4))) # tensor([0, 1, 2, 3, # 4, 5, 6, 7, # 8, 9, 10, 11, # 12, 13, 14, 15, # 16, 17, 18, 19, # 20, 21, 22, 23]) Surprisingly, Pytorch does not allocate memory, and copy elements in the dimension got broadcasted. The only thing that changed is the strides array. Pause for a second and try to figure out what‚Äôs the meaning of setting stride as 0. It means we don‚Äôt need to skip any elements along this dimension, which indicates we are referring to the same data(same memory location). ","date":"2023-07-14","objectID":"/en/how-to-reprensent-a-tensor-or-ndarray/:4:3","series":null,"tags":["Internal","Pytorch","Deep-Learning"],"title":"Demystifying Pytorch's Strides Format","uri":"/en/how-to-reprensent-a-tensor-or-ndarray/#broadcast_to-operation"},{"categories":["ML-DL","Internal"],"content":" reshape operation and contiguous operationThe indexing operation may modify the offset because the resulting tensor after indexing may not start from the first element of the original underlying storage. Moreover, the indexing operation may access the non-contiguous parts of the underlying storage. So the indexing operation will help us to understand the reshape and contiguous operations better. Let‚Äôs say we want to get the following tensor from t python [[[2, 6, 10], [14, 18, 22]]] The corresponding indexing operation is python print(t[:, :, :, 2]) # tensor([[[ 2, 6, 10], # [14, 18, 22]]]) Note that this operation aligns with what I mentioned earlier: the offset will change because the resulting tensor starts from 2 rather than 0 The elements accessed by indexing are not contiguous in the original memory The following code proves our speculation python print(t.storage_offset()) # 0 print(t[:, :, :, 2].storage_offset()) # 2 print(t[:, :, :, 2].is_contiguous()) # False Now let‚Äôs observe the underlying storage python print_internal(t[:, :, :, 2]) # tensor([ 2, 3, # 4, 5, 6, 7, # 8, 9, 10, 11, # 12, 13, 14, 15, # 16, 17, 18, 19, # 20, 21, 22, 23 # 1152921504606846976, -8070441752123218147]]) # ignore the last row because t.data_ptr() has changed but t.storage().nbytes() # kept the same. # As a result, we read 2 invalid elements and get 2 meaningless values Pytorch‚Äôs tensor has a method called storage_offset() which shows the offset in the underlying storage. As we can see, now it starts from the second position in the underlying storage, which corresponds to the first element 2 of t[:, :, :, 2]. And the underlying storage is still the same Note: Because the underlying storage remains unchanged, t.storage().nbytes() remains the same. The data_ptr() will give us the address of the second element. As a result, the printed underlying array will have two additional meaningless positions (as seen in the last row), resulting in two extra irrelevant numbers. ü§îÔ∏è Let‚Äôs try to use reshape(3, 2) after indexing and observe the underlying storage python print_internal(t[:, :, :, 2].reshape(3, 2)) # tensor([ 2, 3, # 4, 5, 6, 7, # 8, 9, 10, 11, # 12, 13, 14, 15, # 16, 17, 18, 19, # 20, 21, 22, 23 # 1152921504606846976, -8070441752123218147]]) We find that the reshape operation does not change the underlying storage. This aligns with what the documentation states: When possible, the returned tensor will be a view of input4 What if we want the tensor after reshape to have compact storage? We can use the contiguous method python print_internal(t[:, :, :, 2].reshape(3, 2).contiguous()) # tensor([ 2, 6, 10, 14, 18, 22]) üò∫ By chaining reshape and contiguous operations, we make the underlying storage compact. And the strides array should align with the aforementioned formula: python # before contiguous print(t[:, :, :, 2].reshape(3, 2).stride()) # (8, 4) # after contiguous print(t[:, :, :, 2].reshape(3, 2).contiguous().shape) # (3, 2) print(t[:, :, :, 2].reshape(3, 2).contiguous().stride()) # (2, 1) üßê One challenging question for you, how indexing operation will change the strides array? Let‚Äôs use the previous indexing operation as an example. First, after indexing, the new dimensions should be (1, 2, 3). The indexing pattern [:, :, :, 2] results in a non-compact underlying storage. So we can not just compute the strides array by the rule. Therefore, we have to reason the strides array based on the definitions. Let‚Äôs assume the strides array of t[:, :, :, 2] is [x, y, z] We can observe which elements are included in t[:, :, :, 2] python print(t[:, :, :, 2]) # tensor([[[ 2, 6, 10], # [14, 18, 22]]]) Because the tensor t starts from 0 and increments by one, we can just compute the strides based on the values(a little trick) for z, we find 2 -\u003e 6 -\u003e 10, that is, we skip 4 elements each time. So z = 4 for y, we find 2 -\u003e 14, 6 -\u003e 18, 10 -\u003e 22, we skip 12 elements each time. So y = 12 for x, since the underlying storage has not changed, the original tensor","date":"2023-07-14","objectID":"/en/how-to-reprensent-a-tensor-or-ndarray/:4:4","series":null,"tags":["Internal","Pytorch","Deep-Learning"],"title":"Demystifying Pytorch's Strides Format","uri":"/en/how-to-reprensent-a-tensor-or-ndarray/#reshape-operation-and-contiguous-operation"},{"categories":["ML-DL","Internal"],"content":" Wrap upAs you can see, many operations on Pytorch tensors are achieved by modifying the offset or(and) strides array. This approach allows many operations to maintain zero-copy overhead, leading to high efficiency. Moreover, this enables the lazy operations. Understanding the strides format helps in constructing a mental model of tensors and facilitates a better understanding of tensor operation code. I would also recommend watching the awesome video which talks about the cool tricks that manipulating strides to perform convolution efficiently Now we can answer the questions raised earlier: Does broadcasting involve copying arrays? No, broadcasting will only change the strides array What does contiguous do in Pytorch, and why is this function needed? By using contiguous, we can make the underlying storage compact. Although this may involve copying, it is beneficial for later calculation because of the memory locality. ","date":"2023-07-14","objectID":"/en/how-to-reprensent-a-tensor-or-ndarray/:5:0","series":null,"tags":["Internal","Pytorch","Deep-Learning"],"title":"Demystifying Pytorch's Strides Format","uri":"/en/how-to-reprensent-a-tensor-or-ndarray/#wrap-up"},{"categories":["ML-DL","Internal"],"content":" Refs Tensor type memory usage - Memory Format - PyTorch Forums¬†‚Ü©Ô∏é torch.permute - PyTorch 2.3 documentation¬†‚Ü©Ô∏é torch.expand - PyTorch 2.0 documentation¬†‚Ü©Ô∏é torch.reshape ‚Äî PyTorch 2.0 documentation¬†‚Ü©Ô∏é ","date":"2023-07-14","objectID":"/en/how-to-reprensent-a-tensor-or-ndarray/:6:0","series":null,"tags":["Internal","Pytorch","Deep-Learning"],"title":"Demystifying Pytorch's Strides Format","uri":"/en/how-to-reprensent-a-tensor-or-ndarray/#refs"},{"categories":["Data-Structure"],"content":"A simple introduction of how the 2-3-4 tree and the Red-black tree is related, and how to memorize the Red-black with the help of 2-3-4 tree","date":"2023-07-01","objectID":"/en/how-to-memorize-insertion-and-deletion-in-rb-tree/","series":null,"tags":["Data-Structure"],"title":"How to memorize the Red-black tree","uri":"/en/how-to-memorize-insertion-and-deletion-in-rb-tree/"},{"categories":["Data-Structure"],"content":" IntroIf you are attracted by the title of this blog, I believe you may agree with me: The process of memorizing the insertion and deletion operations of the Red-black tree can be incredibly arduous. It entails keeping track of complex tree rotations and the necessity to recolor nodes as required. I once read the renowned Introducing to Algorithms written by the CLRS. However, there are so many cases to remember and I quickly get overwhelmed. Of course, the best way to remember something is always to understand it. Recently, when I saw the slides for Stanford‚Äôs CS166 Advanced Data Structures course. It seems like I finally understand the Red-black tree - the Red-black tree is an isometry of 2-3-4 tree. They represent the structure of 2-3-4 trees in a different way1. So how can this help us? Well, We can deduce the changes in shape and color in a Red-black tree by observing the changes in the corresponding 2-3-4 tree. Before we begin, I assume that you are familiar with the following: You know the definitions of a 2-3-4 tree or B-tree. A 2-3-4 tree is a type of B-tree. You need to know how to perform deletion and insertion operations on a 2-3-4 tree, when nodes overflow or underflow, and how to handle these cases You know how to insert and delete nodes in a binary search tree(BST) because a Red-black tree itself is a BST that ensures a height of $O(log n)$. You should already know how to find the insertion position and determine which node to delete in BST You need to understand the definitions of Red-black trees and 2-3-4 trees. You should understand the properties of Red-black trees and which properties can be violated during node insertion and deletion Most importantly, you don‚Äôt need to memorize the rotations and color changes in Red-black trees because once you grasp the techniques I‚Äôm going to discuss today, you can establish an intuitive connection between operations on Red-black trees and operations on 2-3-4 trees ","date":"2023-07-01","objectID":"/en/how-to-memorize-insertion-and-deletion-in-rb-tree/:1:0","series":null,"tags":["Data-Structure"],"title":"How to memorize the Red-black tree","uri":"/en/how-to-memorize-insertion-and-deletion-in-rb-tree/#intro"},{"categories":["Data-Structure"],"content":" Nodes mappingsThere are 3 possible node types in a 2-3-4 tree: 2-node, 2 children with 1 key 3-node, 3 children with 2 key 4-node, 4 children with 3 key The node mappings tell us how to map a node in a 2-3-4 tree to nodes in the corresponding Red-black tree and vice versa. Note that all the structures of a Red-black in the following image start from a black node. We will use the node mappings extensively later. LHS: 2/3/4-node, RHS: the corresponding node structures ","date":"2023-07-01","objectID":"/en/how-to-memorize-insertion-and-deletion-in-rb-tree/:2:0","series":null,"tags":["Data-Structure"],"title":"How to memorize the Red-black tree","uri":"/en/how-to-memorize-insertion-and-deletion-in-rb-tree/#nodes-mappings"},{"categories":["Data-Structure"],"content":" InsertionLet‚Äôs recap how to insert a node in a Red-black tree: Red-black trees are BSTs, so initially, we use the method of inserting nodes in a BST to find the appropriate position for insertion If the newly inserted node becomes the root node (i.e., the original Red-black tree is empty), then the newly inserted node is colored black. In other cases, it is colored red. This is because one of the properties of Red-black trees states that every path from any node to its leaf nodes contains an equal number of black nodes. By coloring the newly inserted node in red, we can maintain this property. We will only consider the case where the newly inserted node is colored red later If the newly inserted node is red, it means that it may violate another property of the Red-black tree: there cannot be two consecutive red nodes. Red-black trees solve this problem by using tree rotations and node recoloring üé®, but the rules can be complex and difficult to remember Before showing specific examples, let‚Äôs summarize the general approach to insertion: Insert this new node and color it red Transform the ‚Äúviolating part‚Äù of the Red-black tree into an equivalent form on a 2-3-4 tree Consider how to handle the equivalent form on the 2-3-4 tree After handling it on the 2-3-4 tree, transform it back to a Red-black tree. At this point, the shape and color are determined üí° To help readers understand how to transform between 2-3-4 tree and Red-black tree, I have used a colored transparent box to highlight the equivalent parts before and after the transformation üí° I chose to use specific numerical values instead of abstract symbols because it provides a more intuitive understanding and makes it easier for readers to find connections between 2-3-4 tree and Red-black tree ","date":"2023-07-01","objectID":"/en/how-to-memorize-insertion-and-deletion-in-rb-tree/:3:0","series":null,"tags":["Data-Structure"],"title":"How to memorize the Red-black tree","uri":"/en/how-to-memorize-insertion-and-deletion-in-rb-tree/#insertion"},{"categories":["Data-Structure"],"content":" Its parent node is blackA trivial case woudl be, the newly insertion node‚Äôs parent node is black. By the definition of the Red-black tree, we know we don‚Äôt need to change anything ","date":"2023-07-01","objectID":"/en/how-to-memorize-insertion-and-deletion-in-rb-tree/:3:1","series":null,"tags":["Data-Structure"],"title":"How to memorize the Red-black tree","uri":"/en/how-to-memorize-insertion-and-deletion-in-rb-tree/#its-parent-node-is-black"},{"categories":["Data-Structure"],"content":" Its parent node is red and it has no uncle nodeNext, let‚Äôs consider a slightly more complex scenario where the parent node of the newly inserted node is red. Red-black trees do not allow such a situation to occur. In this case, the newly inserted node may or may not have an uncle node. Let‚Äôs first consider the scenario where it does not have an uncle node. We can easily draw the following possible forms: Please note that all of these forms are equivalent. Below, I will demonstrate how to operate the first example shown in the above diagram üí° In the subsequent discussions of other scenarios, they may also have equivalent forms. However, the methods are generally similar, so I will pick one example to explain each time. Based on the node mappings mentioned earlier, the Red-black tree before insertion corresponds exactly to a 3-node on the 2-3-4 tree. Then, we insert the node 1 into the Red-black tree. At the same time, we perform the insertion operation on the 3-node, resulting in a 4-node. The 4-node satisfies the requirements of a 2-3-4 tree, so there is no need to split the node. At this point, we can transform it back into a Red-black tree based on the node mappings At this point, you may feel that the 2-3-4 tree doesn‚Äôt bring much convenience because a simple right rotation and recoloring are not complex tasks in this case. However, as the scenarios become more complex, you will find that the perspective from the 2-3-4 tree can be much easier to comprehendü§îÔ∏è. ","date":"2023-07-01","objectID":"/en/how-to-memorize-insertion-and-deletion-in-rb-tree/:3:2","series":null,"tags":["Data-Structure"],"title":"How to memorize the Red-black tree","uri":"/en/how-to-memorize-insertion-and-deletion-in-rb-tree/#its-parent-node-is-red-and-it-has-no-uncle-node"},{"categories":["Data-Structure"],"content":" Its parent node is red and it has an uncle nodeNow let‚Äôs consider a more complex scenario where the uncle node exists, which can be either black or red Let‚Äôs first take a look at one of the possible cases when the uncle node is black Based on the node mappings, we can map the 2, 5 nodes in the Red-black tree to a 3-node on the 2-3-4 tree, while the 7 node on the Red-black tree maps to a 2-node. When we insert 1 into the Red-black tree, we also insert 1 into the 3-node consisting of 2 and 5. The resulting 1, 2, 5 is mapped to a black node with two red children according to the rules. The 7 node is mapped as a black node But what if the uncle node is red? For example, in the case shown below. This case will be slightly more complex. Because after inserting 1 into the equivalent 2-3-4 tree, we need to perform a split operation on 1, 2, 5, 7. This means that we need to insert the node 5 into the parent node. *Since we don‚Äôt know the specific state of the parent node, the ellipses(...) are used to represent the nodes on both sides of 5. Inserting a node into the parent node in the 2-3-4 tree may also cause the parent node to overflow, and in the worst case, we need to modify all the way back Additionally, it‚Äôs important to note that the grandparent node of the newly inserted node should be red. In the example, node 5 is the grandparent of the newly inserted node 1. This ensures that every path from any node to its leaf nodes contains the same number of black nodes. However, there is one exception, which is when the grandparent node is the root node of the Red-black tree. In that case, it should be black. The following diagram clearly shows these two possibilities. ","date":"2023-07-01","objectID":"/en/how-to-memorize-insertion-and-deletion-in-rb-tree/:3:3","series":null,"tags":["Data-Structure"],"title":"How to memorize the Red-black tree","uri":"/en/how-to-memorize-insertion-and-deletion-in-rb-tree/#its-parent-node-is-red-and-it-has-an-uncle-node"},{"categories":["Data-Structure"],"content":" DeletionLet‚Äôs recap how to perform node deletion in a Red-black tree: Following the procedure of deleting a node in a BST, find the node to be deleted. Let‚Äôs assume it is node z Based on the color of node z, we can distinguish the following two cases: z is red. Deleting a red node is relatively straightforward because it doesn‚Äôt break the properties of the Red-black tree. We won‚Äôt delve into this case here. z is black. Deleting a black node may potentially break the property of the Red-black tree that requires every path from any node to its leaf nodes to contain the same number of black nodes. In the Red-black tree, encountering this case still requires tree rotations and node recoloringüé® to resolve the issue. The following discussion primarily focuses on this scenario ","date":"2023-07-01","objectID":"/en/how-to-memorize-insertion-and-deletion-in-rb-tree/:4:0","series":null,"tags":["Data-Structure"],"title":"How to memorize the Red-black tree","uri":"/en/how-to-memorize-insertion-and-deletion-in-rb-tree/#deletion"},{"categories":["Data-Structure"],"content":" The node to delete has a single right child(red) üí° Based on the deletion procedure of BST, we know that the node z to be deleted does not have a left child. If It has a right child, we will denote it as y üí° The yellow node represents the unknown color or is irrelevant Delete the black z and replace z with red y ","date":"2023-07-01","objectID":"/en/how-to-memorize-insertion-and-deletion-in-rb-tree/:4:1","series":null,"tags":["Data-Structure"],"title":"How to memorize the Red-black tree","uri":"/en/how-to-memorize-insertion-and-deletion-in-rb-tree/#the-node-to-delete-has-a-single-right-childred"},{"categories":["Data-Structure"],"content":" The node to delete has a single right child(black)Let‚Äôs temporarily replace the black z with the black y, and mark y as a ‚Äúdouble black‚Äù node. *In the diagram, a black node with a circular border represents a ‚Äúdouble black‚Äù node2 üí° In the context of a Red-black tree, ‚Äúdouble black‚Äù means that we need two black nodes on this side. In the context of a 2-3-4 tree, it corresponds to an underflow situation after you delete a key in a 2-node Delete the black z and replace z with black y, and mark y as ‚Äúdouble black‚Äù Now we need to talk about the different cases based on the sibling node of this ‚Äúdouble black‚Äù node If the sibling node is black and it has a red child In the above example, when we transform it into an equivalent 2-3-4 tree deletion operation, we encounter a situation in the 2-3-4 tree where a transfer operation is required because the sibling nodes 6, 7 is a 3-node, and we need to borrow a key from them. The transfer operation involves moving the key from the parent node to the position of the deleted node, and then moving the minimum key from the sibling node to the parent node to fill the gap üí° Note that now 4 and 5 are two black nodes. Previously, this was a special ‚Äúdouble black‚Äù node, but now that we have two black nodes, the ‚Äúdouble black‚Äù node is no longer necessary. That‚Äôs also the reason why it‚Äôs called a ‚Äúdouble black‚Äù node‚Äîwe need to remind ourselves that two black nodes are needed here. üí° Note that the color of node 6 is the same as the original color of node 5 If the sibling node is black and it has two black children In the above example, when we transform it into an equivalent 2-3-4 tree deletion operation, we encounter a situation in the 2-3-4 tree where a fusion operation is required because the sibling node 7 is a 2-node and cannot lend a key. The fusion operation involves borrowing a key from the parent node and merging it with the sibling node to form a 3-node - 5, 7 üí° However, note that in this fusion operation, when we borrow a key from the parent node, it may cause the parent node to underflow, just as we may encounter overflow when inserting a new node. Based on the node mappings rules, node 5 in this example should be colored black, and we can get rid of the ‚Äúdouble black‚Äù node. However, we should not forget that 5 itself has its own color If 5 was originally red, then changing it to black is not a problem because node 7 is now red If 5 was originally black, then changing it to black would be problematic as it would result in a missing black node. In this case, node 5 becomes a new ‚Äúdouble black‚Äù node, and we may need to continue adjusting upwards. This corresponds precisely to the underflow situation in a 2-3-4 tree. We need to bottom-up adjust our way back to the root node. Finally, if we find that the root node is a double black node, we simply change it to a black node. If the sibling node is red and it has two black childrenThe last scenario is when the sibling node is red and has two black children üí° Note that if the sibling node is red, then the parent should be a black node, as a Red-black tree does not allow two consecutive red nodes This situation can be cleverly transformed into one of the previous cases Now the node 4‚Äôs sibling node is black ","date":"2023-07-01","objectID":"/en/how-to-memorize-insertion-and-deletion-in-rb-tree/:4:2","series":null,"tags":["Data-Structure"],"title":"How to memorize the Red-black tree","uri":"/en/how-to-memorize-insertion-and-deletion-in-rb-tree/#the-node-to-delete-has-a-single-right-childblack"},{"categories":["Data-Structure"],"content":" The node to delete has a single right child(black)Let‚Äôs temporarily replace the black z with the black y, and mark y as a ‚Äúdouble black‚Äù node. *In the diagram, a black node with a circular border represents a ‚Äúdouble black‚Äù node2 üí° In the context of a Red-black tree, ‚Äúdouble black‚Äù means that we need two black nodes on this side. In the context of a 2-3-4 tree, it corresponds to an underflow situation after you delete a key in a 2-node Delete the black z and replace z with black y, and mark y as ‚Äúdouble black‚Äù Now we need to talk about the different cases based on the sibling node of this ‚Äúdouble black‚Äù node If the sibling node is black and it has a red child In the above example, when we transform it into an equivalent 2-3-4 tree deletion operation, we encounter a situation in the 2-3-4 tree where a transfer operation is required because the sibling nodes 6, 7 is a 3-node, and we need to borrow a key from them. The transfer operation involves moving the key from the parent node to the position of the deleted node, and then moving the minimum key from the sibling node to the parent node to fill the gap üí° Note that now 4 and 5 are two black nodes. Previously, this was a special ‚Äúdouble black‚Äù node, but now that we have two black nodes, the ‚Äúdouble black‚Äù node is no longer necessary. That‚Äôs also the reason why it‚Äôs called a ‚Äúdouble black‚Äù node‚Äîwe need to remind ourselves that two black nodes are needed here. üí° Note that the color of node 6 is the same as the original color of node 5 If the sibling node is black and it has two black children In the above example, when we transform it into an equivalent 2-3-4 tree deletion operation, we encounter a situation in the 2-3-4 tree where a fusion operation is required because the sibling node 7 is a 2-node and cannot lend a key. The fusion operation involves borrowing a key from the parent node and merging it with the sibling node to form a 3-node - 5, 7 üí° However, note that in this fusion operation, when we borrow a key from the parent node, it may cause the parent node to underflow, just as we may encounter overflow when inserting a new node. Based on the node mappings rules, node 5 in this example should be colored black, and we can get rid of the ‚Äúdouble black‚Äù node. However, we should not forget that 5 itself has its own color If 5 was originally red, then changing it to black is not a problem because node 7 is now red If 5 was originally black, then changing it to black would be problematic as it would result in a missing black node. In this case, node 5 becomes a new ‚Äúdouble black‚Äù node, and we may need to continue adjusting upwards. This corresponds precisely to the underflow situation in a 2-3-4 tree. We need to bottom-up adjust our way back to the root node. Finally, if we find that the root node is a double black node, we simply change it to a black node. If the sibling node is red and it has two black childrenThe last scenario is when the sibling node is red and has two black children üí° Note that if the sibling node is red, then the parent should be a black node, as a Red-black tree does not allow two consecutive red nodes This situation can be cleverly transformed into one of the previous cases Now the node 4‚Äôs sibling node is black ","date":"2023-07-01","objectID":"/en/how-to-memorize-insertion-and-deletion-in-rb-tree/:4:2","series":null,"tags":["Data-Structure"],"title":"How to memorize the Red-black tree","uri":"/en/how-to-memorize-insertion-and-deletion-in-rb-tree/#if-the-sibling-node-is-black-and-it-has-a-red-child"},{"categories":["Data-Structure"],"content":" The node to delete has a single right child(black)Let‚Äôs temporarily replace the black z with the black y, and mark y as a ‚Äúdouble black‚Äù node. *In the diagram, a black node with a circular border represents a ‚Äúdouble black‚Äù node2 üí° In the context of a Red-black tree, ‚Äúdouble black‚Äù means that we need two black nodes on this side. In the context of a 2-3-4 tree, it corresponds to an underflow situation after you delete a key in a 2-node Delete the black z and replace z with black y, and mark y as ‚Äúdouble black‚Äù Now we need to talk about the different cases based on the sibling node of this ‚Äúdouble black‚Äù node If the sibling node is black and it has a red child In the above example, when we transform it into an equivalent 2-3-4 tree deletion operation, we encounter a situation in the 2-3-4 tree where a transfer operation is required because the sibling nodes 6, 7 is a 3-node, and we need to borrow a key from them. The transfer operation involves moving the key from the parent node to the position of the deleted node, and then moving the minimum key from the sibling node to the parent node to fill the gap üí° Note that now 4 and 5 are two black nodes. Previously, this was a special ‚Äúdouble black‚Äù node, but now that we have two black nodes, the ‚Äúdouble black‚Äù node is no longer necessary. That‚Äôs also the reason why it‚Äôs called a ‚Äúdouble black‚Äù node‚Äîwe need to remind ourselves that two black nodes are needed here. üí° Note that the color of node 6 is the same as the original color of node 5 If the sibling node is black and it has two black children In the above example, when we transform it into an equivalent 2-3-4 tree deletion operation, we encounter a situation in the 2-3-4 tree where a fusion operation is required because the sibling node 7 is a 2-node and cannot lend a key. The fusion operation involves borrowing a key from the parent node and merging it with the sibling node to form a 3-node - 5, 7 üí° However, note that in this fusion operation, when we borrow a key from the parent node, it may cause the parent node to underflow, just as we may encounter overflow when inserting a new node. Based on the node mappings rules, node 5 in this example should be colored black, and we can get rid of the ‚Äúdouble black‚Äù node. However, we should not forget that 5 itself has its own color If 5 was originally red, then changing it to black is not a problem because node 7 is now red If 5 was originally black, then changing it to black would be problematic as it would result in a missing black node. In this case, node 5 becomes a new ‚Äúdouble black‚Äù node, and we may need to continue adjusting upwards. This corresponds precisely to the underflow situation in a 2-3-4 tree. We need to bottom-up adjust our way back to the root node. Finally, if we find that the root node is a double black node, we simply change it to a black node. If the sibling node is red and it has two black childrenThe last scenario is when the sibling node is red and has two black children üí° Note that if the sibling node is red, then the parent should be a black node, as a Red-black tree does not allow two consecutive red nodes This situation can be cleverly transformed into one of the previous cases Now the node 4‚Äôs sibling node is black ","date":"2023-07-01","objectID":"/en/how-to-memorize-insertion-and-deletion-in-rb-tree/:4:2","series":null,"tags":["Data-Structure"],"title":"How to memorize the Red-black tree","uri":"/en/how-to-memorize-insertion-and-deletion-in-rb-tree/#if-the-sibling-node-is-black-and-it-has-two-black-children"},{"categories":["Data-Structure"],"content":" The node to delete has a single right child(black)Let‚Äôs temporarily replace the black z with the black y, and mark y as a ‚Äúdouble black‚Äù node. *In the diagram, a black node with a circular border represents a ‚Äúdouble black‚Äù node2 üí° In the context of a Red-black tree, ‚Äúdouble black‚Äù means that we need two black nodes on this side. In the context of a 2-3-4 tree, it corresponds to an underflow situation after you delete a key in a 2-node Delete the black z and replace z with black y, and mark y as ‚Äúdouble black‚Äù Now we need to talk about the different cases based on the sibling node of this ‚Äúdouble black‚Äù node If the sibling node is black and it has a red child In the above example, when we transform it into an equivalent 2-3-4 tree deletion operation, we encounter a situation in the 2-3-4 tree where a transfer operation is required because the sibling nodes 6, 7 is a 3-node, and we need to borrow a key from them. The transfer operation involves moving the key from the parent node to the position of the deleted node, and then moving the minimum key from the sibling node to the parent node to fill the gap üí° Note that now 4 and 5 are two black nodes. Previously, this was a special ‚Äúdouble black‚Äù node, but now that we have two black nodes, the ‚Äúdouble black‚Äù node is no longer necessary. That‚Äôs also the reason why it‚Äôs called a ‚Äúdouble black‚Äù node‚Äîwe need to remind ourselves that two black nodes are needed here. üí° Note that the color of node 6 is the same as the original color of node 5 If the sibling node is black and it has two black children In the above example, when we transform it into an equivalent 2-3-4 tree deletion operation, we encounter a situation in the 2-3-4 tree where a fusion operation is required because the sibling node 7 is a 2-node and cannot lend a key. The fusion operation involves borrowing a key from the parent node and merging it with the sibling node to form a 3-node - 5, 7 üí° However, note that in this fusion operation, when we borrow a key from the parent node, it may cause the parent node to underflow, just as we may encounter overflow when inserting a new node. Based on the node mappings rules, node 5 in this example should be colored black, and we can get rid of the ‚Äúdouble black‚Äù node. However, we should not forget that 5 itself has its own color If 5 was originally red, then changing it to black is not a problem because node 7 is now red If 5 was originally black, then changing it to black would be problematic as it would result in a missing black node. In this case, node 5 becomes a new ‚Äúdouble black‚Äù node, and we may need to continue adjusting upwards. This corresponds precisely to the underflow situation in a 2-3-4 tree. We need to bottom-up adjust our way back to the root node. Finally, if we find that the root node is a double black node, we simply change it to a black node. If the sibling node is red and it has two black childrenThe last scenario is when the sibling node is red and has two black children üí° Note that if the sibling node is red, then the parent should be a black node, as a Red-black tree does not allow two consecutive red nodes This situation can be cleverly transformed into one of the previous cases Now the node 4‚Äôs sibling node is black ","date":"2023-07-01","objectID":"/en/how-to-memorize-insertion-and-deletion-in-rb-tree/:4:2","series":null,"tags":["Data-Structure"],"title":"How to memorize the Red-black tree","uri":"/en/how-to-memorize-insertion-and-deletion-in-rb-tree/#if-the-sibling-node-is-red-and-it-has-two-black-children"},{"categories":["Data-Structure"],"content":" Wrap upAfter examining the previous examples, we have discovered that we can think about how to handle operations on a 2-3-4 tree and then convert it back to a Red-black tree. The operations of inserting and deleting nodes in a 2-3-4 tree are relatively simple, which is the main advantage of this approach. Most importantly, we no longer need to remember the rotation order and color exchanges, which is a significant improvementüëè. That‚Äôs how I memorize the Red-black trees ","date":"2023-07-01","objectID":"/en/how-to-memorize-insertion-and-deletion-in-rb-tree/:5:0","series":null,"tags":["Data-Structure"],"title":"How to memorize the Red-black tree","uri":"/en/how-to-memorize-insertion-and-deletion-in-rb-tree/#wrap-up"},{"categories":["Data-Structure"],"content":" Recommend reading CS166. Balanced Trees, Part I CS166. Balanced Trees, Part II CS280. Mapping 2-3-4 trees into Red-Black trees ","date":"2023-07-01","objectID":"/en/how-to-memorize-insertion-and-deletion-in-rb-tree/:6:0","series":null,"tags":["Data-Structure"],"title":"How to memorize the Red-black tree","uri":"/en/how-to-memorize-insertion-and-deletion-in-rb-tree/#recommend-reading"},{"categories":["Data-Structure"],"content":" Ref CS166. Balanced Trees, Part II¬†‚Ü©Ô∏é Red Black Trees¬†‚Ü©Ô∏é ","date":"2023-07-01","objectID":"/en/how-to-memorize-insertion-and-deletion-in-rb-tree/:7:0","series":null,"tags":["Data-Structure"],"title":"How to memorize the Red-black tree","uri":"/en/how-to-memorize-insertion-and-deletion-in-rb-tree/#ref"},{"categories":["Git"],"content":"A simple introduction of git bundle command","date":"2023-06-16","objectID":"/en/git-bundle-tutorial/","series":null,"tags":["Git"],"title":"Git bundle guide","uri":"/en/git-bundle-tutorial/"},{"categories":["Git"],"content":" What is the git bundle commandgit bundle is a relatively less commonly used git command. Its purpose is to package a git repo into a single file, which can then be used by others to recreate the original git repo. Additionally, git bundle supports incremental update. Before I learned about the git bundle command, I would usually directly use tar czf some_git_repo to create a package for a git repo. Recently, I accidentally discovered the git bundle and found it quite usefulüçª. To better explain this command, let‚Äôs use the folders HostA and HostB as an example, simulating two hosts. Let‚Äôs assume that there is a git repo named foo on HostA, with the following directory structure text ‚îú‚îÄ‚îÄ HostA ‚îÇ¬†‚îî‚îÄ‚îÄ foo ‚îÇ¬†‚îú‚îÄ‚îÄ 1.txt ‚îÇ¬†‚îú‚îÄ‚îÄ 2.txt ‚îÇ¬†‚îî‚îÄ‚îÄ 3.txt ‚îú‚îÄ‚îÄ HostB There are 3 dummy commits in foo text * 21486d5 (HEAD -\u003e main) add 3.txt * a051186 add 2.txt * 2820a6c add 1.txt ","date":"2023-06-16","objectID":"/en/git-bundle-tutorial/:1:0","series":null,"tags":["Git"],"title":"Git bundle guide","uri":"/en/git-bundle-tutorial/#what-is-the-git-bundle-command"},{"categories":["Git"],"content":" Usage","date":"2023-06-16","objectID":"/en/git-bundle-tutorial/:2:0","series":null,"tags":["Git"],"title":"Git bundle guide","uri":"/en/git-bundle-tutorial/#usage"},{"categories":["Git"],"content":" Full backup on HostAFor the first packaging, it is necessary to package the entire git repo. The command to package the foo repo on HostA is very simple sh # in HostA/foo # syntax: git bundle create \u003cfilename\u003e \u003cgit-rev-list-args\u003e $ git bundle create foo.bundle HEAD main It may be confusing what is the meaning of \u003cgit-rev-list-args\u003e. You may regard it as what we want to package into this bundle file. Here, we want to package the foo repo on HostA, which has a main branch. We also want to include the current location pointed to by HEAD, so we use HEAD main ","date":"2023-06-16","objectID":"/en/git-bundle-tutorial/:2:1","series":null,"tags":["Git"],"title":"Git bundle guide","uri":"/en/git-bundle-tutorial/#full-backup-on-hosta"},{"categories":["Git"],"content":" Make a copy on HostBNow, assuming that HostB has obtained the previously packaged foo.bundle file, recreating the original repo is also very simple, as shown in the following command sh # in HostB # syntax: git clone \u003cfilename\u003e \u003ctarget_dir\u003e $ git clone foo.bundle foo As you can see, extracting information from the bundle file is similar to cloning a regular repository from a URL, except that we replace the URL with the path to the bundle file At this point, if you check the remote repo info of this foo repo, you will notice that its remote repository has been set to the foo.bundle file sh # in HostB/foo $ git remote -v # output: # origin \u003cpath_to_foo.bundle\u003e (fetch) # origin \u003cpath_to_foo.bundle\u003e (push) ","date":"2023-06-16","objectID":"/en/git-bundle-tutorial/:2:2","series":null,"tags":["Git"],"title":"Git bundle guide","uri":"/en/git-bundle-tutorial/#make-a-copy-on-hostb"},{"categories":["Git"],"content":" Making more commits on HostANow assuming that we have made more commits in foo repo on HostA text * 9ac69b0 (HEAD -\u003e main) add 5.txt -- new commit * 0350a1e add 4.txt -- new commit * 21486d5 add 3.txt * a051186 add 2.txt * 2820a6c add 1.txt We want to package these two new commits and send the packaged bundle file to HostB so that we can make them in sync. By exploiting the syntax of specifying commit range1, we can use the following command to bundle the changes: sh # in HostA/foo # let's verify what will be bundled first $ git log --oneline 21486d5..main $ git bundle create increment.bundle 21486d5..main ","date":"2023-06-16","objectID":"/en/git-bundle-tutorial/:2:3","series":null,"tags":["Git"],"title":"Git bundle guide","uri":"/en/git-bundle-tutorial/#making-more-commits-on-hosta"},{"categories":["Git"],"content":" Incremental update on HostBAgain, let‚Äôs assume that the HostB has obtained the incremental.bundle file. The following command can be used to extract the commits inside sh # in HostB/foo # syntax: git fetch \u003cBUNDLE_FILE\u003e \u003cBRANCH_IN_BUNDLE\u003e:\u003cBRANCH_IN_LOCAL_REPO\u003e $ git fetch increment.bundle main:feature The command above will dump the commits contained in the incremental.bundle to a new feature branch sh # in HostB/foo $ git log --oneline --graph --all # output: # * 9ac69b0 (feature) add 5.txt # * 0350a1e add 4.txt # * 21486d5 (HEAD -\u003e main, origin/main, origin/HEAD) add 3.txt # * a051186 add 2.txt # * 2820a6c add 1.txt Once we are sure that there are no problems, we can attempt to merge the feature branch and delete it afterward sh # in HostB/foo $ git merge feature $ git branch -d feature $ git log --oneline --graph --all # output: # * 9ac69b0 (HEAD -\u003e main) add 5.txt # * 0350a1e add 4.txt # * 21486d5 (origin/main, origin/HEAD) add 3.txt # * a051186 add 2.txt # * 2820a6c add 1.txt ü§îÔ∏è You may wonder - Can we directly merge the commits from incremental.bundle into the main branch of foo repo on HostB? It‚Äôs possible, with the command: git pull increment.bundle main:main. However, it is not recommended to do so because foo repo on HostB may have also been updated. It is a good practice to first fetch and then merge You may still remember of that the remote branch of the foo repo on HostB was set to a specific bundle file. Can we directly use git pull to update foo? The answer is yes, we just need to rename the increment.bundle file to foo.bundle and place it in the path displayed by git remote -v (of course, changing the remote information is also an option) ","date":"2023-06-16","objectID":"/en/git-bundle-tutorial/:2:4","series":null,"tags":["Git"],"title":"Git bundle guide","uri":"/en/git-bundle-tutorial/#incremental-update-on-hostb"},{"categories":["Git"],"content":" FAQHow do we know what branches are included in a bundle file? The following command will handle this sh # syntax: git bundle list-heads \u003cBUNDLE_FILE\u003e $ git bundle list-heads increment.bundle # output: 9ac69b08060859bc4b2172a8238cb841846ec5e0 refs/heads/main How do we know if we can use a bundle file in a specific repo? Move the bundle file into your git repo and use git bundle verify sh # in HostB/foo # syntax: git bundle verify \u003cBUNDLE_FILE\u003e $ git bundle verify increment.bundle # output: # The bundle contains this ref: # 9ac69b08060859bc4b2172a8238cb841846ec5e0 refs/heads/main # The bundle requires this ref: # 21486d53326de40678a54159de656714a59b8d09 # The bundle uses this hash algorithm: sha1 # increment.bundle is okay From the above output, we can see that the increment.bundle requires the repo to have the commit 21486d5 to be used for updating. The last commit of foo on HostB before synchronization is precisely this one ","date":"2023-06-16","objectID":"/en/git-bundle-tutorial/:3:0","series":null,"tags":["Git"],"title":"Git bundle guide","uri":"/en/git-bundle-tutorial/#faq"},{"categories":["Git"],"content":" Wrap upUsing git bundle to package a git repository is indeed convenient. By combining it with the syntax for selecting a commit range, you can even choose only specific commits for incremental updates. This way, the bundle file will not be too large, making it easier for us to transfer. ","date":"2023-06-16","objectID":"/en/git-bundle-tutorial/:4:0","series":null,"tags":["Git"],"title":"Git bundle guide","uri":"/en/git-bundle-tutorial/#wrap-up"},{"categories":["Git"],"content":" Refs Git Revision Selection¬†‚Ü©Ô∏é ","date":"2023-06-16","objectID":"/en/git-bundle-tutorial/:5:0","series":null,"tags":["Git"],"title":"Git bundle guide","uri":"/en/git-bundle-tutorial/#refs"},{"categories":["GNN"],"content":"Understanding the classic graph attention network(GAT) throught MPNN(Message passing neural network, MPNN)","date":"2023-05-21","objectID":"/en/understanding-graph-attention-network-through-mpnn/","series":null,"tags":["GNN","Deep-Learning","Paper"],"title":"Understanding GAT throught MPNN","uri":"/en/understanding-graph-attention-network-through-mpnn/"},{"categories":["GNN"],"content":" What‚Äôs MPNNJustin Gilmer proposed the MPNN (Message Passing Neural Network) framework 1 for describing graph neural network models used in supervised learning on graphs. I found this to be a useful framework that provides a clear understanding of how different GNN models work and facilitates a quick grasp of the differences between them. Considering a node $v$ on the graph $G$, the update procedure for its vector representation $h_v$ is as follows: $$m_v^{t+1}=\\sum_{u\\in \\mathcal{N}(v)}M_t(h_v^t,h_u^t,e_{vu})$$ $$h_v^{t+1}=U_t(h_v^t,m_v^{t+1})$$ where $u$ is the neighbor of $v$, and we use $\\mathcal{N}(v)$ to represent all its neighbors $e_{vu}$ is optional, which represents the edge feature $M_t$ is the message function, $m_v^{t+1}$ is the aggregation result of all message from neighbors $U_t$ is the vertex update function After updating the vector representations of all nodes on the graph, we may need to perform graph-level classification tasks, which correspond to the following formula in the MPNN framework: $$\\hat y=R({h_v^T|v\\in G})$$ where $R$ is the readout function, which computes a feature vector for the whole graph (if you‚Äôre doing a graph-level classification problem) ","date":"2023-05-21","objectID":"/en/understanding-graph-attention-network-through-mpnn/:1:0","series":null,"tags":["GNN","Deep-Learning","Paper"],"title":"Understanding GAT throught MPNN","uri":"/en/understanding-graph-attention-network-through-mpnn/#whats-mpnn"},{"categories":["GNN"],"content":" What‚Äôs GAT üßê I have found that linking the formulas with code can help with understanding. Therefore, I will provide relevant code(with ... representing omitted parts). The code is sourced from the official GATConv module in DGL. üßê We can stack multiple GAT modules easily. The following discussion is from the perspective of a specific node $v$ in a particular layer $l$. Step 1. Apply linear transformation to all nodes$$h_v^{l}=W^lh_v^{l}$$ Let‚Äôs assume that the length of the vector representation for each node is denoted as $F$. In the first step, a linear transformation is applied to the vector of each node on the graph, where $W\\in\\mathcal{R}^{F‚Äô\\times F}$. Therefore, the length of each node is updated with a length of $F‚Äô$. To distinguish vectors from different layers, superscript $l$ is used to indicate that it belongs to the $l$-th layer. Note that within the layer $l$, all nodes share the same weight matrix $W^l$ üìí Note that the $h_v^l$ or $h_u^l$ mentioned later have undergone linear transformations. python class GATConv(nn.Module): def __init__(self, ...): ... self.fc = nn.Linear( self._in_src_feats, out_feats * num_heads, bias=False ) ... def forward(self, graph, feat, ...): \"\"\" Args ---- feat: (N, *, D_in) where D_in is the size of input feature Returns ------- torch.Tensor (N, *, num_heads, D_out) \"\"\" ... src_prefix_shape = dst_prefix_shape = feat.shape[:-1] h_src = h_dst = self.feat_drop(feat) # h_src: (N, *, D_in) feat_src = feat_dst = self.fc(h_src).view( *src_prefix_shape, self._num_heads, self._out_feats ) # feat_src/feat_dst: (N, *, num_heads, out_feat) ... Note that in the above code, the presence of two identical feat_src and feat_dst variables in DGL is due to the adoption of a mathematically equivalent but computationally more efficient implementation. This will be explained later Step 2. Compute the attention$$e_{vu}^l=LeakyReLU\\Big((a^l)^T[h_v^{l}||h_u^{l}]\\Big)$$ $$\\alpha_{vu}^l=Softmax_u(e_{vu}^l)$$ The second step is to compute the attention between the central node $v$ and all its neighboring nodes. In the above formula: $e_{vu}^l$ represents the attention coefficient. The paper mentions that different attention computation methods can be used. In the GAT paper, the authors chose to use a single-layer feedforward neural network(FNN) to compute the attention2. Note that the $e_{vu}^l$ here is unrelated to $e_{vu}$ in MPNN; it just happens to have similar notation $||$ denotes the concatenation operation. It means that we concatenate the vector representations of the central node and its corresponding neighbor nodes, resulting in a vector of length $2F‚Äô$, as indicated by $[h_v^{l}||h_u^{l}]$ in the formula. This concatenated vector is then fed into the aforementioned single-layer FNN, represented as $(a^l)^T[h_v^{l}||h_u^{l}]$, where $(a^l)^T$ refers to the learnable parameters of the single-layer FNN in the $l$-th layer $LeakyReLU$ is the activation function Finally, we apply Softmax on all neighbors of node $v$ to normalize the attention coefficients ü§îÔ∏è Step 1 and 2 correspond to the computation of $m_v^{t+1}$ in the MPNN framework. Multi-head attentionJust as Transformers have multi-head attention, the authors of GAT also employ the mechanism of multi-head attention during node updates: $$h_v^{l+1}= ||^{K^l} \\sigma(\\sum_{u\\in\\mathcal{N}(i)}\\alpha_{vu}^{(k,l)}W^{(k,l)}h_u^{l})$$ The notations are getting more complex, but with careful consideration, they can still be understood. The superscript $(k,l)$ indicates the $k$-th head in the $l$-th layer. Here, $K^l$ represents the number of heads in the $l$-th layer. The meaning of the above formula is that each head will compute a vector representation, and these vectors from different heads will be concatenated together. python class GATConv(nn.Module): def __init__(self, ...): ... self.attn_l = nn.Parameter( th.FloatTensor(size=(1, num_heads, out_feats)) ) self.attn_r = nn.Parameter( th.FloatTensor(size=(1, num_heads, out_feats)) ) self.leaky_relu = nn","date":"2023-05-21","objectID":"/en/understanding-graph-attention-network-through-mpnn/:2:0","series":null,"tags":["GNN","Deep-Learning","Paper"],"title":"Understanding GAT throught MPNN","uri":"/en/understanding-graph-attention-network-through-mpnn/#whats-gat"},{"categories":["GNN"],"content":" What‚Äôs GAT üßê I have found that linking the formulas with code can help with understanding. Therefore, I will provide relevant code(with ... representing omitted parts). The code is sourced from the official GATConv module in DGL. üßê We can stack multiple GAT modules easily. The following discussion is from the perspective of a specific node $v$ in a particular layer $l$. Step 1. Apply linear transformation to all nodes$$h_v^{l}=W^lh_v^{l}$$ Let‚Äôs assume that the length of the vector representation for each node is denoted as $F$. In the first step, a linear transformation is applied to the vector of each node on the graph, where $W\\in\\mathcal{R}^{F‚Äô\\times F}$. Therefore, the length of each node is updated with a length of $F‚Äô$. To distinguish vectors from different layers, superscript $l$ is used to indicate that it belongs to the $l$-th layer. Note that within the layer $l$, all nodes share the same weight matrix $W^l$ üìí Note that the $h_v^l$ or $h_u^l$ mentioned later have undergone linear transformations. python class GATConv(nn.Module): def __init__(self, ...): ... self.fc = nn.Linear( self._in_src_feats, out_feats * num_heads, bias=False ) ... def forward(self, graph, feat, ...): \"\"\" Args ---- feat: (N, *, D_in) where D_in is the size of input feature Returns ------- torch.Tensor (N, *, num_heads, D_out) \"\"\" ... src_prefix_shape = dst_prefix_shape = feat.shape[:-1] h_src = h_dst = self.feat_drop(feat) # h_src: (N, *, D_in) feat_src = feat_dst = self.fc(h_src).view( *src_prefix_shape, self._num_heads, self._out_feats ) # feat_src/feat_dst: (N, *, num_heads, out_feat) ... Note that in the above code, the presence of two identical feat_src and feat_dst variables in DGL is due to the adoption of a mathematically equivalent but computationally more efficient implementation. This will be explained later Step 2. Compute the attention$$e_{vu}^l=LeakyReLU\\Big((a^l)^T[h_v^{l}||h_u^{l}]\\Big)$$ $$\\alpha_{vu}^l=Softmax_u(e_{vu}^l)$$ The second step is to compute the attention between the central node $v$ and all its neighboring nodes. In the above formula: $e_{vu}^l$ represents the attention coefficient. The paper mentions that different attention computation methods can be used. In the GAT paper, the authors chose to use a single-layer feedforward neural network(FNN) to compute the attention2. Note that the $e_{vu}^l$ here is unrelated to $e_{vu}$ in MPNN; it just happens to have similar notation $||$ denotes the concatenation operation. It means that we concatenate the vector representations of the central node and its corresponding neighbor nodes, resulting in a vector of length $2F‚Äô$, as indicated by $[h_v^{l}||h_u^{l}]$ in the formula. This concatenated vector is then fed into the aforementioned single-layer FNN, represented as $(a^l)^T[h_v^{l}||h_u^{l}]$, where $(a^l)^T$ refers to the learnable parameters of the single-layer FNN in the $l$-th layer $LeakyReLU$ is the activation function Finally, we apply Softmax on all neighbors of node $v$ to normalize the attention coefficients ü§îÔ∏è Step 1 and 2 correspond to the computation of $m_v^{t+1}$ in the MPNN framework. Multi-head attentionJust as Transformers have multi-head attention, the authors of GAT also employ the mechanism of multi-head attention during node updates: $$h_v^{l+1}= ||^{K^l} \\sigma(\\sum_{u\\in\\mathcal{N}(i)}\\alpha_{vu}^{(k,l)}W^{(k,l)}h_u^{l})$$ The notations are getting more complex, but with careful consideration, they can still be understood. The superscript $(k,l)$ indicates the $k$-th head in the $l$-th layer. Here, $K^l$ represents the number of heads in the $l$-th layer. The meaning of the above formula is that each head will compute a vector representation, and these vectors from different heads will be concatenated together. python class GATConv(nn.Module): def __init__(self, ...): ... self.attn_l = nn.Parameter( th.FloatTensor(size=(1, num_heads, out_feats)) ) self.attn_r = nn.Parameter( th.FloatTensor(size=(1, num_heads, out_feats)) ) self.leaky_relu = nn","date":"2023-05-21","objectID":"/en/understanding-graph-attention-network-through-mpnn/:2:0","series":null,"tags":["GNN","Deep-Learning","Paper"],"title":"Understanding GAT throught MPNN","uri":"/en/understanding-graph-attention-network-through-mpnn/#step-1-apply-linear-transformation-to-all-nodes"},{"categories":["GNN"],"content":" What‚Äôs GAT üßê I have found that linking the formulas with code can help with understanding. Therefore, I will provide relevant code(with ... representing omitted parts). The code is sourced from the official GATConv module in DGL. üßê We can stack multiple GAT modules easily. The following discussion is from the perspective of a specific node $v$ in a particular layer $l$. Step 1. Apply linear transformation to all nodes$$h_v^{l}=W^lh_v^{l}$$ Let‚Äôs assume that the length of the vector representation for each node is denoted as $F$. In the first step, a linear transformation is applied to the vector of each node on the graph, where $W\\in\\mathcal{R}^{F‚Äô\\times F}$. Therefore, the length of each node is updated with a length of $F‚Äô$. To distinguish vectors from different layers, superscript $l$ is used to indicate that it belongs to the $l$-th layer. Note that within the layer $l$, all nodes share the same weight matrix $W^l$ üìí Note that the $h_v^l$ or $h_u^l$ mentioned later have undergone linear transformations. python class GATConv(nn.Module): def __init__(self, ...): ... self.fc = nn.Linear( self._in_src_feats, out_feats * num_heads, bias=False ) ... def forward(self, graph, feat, ...): \"\"\" Args ---- feat: (N, *, D_in) where D_in is the size of input feature Returns ------- torch.Tensor (N, *, num_heads, D_out) \"\"\" ... src_prefix_shape = dst_prefix_shape = feat.shape[:-1] h_src = h_dst = self.feat_drop(feat) # h_src: (N, *, D_in) feat_src = feat_dst = self.fc(h_src).view( *src_prefix_shape, self._num_heads, self._out_feats ) # feat_src/feat_dst: (N, *, num_heads, out_feat) ... Note that in the above code, the presence of two identical feat_src and feat_dst variables in DGL is due to the adoption of a mathematically equivalent but computationally more efficient implementation. This will be explained later Step 2. Compute the attention$$e_{vu}^l=LeakyReLU\\Big((a^l)^T[h_v^{l}||h_u^{l}]\\Big)$$ $$\\alpha_{vu}^l=Softmax_u(e_{vu}^l)$$ The second step is to compute the attention between the central node $v$ and all its neighboring nodes. In the above formula: $e_{vu}^l$ represents the attention coefficient. The paper mentions that different attention computation methods can be used. In the GAT paper, the authors chose to use a single-layer feedforward neural network(FNN) to compute the attention2. Note that the $e_{vu}^l$ here is unrelated to $e_{vu}$ in MPNN; it just happens to have similar notation $||$ denotes the concatenation operation. It means that we concatenate the vector representations of the central node and its corresponding neighbor nodes, resulting in a vector of length $2F‚Äô$, as indicated by $[h_v^{l}||h_u^{l}]$ in the formula. This concatenated vector is then fed into the aforementioned single-layer FNN, represented as $(a^l)^T[h_v^{l}||h_u^{l}]$, where $(a^l)^T$ refers to the learnable parameters of the single-layer FNN in the $l$-th layer $LeakyReLU$ is the activation function Finally, we apply Softmax on all neighbors of node $v$ to normalize the attention coefficients ü§îÔ∏è Step 1 and 2 correspond to the computation of $m_v^{t+1}$ in the MPNN framework. Multi-head attentionJust as Transformers have multi-head attention, the authors of GAT also employ the mechanism of multi-head attention during node updates: $$h_v^{l+1}= ||^{K^l} \\sigma(\\sum_{u\\in\\mathcal{N}(i)}\\alpha_{vu}^{(k,l)}W^{(k,l)}h_u^{l})$$ The notations are getting more complex, but with careful consideration, they can still be understood. The superscript $(k,l)$ indicates the $k$-th head in the $l$-th layer. Here, $K^l$ represents the number of heads in the $l$-th layer. The meaning of the above formula is that each head will compute a vector representation, and these vectors from different heads will be concatenated together. python class GATConv(nn.Module): def __init__(self, ...): ... self.attn_l = nn.Parameter( th.FloatTensor(size=(1, num_heads, out_feats)) ) self.attn_r = nn.Parameter( th.FloatTensor(size=(1, num_heads, out_feats)) ) self.leaky_relu = nn","date":"2023-05-21","objectID":"/en/understanding-graph-attention-network-through-mpnn/:2:0","series":null,"tags":["GNN","Deep-Learning","Paper"],"title":"Understanding GAT throught MPNN","uri":"/en/understanding-graph-attention-network-through-mpnn/#step-2-compute-the-attention"},{"categories":["GNN"],"content":" What‚Äôs GAT üßê I have found that linking the formulas with code can help with understanding. Therefore, I will provide relevant code(with ... representing omitted parts). The code is sourced from the official GATConv module in DGL. üßê We can stack multiple GAT modules easily. The following discussion is from the perspective of a specific node $v$ in a particular layer $l$. Step 1. Apply linear transformation to all nodes$$h_v^{l}=W^lh_v^{l}$$ Let‚Äôs assume that the length of the vector representation for each node is denoted as $F$. In the first step, a linear transformation is applied to the vector of each node on the graph, where $W\\in\\mathcal{R}^{F‚Äô\\times F}$. Therefore, the length of each node is updated with a length of $F‚Äô$. To distinguish vectors from different layers, superscript $l$ is used to indicate that it belongs to the $l$-th layer. Note that within the layer $l$, all nodes share the same weight matrix $W^l$ üìí Note that the $h_v^l$ or $h_u^l$ mentioned later have undergone linear transformations. python class GATConv(nn.Module): def __init__(self, ...): ... self.fc = nn.Linear( self._in_src_feats, out_feats * num_heads, bias=False ) ... def forward(self, graph, feat, ...): \"\"\" Args ---- feat: (N, *, D_in) where D_in is the size of input feature Returns ------- torch.Tensor (N, *, num_heads, D_out) \"\"\" ... src_prefix_shape = dst_prefix_shape = feat.shape[:-1] h_src = h_dst = self.feat_drop(feat) # h_src: (N, *, D_in) feat_src = feat_dst = self.fc(h_src).view( *src_prefix_shape, self._num_heads, self._out_feats ) # feat_src/feat_dst: (N, *, num_heads, out_feat) ... Note that in the above code, the presence of two identical feat_src and feat_dst variables in DGL is due to the adoption of a mathematically equivalent but computationally more efficient implementation. This will be explained later Step 2. Compute the attention$$e_{vu}^l=LeakyReLU\\Big((a^l)^T[h_v^{l}||h_u^{l}]\\Big)$$ $$\\alpha_{vu}^l=Softmax_u(e_{vu}^l)$$ The second step is to compute the attention between the central node $v$ and all its neighboring nodes. In the above formula: $e_{vu}^l$ represents the attention coefficient. The paper mentions that different attention computation methods can be used. In the GAT paper, the authors chose to use a single-layer feedforward neural network(FNN) to compute the attention2. Note that the $e_{vu}^l$ here is unrelated to $e_{vu}$ in MPNN; it just happens to have similar notation $||$ denotes the concatenation operation. It means that we concatenate the vector representations of the central node and its corresponding neighbor nodes, resulting in a vector of length $2F‚Äô$, as indicated by $[h_v^{l}||h_u^{l}]$ in the formula. This concatenated vector is then fed into the aforementioned single-layer FNN, represented as $(a^l)^T[h_v^{l}||h_u^{l}]$, where $(a^l)^T$ refers to the learnable parameters of the single-layer FNN in the $l$-th layer $LeakyReLU$ is the activation function Finally, we apply Softmax on all neighbors of node $v$ to normalize the attention coefficients ü§îÔ∏è Step 1 and 2 correspond to the computation of $m_v^{t+1}$ in the MPNN framework. Multi-head attentionJust as Transformers have multi-head attention, the authors of GAT also employ the mechanism of multi-head attention during node updates: $$h_v^{l+1}= ||^{K^l} \\sigma(\\sum_{u\\in\\mathcal{N}(i)}\\alpha_{vu}^{(k,l)}W^{(k,l)}h_u^{l})$$ The notations are getting more complex, but with careful consideration, they can still be understood. The superscript $(k,l)$ indicates the $k$-th head in the $l$-th layer. Here, $K^l$ represents the number of heads in the $l$-th layer. The meaning of the above formula is that each head will compute a vector representation, and these vectors from different heads will be concatenated together. python class GATConv(nn.Module): def __init__(self, ...): ... self.attn_l = nn.Parameter( th.FloatTensor(size=(1, num_heads, out_feats)) ) self.attn_r = nn.Parameter( th.FloatTensor(size=(1, num_heads, out_feats)) ) self.leaky_relu = nn","date":"2023-05-21","objectID":"/en/understanding-graph-attention-network-through-mpnn/:2:0","series":null,"tags":["GNN","Deep-Learning","Paper"],"title":"Understanding GAT throught MPNN","uri":"/en/understanding-graph-attention-network-through-mpnn/#multi-head-attention"},{"categories":["GNN"],"content":" What‚Äôs GAT üßê I have found that linking the formulas with code can help with understanding. Therefore, I will provide relevant code(with ... representing omitted parts). The code is sourced from the official GATConv module in DGL. üßê We can stack multiple GAT modules easily. The following discussion is from the perspective of a specific node $v$ in a particular layer $l$. Step 1. Apply linear transformation to all nodes$$h_v^{l}=W^lh_v^{l}$$ Let‚Äôs assume that the length of the vector representation for each node is denoted as $F$. In the first step, a linear transformation is applied to the vector of each node on the graph, where $W\\in\\mathcal{R}^{F‚Äô\\times F}$. Therefore, the length of each node is updated with a length of $F‚Äô$. To distinguish vectors from different layers, superscript $l$ is used to indicate that it belongs to the $l$-th layer. Note that within the layer $l$, all nodes share the same weight matrix $W^l$ üìí Note that the $h_v^l$ or $h_u^l$ mentioned later have undergone linear transformations. python class GATConv(nn.Module): def __init__(self, ...): ... self.fc = nn.Linear( self._in_src_feats, out_feats * num_heads, bias=False ) ... def forward(self, graph, feat, ...): \"\"\" Args ---- feat: (N, *, D_in) where D_in is the size of input feature Returns ------- torch.Tensor (N, *, num_heads, D_out) \"\"\" ... src_prefix_shape = dst_prefix_shape = feat.shape[:-1] h_src = h_dst = self.feat_drop(feat) # h_src: (N, *, D_in) feat_src = feat_dst = self.fc(h_src).view( *src_prefix_shape, self._num_heads, self._out_feats ) # feat_src/feat_dst: (N, *, num_heads, out_feat) ... Note that in the above code, the presence of two identical feat_src and feat_dst variables in DGL is due to the adoption of a mathematically equivalent but computationally more efficient implementation. This will be explained later Step 2. Compute the attention$$e_{vu}^l=LeakyReLU\\Big((a^l)^T[h_v^{l}||h_u^{l}]\\Big)$$ $$\\alpha_{vu}^l=Softmax_u(e_{vu}^l)$$ The second step is to compute the attention between the central node $v$ and all its neighboring nodes. In the above formula: $e_{vu}^l$ represents the attention coefficient. The paper mentions that different attention computation methods can be used. In the GAT paper, the authors chose to use a single-layer feedforward neural network(FNN) to compute the attention2. Note that the $e_{vu}^l$ here is unrelated to $e_{vu}$ in MPNN; it just happens to have similar notation $||$ denotes the concatenation operation. It means that we concatenate the vector representations of the central node and its corresponding neighbor nodes, resulting in a vector of length $2F‚Äô$, as indicated by $[h_v^{l}||h_u^{l}]$ in the formula. This concatenated vector is then fed into the aforementioned single-layer FNN, represented as $(a^l)^T[h_v^{l}||h_u^{l}]$, where $(a^l)^T$ refers to the learnable parameters of the single-layer FNN in the $l$-th layer $LeakyReLU$ is the activation function Finally, we apply Softmax on all neighbors of node $v$ to normalize the attention coefficients ü§îÔ∏è Step 1 and 2 correspond to the computation of $m_v^{t+1}$ in the MPNN framework. Multi-head attentionJust as Transformers have multi-head attention, the authors of GAT also employ the mechanism of multi-head attention during node updates: $$h_v^{l+1}= ||^{K^l} \\sigma(\\sum_{u\\in\\mathcal{N}(i)}\\alpha_{vu}^{(k,l)}W^{(k,l)}h_u^{l})$$ The notations are getting more complex, but with careful consideration, they can still be understood. The superscript $(k,l)$ indicates the $k$-th head in the $l$-th layer. Here, $K^l$ represents the number of heads in the $l$-th layer. The meaning of the above formula is that each head will compute a vector representation, and these vectors from different heads will be concatenated together. python class GATConv(nn.Module): def __init__(self, ...): ... self.attn_l = nn.Parameter( th.FloatTensor(size=(1, num_heads, out_feats)) ) self.attn_r = nn.Parameter( th.FloatTensor(size=(1, num_heads, out_feats)) ) self.leaky_relu = nn","date":"2023-05-21","objectID":"/en/understanding-graph-attention-network-through-mpnn/:2:0","series":null,"tags":["GNN","Deep-Learning","Paper"],"title":"Understanding GAT throught MPNN","uri":"/en/understanding-graph-attention-network-through-mpnn/#step-3-aggregation"},{"categories":["GNN"],"content":" Implementation and usage ü§îÔ∏è DGL‚Äôs design is based on the MPNN framework, but their formulas are slightly different. They also introduce an aggregation function, denoted as $\\rho$, which determines how a node aggregates all the information received from its neighbors. I thought their formulas are more generalized. They have thoughtfully provided a tutorial on how to use DGL‚Äôs MPNN-related functions, which can be found here üëçüëçüëç As for the implementation of GAT, the DGL offers GATConv. The DGL team also write a good tutorial about using the built-in message_func and reduce_func to implemente GAT manually Please refers to here to see a full training example ","date":"2023-05-21","objectID":"/en/understanding-graph-attention-network-through-mpnn/:3:0","series":null,"tags":["GNN","Deep-Learning","Paper"],"title":"Understanding GAT throught MPNN","uri":"/en/understanding-graph-attention-network-through-mpnn/#implementation-and-usage"},{"categories":["GNN"],"content":" Wrap upAbove is how the GAT can be explained using the MPNN framework, with the inclusion of DGL source code. Using attention to compute importances between nodes appears to be a natural approach and can be seen as a generalization of GCN. GAT is capable of learning local structural representations of graphs effectively, and the attention computation can be parallelized, making it highly efficient. Cheers! üçªüçªüçª ","date":"2023-05-21","objectID":"/en/understanding-graph-attention-network-through-mpnn/:4:0","series":null,"tags":["GNN","Deep-Learning","Paper"],"title":"Understanding GAT throught MPNN","uri":"/en/understanding-graph-attention-network-through-mpnn/#wrap-up"},{"categories":["GNN"],"content":" Refs Gilmer J, Schoenholz S S, Riley P F, et al. Neural message passing for quantum chemistry[C]//International conference on machine learning. PMLR, 2017: 1263-1272. arXiv¬†‚Ü©Ô∏é Veliƒçkoviƒá P, Cucurull G, Casanova A, et al. Graph attention networks[J]. arXiv preprint arXiv:1710.10903, 2017. arXiv¬†‚Ü©Ô∏é¬†‚Ü©Ô∏é¬†‚Ü©Ô∏é ","date":"2023-05-21","objectID":"/en/understanding-graph-attention-network-through-mpnn/:5:0","series":null,"tags":["GNN","Deep-Learning","Paper"],"title":"Understanding GAT throught MPNN","uri":"/en/understanding-graph-attention-network-through-mpnn/#refs"},{"categories":["Exercise"],"content":"The solution of SICP exercise 2.27","date":"2023-05-16","objectID":"/en/sicp-exercise-2-27/","series":null,"tags":["SICP","Racket"],"title":"SICP Exercise 2.27","uri":"/en/sicp-exercise-2-27/"},{"categories":["Exercise"],"content":" Question Modify your reverse procedure of exercise 2.18 to produce a deep-reverse procedure that takes a list as an argument and returns as its value the list with its elements reversed and with all sublists deep-reversed as well. racket (define x (list (list 1 2) (list 3 4))) ;; x - ((1 2) (3 4)) (deep-reverse x) ;; the output should be ((4 3) (2 1)) ","date":"2023-05-16","objectID":"/en/sicp-exercise-2-27/:1:0","series":null,"tags":["SICP","Racket"],"title":"SICP Exercise 2.27","uri":"/en/sicp-exercise-2-27/#question"},{"categories":["Exercise"],"content":" AnswerIn the previous Exercise 2.18, we ignore the fact that the elements of a list may still be lists too. And this exercise requires us to reverse the entire list recursively. To design a recursive algorithm for a specific problem, we only need to figure out two things: What is the base case? As the problem description says, the argument of deep-reverse is a list. Usually, the base case of a list structure is an empty list - '() How to recursively related the subproblems? Fact 1: (cdr l) always returns a list, and (car l) always return the 1st element of a list(the 1st element may be a list too) Fact 2: The invariant of deep-reverse - its argument is a list Based on the two points, we know the criteria for dividing the problems - check whether the 1st element of the list is an atomic item The code should look like Racket ;; invariants: the argument of deep-reverse are always a list (define (deep-reverse l) (cond ((null? l) '()) ;; base case (else (let ([remains (deep-reverse (cdr l))]) (if (pair? (car l)) ;; the arguments of append procedure should be lists too (append remains (list (deep-reverse (car l)))) (append remains (list (car l)))))))) There are some test cases I wrote Racket (deep-reverse '(2 3)) (deep-reverse '((2 3))) (deep-reverse '((2 3) 1)) (deep-reverse '(5 (2 3) 1)) (deep-reverse '((4 2) (2 3) 1)) (deep-reverse '(5 (2 3) (5 2))) üöß The complete SICP exercise solution is still a work in progress. Please refers to here ","date":"2023-05-16","objectID":"/en/sicp-exercise-2-27/:2:0","series":null,"tags":["SICP","Racket"],"title":"SICP Exercise 2.27","uri":"/en/sicp-exercise-2-27/#answer"},{"categories":["Exercise"],"content":"The solution of SICP exercise 1.46","date":"2023-05-10","objectID":"/en/sicp-exercise-1-46/","series":null,"tags":["SICP","Racket"],"title":"SICP Exercise 1.46","uri":"/en/sicp-exercise-1-46/"},{"categories":["Exercise"],"content":" Question Several of the numerical methods described in this chapter are instances of an extremely general computational strategy known as iterative improvement. Iterative improvement says that, to compute something, we start with an initial guess for the answer, test if the guess is good enough, and otherwise improve the guess and continue the process using the improved guess as the new guess. Write a procedure iterative-improve that takes two procedures as arguments: a method for telling whether a guess is good enough and a method for improving a guess. Iterative-improve should return as its value a procedure that takes a guess as argument and keeps improving the guess until it is good enough. Rewrite the sqrt procedure of section 1.1.7 and the fixed-point procedure of section 1.3.3 in terms of iterative-improve. ","date":"2023-05-10","objectID":"/en/sicp-exercise-1-46/:1:0","series":null,"tags":["SICP","Racket"],"title":"SICP Exercise 1.46","uri":"/en/sicp-exercise-1-46/#question"},{"categories":["Exercise"],"content":" AnswerLet‚Äôs summarize what the problem asks us to do: Write a procedure called iterative-improve with 2 arguments. The first argument is a procedure that can tell where a guess is good enough. The second argument is a procedure that can improve a guess (the input argument). Rewrite fixed-point and sqrt using iterative-improve. If you walk along the Exercise of Chapter 1, you can quickly write iterative-improve like this: racket ;; test: test if a guess is good enough ;; improve: how to improve a guess (define (iterative-improve test improve) (lambda (guess) (if (test guess) guess ...))) Using lambda to create an anonymous procedure and return is quite convenient. The main difficulty arises from the ... part, that is, how should we recursively improve the guess? We can put ((iterative-improve good-enough? improve) (improve guess)) in the ... and it will work correctly. However, this may not be very intuitive. That‚Äôs where helper functions come in handy. When designing a recursive procedure, we can define an inner helper function to perform the heavy work and simply return the helper function in the main body. racket (define (iterative-improve test improve) (define (helper guess) (if (test guess) guess (helper (improve guess)))) helper) It‚Äôs easy to rewrite the fixed-point and sqrt procedures. All we have to do is define the corresponding test and improve procedures and then call iterative-improve. racket (define (average x y) (/ (+ x y) 2)) (define (square x) (* x x)) (define (fixed-point f first-guess) ;; it's fine to refer a variable in the enclosing scope (define (close-enough? v) (let ([next (f v)]) (\u003c (abs (- v next)) 0.00001))) ((iterative-improve close-enough? f) first-guess)) (define (sqrt x) ;; it's fine to refer a variable in the enclosing scope (define (good-enough? v) (\u003c (abs (- (square v) x)) 0.001)) (define (improve guess) (average guess (/ x guess))) ((iterative-improve good-enough? improve) 1.0)) üöß The complete SICP exercise solution is still a work in progress. Please refers to here ","date":"2023-05-10","objectID":"/en/sicp-exercise-1-46/:2:0","series":null,"tags":["SICP","Racket"],"title":"SICP Exercise 1.46","uri":"/en/sicp-exercise-1-46/#answer"},{"categories":["Exercise"],"content":"The solution of SICP exercise 1.34","date":"2023-05-09","objectID":"/en/sicp-exercise-1-34/","series":null,"tags":["SICP","Racket"],"title":"SICP Exercise 1.34","uri":"/en/sicp-exercise-1-34/"},{"categories":["Exercise"],"content":" Question Suppose we define the procedure f. What happens if we (perversely) ask the interpreter to evaluate the combination (f f)? racket (define (square x) (* x x)) (define (f g) (g 2)) Then we have racket (f square) ;; 4 (f (lambda (z) (* z (+ z 1)))) ;; 6 = 2 * 3 ","date":"2023-05-09","objectID":"/en/sicp-exercise-1-34/:1:0","series":null,"tags":["SICP","Racket"],"title":"SICP Exercise 1.34","uri":"/en/sicp-exercise-1-34/#question"},{"categories":["Exercise"],"content":" AnswerRecall what the applicative-order evaluation says: We need to evaluate all arguments and then we apply procedure on these arguments. The first step: we evalute the argument f in (f f). racket ;; replace g with f ;; (define (f g) ;; (g 2)) (f 2) The second step: we evaluate the argument 2 in (f 2). Note that the 2 here is regarded as a procedure rather than a primitive number. racket ;; replace g with 2 ;; (define (f g) ;; (g 2)) (2 2) So we finally get the S-expression (2 2). It‚Äôs regarded as a function/procedure application. That‚Äôs how we interprete an S-expression :) However, the 2 is not a procedure at all. This explains why Racket says: text application: not a procedure; expected a procedure that can be applied to arguments given: 2 üöß The complete SICP exercise solution is still a work in progress. Please refers to here ","date":"2023-05-09","objectID":"/en/sicp-exercise-1-34/:2:0","series":null,"tags":["SICP","Racket"],"title":"SICP Exercise 1.34","uri":"/en/sicp-exercise-1-34/#answer"},{"categories":["Course"],"content":"The solution of proj4. Scheme Interpreter","date":"2023-04-21","objectID":"/en/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/","series":null,"tags":["Course","Python","Scheme"],"title":"Solution of Proj4. Scheme Interpreter of CS61A (2021-Fall)","uri":"/en/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/"},{"categories":["Course"],"content":" IntroRecently, I am reading a book called Crafting interpreters written by Robert Nystrom. In the original book, a Tree-walker interpreter jlox was implemented in Java. And I am trying to rewrite in Python - pylox. I highly recommend itüëç. At this moment, I suddenly remembered that there were a few small issues with the Scheme interpreter for CS61A that I had not resolved after finishing it a year ago, which kept it in an unfinished state. So today I opened the project and intended to run through it from beginning to end and talk about the ideas. Note: I only quote part of the original problem description. To make the post more compact, I also omit the irrelevant code :) ","date":"2023-04-21","objectID":"/en/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:1:0","series":null,"tags":["Course","Python","Scheme"],"title":"Solution of Proj4. Scheme Interpreter of CS61A (2021-Fall)","uri":"/en/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/#intro"},{"categories":["Course"],"content":" Part 1. The Evaluator","date":"2023-04-21","objectID":"/en/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:2:0","series":null,"tags":["Course","Python","Scheme"],"title":"Solution of Proj4. Scheme Interpreter of CS61A (2021-Fall)","uri":"/en/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/#part-1-the-evaluator"},{"categories":["Course"],"content":" Problem 1 Implement the define and lookup methods of the Frame class‚Ä¶bindings is a dictionary representing the bindings in the frame‚Ä¶parent is the parent Frame instance‚Ä¶The environment for a Frame instance consists of that frame, its parent frame, and all its ancestor frames, including the Global Frame. Problem 1 is trivial in my opinion. To implement the define function, you just need to save the { symbol: value } in self.bindings. As for the lookup function, we can write a iterative solution or recursive one. The iterative solution is more intuitive though. python ... def define(self, symbol, value): \"\"\"Define Scheme SYMBOL to have VALUE.\"\"\" self.bindings[symbol] = value def lookup(self, symbol): \"\"\"Return the value bound to SYMBOL. Errors if SYMBOL is not found.\"\"\" # Case 1. we check if the symbol is in the current frame if symbol in self.bindings.keys(): return self.bindings[symbol] else: # Case 2. we check the parent of the current frame repreatly pos = self.parent while pos is not None: if symbol in pos.bindings.keys(): return pos.bindings[symbol] pos = pos.parent # Case 3. we can't find the symbol raise SchemeError(\"unknown identifier: {0}\".format(symbol)) ... ","date":"2023-04-21","objectID":"/en/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:2:1","series":null,"tags":["Course","Python","Scheme"],"title":"Solution of Proj4. Scheme Interpreter of CS61A (2021-Fall)","uri":"/en/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/#problem-1"},{"categories":["Course"],"content":" Problem 2 To be able to call built-in procedures, such as +, you need to complete the BuiltinProcedure case within the scheme_apply function in scheme_eval_apply.py. Built-in procedures are applied by calling a corresponding Python function that implements the procedure. The full problem description elaborates on the procedure of implementing scheme_apply function. Notice that you should distinguish nil and None. This subtle bug may cause you other correct solutions fail to pass the test suite. python def scheme_apply(procedure, args, env): ... if isinstance(procedure, BuiltinProcedure): # Convert the Scheme list to a Python list of arguments args_list = [] pos = args while pos is not nil: if pos.first is not nil: args_list.append(pos.first) else: args_list.append(nil) pos = pos.rest # Add the current environment if procedure.expect_env == True if procedure.expect_env: args_list.append(env) # Call procedure.py_func on all arguments try: return procedure.py_func(*args_list) except TypeError as e: raise SchemeError(f\"incorrect number of arguments, {e}\") ... ","date":"2023-04-21","objectID":"/en/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:2:2","series":null,"tags":["Course","Python","Scheme"],"title":"Solution of Proj4. Scheme Interpreter of CS61A (2021-Fall)","uri":"/en/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/#problem-2"},{"categories":["Course"],"content":" Problem 3 Implement the missing part of scheme_eval, which evaluates a call expression‚Ä¶You‚Äôll have to recursively call scheme_eval in the first two steps‚Ä¶The map method of Pair returns a new Scheme list constructed by applying a one-argument function to every item in a Scheme list‚Ä¶Important: do not mutate the passed-in expr. That would change a program as it‚Äôs being evaluated, creating strange and incorrect effects. Is‚Äô quite straightforward to implement scheme_eval. The main obstacle in the way may comes from the requirement that we need to pass one-argument function to rest.map. However, the scheme_eval has two arguments(let‚Äôs ignore the optional part). To make the scheme_eval a one-argument function, we may write a simple lambda to wrapper it, or we can use the partial function in functools packages to fix arguments for a specefic function. I choose to use the latter solution. python def scheme_eval(expr, env, _=None): # Optional third argument is ignored ... else: # Evaluate the operator(first argument) operator = scheme_eval(first, env) validate_procedure(operator) # Evaluate all of the operands(other arguments) from functools import partial operands = rest.map(partial(scheme_eval, env=env)) return scheme_apply(operator, operands, env) ","date":"2023-04-21","objectID":"/en/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:2:3","series":null,"tags":["Course","Python","Scheme"],"title":"Solution of Proj4. Scheme Interpreter of CS61A (2021-Fall)","uri":"/en/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/#problem-3"},{"categories":["Course"],"content":" Problem 4 The type of the first operand tells us what is being defined‚Ä¶implement just the first part, which evaluates the second operand to obtain a value and binds the first operand, a symbol, to that value. Then, do_define_form returns the symbol that was bound. In problem 1, we have implemented the define method, which can bind value to a symbol. All we need to do is pass the correct arguments to this method. To access the some_val part in (define a some_val), we can use the .rest.first python def do_define_form(expressions, env): ... if scheme_symbolp(signature): # assigning a name to a value e.g. (define x (+ 1 2)) validate_form( expressions, 2, 2 ) # Checks that expressions is a list of length exactly 2 env.define(signature, scheme_eval(expressions.rest.first, env)) return signature ... ","date":"2023-04-21","objectID":"/en/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:2:4","series":null,"tags":["Course","Python","Scheme"],"title":"Solution of Proj4. Scheme Interpreter of CS61A (2021-Fall)","uri":"/en/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/#problem-4"},{"categories":["Course"],"content":" Problem 5 Implement the do_quote_form function in scheme_forms.py so that it simply returns the unevaluated operand of the (quote ...) expression. validate_form(expressions, 1, 1) ensures that the expressions is '.... And we just need to return it. python def do_quote_form(expressions, env): validate_form(expressions, 1, 1) return expressions.first ","date":"2023-04-21","objectID":"/en/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:2:5","series":null,"tags":["Course","Python","Scheme"],"title":"Solution of Proj4. Scheme Interpreter of CS61A (2021-Fall)","uri":"/en/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/#problem-5"},{"categories":["Course"],"content":" Part 2. Procedures","date":"2023-04-21","objectID":"/en/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:3:0","series":null,"tags":["Course","Python","Scheme"],"title":"Solution of Proj4. Scheme Interpreter of CS61A (2021-Fall)","uri":"/en/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/#part-2-procedures"},{"categories":["Course"],"content":" Problem 6 Change the eval_all function in scheme_eval_apply.py (which is called from do_begin_form in scheme_forms.py) to complete the implementation of the begin special form (spec). A begin expression is evaluated by evaluating all sub-expressions in order. The value of the begin expression is the value of the final sub-expression. Let‚Äôs write the recursive solution: Check if expressions is nil, and return None if it holds Check f expressions.rest is nil, return the evaluation result of expressions.first if it holds, or recursively call eval_all python def eval_all(expressions, env): if expressions is nil: return None res = scheme_eval(expressions.first, env) if expressions.rest is nil: return res else: return eval_all(expressions.rest, env) ","date":"2023-04-21","objectID":"/en/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:3:1","series":null,"tags":["Course","Python","Scheme"],"title":"Solution of Proj4. Scheme Interpreter of CS61A (2021-Fall)","uri":"/en/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/#problem-6"},{"categories":["Course"],"content":" Problem 7 Implement the do_lambda_form function (spec), which creates and returns a LambdaProcedure instance By reading the problem description of Problem 6, we know how to construct a LambdaProcedure python def do_lambda_form(expressions, env): validate_form(expressions, 2) formals = expressions.first validate_formals(formals) return LambdaProcedure(formals, expressions.rest, env) ","date":"2023-04-21","objectID":"/en/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:3:2","series":null,"tags":["Course","Python","Scheme"],"title":"Solution of Proj4. Scheme Interpreter of CS61A (2021-Fall)","uri":"/en/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/#problem-7"},{"categories":["Course"],"content":" Problem 8 This method takes in two arguments: formals, which is a Scheme list of symbols, and vals, which is a Scheme list of values. It should return a new child frame, binding the formal parameters to the values. The full problem description is well written and this problem us trivial. python def make_child_frame(self, formals, vals): if len(formals) != len(vals): raise SchemeError(\"Incorrect number of arguments to function call\") sub_frame = Frame(self) # iterate pos1, pos2 = formals, vals while pos1 is not nil: key, value = pos1.first, pos2.first sub_frame.define(key, value) pos1, pos2 = pos1.rest, pos2.rest return sub_frame ","date":"2023-04-21","objectID":"/en/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:3:3","series":null,"tags":["Course","Python","Scheme"],"title":"Solution of Proj4. Scheme Interpreter of CS61A (2021-Fall)","uri":"/en/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/#problem-8"},{"categories":["Course"],"content":" Problem 9 You should first create a new Frame instance using the make_child_frame method of the appropriate parent frame, binding formal parameters to argument values. Then, evaluate each of the expressions of the body of the procedure using eval_all within this new frame. In this problem, we can use the make_child_frame implemented in Problem 8. python def scheme_apply(procedure, args, env): ... elif isinstance(procedure, LambdaProcedure): child_frame = procedure.env.make_child_frame(procedure.formals, args) return eval_all(procedure.body, child_frame) ... ","date":"2023-04-21","objectID":"/en/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:3:4","series":null,"tags":["Course","Python","Scheme"],"title":"Solution of Proj4. Scheme Interpreter of CS61A (2021-Fall)","uri":"/en/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/#problem-9"},{"categories":["Course"],"content":" Problem 10 Modify the do_define_form function in scheme_forms.py so that it correctly handles define (...) ...) expressions Use do_lambda_form or just call the constructer of LambdaProcedure. python def do_define_form(expressions, env): ... elif isinstance(signature, Pair) and scheme_symbolp(signature.first): # defining a named procedure e.g. (define (f x y) (+ x y)) # the signature is (f x y) formals = signature.rest # (x y) validate_formals(formals) # now we need to parse (+ x y) env.define(signature.first, LambdaProcedure(formals, expressions.rest, env)) return signature.first # f ... ","date":"2023-04-21","objectID":"/en/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:3:5","series":null,"tags":["Course","Python","Scheme"],"title":"Solution of Proj4. Scheme Interpreter of CS61A (2021-Fall)","uri":"/en/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/#problem-10"},{"categories":["Course"],"content":" Problem 11 Implement do_mu_form in scheme_forms.py to evaluate the mu special form. A mu expression evaluates to a MuProcedure. Most of the MuProcedure class (defined in scheme_classes.py) has been provided for you. The key to this problem is understanding dynamic scoping. We can make a child frame and evaluate the MuProcedure and it should work as expected. python def scheme_apply(procedure, args, env): ... elif isinstance(procedure, MuProcedure): child_frame = env.make_child_frame(procedure.formals, args) return eval_all(procedure.body, child_frame) ... def do_mu_form(expressions, env): validate_form(expressions, 2) formals = expressions.first validate_formals(formals) return MuProcedure(formals, expressions.rest) ","date":"2023-04-21","objectID":"/en/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:3:6","series":null,"tags":["Course","Python","Scheme"],"title":"Solution of Proj4. Scheme Interpreter of CS61A (2021-Fall)","uri":"/en/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/#problem-11"},{"categories":["Course"],"content":" Part 3. Special Forms","date":"2023-04-21","objectID":"/en/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:4:0","series":null,"tags":["Course","Python","Scheme"],"title":"Solution of Proj4. Scheme Interpreter of CS61A (2021-Fall)","uri":"/en/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/#part-3-special-forms"},{"categories":["Course"],"content":" Problem 12 Implement do_and_form and do_or_form so that and and or expressions are evaluated correctly. The logical forms and and or are short-circuiting I write do_and_form and do_or_form recursively: do_and_form: the base case is nil and we should return True. Otherwise, we check each one and return immediately if we found False do_or_form: the base case is nil and we should return False. Otherwise, we check each one and return immediately if we found True python def do_and_form(expressions, env): # base case: (and) if expressions is nil: return True front = scheme_eval(expressions.first, env) if is_scheme_true(front): if expressions.rest is nil: return front else: return do_and_form(expressions.rest, env) else: return front def do_or_form(expressions, env): # base case: (or) if expressions is nil: return False front = scheme_eval(expressions.first, env) if is_scheme_false(front): if expressions.rest is nil: return front else: return do_or_form(expressions.rest, env) else: return front ","date":"2023-04-21","objectID":"/en/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:4:1","series":null,"tags":["Course","Python","Scheme"],"title":"Solution of Proj4. Scheme Interpreter of CS61A (2021-Fall)","uri":"/en/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/#problem-12"},{"categories":["Course"],"content":" Problem 13 Fill in the missing parts of do_cond_form so that it correctly implements cond, returning the value of the first result sub-expression corresponding to a true predicate, or the result sub-expression corresponding to else. Just do as the problem description says. python def do_cond_form(expressions, env): ... if is_scheme_true(test): # no sub-expression if clause.rest is nil: return test return eval_all(clause.rest, env) ... ","date":"2023-04-21","objectID":"/en/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:4:2","series":null,"tags":["Course","Python","Scheme"],"title":"Solution of Proj4. Scheme Interpreter of CS61A (2021-Fall)","uri":"/en/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/#problem-13"},{"categories":["Course"],"content":" Problem 14 Implement make_let_frame in scheme_forms.py, which returns a child frame of env that binds the symbol in each element of bindings to the value of its corresponding expression. The bindings Scheme list contains pairs that each contain a symbol and a corresponding expression. Check each binding and use the Pair to collection the names and values. python def make_let_frame(bindings, env): if not scheme_listp(bindings): raise SchemeError(\"bad bindings list in let form\") names = values = nil # bingding: (\u003cname\u003e \u003cexpression\u003e) # bingdings: ( (\u003cname1\u003e \u003cexpression1\u003e) (\u003cname2\u003e \u003cexpression2\u003e) ...) pos = bindings while pos is not nil: front = pos.first # i.e. the first binding validate_form(front, 2, 2) # verify the structure is (\u003cname\u003e \u003cexpression\u003e) names = Pair(front.first, names) values = Pair(eval_all(front.rest, env), values) pos = pos.rest validate_formals(names) return = env.make_child_frame(names, values) ","date":"2023-04-21","objectID":"/en/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:4:3","series":null,"tags":["Course","Python","Scheme"],"title":"Solution of Proj4. Scheme Interpreter of CS61A (2021-Fall)","uri":"/en/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/#problem-14"},{"categories":["Course"],"content":" Problem 15 Implement the enumerate procedure, which takes in a list of values and returns a list of two-element lists, where the first element is the index of the value, and the second element is the value itself. We can implement the enumerate procedure recursively by writing a helper function called helper: base case: the input is nil and we just return '() other cases: recursively call the helper function. Notice that how the arguments change: input -\u003e (cdr input) and index -\u003e (+ index 1) scheme (define (enumerate s) (begin ;; a helper funtion (define (helper input index) (cond ((null? input) '()) ;; base case: return () if it is nil (else (cons (cons index (cons (car input) nil)) (helper (cdr input) (+ index 1)))))) ;; recursive call (helper s 0)) ) ","date":"2023-04-21","objectID":"/en/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:4:4","series":null,"tags":["Course","Python","Scheme"],"title":"Solution of Proj4. Scheme Interpreter of CS61A (2021-Fall)","uri":"/en/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/#problem-15"},{"categories":["Course"],"content":" Problem 16 Implement the merge procedure, which takes in a comparator function inorder? and two lists that are sorted, and combines the two lists into a single sorted list. A comparator defines an ordering by comparing two values and returning a true value if and only if the two values are ordered. Here, sorted means sorted according to the comparator A classic interview problem: merge two sorted lists. We just need to compare the head of each list and recursively call merge in the right arguments form scheme (define (merge inorder? list1 list2) (cond ((null? list1) list2) ;; base case: list1 is empty ((null? list2) list1) ;; base case: list2 is empty ((inorder? (car list1) (car list2)) (cons (car list1) (merge inorder? (cdr list1) list2))) ;; consume list1 (else (cons (car list2) (merge inorder? list1 (cdr list2))))) ;; consume list2 ) ","date":"2023-04-21","objectID":"/en/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:4:5","series":null,"tags":["Course","Python","Scheme"],"title":"Solution of Proj4. Scheme Interpreter of CS61A (2021-Fall)","uri":"/en/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/#problem-16"},{"categories":["Algorithm"],"content":"Intoduce the SRTBOT Framework which can be utilized to solving DP problems","date":"2023-04-09","objectID":"/en/solving-dynamic-programming-problems-using-srtbot/","series":null,"tags":["Algorithm"],"title":"Solving DP problems by SRTBOT Framework","uri":"/en/solving-dynamic-programming-problems-using-srtbot/"},{"categories":["Algorithm"],"content":"Changelog: Update dependency graphs @2023.04.13 ","date":"2023-04-09","objectID":"/en/solving-dynamic-programming-problems-using-srtbot/:0:0","series":null,"tags":["Algorithm"],"title":"Solving DP problems by SRTBOT Framework","uri":"/en/solving-dynamic-programming-problems-using-srtbot/#"},{"categories":["Algorithm"],"content":" IntroWhen solving algorithm problems, what often gives me a headache are dynamic programming problems(DP problems). They are the type of problems that I can‚Äôt figure out on my own after thinking for a long time, but after seeing the answer, it suddenly becomes clear and reasonable. However, the next time I encounter a similar problem, I may forget how to solve it. I have also read many people‚Äôs solutions and tried to digest and apply their ideas, but I have been unable to find a particularly good framework that works for all dynamic programming problems. It seems that everyone has their way of solving dynamic programming problems, and when I try to apply their methods to new problems, I always encounter difficulties. Things start to change after I learned MIT6.006. The teacher presented 6 steps to solve dynamic programming problems, which is called the SRTBOT framework. I found it to be so useful and practical that I decided to write this blog post to share it with everyone üôå üëâ Overall, this blog post is more suitable for those who already have a basic understanding of dynamic programming but have not yet found a systematic approach ","date":"2023-04-09","objectID":"/en/solving-dynamic-programming-problems-using-srtbot/:1:0","series":null,"tags":["Algorithm"],"title":"Solving DP problems by SRTBOT Framework","uri":"/en/solving-dynamic-programming-problems-using-srtbot/#intro"},{"categories":["Algorithm"],"content":" What‚Äôs the DP problem?The two main features of dynamic programming problems are ‚Äúoverlapping subproblems‚Äù and ‚Äúoptimal substructure‚Äù 1: Overlapping subproblems: Solving a dynamic programming problem often involves breaking it down into several overlapping subproblems. Optimal substructure: The solution to a large problem can be calculated by combining the optimal solutions of smaller subproblems. It is important to note the terms ‚Äúoverlapping‚Äù and ‚Äúsubproblems‚Äù in the above definitions. Emphasis is placed on overlapping because the power of dynamic programming lies in its ability to remember the answers(by memorization) to solve subproblems. Therefore, the more overlapping subproblems there are, the more pronounced the advantage of dynamic programming. ü§îÔ∏è If the subproblems are not overlapping, then we may use another algorithm - Divide and conquer. From the perspective of programming problems, the following two types of problems usually require dynamic programming algorithms: Optimization problems: finding the optimal solution + overlapping subproblems Combination problems: finding the number of possible solutions üìí Alternatively, based on my personal experience, dynamic programming problems are generally recursive problems that can be solved by brute force, but they have a large number of overlapping subproblems, so they can be optimized using dynamic programming. ","date":"2023-04-09","objectID":"/en/solving-dynamic-programming-problems-using-srtbot/:2:0","series":null,"tags":["Algorithm"],"title":"Solving DP problems by SRTBOT Framework","uri":"/en/solving-dynamic-programming-problems-using-srtbot/#whats-the-dp-problem"},{"categories":["Algorithm"],"content":" SRTBOT FrameworkSRTBOT is an acronym for 6 steps, which are 2: Subproblems definition Relate subproblem solutions recursively Topological order to argue relation is acyclic and subproblems form a DAG Base cases Original problem Time analysis Now let‚Äôs talk about each step ","date":"2023-04-09","objectID":"/en/solving-dynamic-programming-problems-using-srtbot/:3:0","series":null,"tags":["Algorithm"],"title":"Solving DP problems by SRTBOT Framework","uri":"/en/solving-dynamic-programming-problems-using-srtbot/#srtbot-framework"},{"categories":["Algorithm"],"content":" Subproblems definitionSteps Define subproblems and describe their meaning in words. The subproblems defined here will include parameters. Specific techniques for defining subproblems will be mentioned later The parameters of subproblems generally include subsets of inputs. Different DP problems may have different input formats: binary trees, single sequences, numbers, etc Some tricks for defining subproblems: If the input is a single sequence A Prefix form: Define dp[i] as the solution to the subproblem with input A[:i+1], note that the interval representation here is based on Python and is left-closed and right-open Suffix form: Define dp[i] as the solution to the subproblem with input A[i:] Contiguous substrings of a sequenceÔºöDefine dp[i][j] as the solution to the subproblem with input A[i:j+1] If the input is double sequences A Âíå B There are a total of $3 \\times 3 = 9$ possible Cartesian products for the previous 3 types, depending on the specific situation *For example, in the problem of finding the longest common subsequence(LCS), dp[i][j] can be used to represent the LCS of inputs A[:i+1] and B[:j+1] If the input is number k Define dp[k] as the solution to the subproblem with input K. If the input is a binary tree r Define dp[r] as the solution to the subproblem with input being the subtree with r as the root node. In tree DP, pay attention to the relevance between ‚Äúsubproblem‚Äù and ‚Äúsubtree‚Äù üìí Advanced: Once you have mastered the general approach above, you can solve many dynamic programming problems. However, you may find it difficult to relate subproblems with your loose definition. When you have difficulties in associating subproblems, you can always try to add constraints to the subproblems you define or expand the subproblems. In MIT 6.006, this is called Subproblem Constraints and Expansion Expanding subproblems is more common. Generally, this involves changing the form of dp[i] to dp[i][j], which will also change the definition of your subproblems. *For example, in 198. House Robber, an additional state can be introduced to remember whether house i was robbed or not I will also mention briefly what it means to add constraints to the definition of subproblems. *For example, if we define dp[i] as the solution with input A[:i+1], assuming that each A[i] has two states of being selected or not, we can consider defining dp[i] as the solution with input A[:i+1] and A[i] must be in the selected state (this may be a bit abstract. I will provide a link to a problem that can be handled in this way later). üìí You will find that when defining subproblems, we don‚Äôt think about how to calculate the value. Don‚Äôt start thinking about how to calculate the value when defining subproblems. When you use the SRTBOT framework to analyze, you will naturally know how to calculate it~ ","date":"2023-04-09","objectID":"/en/solving-dynamic-programming-problems-using-srtbot/:3:1","series":null,"tags":["Algorithm"],"title":"Solving DP problems by SRTBOT Framework","uri":"/en/solving-dynamic-programming-problems-using-srtbot/#subproblems-definition"},{"categories":["Algorithm"],"content":" Relate subproblem solutions recursively‚ÄúIdentify a question about a subproblem solution that, if you knew the answer to, reduces the subproblem to smaller subproblem(s)‚Äù2. If we try to write the formula, it will be likes this: $$ dp[i] = f(dp[j_1],dp[j_2], ‚Ä¶, dp[j_k])\\ where\\ j_k \u003ci $$ Where $f$ is an abstract operation. It‚Äôs the way how we relate different subproblem(s). **The way to relate subproblem(s) is by making ‚Äúdecisions‚Äù. Here comes the question, what decisions we get? Read the problem description and you will find the answer. Then try to ‚Äúlocally brute-force‚Äù all possible answers to the question :) üëª It‚Äôs fine that you find difficulties in finding the relationship at first. However, after getting enough practice, you will become comfortable. ü§îÔ∏è I found that when trying to recursively relate subproblem(s), it is always helpful to draw a dependency graph (nodes are subproblem and edges are ‚Äúdecisions‚Äù). The dependency graph not only clearly shows the relationship between subproblem(s) but also verify that there are overlapping subproblems python dp[i] (apply f to aggregate results) / | \\ (?)/ |(?) \\(?) / | \\ dp[j_1] dp[j_2] ... / \\ / \\ / \\ ... ... ... ... ... For example, in the problem of 70. Climbing stairs on LeetCode, where each time one can climb one or two steps ($K=2$), reaching the i-th step must have come from either the i-1-th step or the i-2-th step. Since we are looking for all possible ways to climb the stairs, dp[i] = dp[i-1] + dp[i-2] python dp[i] (sum) / \\ (climb one step)/ \\(climb two steps) / \\ dp[i - 1] dp[i - 2] / \\ / \\ ... ...... ... ü§îÔ∏è You can use this example to understand the meaning of ‚Äúlocal‚Äù in ‚Äúlocal brute-force‚Äù: we only use one decision one-time. For example, you may want to climb one step at a time and finally climb n steps and try to find a relationship betweena dp[i] and dp[i - n]. That‚Äôs not local! ","date":"2023-04-09","objectID":"/en/solving-dynamic-programming-problems-using-srtbot/:3:2","series":null,"tags":["Algorithm"],"title":"Solving DP problems by SRTBOT Framework","uri":"/en/solving-dynamic-programming-problems-using-srtbot/#relate-subproblems"},{"categories":["Algorithm"],"content":" Topological order to argue relation is acyclic and subproblems form a DAGYou may have seen another name for dynamic programming problems elsewhere - ‚Äútabulation method‚Äù. This is because when we use the bottom-up approach to solve dynamic programming problems, it can be seen as filling in a table. However, in my opinion, it is more helpful to understand dynamic programming by viewing it as a directed acyclic graph (DAG) - viewing subproblems as vertices on the graph and connecting ‚Äúsmaller subproblems‚Äù -\u003e ‚Äúlarger subproblems‚Äù with directed edges. This graph will form a directed acyclic graph (DAG), and the dynamic programming algorithm is the process of traversing the topological order of the DAG ü§îÔ∏è Why is it a directed acyclic graph? Firstly, directed edges represent the dependency between subproblems and also indicate the order in which we solve the subproblems: to solve a subproblem, we need to solve smaller subproblems first. Secondly, it must be acyclic because dynamic programming remembers the subproblems that have been solved, and we cannot solve the same subproblem multiple times, so it must be acyclic Understanding that order of solving subproblems in dynamic programming is the topological sorting of a DAG is very helpful in understanding tree DP problems. To solve a DP problem, we need to solve subproblems first. In the context of tree DP, the concepts of ‚Äúsubtree‚Äù and ‚Äúsubproblem‚Äù are equivalent. Therefore, solving subproblems first means calculating dp[r.left] and dp[r.right] before calculating dp[r], which follows the post-order traversal order of a binary tree. Therefore, tree DP problems are often implemented through post-order traversal. If the tree is viewed as a graph (with directed edges pointing from child nodes to parent nodes), then the topological sorting is also in correspondence with the post-order traversal order ü§îÔ∏è When writing code, you may be unsure of how to update subproblems in the correct order. Just remember to always solve smaller problems first and then move to larger problems. Combined with the relationship equation among subproblems defined earlier, you will know what the update order is ","date":"2023-04-09","objectID":"/en/solving-dynamic-programming-problems-using-srtbot/:3:3","series":null,"tags":["Algorithm"],"title":"Solving DP problems by SRTBOT Framework","uri":"/en/solving-dynamic-programming-problems-using-srtbot/#topological-order-to-argue-relation-is-acyclic-and-subproblems-form-a-dag"},{"categories":["Algorithm"],"content":" Base casesSimilar to the base case in recursive algorithms, it represents the solution to the independent smallest subproblems and is the starting point for deriving the relationship formula. This information can usually be determined by examining the problem description ","date":"2023-04-09","objectID":"/en/solving-dynamic-programming-problems-using-srtbot/:3:4","series":null,"tags":["Algorithm"],"title":"Solving DP problems by SRTBOT Framework","uri":"/en/solving-dynamic-programming-problems-using-srtbot/#base-cases"},{"categories":["Algorithm"],"content":" Original problemUsually, the original problem corresponds to dp[n] or dp[0], but don‚Äôt just memorize this. You still need to combine the problem description with the form of the subproblems you defined to represent the original problem. However, don‚Äôt worry about this because **this step is usually not the hard part of solving dynamic programming problems ","date":"2023-04-09","objectID":"/en/solving-dynamic-programming-problems-using-srtbot/:3:5","series":null,"tags":["Algorithm"],"title":"Solving DP problems by SRTBOT Framework","uri":"/en/solving-dynamic-programming-problems-using-srtbot/#original-problem"},{"categories":["Algorithm"],"content":" Time analysisThe dynamic programming algorithm is to solve all the subproblems that need to be solved and then calculates the original problem. Assuming there are a total of $n$ subproblems to be solved, the time complexity of dynamic programming can be solved using this formula: $$ n * O(each\\ subproblem) + O(original\\ problem) $$ ","date":"2023-04-09","objectID":"/en/solving-dynamic-programming-problems-using-srtbot/:3:6","series":null,"tags":["Algorithm"],"title":"Solving DP problems by SRTBOT Framework","uri":"/en/solving-dynamic-programming-problems-using-srtbot/#time-analysis"},{"categories":["Algorithm"],"content":" Get some practiceThe only way to master this technique is to get your hands dirty. Only by applying the SRTBOT framework to dynamic programming problems can you appreciate its power. Below are some of the solutions to dynamic programming problems that I have written. In the solutions, I will talk about how to analyze dynamic programming problems using the SRTBOT framework. I will continue to add the dynamic programming problems I have solved here, or you can also directly view the solutions on my Leetcode accountüëª üìí Note: My solution is not necessarily the optimal solution, for example, sometimes we can use the technique of ‚Äústate compression‚Äù to reduce space complexity, but I may not do this, I just apply the SRTBOT framework to these dynamic programming problems Problem Solution Note 70. Climbing stairs Solution Number 746. Min Cost Climbing Stairs Solution Single sequence 198. House Robber Solution Single sequence + Subproblem expansion 322. Coin changes Solution Number + non-$O(1)$ subproblem 300.¬†Longest Increasing Subsequence Solution Single sequence + subproblem restriction 5.¬†Longest Palindromic Substring Solution Substring 91.¬†Decode Ways Solution Single sequence 139.¬†Word Break Solution Single sequence 62. Unique Paths Solution Grid 1143. Longest Common Subsequence Solution Two sequences 309.¬†Best Time to Buy and Sell Stock with Cooldown Solution Single sequence + subproblem expansion 1911.¬†Maximum Alternating Subsequence Sum Solution Single sequence + subproblem expansion ","date":"2023-04-09","objectID":"/en/solving-dynamic-programming-problems-using-srtbot/:4:0","series":null,"tags":["Algorithm"],"title":"Solving DP problems by SRTBOT Framework","uri":"/en/solving-dynamic-programming-problems-using-srtbot/#get-some-practice"},{"categories":["Algorithm"],"content":" Refs Dynamic programming - Wiki¬†‚Ü©Ô∏é Lecture 15 ~ 18 of MIT 6.006¬†‚Ü©Ô∏é¬†‚Ü©Ô∏é ","date":"2023-04-09","objectID":"/en/solving-dynamic-programming-problems-using-srtbot/:5:0","series":null,"tags":["Algorithm"],"title":"Solving DP problems by SRTBOT Framework","uri":"/en/solving-dynamic-programming-problems-using-srtbot/#refs"},{"categories":["ML-DL"],"content":"A simple tutorial about the backpropagation algorithm in deep learning","date":"2023-04-04","objectID":"/en/backpropagation-tutorial/","series":null,"tags":["Deep-Learning"],"title":"How to understand the backpropagation algorithm","uri":"/en/backpropagation-tutorial/"},{"categories":["ML-DL"],"content":" Update: Backpropagation in matrix form could be found here ","date":"2023-04-04","objectID":"/en/backpropagation-tutorial/:0:0","series":null,"tags":["Deep-Learning"],"title":"How to understand the backpropagation algorithm","uri":"/en/backpropagation-tutorial/#"},{"categories":["ML-DL"],"content":" IntroIn the field of deep learning, optimizing the network involves a crucial process of continuously updating the weights and bias items. This is achieved by implementing the gradient descent method, which progressively minimizes the loss function. At the heart of this process lies the backpropagation algorithm, which facilitates efficient computation of gradients across the network To better understand this concept, let us recall the formula for gradient descent. In this formula, we utilize the symbol $\\theta$ to represent all the learnable parameters of the model, $J$ to represent the cost or loss function, and $\\alpha$ to denote the learning rate. Thus, we can express the updating process as: $$ \\theta \\leftarrow \\theta - \\alpha * \\frac{\\partial J}{\\partial \\theta} $$ To optimize the model continuously, it‚Äôs crucial to calculate the gradient $\\frac{\\partial J}{\\partial \\theta}$ accurately and efficiently through backpropagation. This process involves computing the partial derivatives of the loss function with respect to the model‚Äôs parameters, which are also referred to as weights and biases. üìí Throughout the post, the terms ‚Äúparameters‚Äù and ‚Äúweights and biases‚Äù will be used interchangeably as they both represent the learnable elements of the model üìí It is assumed that the reader has a basic understanding of the chain rule of derivation in mathematics to follow the explanations providedü´° ","date":"2023-04-04","objectID":"/en/backpropagation-tutorial/:1:0","series":null,"tags":["Deep-Learning"],"title":"How to understand the backpropagation algorithm","uri":"/en/backpropagation-tutorial/#intro"},{"categories":["ML-DL"],"content":" Define a modelBefore we proceed, we need to define a model for subsequent derivation. For this purpose, let‚Äôs consider a simple yet classical three-layer fully connected neural network: üìí Note: Uppercase letters represent matrices, and lowercase letters represent vectors (without subscripts) or scalars (with subscripts) where: The network consists of an input layer with $n$ neurons, a hidden layer with $h$ neurons, and an output layer with $k$ neurons $x^1_j$ represents the $j$-th feature value of the input vector. Note that we start counting from 1, the output layer is the 1st layer $y_j$ represents the true value of the $j$-th output of the corresponding output layer $w^l_{jk}$ represents the weight corresponding to the link between the $k$-th neuron of the $l-1$ layer and the $j$-th neuron of the $l$ layer, Note the order of subscripts. Based on this, we can deduce that the dimensionality of $W^2$ and $W^3$ are as follows: $W^2\\in \\mathcal{R}^{h\\times n}$ $W^3\\in \\mathcal{R}^{k\\times h}$ $b_j^l$ represents the bias term of the $j$-th neuron of the layer $l$ $z_j^l$ represents the weighted output of the $j$ neuron of the layer $l$ $a_j^l$ represents the output after the activation function of the $j$-th neuron in the layer $l$ With these terms defined, we can formulate the process of forward propagation in a neural network as follows: $$ z_j^2 = \\sum_kw_{jk}^2x^1_k+b_j^2 $$ $$ a_j^2=\\sigma(z_j^2) $$ $$ z_j^3 = \\sum_kw_{jk}^3a_k^2+b_j^3 $$ $$ a_j^3=\\sigma(z_j^3) $$ Let‚Äôs generalize $z_j^l$ and $a_j^l$: $$ z_j^l=\\sum_kw_{jk}^la^{l-1}_k+b_j^l $$ $$ a_j^l=\\sigma(z_j^l) $$ The above two formulas are very important, they will be very useful in the derivation of the four formulas of backpropagation Here we consider using the mean squared error (MSE) as the cost or loss function $J$ and the $sigmoid$ function as the activation function. Of course, the derivation process is similar if we use different cost/loss function and activation function $$ J = \\frac{1}{2k}\\sum_{j=1}^k(a_j^L-y_j)^2 $$ ","date":"2023-04-04","objectID":"/en/backpropagation-tutorial/:2:0","series":null,"tags":["Deep-Learning"],"title":"How to understand the backpropagation algorithm","uri":"/en/backpropagation-tutorial/#define-a-model"},{"categories":["ML-DL"],"content":" The intuition of backpropagationUnderstanding a concept at a high level before delving into its details is always beneficial. In the context of deep learning, the goal of the training process is to minimize the error between the predicted value $a^L_j$ and the actual label $y_j$ for each sample. By calculating this error, we can determine whether to increase or decrease $a^L_j$ to improve the model‚Äôs predictions. However, we can only adjust $a^L_j$ by modifying the weights $w^L_{jk}$ between the $L-1$ layer and the output layer, the bias term $b_j^L$, or the output value $a^{L-1}_k$ after the activation function in the $L-1$ layer. It‚Äôs worth mentioning that we can‚Äôt directly modify $a_k^{L-1}$, which is determined by the values of the previous weight and bias items. When we decide how to modify each weight and bias of the model backwardly based on the prediction error, we are doing backpropagation1 The above process describes how $a_j^L$ wants to adjust the weights and biases of the entire model. However, we need to consider the opinions of all neurons in the output layer, as each neuron may has a different idea of how the weights and biases should change. Ultimately, we need to update the model‚Äôs weights and biases by incorporating the opinions of all neurons in the output layer. ","date":"2023-04-04","objectID":"/en/backpropagation-tutorial/:3:0","series":null,"tags":["Deep-Learning"],"title":"How to understand the backpropagation algorithm","uri":"/en/backpropagation-tutorial/#the-intuition-of-backpropagation"},{"categories":["ML-DL"],"content":" The four formulas of the backpropagationThe core of the backpropagation algorithm contains 4 formulas ","date":"2023-04-04","objectID":"/en/backpropagation-tutorial/:4:0","series":null,"tags":["Deep-Learning"],"title":"How to understand the backpropagation algorithm","uri":"/en/backpropagation-tutorial/#the-four-formulas-of-the-backpropagation"},{"categories":["ML-DL"],"content":" Formula 1$$ \\delta_j^L=\\frac{\\partial J}{\\partial a_j^L}\\sigma‚Äô(z_j^L) $$ Where $L$ is the number of layers of the model($L=3$ in this example), $\\delta_j^L$ represents the gradient of the $j$-th neuron in the $L$ layer By the way, the above formula can be rewritten as $\\delta^L=\\nabla J\\odot \\sigma‚Äô(z^L)$ in vectorized form. The $\\odot$ represents the element-wise multiplication üìí Formula 1 calculates the gradient of each neuron in the output layer How to derive this‚¨áÔ∏è $$ \\begin{aligned} \\delta_j^L\u0026=\\frac{\\partial J}{\\partial z_j^L} \\\\\\ \u0026=\\sum_k\\frac{\\partial J}{\\partial a_k^L}\\frac{\\partial a_k^L}{\\partial z_j^L} \\\\\\ \u0026=\\frac{\\partial J}{\\partial a_j^L}\\frac{\\partial a_j^L}{\\partial z_j^L}\\ (only\\ \\frac{\\partial a_j^L}{\\partial z_j^L}\\ne 0) \\\\\\ \u0026=\\frac{\\partial J}{\\partial a_j^L}\\frac{\\partial \\sigma(z_j^L)}{\\partial z_j^L}\\ \\\\\\ \u0026=\\frac{\\partial J}{\\partial a_j^L}\\sigma‚Äô(z_j^L) \\end{aligned} $$ ","date":"2023-04-04","objectID":"/en/backpropagation-tutorial/:4:1","series":null,"tags":["Deep-Learning"],"title":"How to understand the backpropagation algorithm","uri":"/en/backpropagation-tutorial/#formula-1"},{"categories":["ML-DL"],"content":" Formula 2$$ \\delta^l=((w^{l+1})^T\\delta^{l+1})\\odot \\sigma‚Äô(z^l) $$ üìí Formula 2 calculates the gradient vector of any layer $l$. It is worth noting how this formula links the gradient of layer $l$ with that of layer $l+1$. This allows us to compute the gradient of a previous layer using the gradients of subsequent layers How to derive this‚¨áÔ∏è $$ \\begin{aligned} \\delta_j^l\u0026=\\frac{\\partial J}{\\partial z_j^l} \\\\\\ \u0026=\\sum_k\\frac{\\partial J}{\\partial z_k^{l+1}}\\frac{\\partial z_k^{l+1}}{\\partial z_j^l} \\\\\\ \u0026=\\sum_k\\delta_k^{l+1}\\frac{\\partial }{\\partial z_j^l}z_k^{l+1} \\end{aligned} $$ Note that $\\frac{\\partial }{\\partial z_j^l}z_k^{l+1} = \\frac{\\partial }{\\partial z_j^l}\\ \\sum_pw^{l+1}_{kp}\\sigma(z_p^l)+b^{l+1}_k$ The derivative only exists when $p=j$, so the solution to the above formula is $w^{l+1}_{kj}\\sigma‚Äô(z_j^l)$. That is, we have shown that $\\delta_j^l=\\sum_k\\delta_k^{l+1}\\ w^{l+1}_{kj}\\sigma‚Äô(z_j^l)$ $\\sum_k\\delta_k^{l+1}w^{l+1}_{kj}$ is actually calculating the inner product of 2 vectors, so it can be rewritten as a vectorized form - $\\delta^l=((w^{l+1})^T\\delta^{l+1})\\odot \\sigma‚Äô(z^l)$ ","date":"2023-04-04","objectID":"/en/backpropagation-tutorial/:4:2","series":null,"tags":["Deep-Learning"],"title":"How to understand the backpropagation algorithm","uri":"/en/backpropagation-tutorial/#formula-2"},{"categories":["ML-DL"],"content":" Formula 3$$ \\frac{\\partial J}{\\partial b^l_j}=\\delta_j^l $$ üìí Formula 3 can be used to calculate the gradient of any bias term in the model How to derive this‚¨áÔ∏è $$ \\begin{aligned} \\frac{\\partial J}{\\partial b^l_j}\u0026= \\frac{\\partial J}{\\partial z^l_j}\\frac{\\partial z^l_j}{\\partial b^l_j} \\\\\\ \u0026= \\delta_j^l \\frac{\\partial}{\\partial b^l_j}\\sum_kw^l_{jk}a^{l-1}_j+b^l_j\\\\\\ \u0026= \\delta_j^l \\end{aligned} $$ Note that the first equal sign above is similar to the derivation of formula 1. I skipped the process of removing $\\sum_k$ ","date":"2023-04-04","objectID":"/en/backpropagation-tutorial/:4:3","series":null,"tags":["Deep-Learning"],"title":"How to understand the backpropagation algorithm","uri":"/en/backpropagation-tutorial/#formula-3"},{"categories":["ML-DL"],"content":" Formula 4$$ \\frac{\\partial J}{\\partial w_{jk}^l}=a_k^{l-1}\\delta_j^l $$ üìí Formula 4 can be used to calculate the gradient of any weight term in the model How to derive this‚¨áÔ∏è $$ \\begin{aligned} \\frac{\\partial J}{\\partial w_{jk}^l}\u0026=\\frac{\\partial J}{\\partial z^l_j}\\frac{\\partial z^l_j}{\\partial w_{jk}^l} \\\\\\ \u0026=\\frac{\\partial J}{\\partial z^l_j}\\frac{\\partial }{\\partial w_{jk}^l}\\sum_pw_{jp}^la_p^{l-1}+b_j^l \\\\\\ \u0026=\\delta_j^l\\frac{\\partial }{\\partial w_{jk}^l}\\sum_kw_{jk}^la_k^{l-1}+b_j^l \\\\\\ \u0026=\\delta_j^la_k^{l-1} \\end{aligned} $$ ","date":"2023-04-04","objectID":"/en/backpropagation-tutorial/:4:4","series":null,"tags":["Deep-Learning"],"title":"How to understand the backpropagation algorithm","uri":"/en/backpropagation-tutorial/#formula-4"},{"categories":["ML-DL"],"content":" Backpropagation algorithm procedureBased on the aforementioned formulas, we can know the whole process of backpropagation will be: Forward propagation, compute $z_j^l$Ôºå$a_j^l$ for each neuron in each layer Compute $\\delta^L$ in the output layer based on the formula 1 Repeat the following process backwardly Calculate the gradient vector $\\delta^l$ for each layer based on formula2. Note that we can always compute $\\delta^l$ using $\\delta^{l+1}$ :) Calculate the gradient of each bias term $b^l_j$ based on formula 3, which is equal to $\\delta^l_j$ Calculate the gradient of each weight $w^l_{jk}$ based on formula 4, which is equal to $\\delta_j^la_k^{l-1}$ The above process also answers the question of why backpropagation is an efficient algorithm: üëç When calculating the gradient vector $\\delta^l$ for the $l$-th layer based on formula 2, $\\delta^{l+1}$ has already been computed and there is no need to start from scratch at the output layer. üëç By directly calculating the gradient of the loss function with respect to the current layer‚Äôs weights and bias terms using formulas 3 and 4, we avoid computing intermediate gradient results. ","date":"2023-04-04","objectID":"/en/backpropagation-tutorial/:4:5","series":null,"tags":["Deep-Learning"],"title":"How to understand the backpropagation algorithm","uri":"/en/backpropagation-tutorial/#backpropagation-algorithm-procedure"},{"categories":["ML-DL"],"content":" Wrap upThe above is the entire process of the backpropagation algorithm. Although it involves a lot of formulas and notation, it is still relatively easy to understand. When reviewing the backpropagation algorithm, I found some points that may help readers understand it: Backpropagation is an algorithm for a single sample, so when you derive the formulas, you only need to consider one sample as the input of the model When deriving the formulas, start from the scalar form and then generalize it into vectorized form. Don‚Äôt start with vectorized form or you may get stuck easily. Of course, if you‚Äôve solid basics of math, ignore what I just said That‚Äôs all, thanks for readingüëã ","date":"2023-04-04","objectID":"/en/backpropagation-tutorial/:5:0","series":null,"tags":["Deep-Learning"],"title":"How to understand the backpropagation algorithm","uri":"/en/backpropagation-tutorial/#wrap-up"},{"categories":["ML-DL"],"content":" Refs What is backpropagation really doing? - 3Blue1Brown¬†‚Ü©Ô∏é ","date":"2023-04-04","objectID":"/en/backpropagation-tutorial/:6:0","series":null,"tags":["Deep-Learning"],"title":"How to understand the backpropagation algorithm","uri":"/en/backpropagation-tutorial/#refs"},{"categories":["ML-DL"],"content":"The simple guide of theory part of linear regression model in machine learning","date":"2023-03-15","objectID":"/en/linear-regression-model-guide-theory/","series":null,"tags":["Machine-Learning"],"title":"Linear Regression Model Guide - theory part","uri":"/en/linear-regression-model-guide-theory/"},{"categories":["ML-DL"],"content":" IntroductionRecently, I review the machine learning course of Andrew ng in Coursera. Surprisingly, I can still learn a lot, so I decided to write some postsüëç. To talk about linear regression, we must first have a basic understanding of what is machine learning. What is machine learning? abstractly speaking, machine learning is learning a function: $$ f(input) = output $$ where $f$ refers to the specific machine learning model. Machine learning is a methodology for automatically mining the relationship between input and output. Sometimes we find it hard to define a specific algorithm to solve some problems, and this is where machine learning shines, we can let it learn and summarize some patterns from data and make predictions. This is also where it differs from traditional algorithms (binary search, recursive, etc.). One has to admit that machine learning is fascinating by definition, and it seems to provide a viable framework for solving all intractable problems. It just so happens that many real-life problems are so hard that solving them with traditional algorithms is impossible. üìí That‚Äôs why I always feel that every programmer should know some machine learning/deep learning, it is a great tool for us to solve problemsüí™ Linear regression is one of the classic machine learning models. In my opinion, it can be regarded as the counterpart of ‚ÄúHello world‚Äù in the machine learning world. In the previous formula, $input$ is the so-called feature in machine learning, which is often represented by the symbol $x$. And $output$ can be roughly divided into two categories: class/category (Classification problem) and number (Regression problem). üìí How to understand features? The so-called features are characteristics that are highly correlated with the target to be predicted. Take predicting housing prices as an example. The housing price is obviously related to the house area, distance to the downtown, etc. The house area here is a feature. In machine learning, we can analyze the importance of different features to see which ones are highly correlated with the output, or use our domain knowledge (Domain knowledge) to choose good features wisely. But in general, machine learning still requires us to spend a lot of time spotting good features. This is the drawback of machine learning, and this shortcoming is greatly alleviated in deep learning. Of course, that is not the topic today. üìí Machine learning cannot magically understand the various formats of $input$ you provide, such as images, text, videos, etc.. In machine learning, $input$ is often processed as numbers, so that they can be learned by various machine learning algorithms. Some features are numbers themselves, such as the house area we previously talked about. When the input is not transformered into numbers, we needed to invent some procedure to do so, such as using a word embedding vector model to represent text, etc., and I will not go into details here. Let‚Äôs assume that the input has been processed into numbers below. The topic of this post, the linear regression model, belongs to the regression model in the supervised learning domain. It is a simple model, but it can explain a lot of machine learning ideas, which makes it a perfect choice to get started. Without further ado, let‚Äôs get started :) üìí This article assumes that you have a basic understanding of matrix/vector calculus, for example, you need to know the definition of matrix multiplication, how to calculate derivatives, etc. ","date":"2023-03-15","objectID":"/en/linear-regression-model-guide-theory/:1:0","series":null,"tags":["Machine-Learning"],"title":"Linear Regression Model Guide - theory part","uri":"/en/linear-regression-model-guide-theory/#introduction"},{"categories":["ML-DL"],"content":" Linear regression modelAs the name suggests, it consists of two parts: Linear. Taking a two-dimensional plane as an example, $y=kx+b$ is linear, for it is a straight line when drawn, but $y=x^2$ is not, because it is drawn as a curve Regression because it fits the definition of a regression problem in machine learning - predicting a value of unlimited range ","date":"2023-03-15","objectID":"/en/linear-regression-model-guide-theory/:2:0","series":null,"tags":["Machine-Learning"],"title":"Linear Regression Model Guide - theory part","uri":"/en/linear-regression-model-guide-theory/#linear-regression-model"},{"categories":["ML-DL"],"content":" Categories üìí To reduce the visual noise, the following notation $f(x)$ omits the subscripts $w,b$ for simplicity. I.e. $f(x)=f_{w,b}(x)$ üìí Sometimes you may see some books or blogs use $h_\\theta$ to represent the model(h means hypothesis), I think $f(x)$ as it is more concise and intuitive. The linear regression model can be divided into the following categories: ","date":"2023-03-15","objectID":"/en/linear-regression-model-guide-theory/:3:0","series":null,"tags":["Machine-Learning"],"title":"Linear Regression Model Guide - theory part","uri":"/en/linear-regression-model-guide-theory/#categories"},{"categories":["ML-DL"],"content":" Univariate linear regression modelUnivariate means that your model only accepts a single feature: $$ f(x)=wx+b $$ In machine learning world, we call $w$ and $b$ as weight and bias üìí Note: $\\theta$ is a column vector, logically it should be represented by $\\vec \\theta$, but for the sake of brevity, I have omitted the arrow. üìí The equation above can also be written in the form of vector multiplication. Let $\\theta=[b, w]$ represent the parameters of the model, and rewrite x as $\\vec x=[1, x]^T$. According to the knowledge of vector multiplication, we can infer that $\\theta^T\\vec x=wx+b$ ","date":"2023-03-15","objectID":"/en/linear-regression-model-guide-theory/:3:1","series":null,"tags":["Machine-Learning"],"title":"Linear Regression Model Guide - theory part","uri":"/en/linear-regression-model-guide-theory/#univariate-linear-regression-model"},{"categories":["ML-DL"],"content":" Multiple linear regression modelMultiple means that your model accepts multiple features: $$ f(x)=w_1x_1+w_1x_2+‚Ä¶w_nx_n+b $$ Where $x_i$ is the ith feature, there are $n$ features in total, for this, we need to learn a weight $w_i$ for each feature üìí Similarly, we can choose to write in the form of vector multiplication. Let $\\theta=[b, w_1, w_2, ‚Ä¶, w_n]$ and $\\vec x=[1, x_1, x_2, ‚Ä¶, x_n]^T$. You will be surprised to find that univariate linear regression and multivariate linear regression have a unified form - $f(\\vec x)=\\theta^T\\vec x$. This will bring great convenience when calculating the gradient later. ","date":"2023-03-15","objectID":"/en/linear-regression-model-guide-theory/:3:2","series":null,"tags":["Machine-Learning"],"title":"Linear Regression Model Guide - theory part","uri":"/en/linear-regression-model-guide-theory/#multiple-linear-regression-model"},{"categories":["ML-DL"],"content":" How to train this model","date":"2023-03-15","objectID":"/en/linear-regression-model-guide-theory/:4:0","series":null,"tags":["Machine-Learning"],"title":"Linear Regression Model Guide - theory part","uri":"/en/linear-regression-model-guide-theory/#how-to-train-this-model"},{"categories":["ML-DL"],"content":" Cost functionAfter defining the linear regression model, we need to measure its prediction quality. Obviously, we wish to minimize the ‚Äúdistance‚Äù between the predicted value and the actual value. In machine learning, we will specify a cost function to measure the ‚Äúdistance‚Äù. The lower the cost, the better. When the cost of the model on the validation set is minimized to a small value and no longer changes significantly, we think that the model has converged, and the best model is obtained at this time üìí In machine learning, the data is usually divided into training/validation/test set, the model learns on the training set, verifies and adjusts parameters on the validation set, and performs generalization verification on the test set finally (The test set contains unseen data). It is incorrect to directly adjust parameters on the test set by only using the division method of training/test set. The test set is used if and only if after you finish training and tuning your model The most commonly used cost function of the linear regression model is the mean square error function(MSE). Its formula is as follows: $$ MSE=\\frac{1}{2m}\\sum^m_{i=1}(\\hat y^{(i)} - y^{(i)})^2 $$ where $m$ represents the number of samples The superscript ${(i)}$ is different from exponent marks. ${(i)}$ indicates the predicted/true value of the $i$th sample $\\hat y$ represents the prediction of the linear regression model, and $y$ represents the original true value üìí I use notations that conforms to machine learning conventions~ üìí Linear regression model does not have to use MSE though, you can also use the absolute value error(MAE). Use MAE when there are many outliers in the training set, which can reduce the sensitivity to them. ","date":"2023-03-15","objectID":"/en/linear-regression-model-guide-theory/:4:1","series":null,"tags":["Machine-Learning"],"title":"Linear Regression Model Guide - theory part","uri":"/en/linear-regression-model-guide-theory/#cost-function"},{"categories":["ML-DL"],"content":" Training use gradient descentAs aforementioned, when the cost of the model on the validation set is minimized and does not change significantly, we get the best model. But how to make the model continuously improve the prediction and reduce the cost? ü§î The Gradient descent algorithm is a general practice Don‚Äôt be fooled by the name, the gradient descent algorithm is not that mysterious. Let‚Äôs recap what we have learned so far: The prediction $\\hat y$ of the model is related to its parameters, if it is a univariate linear regression model, it is related to $w$ and $b$ The cost function is related to the prediction of the model because we cannot change the real value of the data So The cost function is a function about the model parameters. In machine learning, it is usually denoted by $J$. Consider first simple univariate linear regression when it uses MSE as the cost function: $$ J(w, b) = \\frac{1}{2m}\\sum^m_{i=1}(f(x^{(i)})-y^{(i)})^2 = \\frac{1}{2m}\\sum^m_{i=1}(wx^{(i)} + b - y^{(i)})^2 $$ By changing the values of $w$ and $b$, the cost $J(w,b)$ will change accordingly, so improving the linear regression model is adjusting these two parameters so that $J(w, b)$ reaches its minimum. In the language of mathematics, solving the optimal model is solving the minimum point of the function $J(w,b)$ üìí Recall that $m$ is the number of samples in the training set. More strictly speaking, the above gradient descent formula is batch gradient descent, that is, every calculation of the gradient uses samples from the entire training set. When the training set is very large, this method cannot scale well. At this time, we need to use stochastic gradient descent. üìí If you are good at mathematics, it is not difficult for you to find the minimum value of the above formula. But this is because the linear regression model is relatively simple, when the model becomes more complicated, it will be more difficult to solve it with mathematical methods. In practice, we use the gradient descent algorithms all the time in the machine learning world (reinforcement learning is an exception, for the goal of reinforcement learning optimization is generally not a differentiable function) Let us forget $b$ temporarily and only consider $w$, then $J$ is a function about $w$ at this time. We can take $w$ as the horizontal axis, and $J(w)$ as the vertical axis, which gives us the following plot üìí Note that the above diagram does not strictly follow the definition of $J(w)$. For convenience, I directly draw $y=\\frac{1}{2}x^2$ here. But the shape should be similar, which can be used to understand the gradient descent algorithm. It is trivial to find out from the figure that $J(w)$ reaches its minimum when $w=0$. Assuming that the model‚Äôs current parameter $w$ is $5$, we can calculate the cost as $J(5)=12.5$. How do we update $w$ to minimize the cost? The solution is to let $w$ update along the opposite direction of the gradient (the red line in the figure is the tangent at the point $w=5$), it is not difficult to compute the gradient/derivative at this point, which is $5$, $w$ should be reduced, so it should minus this gradient (that‚Äôs why we say opposite direction). We also introduce learning rate $\\alpha$ to control the step size, which give us the update formula $w \\leftarrow w - \\alpha \\cdot 5$ üìí Intuition: Imagine yourself standing at the point of $w=5$ and want to reach the minimum. If the learning rate $\\alpha$ is too large, your new position $w$ may be less than $0$. You will find that you suddenly crossed the minimum. Although you can try to update again through gradient descent, at this time you will often find that the loss of your model has been changing and cannot converge. The learning rate and the gradient jointly control the magnitude of each parameter update üìí We concluded how to update when only considering $w$ - along the opposite direction of the gradient. This conclusion still holds when considering more parameters, but that involves the knowl","date":"2023-03-15","objectID":"/en/linear-regression-model-guide-theory/:4:2","series":null,"tags":["Machine-Learning"],"title":"Linear Regression Model Guide - theory part","uri":"/en/linear-regression-model-guide-theory/#training-use-gradient-descent"},{"categories":["ML-DL"],"content":" Wrap upWe have finished the theoretical part of the linear regression model. This post introduces univariate linear regression and multivariate linear regression. The former can be regarded as a special case of the latter. Finally, we unified the equations in vector form, and derive the gradient when MSE is used as the cost function. I originally wanted to put the code here, but I found out that this blog is already very long. It will be a better choice to put the implementation part in another postüôå ","date":"2023-03-15","objectID":"/en/linear-regression-model-guide-theory/:5:0","series":null,"tags":["Machine-Learning"],"title":"Linear Regression Model Guide - theory part","uri":"/en/linear-regression-model-guide-theory/#wrap-up"},{"categories":["Vim-Neovim"],"content":"Configure your neovim from scratch, including LSP support","date":"2023-02-08","objectID":"/en/config-neovim-from-scratch/","series":null,"tags":["Vim-Neovim"],"title":"Transform Your Neovim into a IDE: A Step-by-Step Guide","uri":"/en/config-neovim-from-scratch/"},{"categories":["Vim-Neovim"],"content":" Info Updates: 2024-04-04. Use lazy.nvim rather than packer.nvim ü§ó If you have configured your Neovim followed my post previously, you may check this commit to see how to migrate from packer.nvim to lazy.nvim. Remember to run :checkhealth lazy after the migration as we also need to remove some outdated files of packer.nvim. Further reading How to set up Neovim for a new programming langauge and get more control over code formatting, please refer to the next post ","date":"2023-02-08","objectID":"/en/config-neovim-from-scratch/:0:0","series":null,"tags":["Vim-Neovim"],"title":"Transform Your Neovim into a IDE: A Step-by-Step Guide","uri":"/en/config-neovim-from-scratch/#"},{"categories":["Vim-Neovim"],"content":" Version infoI use a Macbook pro-2020 Intel Edition with macOS 13.2. This is my Nvim edition: text NVIM v0.9.5 Build type: Release LuaJIT 2.1.1710088188 system vimrc file: \"$VIM/sysinit.vim\" fall-back for $VIM: \"/usr/local/Cellar/neovim/0.9.5/share/nvim\" Run :checkhealth for more info ","date":"2023-02-08","objectID":"/en/config-neovim-from-scratch/:1:0","series":null,"tags":["Vim-Neovim"],"title":"Transform Your Neovim into a IDE: A Step-by-Step Guide","uri":"/en/config-neovim-from-scratch/#version-info"},{"categories":["Vim-Neovim"],"content":" Why NeovimAfter using Vim for one year, I find myself having trouble in configure ~/.vimrc. The syntax of Vimscript is not my liking, leading me to switch Neovim(Nvim). Rather than migrating my old ~/.vimrc. I decided to start from scratch and take this opportunity to re-evaluate my previous Vim configuration. I aim to replace my plugins with the latest SOTA(State-of-the-art) alternatives. It‚Äôs been some time since I last edited my ~/.vimrc In my opinion, it‚Äôs essential to understand the meaning behind each option and statement in the configuration file. That‚Äôs the approach I took in this post. My goal is to make the configuration files self-contained and easily understandable. To achieve this, I aim to provide clear explanations for each setting and include comments to enhance readability. üí° Please note that I may have missed some options. However, as a reminder, you can always access the help docs in the Nvim by typing :h \u003cname\u003e to get more information üí° This post assumes that you have a basic understanding of Vim ","date":"2023-02-08","objectID":"/en/config-neovim-from-scratch/:2:0","series":null,"tags":["Vim-Neovim"],"title":"Transform Your Neovim into a IDE: A Step-by-Step Guide","uri":"/en/config-neovim-from-scratch/#why-neovim"},{"categories":["Vim-Neovim"],"content":" The basics","date":"2023-02-08","objectID":"/en/config-neovim-from-scratch/:3:0","series":null,"tags":["Vim-Neovim"],"title":"Transform Your Neovim into a IDE: A Step-by-Step Guide","uri":"/en/config-neovim-from-scratch/#the-basics"},{"categories":["Vim-Neovim"],"content":" LuaIn my Nvim configuration, I will use the Lua programming language as much as possible. Thus, it‚Äôs recommended that the reader familiarize themselves with Lua. Take a look at Learn Lua in Y minutes ","date":"2023-02-08","objectID":"/en/config-neovim-from-scratch/:3:1","series":null,"tags":["Vim-Neovim"],"title":"Transform Your Neovim into a IDE: A Step-by-Step Guide","uri":"/en/config-neovim-from-scratch/#lua"},{"categories":["Vim-Neovim"],"content":" Configurations files pathsThe configuration directory for Nvim is located at ~/.config/nvim. On Linux/Mac, Nvim will read ~/.config/nvim/init.lua when it starts up. Theoretically, we can put everything inside this single file. It‚Äôs a bad practice though. To keep things organized, I prefer to break it down into smaller, more manageable parts. If you follow this post to configure your Nvim, your ~/.config/nvim should look like this‚¨áÔ∏è text nvim ‚îú‚îÄ‚îÄ init.lua ‚îî‚îÄ‚îÄ lua ‚îú‚îÄ‚îÄ colorscheme.lua ‚îú‚îÄ‚îÄ config ‚îÇ¬†‚îî‚îÄ‚îÄ nvim-cmp.lua ‚îú‚îÄ‚îÄ keymaps.lua ‚îú‚îÄ‚îÄ lsp.lua ‚îú‚îÄ‚îÄ options.lua ‚îî‚îÄ‚îÄ plugins.lua The explanations init.lua is the entry point. We will ‚Äúimport‚Äù other *.lua files in init.lua colorscheme.lua for the theme keymaps.lua for key mappings lsp.lua for the LSP support options.lua for some global options plugins.lua for third-party plugins Put the configurations of third-party plugins in this config folder. For example, nvim-cmp.lua for the nvim-cmp plugin lua folder. When we call require to import a module in Lua, it will search this folder. Replace the path separator / with ., and remove the suffix - .lua. That‚Äôs how you get the parameter of require For example, to import nvim-cmp.lua, you should write require('config.nvim-cmp') ","date":"2023-02-08","objectID":"/en/config-neovim-from-scratch/:3:2","series":null,"tags":["Vim-Neovim"],"title":"Transform Your Neovim into a IDE: A Step-by-Step Guide","uri":"/en/config-neovim-from-scratch/#configurations-files-paths"},{"categories":["Vim-Neovim"],"content":" OptionsWe mainly use these: vim.g, vim.opt, and vim.cmd. I made a cheatsheet below: In Vim In Nvim Note let g:foo = bar vim.g.foo = bar set foo = bar vim.opt.foo = bar set foo = vim.opt.foo = true some_vimscript vim.cmd(some_vimscript) ","date":"2023-02-08","objectID":"/en/config-neovim-from-scratch/:3:3","series":null,"tags":["Vim-Neovim"],"title":"Transform Your Neovim into a IDE: A Step-by-Step Guide","uri":"/en/config-neovim-from-scratch/#options"},{"categories":["Vim-Neovim"],"content":" key mappingsThe syntax of key binding in Nvim: lua vim.keymap.set(\u003cmode\u003e, \u003ckey\u003e, \u003caction\u003e, \u003copts\u003e) For a detailed explanation, please refer to :h vim.keymap.set ","date":"2023-02-08","objectID":"/en/config-neovim-from-scratch/:3:4","series":null,"tags":["Vim-Neovim"],"title":"Transform Your Neovim into a IDE: A Step-by-Step Guide","uri":"/en/config-neovim-from-scratch/#key-mappings"},{"categories":["Vim-Neovim"],"content":" Configure Nvim from scratchNow we can configure Nvim step by step :) ","date":"2023-02-08","objectID":"/en/config-neovim-from-scratch/:4:0","series":null,"tags":["Vim-Neovim"],"title":"Transform Your Neovim into a IDE: A Step-by-Step Guide","uri":"/en/config-neovim-from-scratch/#configure-nvim-from-scratch"},{"categories":["Vim-Neovim"],"content":" Install NeovimI am a Mac user, so I use Homebrew to install Nvim1 sh $ brew install neovim After completing the installation, If the ~/.config/nvim/ directory doesn‚Äôt exist, you should create the folder and init.lua file sh $ mkdir ~/.config/nvim $ mkdir ~/.config/nvim/lua $ touch ~/.config/nvim/init.lua üí° Please note that after making any modifications to the *.lua files, you need to restart the Nvim to see the changes take effect. I will assume that you restart your Nvim after each section ","date":"2023-02-08","objectID":"/en/config-neovim-from-scratch/:4:1","series":null,"tags":["Vim-Neovim"],"title":"Transform Your Neovim into a IDE: A Step-by-Step Guide","uri":"/en/config-neovim-from-scratch/#install-neovim"},{"categories":["Vim-Neovim"],"content":" Options configurationThe features: Use the system‚Äôs clipboard Use the mouse in Nvim Tab and whitespace UI configuration Smart search Create ~/.config/nvim/lua/options.lua file and edit: lua -- Hint: use `:h \u003coption\u003e` to figure out the meaning if needed vim.opt.clipboard = 'unnamedplus' -- use system clipboard vim.opt.completeopt = {'menu', 'menuone', 'noselect'} vim.opt.mouse = 'a' -- allow the mouse to be used in Nvim -- Tab vim.opt.tabstop = 4 -- number of visual spaces per TAB vim.opt.softtabstop = 4 -- number of spacesin tab when editing vim.opt.shiftwidth = 4 -- insert 4 spaces on a tab vim.opt.expandtab = true -- tabs are spaces, mainly because of python -- UI config vim.opt.number = true -- show absolute number vim.opt.relativenumber = true -- add numbers to each line on the left side vim.opt.cursorline = true -- highlight cursor line underneath the cursor horizontally vim.opt.splitbelow = true -- open new vertical split bottom vim.opt.splitright = true -- open new horizontal splits right -- vim.opt.termguicolors = true -- enabl 24-bit RGB color in the TUI vim.opt.showmode = false -- we are experienced, wo don't need the \"-- INSERT --\" mode hint -- Searching vim.opt.incsearch = true -- search as characters are entered vim.opt.hlsearch = false -- do not highlight matches vim.opt.ignorecase = true -- ignore case in searches by default vim.opt.smartcase = true -- but make it case sensitive if an uppercase is entered Then edit the init.lua file, use require to import options.lua file lua require('options') ","date":"2023-02-08","objectID":"/en/config-neovim-from-scratch/:4:2","series":null,"tags":["Vim-Neovim"],"title":"Transform Your Neovim into a IDE: A Step-by-Step Guide","uri":"/en/config-neovim-from-scratch/#options-configuration"},{"categories":["Vim-Neovim"],"content":" Key mappings configurationThe features: Use \u003cC-h/j/k/l\u003e to move the cursor among windows Use Ctrl + arrow keys to resize windows In select mode, we can use Tab or Shift-Tab to change the indentation repeatedly Create ~/.config/nvim/lua/keymaps.lua and edit: lua -- define common options local opts = { noremap = true, -- non-recursive silent = true, -- do not show message } ----------------- -- Normal mode -- ----------------- -- Hint: see `:h vim.map.set()` -- Better window navigation vim.keymap.set('n', '\u003cC-h\u003e', '\u003cC-w\u003eh', opts) vim.keymap.set('n', '\u003cC-j\u003e', '\u003cC-w\u003ej', opts) vim.keymap.set('n', '\u003cC-k\u003e', '\u003cC-w\u003ek', opts) vim.keymap.set('n', '\u003cC-l\u003e', '\u003cC-w\u003el', opts) -- Resize with arrows -- delta: 2 lines vim.keymap.set('n', '\u003cC-Up\u003e', ':resize -2\u003cCR\u003e', opts) vim.keymap.set('n', '\u003cC-Down\u003e', ':resize +2\u003cCR\u003e', opts) vim.keymap.set('n', '\u003cC-Left\u003e', ':vertical resize -2\u003cCR\u003e', opts) vim.keymap.set('n', '\u003cC-Right\u003e', ':vertical resize +2\u003cCR\u003e', opts) ----------------- -- Visual mode -- ----------------- -- Hint: start visual mode with the same area as the previous area and the same mode vim.keymap.set('v', '\u003c', '\u003cgv', opts) vim.keymap.set('v', '\u003e', '\u003egv', opts) Edit init.lua and import keymaps.lua lua ... -- rest of the configuration require('keymaps') Warning ... means that I omit other lines(in order to save the length of the post) ","date":"2023-02-08","objectID":"/en/config-neovim-from-scratch/:4:3","series":null,"tags":["Vim-Neovim"],"title":"Transform Your Neovim into a IDE: A Step-by-Step Guide","uri":"/en/config-neovim-from-scratch/#key-mappings-configuration"},{"categories":["Vim-Neovim"],"content":" Install package managerA powerful Nvim should be augmented with third-party plugins. I have selected lazy.nvim as my plugin manager, which has several amazing features including: üß™ Correct sequencing of dependencies üîí Lockfile lazy-lock.json to keep track of installed plugins ‚Ä¶ Create ~/.config/nvim/lua/plugins.lua and paste the following code. At the moment, I haven‚Äôt added any third-party packages. The template code will bootstrap lazy.nvim for us. lua local lazypath = vim.fn.stdpath(\"data\") .. \"/lazy/lazy.nvim\" if not (vim.uv or vim.loop).fs_stat(lazypath) then vim.fn.system({ \"git\", \"clone\", \"--filter=blob:none\", \"https://github.com/folke/lazy.nvim.git\", \"--branch=stable\", -- latest stable release lazypath, }) end vim.opt.rtp:prepend(lazypath) require(\"lazy\").setup({}) üí° The syntax of adding a third-party plugin in lazy.nvim is adding specification in the ... of require(\"lazy\").setup({}). Again, import plugins.lua in init.lua lua ... -- rest of the configuration require('plugins') If you see a black window with no content when opening Nvim, just wait for a moment as lazy.nvim is in the process of installing itself‚òïÔ∏è. After the Dashboard appears, you may type :Lazy to check if it works correctly. Tip Tip: use :q to quit the floating window of lazy.nvim. ","date":"2023-02-08","objectID":"/en/config-neovim-from-scratch/:4:4","series":null,"tags":["Vim-Neovim"],"title":"Transform Your Neovim into a IDE: A Step-by-Step Guide","uri":"/en/config-neovim-from-scratch/#install-package-manager"},{"categories":["Vim-Neovim"],"content":" Colorscheme Note The built-in Terminal.app in macOS only supports ANSI 256 colors, which means that you may encounter rendering problems if the theme requires more color support. Use modern terminals such as iTerm2 or Kitty could resolve this issue. My favorite theme - monokai.nvim. Add this plugin in plugins.lua lua ... -- rest of the configuration require(\"lazy\").setup({ \"tanvirtin/monokai.nvim\", }) Save the changes and wait for lazy.nvim to finish installing. Create ~/.config/nvim/lua/colorscheme.lua and edit: lua -- define your colorscheme here local colorscheme = 'monokai_pro' local is_ok, _ = pcall(vim.cmd, \"colorscheme \" .. colorscheme) if not is_ok then vim.notify('colorscheme ' .. colorscheme .. ' not found!') return end The pcall here refers to a protected call in Lua, which will return a boolean value to indicate its successful execution(a similar approach can be found in Go with the use of err). By using pcall instead of vim.cmd('colorscheme monokai_pro'), we can avoid some annoying error messages in case the colorscheme is not installed2 Again, import colorscheme.lua in init.lua lua ... -- rest of the configuration require('colorscheme') ","date":"2023-02-08","objectID":"/en/config-neovim-from-scratch/:4:5","series":null,"tags":["Vim-Neovim"],"title":"Transform Your Neovim into a IDE: A Step-by-Step Guide","uri":"/en/config-neovim-from-scratch/#colorscheme"},{"categories":["Vim-Neovim"],"content":" Auto-completionIt can be quite complicated to configure auto-completion manually, which is why we use some fantastic plugins to ease the burden. Now I will discuss a simpler solution I have found. First, use this plugin nvim-cmp, which can manage many completion sources for us. It can also let us customize the completion menu etc. Create ~/.config/nvim/lua/config/nvim-cmp.lua and edit lua local has_words_before = function() unpack = unpack or table.unpack local line, col = unpack(vim.api.nvim_win_get_cursor(0)) return col ~= 0 and vim.api.nvim_buf_get_lines(0, line - 1, line, true)[1]:sub(col, col):match(\"%s\") == nil end local luasnip = require(\"luasnip\") local cmp = require(\"cmp\") cmp.setup({ snippet = { -- REQUIRED - you must specify a snippet engine expand = function(args) require('luasnip').lsp_expand(args.body) -- For `luasnip` users. end, }, mapping = cmp.mapping.preset.insert({ -- Use \u003cC-b/f\u003e to scroll the docs ['\u003cC-b\u003e'] = cmp.mapping.scroll_docs( -4), ['\u003cC-f\u003e'] = cmp.mapping.scroll_docs(4), -- Use \u003cC-k/j\u003e to switch in items ['\u003cC-k\u003e'] = cmp.mapping.select_prev_item(), ['\u003cC-j\u003e'] = cmp.mapping.select_next_item(), -- Use \u003cCR\u003e(Enter) to confirm selection -- Accept currently selected item. Set `select` to `false` to only confirm explicitly selected items. ['\u003cCR\u003e'] = cmp.mapping.confirm({ select = true }), -- A super tab -- sourc: https://github.com/hrsh7th/nvim-cmp/wiki/Example-mappings#luasnip [\"\u003cTab\u003e\"] = cmp.mapping(function(fallback) -- Hint: if the completion menu is visible select next one if cmp.visible() then cmp.select_next_item() elseif has_words_before() then cmp.complete() else fallback() end end, { \"i\", \"s\" }), -- i - insert mode; s - select mode [\"\u003cS-Tab\u003e\"] = cmp.mapping(function(fallback) if cmp.visible() then cmp.select_prev_item() elseif luasnip.jumpable( -1) then luasnip.jump( -1) else fallback() end end, { \"i\", \"s\" }), }), -- Let's configure the item's appearance -- source: https://github.com/hrsh7th/nvim-cmp/wiki/Menu-Appearance formatting = { -- Set order from left to right -- kind: single letter indicating the type of completion -- abbr: abbreviation of \"word\"; when not empty it is used in the menu instead of \"word\" -- menu: extra text for the popup menu, displayed after \"word\" or \"abbr\" fields = { 'abbr', 'menu' }, -- customize the appearance of the completion menu format = function(entry, vim_item) vim_item.menu = ({ nvim_lsp = '[Lsp]', luasnip = '[Luasnip]', buffer = '[File]', path = '[Path]', })[entry.source.name] return vim_item end, }, -- Set source precedence sources = cmp.config.sources({ { name = 'nvim_lsp' }, -- For nvim-lsp { name = 'luasnip' }, -- For luasnip user { name = 'buffer' }, -- For buffer word completion { name = 'path' }, -- For path completion }) }) Then we modify plugins.lua file to add the plugins needed: lua ... -- rest of the configuration require(\"lazy\").setup({ -- Vscode-like pictograms { \"onsails/lspkind.nvim\", event = { \"VimEnter\" }, }, -- Auto-completion engine { \"hrsh7th/nvim-cmp\", dependencies = { \"lspkind.nvim\", \"hrsh7th/cmp-nvim-lsp\", -- lsp auto-completion \"hrsh7th/cmp-buffer\", -- buffer auto-completion \"hrsh7th/cmp-path\", -- path auto-completion \"hrsh7th/cmp-cmdline\", -- cmdline auto-completion }, config = function() require(\"config.nvim-cmp\") end, }, -- Code snippet engine { \"L3MON4D3/LuaSnip\", version = \"v2.*\", }, ... -- rest of the configuration }) Explanations: cmp.setup function accepts a Lua table, which defines some options for customization. You will find that plenty of plugins follow this API design. It‚Äôs a common practice. LuaSnip is a code snippet engine. The nvim-cmp says that we should pick a code snippet engine at least. Just ignore this if you don‚Äôt need this We can use config = function() ... end in lazy.nvim to specify the code to run after the plugin is loaded. I set it to load the nvim-cmp.lua file The nvim-cmp is the main plugin we care about. All other plugins begin with cmp- is the completion sources helper used by nvim-cmp. The lspkind.nvim w","date":"2023-02-08","objectID":"/en/config-neovim-from-scratch/:4:6","series":null,"tags":["Vim-Neovim"],"title":"Transform Your Neovim into a IDE: A Step-by-Step Guide","uri":"/en/config-neovim-from-scratch/#auto-completion"},{"categories":["Vim-Neovim"],"content":" Auto-completionIt can be quite complicated to configure auto-completion manually, which is why we use some fantastic plugins to ease the burden. Now I will discuss a simpler solution I have found. First, use this plugin nvim-cmp, which can manage many completion sources for us. It can also let us customize the completion menu etc. Create ~/.config/nvim/lua/config/nvim-cmp.lua and edit lua local has_words_before = function() unpack = unpack or table.unpack local line, col = unpack(vim.api.nvim_win_get_cursor(0)) return col ~= 0 and vim.api.nvim_buf_get_lines(0, line - 1, line, true)[1]:sub(col, col):match(\"%s\") == nil end local luasnip = require(\"luasnip\") local cmp = require(\"cmp\") cmp.setup({ snippet = { -- REQUIRED - you must specify a snippet engine expand = function(args) require('luasnip').lsp_expand(args.body) -- For `luasnip` users. end, }, mapping = cmp.mapping.preset.insert({ -- Use to scroll the docs [''] = cmp.mapping.scroll_docs( -4), [''] = cmp.mapping.scroll_docs(4), -- Use to switch in items [''] = cmp.mapping.select_prev_item(), [''] = cmp.mapping.select_next_item(), -- Use (Enter) to confirm selection -- Accept currently selected item. Set `select` to `false` to only confirm explicitly selected items. [''] = cmp.mapping.confirm({ select = true }), -- A super tab -- sourc: https://github.com/hrsh7th/nvim-cmp/wiki/Example-mappings#luasnip [\"\"] = cmp.mapping(function(fallback) -- Hint: if the completion menu is visible select next one if cmp.visible() then cmp.select_next_item() elseif has_words_before() then cmp.complete() else fallback() end end, { \"i\", \"s\" }), -- i - insert mode; s - select mode [\"\"] = cmp.mapping(function(fallback) if cmp.visible() then cmp.select_prev_item() elseif luasnip.jumpable( -1) then luasnip.jump( -1) else fallback() end end, { \"i\", \"s\" }), }), -- Let's configure the item's appearance -- source: https://github.com/hrsh7th/nvim-cmp/wiki/Menu-Appearance formatting = { -- Set order from left to right -- kind: single letter indicating the type of completion -- abbr: abbreviation of \"word\"; when not empty it is used in the menu instead of \"word\" -- menu: extra text for the popup menu, displayed after \"word\" or \"abbr\" fields = { 'abbr', 'menu' }, -- customize the appearance of the completion menu format = function(entry, vim_item) vim_item.menu = ({ nvim_lsp = '[Lsp]', luasnip = '[Luasnip]', buffer = '[File]', path = '[Path]', })[entry.source.name] return vim_item end, }, -- Set source precedence sources = cmp.config.sources({ { name = 'nvim_lsp' }, -- For nvim-lsp { name = 'luasnip' }, -- For luasnip user { name = 'buffer' }, -- For buffer word completion { name = 'path' }, -- For path completion }) }) Then we modify plugins.lua file to add the plugins needed: lua ... -- rest of the configuration require(\"lazy\").setup({ -- Vscode-like pictograms { \"onsails/lspkind.nvim\", event = { \"VimEnter\" }, }, -- Auto-completion engine { \"hrsh7th/nvim-cmp\", dependencies = { \"lspkind.nvim\", \"hrsh7th/cmp-nvim-lsp\", -- lsp auto-completion \"hrsh7th/cmp-buffer\", -- buffer auto-completion \"hrsh7th/cmp-path\", -- path auto-completion \"hrsh7th/cmp-cmdline\", -- cmdline auto-completion }, config = function() require(\"config.nvim-cmp\") end, }, -- Code snippet engine { \"L3MON4D3/LuaSnip\", version = \"v2.*\", }, ... -- rest of the configuration }) Explanations: cmp.setup function accepts a Lua table, which defines some options for customization. You will find that plenty of plugins follow this API design. It‚Äôs a common practice. LuaSnip is a code snippet engine. The nvim-cmp says that we should pick a code snippet engine at least. Just ignore this if you don‚Äôt need this We can use config = function() ... end in lazy.nvim to specify the code to run after the plugin is loaded. I set it to load the nvim-cmp.lua file The nvim-cmp is the main plugin we care about. All other plugins begin with cmp- is the completion sources helper used by nvim-cmp. The lspkind.nvim w","date":"2023-02-08","objectID":"/en/config-neovim-from-scratch/:4:6","series":null,"tags":["Vim-Neovim"],"title":"Transform Your Neovim into a IDE: A Step-by-Step Guide","uri":"/en/config-neovim-from-scratch/#key-mappings-in-nvim-cmp"},{"categories":["Vim-Neovim"],"content":" Auto-completionIt can be quite complicated to configure auto-completion manually, which is why we use some fantastic plugins to ease the burden. Now I will discuss a simpler solution I have found. First, use this plugin nvim-cmp, which can manage many completion sources for us. It can also let us customize the completion menu etc. Create ~/.config/nvim/lua/config/nvim-cmp.lua and edit lua local has_words_before = function() unpack = unpack or table.unpack local line, col = unpack(vim.api.nvim_win_get_cursor(0)) return col ~= 0 and vim.api.nvim_buf_get_lines(0, line - 1, line, true)[1]:sub(col, col):match(\"%s\") == nil end local luasnip = require(\"luasnip\") local cmp = require(\"cmp\") cmp.setup({ snippet = { -- REQUIRED - you must specify a snippet engine expand = function(args) require('luasnip').lsp_expand(args.body) -- For `luasnip` users. end, }, mapping = cmp.mapping.preset.insert({ -- Use to scroll the docs [''] = cmp.mapping.scroll_docs( -4), [''] = cmp.mapping.scroll_docs(4), -- Use to switch in items [''] = cmp.mapping.select_prev_item(), [''] = cmp.mapping.select_next_item(), -- Use (Enter) to confirm selection -- Accept currently selected item. Set `select` to `false` to only confirm explicitly selected items. [''] = cmp.mapping.confirm({ select = true }), -- A super tab -- sourc: https://github.com/hrsh7th/nvim-cmp/wiki/Example-mappings#luasnip [\"\"] = cmp.mapping(function(fallback) -- Hint: if the completion menu is visible select next one if cmp.visible() then cmp.select_next_item() elseif has_words_before() then cmp.complete() else fallback() end end, { \"i\", \"s\" }), -- i - insert mode; s - select mode [\"\"] = cmp.mapping(function(fallback) if cmp.visible() then cmp.select_prev_item() elseif luasnip.jumpable( -1) then luasnip.jump( -1) else fallback() end end, { \"i\", \"s\" }), }), -- Let's configure the item's appearance -- source: https://github.com/hrsh7th/nvim-cmp/wiki/Menu-Appearance formatting = { -- Set order from left to right -- kind: single letter indicating the type of completion -- abbr: abbreviation of \"word\"; when not empty it is used in the menu instead of \"word\" -- menu: extra text for the popup menu, displayed after \"word\" or \"abbr\" fields = { 'abbr', 'menu' }, -- customize the appearance of the completion menu format = function(entry, vim_item) vim_item.menu = ({ nvim_lsp = '[Lsp]', luasnip = '[Luasnip]', buffer = '[File]', path = '[Path]', })[entry.source.name] return vim_item end, }, -- Set source precedence sources = cmp.config.sources({ { name = 'nvim_lsp' }, -- For nvim-lsp { name = 'luasnip' }, -- For luasnip user { name = 'buffer' }, -- For buffer word completion { name = 'path' }, -- For path completion }) }) Then we modify plugins.lua file to add the plugins needed: lua ... -- rest of the configuration require(\"lazy\").setup({ -- Vscode-like pictograms { \"onsails/lspkind.nvim\", event = { \"VimEnter\" }, }, -- Auto-completion engine { \"hrsh7th/nvim-cmp\", dependencies = { \"lspkind.nvim\", \"hrsh7th/cmp-nvim-lsp\", -- lsp auto-completion \"hrsh7th/cmp-buffer\", -- buffer auto-completion \"hrsh7th/cmp-path\", -- path auto-completion \"hrsh7th/cmp-cmdline\", -- cmdline auto-completion }, config = function() require(\"config.nvim-cmp\") end, }, -- Code snippet engine { \"L3MON4D3/LuaSnip\", version = \"v2.*\", }, ... -- rest of the configuration }) Explanations: cmp.setup function accepts a Lua table, which defines some options for customization. You will find that plenty of plugins follow this API design. It‚Äôs a common practice. LuaSnip is a code snippet engine. The nvim-cmp says that we should pick a code snippet engine at least. Just ignore this if you don‚Äôt need this We can use config = function() ... end in lazy.nvim to specify the code to run after the plugin is loaded. I set it to load the nvim-cmp.lua file The nvim-cmp is the main plugin we care about. All other plugins begin with cmp- is the completion sources helper used by nvim-cmp. The lspkind.nvim w","date":"2023-02-08","objectID":"/en/config-neovim-from-scratch/:4:6","series":null,"tags":["Vim-Neovim"],"title":"Transform Your Neovim into a IDE: A Step-by-Step Guide","uri":"/en/config-neovim-from-scratch/#completion-menu-in-nvim-cmp"},{"categories":["Vim-Neovim"],"content":" Auto-completionIt can be quite complicated to configure auto-completion manually, which is why we use some fantastic plugins to ease the burden. Now I will discuss a simpler solution I have found. First, use this plugin nvim-cmp, which can manage many completion sources for us. It can also let us customize the completion menu etc. Create ~/.config/nvim/lua/config/nvim-cmp.lua and edit lua local has_words_before = function() unpack = unpack or table.unpack local line, col = unpack(vim.api.nvim_win_get_cursor(0)) return col ~= 0 and vim.api.nvim_buf_get_lines(0, line - 1, line, true)[1]:sub(col, col):match(\"%s\") == nil end local luasnip = require(\"luasnip\") local cmp = require(\"cmp\") cmp.setup({ snippet = { -- REQUIRED - you must specify a snippet engine expand = function(args) require('luasnip').lsp_expand(args.body) -- For `luasnip` users. end, }, mapping = cmp.mapping.preset.insert({ -- Use to scroll the docs [''] = cmp.mapping.scroll_docs( -4), [''] = cmp.mapping.scroll_docs(4), -- Use to switch in items [''] = cmp.mapping.select_prev_item(), [''] = cmp.mapping.select_next_item(), -- Use (Enter) to confirm selection -- Accept currently selected item. Set `select` to `false` to only confirm explicitly selected items. [''] = cmp.mapping.confirm({ select = true }), -- A super tab -- sourc: https://github.com/hrsh7th/nvim-cmp/wiki/Example-mappings#luasnip [\"\"] = cmp.mapping(function(fallback) -- Hint: if the completion menu is visible select next one if cmp.visible() then cmp.select_next_item() elseif has_words_before() then cmp.complete() else fallback() end end, { \"i\", \"s\" }), -- i - insert mode; s - select mode [\"\"] = cmp.mapping(function(fallback) if cmp.visible() then cmp.select_prev_item() elseif luasnip.jumpable( -1) then luasnip.jump( -1) else fallback() end end, { \"i\", \"s\" }), }), -- Let's configure the item's appearance -- source: https://github.com/hrsh7th/nvim-cmp/wiki/Menu-Appearance formatting = { -- Set order from left to right -- kind: single letter indicating the type of completion -- abbr: abbreviation of \"word\"; when not empty it is used in the menu instead of \"word\" -- menu: extra text for the popup menu, displayed after \"word\" or \"abbr\" fields = { 'abbr', 'menu' }, -- customize the appearance of the completion menu format = function(entry, vim_item) vim_item.menu = ({ nvim_lsp = '[Lsp]', luasnip = '[Luasnip]', buffer = '[File]', path = '[Path]', })[entry.source.name] return vim_item end, }, -- Set source precedence sources = cmp.config.sources({ { name = 'nvim_lsp' }, -- For nvim-lsp { name = 'luasnip' }, -- For luasnip user { name = 'buffer' }, -- For buffer word completion { name = 'path' }, -- For path completion }) }) Then we modify plugins.lua file to add the plugins needed: lua ... -- rest of the configuration require(\"lazy\").setup({ -- Vscode-like pictograms { \"onsails/lspkind.nvim\", event = { \"VimEnter\" }, }, -- Auto-completion engine { \"hrsh7th/nvim-cmp\", dependencies = { \"lspkind.nvim\", \"hrsh7th/cmp-nvim-lsp\", -- lsp auto-completion \"hrsh7th/cmp-buffer\", -- buffer auto-completion \"hrsh7th/cmp-path\", -- path auto-completion \"hrsh7th/cmp-cmdline\", -- cmdline auto-completion }, config = function() require(\"config.nvim-cmp\") end, }, -- Code snippet engine { \"L3MON4D3/LuaSnip\", version = \"v2.*\", }, ... -- rest of the configuration }) Explanations: cmp.setup function accepts a Lua table, which defines some options for customization. You will find that plenty of plugins follow this API design. It‚Äôs a common practice. LuaSnip is a code snippet engine. The nvim-cmp says that we should pick a code snippet engine at least. Just ignore this if you don‚Äôt need this We can use config = function() ... end in lazy.nvim to specify the code to run after the plugin is loaded. I set it to load the nvim-cmp.lua file The nvim-cmp is the main plugin we care about. All other plugins begin with cmp- is the completion sources helper used by nvim-cmp. The lspkind.nvim w","date":"2023-02-08","objectID":"/en/config-neovim-from-scratch/:4:6","series":null,"tags":["Vim-Neovim"],"title":"Transform Your Neovim into a IDE: A Step-by-Step Guide","uri":"/en/config-neovim-from-scratch/#lsp"},{"categories":["Vim-Neovim"],"content":" Wrap-upWith this configuration, we successfully turned Nvim into a lightweight IDE, which supports code highlighting, code completion, syntax checking, and other functionalities. It is completely open source and free ü§ó. I realized that even after trying different code editors and IDEs, I always found myself searching for Vim support. So I chose to turn Nvim into an IDE and host the configuration files on my martinlwx/dotfiles. In this way, I can easily clone my configuration files to any new machine and have a consistent programming experience across machines. Polishing tools requires effort and time. To understand the purpose of each option, I had to search for various materials. However, despite the challenges, I firmly believe that it‚Äôs worth it. Understanding your tools allows you to further extend and customize them. This article aims to present a simple and straightforward configuration, but there are still many beautification and customization things that can be done, including many excellent third-party plug-ins that have not been mentioned yet. The exploration and discovery are left to the readers ","date":"2023-02-08","objectID":"/en/config-neovim-from-scratch/:5:0","series":null,"tags":["Vim-Neovim"],"title":"Transform Your Neovim into a IDE: A Step-by-Step Guide","uri":"/en/config-neovim-from-scratch/#wrap-up"},{"categories":["Vim-Neovim"],"content":" Refs Installing-Neovim¬†‚Ü©Ô∏é Adding a colorscheme/theme¬†‚Ü©Ô∏é Language Server Protocol - Wiki¬†‚Ü©Ô∏é ","date":"2023-02-08","objectID":"/en/config-neovim-from-scratch/:6:0","series":null,"tags":["Vim-Neovim"],"title":"Transform Your Neovim into a IDE: A Step-by-Step Guide","uri":"/en/config-neovim-from-scratch/#refs"},{"categories":["Programming-Languages"],"content":"An introduction to type hints in Python","date":"2023-01-13","objectID":"/en/type-hints-in-python/","series":null,"tags":["Python"],"title":"Type hints: what and why","uri":"/en/type-hints-in-python/"},{"categories":["Programming-Languages"],"content":" IntroI was immediately drawn to Python when I first encountered it due to its dynamic language features. Python use the ‚Äúduck typing‚Äù design, which means that the type of an object is not as important as its behavior. This feature allows for faster development and a reduction in burdensome type declarations. Additionally, the support of powerful third-party libraries solidifies Python as my preferred programming language.üò∫ However, with the proposal of PEP 4841, Python decided to introduce type hints, which seem to be in line with statically typed languages. It‚Äôs not true though, Python‚Äôs type hints are optional, and it has no runtime effect. It seems that writing this blog post specifically to introduce Python‚Äôs type hints is unnecessary, but I have found that using them in my code still provides several benefits: Static type checker can check your code. For example, Mypy The code completion in IDE will become more intelligent. It will also report a bug if we use the wrong APIs. This is probably the biggest motivation for me to choose to write type hints Manage code complexity. Type hints expose useful information about APIs. As a developer, we can get a general idea by just looking at the signature of such an annotated function, without having to check the docstrings frequently. python ! python --version Python 3.11.0 ","date":"2023-01-13","objectID":"/en/type-hints-in-python/:1:0","series":null,"tags":["Python"],"title":"Type hints: what and why","uri":"/en/type-hints-in-python/#intro"},{"categories":["Programming-Languages"],"content":" Function annotationsShipped with Python 3.0, the syntax of type hints has been established2: Arguments: name[: type] [ = default_val ], the [] means optional Return type: the syntax is -\u003e return_type We can access the __annotations__ attribute to get type hints informatios. It returns a dict with {ParamName: ParamType}. ==It‚Äôs a bad practice to access this attribute directly. We can use the functions inside the inspect module(Python 3.10+) or the typing module(Python 3.5 ~ 3.9)==. See the following example: python def maximum(a: float, b: float) -\u003e float: \"\"\" A simple function to return the maximum elements of two floats\"\"\" return max(a, b) # \u003e= Python 3.10, do this import inspect assert inspect.get_annotations(maximum) == maximum.__annotations__ # Python 3.5 ~ 3.9 import typing assert typing.get_type_hints(maximum) == maximum.__annotations__ inspect.get_annotations(maximum) {'a': float, 'b': float, 'return': float} üìí It‚Äôs important to reiterate that type hints in Python have no impact on the runtime of the program. This means that even if we violate the type hints, the program will still execute as normal. However, a static type checker like Mypy will throw warnings. python # returns the maximum of two strings # , but we declared the arguments should be float! maximum('hello', 'world') 'world' ","date":"2023-01-13","objectID":"/en/type-hints-in-python/:2:0","series":null,"tags":["Python"],"title":"Type hints: what and why","uri":"/en/type-hints-in-python/#function-annotations"},{"categories":["Programming-Languages"],"content":" Variables annotationsPrior to Python 3.6, the only way to annotate the type of a variable was to include this information in comments, such as # type ...1. This is referred to as ‚Äútype comments.‚Äù With the introduction of PEP 526, a new syntax for variable annotations was established, which is similar to the syntax used for annotating function arguments3 python a: int # undefined typed value a: int = 0 # typed value with default value a 0 Similarly, we can access the module level __annotations__ attributes to get type hints information. python __annotations__ {'a': int} ","date":"2023-01-13","objectID":"/en/type-hints-in-python/:3:0","series":null,"tags":["Python"],"title":"Type hints: what and why","uri":"/en/type-hints-in-python/#variables-annotations"},{"categories":["Programming-Languages"],"content":" Common usage","date":"2023-01-13","objectID":"/en/type-hints-in-python/:4:0","series":null,"tags":["Python"],"title":"Type hints: what and why","uri":"/en/type-hints-in-python/#common-usage"},{"categories":["Programming-Languages"],"content":" Simple built-in typesThe simple built-in types refer to int, str etc. They can also be types defined in third-party packages. As an example, the arguments of the previously mentioned maximum function use float. ","date":"2023-01-13","objectID":"/en/type-hints-in-python/:4:1","series":null,"tags":["Python"],"title":"Type hints: what and why","uri":"/en/type-hints-in-python/#simple-built-in-types"},{"categories":["Programming-Languages"],"content":" Any typeThe Any type denotes that it can be any type. But it‚Äôs different from the object type1 We can think of an unannotated function that is annotated with the Any type. python def foo(x): ... # it assumes: def foo(x: Any) -\u003e Any: ... ","date":"2023-01-13","objectID":"/en/type-hints-in-python/:4:2","series":null,"tags":["Python"],"title":"Type hints: what and why","uri":"/en/type-hints-in-python/#any-type"},{"categories":["Programming-Languages"],"content":" Collections and MappingsWe refer to each element inside a collection as an item. To add type hints for both the collection type and the item type, Python uses the [] notation. For example, to express a list of strings, we would write list[str]. This notation makes it clear that the list contains elements of the str type. Notes: After PEP 585(Python 3.9+)4, we can use the built-in list, dict etc instead of the counterparts in the typing module4. \u003c Python 3.9 \u003e= Python 3.9 typing.Tuple tuple typing.Dict dict typing.List list typing.Set set typing.Frozenset frozenset typing.Type type typing.AbstractSet collections.abc.Set typing.ContextManager contextlib.AbstractContextManager typing.AsyncContextManager contextlib.AbstractAsyncContextManager typing.Pattern, typing.re.Pattern re.Pattern typing.Match, typing.re.Match re.Match üìí Some features of the typing module will be removed in the future, so I will use the latest syntax below‚úèÔ∏è python string_list: list[str] = ['hello', 'world'] # tuple[type1, type2, ..., typen] with fixed size date: tuple[int, int, int] = (2023, 1, 11) string_count: dict[str, int] = { 'hello': 1, 'world': 2, } python __annotations__ {'a': int, 'string_list': list[str], 'date': tuple[int, int, int], 'string_count': dict[str, int]} The join_str_list function accepts a list of strings and uses the whitespace to join them. python def join_str_list(string_list: list[str]) -\u003e str: \"\"\" join all string in a list\"\"\" return ' '.join(string_list) print(join_str_list(string_list)) print(inspect.get_annotations(join_str_list)) hello world {'string_list': list[str], 'return': \u003cclass 'str'\u003e} üìí In Python 3.9+, we can use tuple[type1, ...] to represent a tuple of any length whose types are all type1 python def sum_variable_integers(data: tuple[int, ...]): \"\"\" Sum all integers of a tuple\"\"\" sum_val = 0 for integer in data: sum_val += integer return sum_val print(sum_variable_integers((1, 2, 3))) print(sum_variable_integers((3,))) 6 3 As we know, we can put any type of variable in the list. How do we add type hints for such a list? The solution is Any type: python list[Any] We can just use list, which is less verbose. üìí If you want to know more collections types, please refer to collections.abc ","date":"2023-01-13","objectID":"/en/type-hints-in-python/:4:3","series":null,"tags":["Python"],"title":"Type hints: what and why","uri":"/en/type-hints-in-python/#collections-and-mappings"},{"categories":["Programming-Languages"],"content":" Type aliasSometimes, the type will be so complicated that we don‚Äôt want to write it everywhere. So what do we do? Well, we can give it an alias with a meaningful name. The syntax is simple: python AliasName = Type Take the previously defined date type as an example. A date is a tuple containing three int types. The type list[tuple[int, int, int] would denote a list of dates. To make the code more readable, it can be beneficial to give this type an alias, such as Date. See the following example: python Date = tuple[int, int, int] DateList = list[Date] def print_date_list(l: DateList): \"\"\" Print all dates in the format `year-month-day` in the date list\"\"\" for year, month, day in l: print(f'{year}-{month}-{day}') print_date_list([(2022, 1, 1), (2023, 1, 3)]) print(inspect.get_annotations(print_date_list)) 2022-1-1 2023-1-3 {'l': list[tuple[int, int, int]]} The syntax of type alias is quite similar to defining a global variable. To make it more explicit, PEP 613(Python 3.10+) proposes a better way5: python AliasName: TypeAlias = Type python from typing import TypeAlias Date: TypeAlias = tuple[int, int, int] ","date":"2023-01-13","objectID":"/en/type-hints-in-python/:4:4","series":null,"tags":["Python"],"title":"Type hints: what and why","uri":"/en/type-hints-in-python/#type-alias"},{"categories":["Programming-Languages"],"content":" Parameterized generic typesIn other programming languages, usually, they use an uppercase letter like T to denote a parameterized generic type. In python, we use TypeVar to do same thing. As the docs say: python T = TypeVar('T') # Can be anything S = TypeVar('S', bound=str) # Can be any subtype of str A = TypeVar('A', str, bytes)# Must be exactly str or bytes To summarize, TypeVar provides two ways for us to restrict the generic types: use bound=some_type, then we can only pass the subtype of some_type. specify the allowed types directly üìí The definition of subtype is in PEP 4836. In general: each type is its own subtype; In Object-oriented programming, the subclass is the subtype of its superclass python from typing import TypeVar GenericString = TypeVar('GenericString', str, bytes) def process(s: GenericString): \"\"\" The GenericString can be either str or bytes\"\"\" ... üìí The typing module already provides us a AnyStr type to represent either str or bytes ","date":"2023-01-13","objectID":"/en/type-hints-in-python/:4:5","series":null,"tags":["Python"],"title":"Type hints: what and why","uri":"/en/type-hints-in-python/#parameterized-generic-types"},{"categories":["Programming-Languages"],"content":" Optional and UnionOptional[type1] represents a type that can be either type1 or None. The Union[type1, type2, ...] means that the allowed type is one of the types we specified, which is the logical or relationship. So we can know that the Optional[type1] is equal to Union[type1, None]. python from typing import Optional, Union def parse(s: Union[str, int]) -\u003e Optional[int]: \"\"\" Parse `s` and get an integer value. The `s` may be a string. Return None if fail \"\"\" if isinstance(s, str): if not s.isdigit(): return None else: return int(s) elif isinstance(s, int): return s assert parse('foo') is None assert parse('123') == 123 assert parse(123) == 123 inspect.get_annotations(parse) {'s': typing.Union[str, int], 'return': typing.Optional[int]} In Python 3.10+, it introduces | to replace the Union. Some other programming languages also use |. For example, Rust use | to seperate multiple possible patterns. The parse function we defined earlier can be written in the following form: python def parse(s: str | int) -\u003e int | None: \"\"\" Parse `s` and get an integer value. The `s` may be a string. Return None if fail \"\"\" if isinstance(s, str): if not s.isdigit(): return None else: return int(s) elif isinstance(s, int): return s inspect.get_annotations(parse) {'s': str | int, 'return': int | None} ","date":"2023-01-13","objectID":"/en/type-hints-in-python/:4:6","series":null,"tags":["Python"],"title":"Type hints: what and why","uri":"/en/type-hints-in-python/#optional-and-union"},{"categories":["Programming-Languages"],"content":" CallablesWe use the function as an example of callable. In Python, a function is a first-class object, which means that it can be a parameter or a return value of another function. The type hints to support this: python Callable[[ParamType1, ParamType2], ReturnType] Let‚Äôs define a apply function which can apply a function on the data python # from typing import Callable # Python \u003c 3.9 from collections.abc import Callable def apply(f: Callable[[str | int], int | None], data: list): \"\"\" Apply callable object on data. The `Callable[[str | int], int | None]` is the type hints of `parse` we aforementioned \"\"\" for d in data: print(f(d)) apply(parse, ['hello', 123]) None 123 ","date":"2023-01-13","objectID":"/en/type-hints-in-python/:4:7","series":null,"tags":["Python"],"title":"Type hints: what and why","uri":"/en/type-hints-in-python/#callables"},{"categories":["Programming-Languages"],"content":" ClassIn Python 3.117, the Self type is proposed, which represents an instance of the current class. We can use Self within the class definition everywhere :) No need to use TypeVar anymore python from typing import Self class Shape: def set_scale(self, scale: float) -\u003e Self: self.scale = scale return self üí° Rust also uses Self to denote the current object, which usually appears in an impl block. ","date":"2023-01-13","objectID":"/en/type-hints-in-python/:4:8","series":null,"tags":["Python"],"title":"Type hints: what and why","uri":"/en/type-hints-in-python/#class"},{"categories":["Programming-Languages"],"content":" SummaryWell, that‚Äôs the entire content of this blog. I have covered some of the most common and practical uses of type hints that I have found useful. However, it is not an exhaustive guide, and there are more advanced features such as static protocols8 that readers can explore. Personally, I follow the strategy of using type hints only when the added benefits outweigh the potential added complexity. In situations where the type hints become too complex, I choose not to use them unless it is deemed necessary. I will also give you some advice based on my experiencesüéØ: When you decide what to add, try to think what this type it can do8. The static protocols8 are well suited to this requirement. This makes me think of the traits in Rust :) Always make the return type as precise as possible. Just try to imagine that a function returns Union[str, int]. We have to check it manually, which makes me fell like the type hints are a little unnecessary. Even if you pass the type checker, you are not free of bugs. Software testing is the standard practice to make your programs work as expected. Add the cheatsheet to your bookmark üëç ","date":"2023-01-13","objectID":"/en/type-hints-in-python/:5:0","series":null,"tags":["Python"],"title":"Type hints: what and why","uri":"/en/type-hints-in-python/#summary"},{"categories":["Programming-Languages"],"content":" Refs PEP 484. Type Hints¬†‚Ü©Ô∏é¬†‚Ü©Ô∏é¬†‚Ü©Ô∏é PEP 3107. Function Annotations¬†‚Ü©Ô∏é PEP 526. Syntax for Variable Annotations¬†‚Ü©Ô∏é PEP 585. Type Hinting Generics In Standard Collections¬†‚Ü©Ô∏é¬†‚Ü©Ô∏é PEP 613. Explicit Type Aliases¬†‚Ü©Ô∏é PEP 483. The Theory of Type Hints¬†‚Ü©Ô∏é PEP 673. Self Type¬†‚Ü©Ô∏é PEP 544. Protocols: Structural subtyping (static duck typing)¬†‚Ü©Ô∏é¬†‚Ü©Ô∏é¬†‚Ü©Ô∏é ","date":"2023-01-13","objectID":"/en/type-hints-in-python/:6:0","series":null,"tags":["Python"],"title":"Type hints: what and why","uri":"/en/type-hints-in-python/#refs"},{"categories":["Programming-Languages"],"content":"A simple introduction of the unpakcing operators in python","date":"2022-12-05","objectID":"/en/unpacking-in-python/","series":null,"tags":["Python"],"title":"Unpacking in Python 3.5","uri":"/en/unpacking-in-python/"},{"categories":["Programming-Languages"],"content":" IntroToday I want to talk about the unpacking operators(* and **) in python. ","date":"2022-12-05","objectID":"/en/unpacking-in-python/:1:0","series":null,"tags":["Python"],"title":"Unpacking in Python 3.5","uri":"/en/unpacking-in-python/#intro"},{"categories":["Programming-Languages"],"content":" Basic usageWe use * for numeric data types to indicate we want to do multiplication. However, we can also apply * to iterable objects1, which means we want to unpack all the elements inside them. üìíThe built-in iterable objects: list, tuple, set, and dict ","date":"2022-12-05","objectID":"/en/unpacking-in-python/:2:0","series":null,"tags":["Python"],"title":"Unpacking in Python 3.5","uri":"/en/unpacking-in-python/#basic-usage"},{"categories":["Programming-Languages"],"content":" Starred assignment/expressionIn the release of python 3.0, it is shipped with powerful iterable unpacking operations2, which is called the starred assignment/expression(or parallel assignment). We are allowed to specify a catch-all name in the LHS(i.e. Left Hand Side) of = to catch values in the RHS(i.e. Right Hand Side). The example says more: python \u003e\u003e\u003e first, *rest, last = [1, 2, 3, 4, 5] \u003e\u003e\u003e first 1 \u003e\u003e\u003e rest [2, 3, 4] \u003e\u003e\u003e last 5 üìí The syntax is quite simple: a variable name follows a star - *foo. we can put it anywhere in the LHS of = to catch items, but only once. Also, the type of foo will be list In my opinion, this feature makes python code more human-readableüëç There are some restrictions though: We can‚Äôt just use a single *foo in the LHS of = as a long assignment target. The LHS must be in a list or tuple It would be an error if the RHS of = doesn‚Äôt have enough items to unpack To demonstrate the restrictions: python *first = [1, 2, 3] Cell In [1], line 1 *first = [1, 2, 3] ^ SyntaxError: starred assignment target must be in a list or tuple python # just add `,` would be fine # now the LHS is a tuple *first, = [1, 2, 3] first [1, 2, 3] python first, second, *rest = [1] --------------------------------------------------------------------------- ValueError Traceback (most recent call last) Cell In [3], line 1 ----\u003e 1 first, second, *rest = [1] ValueError: not enough values to unpack (expected at least 2, got 1) üìí Usually, we will combine * and _(i.e. *_) to indicate we don‚Äôt care about the items it caught python first, *_ = [1, 2, 3] first 1 ","date":"2022-12-05","objectID":"/en/unpacking-in-python/:2:1","series":null,"tags":["Python"],"title":"Unpacking in Python 3.5","uri":"/en/unpacking-in-python/#starred-assignmentexpression"},{"categories":["Programming-Languages"],"content":" More powerStart from Python 3.5, we can use * and ** in more circumstances.3 Case 1. we are allowed to use them as many times as we want inside function calls python foo, bar = {'a': 1, 'b': 2}, {'c': 3, 'd': 4} dict(**foo, **bar) # dict is a function {'a': 1, 'b': 2, 'c': 3, 'd': 4} üìíThe keys in a dictionary remain in a right-to-left priority order3. i.e. The later values will always override the earlier ones. See the following example: python {**{'a': 1, 'b': 2}, **{'a': 3}} {'a': 3, 'b': 2} üìíWhen we use multiple ** in function calls. We need to make sure they have no duplicate keys. python dict(**{'a': 1, 'b': 2}, **{'a': 3}) --------------------------------------------------------------------------- TypeError Traceback (most recent call last) Cell In [7], line 1 ----\u003e 1 dict(**{'a': 1, 'b': 2}, **{'a': 3}) TypeError: dict() got multiple values for keyword argument 'a' Case 2. We can use them in tuple/list/set/dict literals. But we can‚Äôt use them inside the list/set/dict comprehensionsüò∫ python # an example drawn from PEP 448 \u003e\u003e\u003e *range(4), 4 (0, 1, 2, 3, 4) \u003e\u003e\u003e [*range(4), 4] [0, 1, 2, 3, 4] \u003e\u003e\u003e {*range(4), 4} {0, 1, 2, 3, 4} \u003e\u003e\u003e {'x': 1, **{'y': 2}} {'x': 1, 'y': 2} {'x': 1, 'y': 2} python matrix = [ [1, 2, 3] [4, 5, 6] ] [*sublist for sublist in matrix] Cell In [9], line 5 [*sublist for sublist in matrix] ^ SyntaxError: iterable unpacking cannot be used in comprehension ","date":"2022-12-05","objectID":"/en/unpacking-in-python/:2:2","series":null,"tags":["Python"],"title":"Unpacking in Python 3.5","uri":"/en/unpacking-in-python/#more-power"},{"categories":["Programming-Languages"],"content":" Wrap-upThe unpacking feature in python makes life easier. It‚Äôs an intuitive way to destructure the iterable object. With the help of this operator, we can avoid some silly indexErrorüôÖ ","date":"2022-12-05","objectID":"/en/unpacking-in-python/:3:0","series":null,"tags":["Python"],"title":"Unpacking in Python 3.5","uri":"/en/unpacking-in-python/#wrap-up"},{"categories":["Programming-Languages"],"content":" Refs Python iterators¬†‚Ü©Ô∏é PEP 3132. Extended Iterable Unpacking¬†‚Ü©Ô∏é PEP 448. Additional Unpacking Generalizations¬†‚Ü©Ô∏é¬†‚Ü©Ô∏é ","date":"2022-12-05","objectID":"/en/unpacking-in-python/:4:0","series":null,"tags":["Python"],"title":"Unpacking in Python 3.5","uri":"/en/unpacking-in-python/#refs"},{"categories":["Programming-Languages"],"content":"A simple tutorial for the f-strings in python 3.6","date":"2022-11-16","objectID":"/en/f-strings-in-python/","series":null,"tags":["Python"],"title":"The f-strings in Python3.6","uri":"/en/f-strings-in-python/"},{"categories":["Programming-Languages"],"content":" Info UpdatesÔºö 2024-04-19: This post is completely rewritten for better reference. ","date":"2022-11-16","objectID":"/en/f-strings-in-python/:0:0","series":null,"tags":["Python"],"title":"The f-strings in Python3.6","uri":"/en/f-strings-in-python/#"},{"categories":["Programming-Languages"],"content":" IntroString formatting can be regarded as one of the most common activities in daily programming. We often need to output various strings and precisely control their format. You may still see the usage of % to format strings in some outdated Python tutorials. However, the f-strings have become the optimal choice for formatting strings since Python3.6. The main advantages in my opinion are: Expressions can be embedded in the string literals conveniently More human-readable The following simple comparison shows the advantages of f-strings in readability: python name = \"Martin\" f\"My name is {name}\" 'My name is Martin' python name = \"Martin\" \"My name is %s\" % name 'My name is Martin' We implemented the same string output in two different ways. Without any effort, we can find that the f-strings here are to output the name (this requires you to use meaningful variable names, such as name here). On the contrary, it is slightly unnatural to look at the % format string. We first saw it use %s as a placeholder, then we need to go to the right to find out which variable it refers to. The example here is too short to show the real power of f-strings. Just trying to imagine that we are reading a long format string written in % syntax, we will need to look it back and forth to figure out what it means. Not just about reading the code, if you write a long format string by yourself, you have to check whether the order of the placeholders and variables is consistent, which is undoubtedly a burden. üò´ Note The minimal version of Python which supports f-strings is Python3.6. ","date":"2022-11-16","objectID":"/en/f-strings-in-python/:1:0","series":null,"tags":["Python"],"title":"The f-strings in Python3.6","uri":"/en/f-strings-in-python/#intro"},{"categories":["Programming-Languages"],"content":" Syntax rulesTo create a f-string, we first add the leading f before \"...\" or '...'. python f\"...\" # or f'...' Then, we can use {expression} inside the quotes. Python will evaluate this expression for us and print its corresponding value. If we want to get more control over the output, we can use the format_specifier, which contains various optional parts for different purposes. From the perspective of grammar, the syntax rule of f-strings is python f\"...{expression:format_specifier}...\" Now let‚Äôs figure out how to use f-strings in various scenarios ","date":"2022-11-16","objectID":"/en/f-strings-in-python/:2:0","series":null,"tags":["Python"],"title":"The f-strings in Python3.6","uri":"/en/f-strings-in-python/#syntax-rules"},{"categories":["Programming-Languages"],"content":" Usage","date":"2022-11-16","objectID":"/en/f-strings-in-python/:3:0","series":null,"tags":["Python"],"title":"The f-strings in Python3.6","uri":"/en/f-strings-in-python/#usage"},{"categories":["Programming-Languages"],"content":" Basic usage python left, right = 3, 5 f\"{left} + {right} = {left + right}\" '3 + 5 = 8' Tip Using {} as a placeholder naturally leads to a question: what if we want to display {} in the string? The answer is very simple, we just need to add another {}, i.e. {{}} python f\"{{}}\" '{}' It is also worth mentioning that : and ! and \\ are not allowed in expression These characters rarely appear in expression though. One usage scenario of \\ is to escape quotes. However, we could just use a different type of quote inside the expression. As for :, a use case would be defining a lambda function in expression1. In this situation, we only need to enclose the lambda expression within (): python # Note that we need to add () around the lambda expression f\"{(lambda x: x + 1)(3)}\" '4' ","date":"2022-11-16","objectID":"/en/f-strings-in-python/:3:1","series":null,"tags":["Python"],"title":"The f-strings in Python3.6","uri":"/en/f-strings-in-python/#basic-usage"},{"categories":["Programming-Languages"],"content":" Different string representationIn Python, objects generally have two types of string representations, corresponding to the __str__ and __repr__ methods, where the former is typically user-facing and more readable, while the latter is typically developer-facing and aids in debugging programs. The f-strings allowes us to specify which one to use. python {foo!s} # it's equal to call str(foo) first {foo!r} # similarily, call repr(foo) first {foo!a} # similarilyÔºåcall ascii(foo) first ","date":"2022-11-16","objectID":"/en/f-strings-in-python/:3:2","series":null,"tags":["Python"],"title":"The f-strings in Python3.6","uri":"/en/f-strings-in-python/#different-string-representation"},{"categories":["Programming-Languages"],"content":" Padding \u0026 AlignmentThe padding and alignment involve the following issues: Which character should we use? Here, we use fill to represent that. To what length should it be padded? Here, we use width to represent that. How should it be aligned? Here, we use align to represent that. The general format_specifier for padding and alignment is [[fill]align][width]. Note In grammar specification, the [] indicates that this part is optional. The various ways of alignment options: python \u003c # left-aligned \u003e # right-aligned ^ # centered = # only valid for numeric types, pad between sign and digits For example python f\"{-1:*^9}\" # set `fill` to *, and set width to 9 '***-1****' python f\"{-1:*\u003e9}\" # set `fill` to *, and set width to 9 '*******-1' python f\"{-1:*\u003c9}\" # set `fill` to *, and set width to 9 '-1*******' python f\"{-1:*=9}\" # set `fill` to *, and set width to 9 '-*******1' SignIt decides how the sign should be represented and is only valid for numerical values. python + # both positive and negative - # only negative (default) space # a leading space for positive and minus sign for negative python f\"{1:+}\" '+1' python f\"{-1:+}\" '-1' python assert f\"{1}\" == f\"{1:-}\" # because it's the default behavior ","date":"2022-11-16","objectID":"/en/f-strings-in-python/:3:3","series":null,"tags":["Python"],"title":"The f-strings in Python3.6","uri":"/en/f-strings-in-python/#padding--alignment"},{"categories":["Programming-Languages"],"content":" Padding \u0026 AlignmentThe padding and alignment involve the following issues: Which character should we use? Here, we use fill to represent that. To what length should it be padded? Here, we use width to represent that. How should it be aligned? Here, we use align to represent that. The general format_specifier for padding and alignment is [[fill]align][width]. Note In grammar specification, the [] indicates that this part is optional. The various ways of alignment options: python \u003c # left-aligned \u003e # right-aligned ^ # centered = # only valid for numeric types, pad between sign and digits For example python f\"{-1:*^9}\" # set `fill` to *, and set width to 9 '***-1****' python f\"{-1:*\u003e9}\" # set `fill` to *, and set width to 9 '*******-1' python f\"{-1:*\u003c9}\" # set `fill` to *, and set width to 9 '-1*******' python f\"{-1:*=9}\" # set `fill` to *, and set width to 9 '-*******1' SignIt decides how the sign should be represented and is only valid for numerical values. python + # both positive and negative - # only negative (default) space # a leading space for positive and minus sign for negative python f\"{1:+}\" '+1' python f\"{-1:+}\" '-1' python assert f\"{1}\" == f\"{1:-}\" # because it's the default behavior ","date":"2022-11-16","objectID":"/en/f-strings-in-python/:3:3","series":null,"tags":["Python"],"title":"The f-strings in Python3.6","uri":"/en/f-strings-in-python/#sign"},{"categories":["Programming-Languages"],"content":" The precision of float-point numbersWe can use .nf to keep n decimal places for float-point numbers, which is somewhat similar to C/C++‚Äôs printf. For example python x = 1.23456 f\"{x:.1f}\" '1.2' python x = 1.23456 f\"{x:.3f}\" '1.235' The -0.0 issueWe can use z to handle negative zero (i.e. -0.) since Python3.11. According to the PEP2, programmers usually will suppress negative zero. python x = -0.0001 f\"{x:.1f}\" # set the precision to 1, so it will round to -0.0 '-0.0' python x = -0.0001 f\"{x:z.1f}\" # with z, we will get 0.0 rather than -0.0 '0.0' ","date":"2022-11-16","objectID":"/en/f-strings-in-python/:3:4","series":null,"tags":["Python"],"title":"The f-strings in Python3.6","uri":"/en/f-strings-in-python/#the-precision-of-float-point-numbers"},{"categories":["Programming-Languages"],"content":" The precision of float-point numbersWe can use .nf to keep n decimal places for float-point numbers, which is somewhat similar to C/C++‚Äôs printf. For example python x = 1.23456 f\"{x:.1f}\" '1.2' python x = 1.23456 f\"{x:.3f}\" '1.235' The -0.0 issueWe can use z to handle negative zero (i.e. -0.) since Python3.11. According to the PEP2, programmers usually will suppress negative zero. python x = -0.0001 f\"{x:.1f}\" # set the precision to 1, so it will round to -0.0 '-0.0' python x = -0.0001 f\"{x:z.1f}\" # with z, we will get 0.0 rather than -0.0 '0.0' ","date":"2022-11-16","objectID":"/en/f-strings-in-python/:3:4","series":null,"tags":["Python"],"title":"The f-strings in Python3.6","uri":"/en/f-strings-in-python/#the--00-issue"},{"categories":["Programming-Languages"],"content":" Other number representationIn Python, we can use the built-in functions to get the representation in other bases including bin and oct. You may attempt to use {bin(a)} to get the binary representation output of a. However, the f-strings offers a more elegant way to handle this python b # base 2 o # base 8 d # base 10 x # base 16, low-case letters X # base 16, upper-case letters Tip Adding a # character will add the corresponding prefix (e.g. 0b) python f\"{15:b}\" # represent 15 in base 2 '1111' python f\"{15:#b}\" # represent 15 in base 2, use # to add prefix 0b '0b1111' python f\"{15:#X}\" # represent 15 in base 16, use # to add prefix 0X '0XF' ","date":"2022-11-16","objectID":"/en/f-strings-in-python/:3:5","series":null,"tags":["Python"],"title":"The f-strings in Python3.6","uri":"/en/f-strings-in-python/#other-number-representation"},{"categories":["Programming-Languages"],"content":" Thousands separatorSpecify the thousands separators. Two options available34Ôºö _ , Both separators will make the long numbers more human-readable. python f\"{123456789:,}\" '123,456,789' python f\"{1234.56789:,}\" '1,234.56789' python f\"{123456789:_}\" '123_456_789' python f\"{1234.56789:_}\" '1_234.56789' ","date":"2022-11-16","objectID":"/en/f-strings-in-python/:3:6","series":null,"tags":["Python"],"title":"The f-strings in Python3.6","uri":"/en/f-strings-in-python/#thousands-separator"},{"categories":["Programming-Languages"],"content":" TrickWe can use {expression=} for self-documenting expression since Python3.85. How could it be helpful? As a print debugger, I usually print values of variables to debug a Python program. It‚Äôs kind of annoying that every time I need to write the variable name twice. python f\"left={left}, right={right}\" 'left=3, right=5' Now we can write python f\"{left=}, {right=}\" 'left=3, right=5' ","date":"2022-11-16","objectID":"/en/f-strings-in-python/:3:7","series":null,"tags":["Python"],"title":"The f-strings in Python3.6","uri":"/en/f-strings-in-python/#trick"},{"categories":["Programming-Languages"],"content":" Wrap-upWhen I started to learn Python a long time ago, most of the tutorials said we should use % to format strings. After str.format appeared, it became a better choice and outdated the % syntax. F-strings, released with Python3.6, has become the best practice now.üöÄ It meets the zen of Python - There should be one‚Äì and preferably only one ‚Äìobvious way to do it ","date":"2022-11-16","objectID":"/en/f-strings-in-python/:4:0","series":null,"tags":["Python"],"title":"The f-strings in Python3.6","uri":"/en/f-strings-in-python/#wrap-up"},{"categories":["Programming-Languages"],"content":" Refs PEP 498 ‚Äì Literal String Interpolation¬†‚Ü©Ô∏é PEP 682 ‚Äì Format Specifier for Signed Zero¬†‚Ü©Ô∏é PEP 378 ‚Äì Format Specifier for Thousands Separator¬†‚Ü©Ô∏é PEP 515. Underscores in Numeric Literals¬†‚Ü©Ô∏é https://docs.python.org/3/whatsnew/3.8.html#f-strings-support-for-self-documenting-expressions-and-debugging¬†‚Ü©Ô∏é ","date":"2022-11-16","objectID":"/en/f-strings-in-python/:5:0","series":null,"tags":["Python"],"title":"The f-strings in Python3.6","uri":"/en/f-strings-in-python/#refs"},{"categories":["Programming-Languages"],"content":"A simple tutorial for the walrus operator in python 3.8","date":"2022-10-29","objectID":"/en/walrus-operator-in-python/","series":null,"tags":["Python"],"title":"Walrus Operator in Python 3.8","uri":"/en/walrus-operator-in-python/"},{"categories":["Programming-Languages"],"content":" IntroToday I‚Äôm going to talk about a new feature introduced in Python 3.8: the Walrus operatorÔºà:=Ôºâ, which is a much-debated feature, but it‚Äôs finally passed and released ü§î In Python, an assignment statement (=) is not an expression but a statement. Walrus operator is expression though. The difference between statement and expression can be simply understood as: expression always returns a value, while statement does not return a value. The difference between the two can be seen in the following code: python # `=` is a statement, so it will print no value x = 5 python # `:=` is an expression, so it will evaluate to a value # not recommended :) (x := 5) 5 üìí The () needs to be added to avoid confusion. According to the Zen of Python: ‚ÄúThere should be one‚Äì and preferably only one ‚Äìobvious way to do it.‚Äù. If we can use it without (), we definitely will be confused about which one to use ü§ïÔ∏è In C/C++, = is an expression. We can write this: c // = will store the value in the LHS(left-hand-side) variable. // , and it has the value of the LHS // so we store the result of `foo` function call to `a` // , then we check if `a` \u003e 0 while ( (a = foo(...)) \u003e 0 ) { ... } Before Python 3.8, it was not possible to do something similar. Because the = is a statement. This is where the walrus expression comes into play ü§© ","date":"2022-10-29","objectID":"/en/walrus-operator-in-python/:1:0","series":null,"tags":["Python"],"title":"Walrus Operator in Python 3.8","uri":"/en/walrus-operator-in-python/#intro"},{"categories":["Programming-Languages"],"content":" Syntax rules The syntax of walrus expressions is quite simple: NAME := EXPRESSION. := assigns the value of EXPRESSION to NAME. we are not allowed to use attributes or subscripts as NAME. See the code below python # a dummy example. we bind `1 + 2 + 3` to `res` for future usage if (res := 1 + 2 + 3) \u003e 5: print(f\"res is {res}\") res is 6 python class foo: val: int = 0 some_foo = foo() (some_foo.val := 1) Input In [4] (some_foo.val := 1) ^ SyntaxError: cannot use assignment expressions with attribute python x = [1, 2, 3] (x[1] := 3) Input In [5] (x[1] := 3) ^ SyntaxError: cannot use assignment expressions with subscript The scope of NAME Walrus expressions do not introduce new scopes ü§© NAME can be used in the current scope, with one exception: if it is used inside a list/dict/set comprehension. We can use NAME in the enclosing scope. See the following example: python s = [1, 2, 3] # the list comprehension forms a new scope. # its enclosing scope is the global scope double_s = [item * 2 for item in s] # `item` is not in the global scope :) print(item) --------------------------------------------------------------------------- NameError Traceback (most recent call last) Input In [6], in \u003ccell line: 7\u003e() 4 double_s = [item * 2 for item in s] 6 # `item` is not in the global scope :) ----\u003e 7 print(item) NameError: name 'item' is not defined python s = [1, 2, 3] # the list comprehension forms a new scope. # its enclosing scope is the global scope double_s = [last := item * 2 for item in s] # so we can use `last` variable here print(last) Order of evaluation: lower than others except the comma(,) python x = 1, 2 x (1, 2) python (x := 1, 2) x 1 ","date":"2022-10-29","objectID":"/en/walrus-operator-in-python/:2:0","series":null,"tags":["Python"],"title":"Walrus Operator in Python 3.8","uri":"/en/walrus-operator-in-python/#syntax-rules"},{"categories":["Programming-Languages"],"content":" Usage üìí Combined with the content of 1 and my personal programming experience. The most convenient thing about walrus expressions is: dealing with functions whose return value may be None To deal with functions that may return None, we will usually first use the = statement to save the return result of the function. Then we check if it is None so we can refer to it later safely python some_thing = foo(....) if some_thing: ... else: ... I will use the re as an example python import re # define a regex pattern to extract digits in a string DIGIT_PATTERN = r'\\d+' text = 'There are 10 dogs' # re.search will return None if no match was found. match = re.search(DIGIT_PATTERN, text) if match: # group(0) will return the entire match print(f\"Find match: {match.group(0)}\") else: print(\"Not match was found\") Find match: 10 To avoid getting an AttributeError: 'NoneType' object has no attribute 'group' error when using match.group() later, we have to use an intermediate variable match to temporarily hold the return value rather then chain them together: re.search(DIGIT_PATTERN, text).group(0). It may seem kind of redundant though. üìí In Rust, the return type that may return None is called Option\u003cT\u003e. We can use ? to handle this situation, it will try to extract the value inside, and if it fails it will terminate early with an error. So in Rust, we can do this (assuming Rust has a similar API): re.search(DIGIT_PATTERN, text)?.group(0) üç∫ The readability is slightly weaker in my opinion, of course, this is quite personal. i.e. We can only use the match variable when match is not None. There is no chance to use it inside the else branch. However, if we look at the code from the top down quickly, match = ... on a separate line is like the match can be used later everywhere ü§£ Instead, we can use := to bind its return value here: python if match := re.search(DIGIT_PATTERN, text): # group(0) will return the entire match print(f\"Find match: {match.group(0)}\") else: print(\"Not match was found\") Find match: 10 1 One of the reasons for supporting := is that research shows that developers tend to write fewer lines of code rather than shorter code. That‚Äôs what we did here. At the same time, we can see the scope of match at a glance üëè Similarly, we can use this feature in while loops too: python val = foo(...) while val: # do something while val is not None val = foo(...) ","date":"2022-10-29","objectID":"/en/walrus-operator-in-python/:3:0","series":null,"tags":["Python"],"title":"Walrus Operator in Python 3.8","uri":"/en/walrus-operator-in-python/#usage"},{"categories":["Programming-Languages"],"content":" üÜö =A few differences worth mentioning: = is a statement, := is an expression. This also determines their application scenarios. Only = supports the continuous use of foo = bar = 1; and the left side of = can be an attribute like foo.bar, or an subscript like foo[1], but := can only be a simple variable name on the left = supports the augmented form of +=, but := does not ","date":"2022-10-29","objectID":"/en/walrus-operator-in-python/:4:0","series":null,"tags":["Python"],"title":"Walrus Operator in Python 3.8","uri":"/en/walrus-operator-in-python/#-"},{"categories":["Programming-Languages"],"content":" Wrap upIn my opinion, the walrus operator is quite useful in the aforementioned scenarios (Recommended üëç), and the readability is much improved üöÄ. But some examples in 1 just make me more confused ","date":"2022-10-29","objectID":"/en/walrus-operator-in-python/:5:0","series":null,"tags":["Python"],"title":"Walrus Operator in Python 3.8","uri":"/en/walrus-operator-in-python/#wrap-up"},{"categories":["Programming-Languages"],"content":" Refs PEP 572. Assignment Expressions¬†‚Ü©Ô∏é¬†‚Ü©Ô∏é¬†‚Ü©Ô∏é ","date":"2022-10-29","objectID":"/en/walrus-operator-in-python/:6:0","series":null,"tags":["Python"],"title":"Walrus Operator in Python 3.8","uri":"/en/walrus-operator-in-python/#refs"},{"categories":["Programming-Languages"],"content":"The tutorial about the pattern matching in Python 3.10","date":"2022-10-16","objectID":"/en/pattern-matching-in-python/","series":null,"tags":["Python"],"title":"Pattern Matching in Python 3.10","uri":"/en/pattern-matching-in-python/"},{"categories":["Programming-Languages"],"content":" IntroToday I want to talk about the new feature bring in Python 3.10 ‚Äì Pattern matching üéâ Those who have learned C language must be familiar with the following switch statement: c switch (expression) { case constant_1: // statements break; case constant_2: // statements break; // Fall through // the value of the expression can be either constant_3 or constant_4 :) case constant_3: case constant_4: // statements default: // default statements } To recap, the syntax rules of the switch statement: expression should be the int or char type. constant should be the int or char constant The execution process of the switch statement: Calculate the value of expression, and compare this value with each constant from top to bottom. If they are equal, the statements inside the specific case and all the case after the matched case will be executed, unless it finds a break statement. This feature is called Fall through, and we can use this feature to stack multiple case statements together to represent a logical ‚Äúor‚Äù relationship The default branch will be executed when all the previous case branches fail to match Python does not provide a switch statement, but we can use if...elif..elif..else to achieve the same effect, for example, suppose we want to perform different operations depending on the length of the list, We can write this: python some_list = [1, 2, 3, 4, 5] if len(some_list) == 1: # do something when the length is 1 ... # or more pythonic way: elif len(some_list) in [3, 5]: elif len(some_list) == 3 or len(some_list) == 5: # do something when the length is 3 or 5 ... else: ... The above series of if...elif..elif..else is actually slightly less readable, and it also violates the DRY(Don‚Äôt repeat yourself) principle, we write len(some_list) many times. Of course, we can choose to use a variable length to remember the length of some_list first, so that we can type less code. However, if the situation is more complicated, this trick is not applicable. A more elegant way to handle this situation is what this article is about: Pattern matching ‚¨áÔ∏è python match len(some_list): case 1: # do something when the length is 1 ... case 3 | 5: # do something when the length is 3 or 5 ... case _: # equal to the `default:` ... ","date":"2022-10-16","objectID":"/en/pattern-matching-in-python/:1:0","series":null,"tags":["Python"],"title":"Pattern Matching in Python 3.10","uri":"/en/pattern-matching-in-python/#intro"},{"categories":["Programming-Languages"],"content":" Syntax rulesThe syntax of the pattern matching is: python match subject: case \u003cpattern_1\u003e: \u003caction_1\u003e case \u003cpattern_2\u003e: \u003caction_2\u003e case \u003cpattern_3\u003e: \u003caction_3\u003e # [Optional] wildcard to cover all situations case _: \u003caction_wildcard\u003e Syntactically, it is similar to the aforementioned switch statement in C. The differences are: There is no fall through in pattern matching. Only the code inside the matched case branch will be executed. So we don‚Äôt need to add a break statement at the end of each case block No default available. But we can use case _ to capture all cases, which is called the Wildcard pattern that will be discussed later The subject and pattern here are much more powerful than the C language, not only the integer and char types, but pattern can also be combined and nested with each other. It will be explained in detail later ","date":"2022-10-16","objectID":"/en/pattern-matching-in-python/:2:0","series":null,"tags":["Python"],"title":"Pattern Matching in Python 3.10","uri":"/en/pattern-matching-in-python/#syntax-rules"},{"categories":["Programming-Languages"],"content":" PatternsIn pattern matching, a pattern basically does two things: Structure constraints: we can add constraints to the subject in various ways. For example the length, the specific value in a specific position, etc Bind variables: we can bind some names in the pattern to component elements of the subject. See the Capture pattern below. Below I discuss different patterns :) To avoid confusion, it‚Äôs worth explaining in advance that both () and [] are optional when pattern matching matches a sequence. For example, case foo, bar and case (foo, bar) and case [foo, bar] are equivalent. They have the same meaning. ","date":"2022-10-16","objectID":"/en/pattern-matching-in-python/:3:0","series":null,"tags":["Python"],"title":"Pattern Matching in Python 3.10","uri":"/en/pattern-matching-in-python/#patterns"},{"categories":["Programming-Languages"],"content":" Capture patternCapture pattern means that when we check whether a pattern matches, we can use variable names to bind to any part of it, and we can use these variables later python some_list = [\"foo\", \"bar\"] match some_list: # we want to match a seq which has length = 2 # , we also use `first` and `second` to capture \\ # the 1st and 2nd elements here. case [first, second]: # we can access first, second now print(f'the 1st element: {first}, 2nd element: {second}') the 1st element: foo, 2nd element: bar People who often deal with sequences must be familiar with the following code: python *before, last = [1, 2, 3, 4] assert last == 4, \"Error\" first, *middle, last = [1, 2, 3, 4] assert first == 1 and last == 4, \"Error\" first, *rest = [1, 2, 3, 4] assert first == 1, \"Error\" Similarly, we can do this in pattern matching: python some_list = [\"foo\", \"bar\", \"another_foo\", \"another_bar\"] match some_list: # we want to match a seq # , we also use `*rest` to capture the remaining elements case [first, *rest]: print(f'the 1st element: {first}, 2nd element: {rest}') the 1st element: foo, 2nd element: ['bar', 'another_foo', 'another_bar'] ","date":"2022-10-16","objectID":"/en/pattern-matching-in-python/:3:1","series":null,"tags":["Python"],"title":"Pattern Matching in Python 3.10","uri":"/en/pattern-matching-in-python/#capture-pattern"},{"categories":["Programming-Languages"],"content":" Literal patternLiteral pattern means that we can specify literal values in specific positions. The literals here can be number literals, string literals, True, False, and None üìí Note: For number literals and string literals, python will use == for comparison, and for True/False/None these three will use is. python some_list = [\"foo\", \"bar\"] match some_list: # we want to match a seq which has length = 2 # , the 1st element should be equal to \"foo\" # , and we use `second` to capture the 2nd element case [\"foo\", second]: print(f'the 2nd element: {second}') the 2nd element: bar python some_list = [True] match some_list: case [1]: print(f'Matched, 1 == True') Matched, 1 == True ","date":"2022-10-16","objectID":"/en/pattern-matching-in-python/:3:2","series":null,"tags":["Python"],"title":"Pattern Matching in Python 3.10","uri":"/en/pattern-matching-in-python/#literal-pattern"},{"categories":["Programming-Languages"],"content":" Wildcard patternIt is a common practice in python that: use _ to indicate that we don‚Äôt care about the value. Similarly, _ can be used here, and it will not bind any variables python some_list = [\"foo\", \"bar\"] match some_list: # we want to match a seq which has length = 2 # , the 1st element should be equal to \"foo\" # , and we use `_` to ignore the 2nd value case [\"foo\", _]: print(f'the 2nd value: {_}') # you should see empty output because we aren't binding value here the 2nd value: Another common usage is the case _ that appeared before. The _ will match everything, so case _ is often put at the end to indicate the default case python some_list = [\"foo\", \"bar\"] match some_list: # this case branch will not be matched case [\"bar\", _]: print('Match successfully') case _: print('Default case') Default case ","date":"2022-10-16","objectID":"/en/pattern-matching-in-python/:3:3","series":null,"tags":["Python"],"title":"Pattern Matching in Python 3.10","uri":"/en/pattern-matching-in-python/#wildcard-pattern"},{"categories":["Programming-Languages"],"content":" Or patternJust like in the if statement we can use or, in pattern matching we also have a similar syntax. Like most other languages, Python chooses to use | to express an ‚Äúor‚Äù logical relationship. We can declare the alternatives conveniently python some_list1 = [\"foo\"] some_list2 = [\"bar\"] match some_list1: # we want to match a seq which has length = 1 # , the 1st element can be \"foo\" or \"bar\" case [\"foo\" | \"bar\"]: print('[First match] Match foo or bar') match some_list2: case [\"foo\" | \"bar\"]: print('[Second match] Match foo or bar') [First match] Match foo or bar [Second match] Match foo or bar The disadvantage of the Or pattern above is that we have no way of knowing which one we matched exactly ","date":"2022-10-16","objectID":"/en/pattern-matching-in-python/:3:4","series":null,"tags":["Python"],"title":"Pattern Matching in Python 3.10","uri":"/en/pattern-matching-in-python/#or-pattern"},{"categories":["Programming-Languages"],"content":" As patternIn the previous example, we may match any of the alternatives, so how do we know which one we match? Because we may need to decide what to do based on which one is matched. In pattern matching, we can use as to bind a value python some_list = [\"foo\"] match some_list: # we want to match a seq which has length = 1 # , the 1st element can be \"foo\" or \"bar\" # we bind matched string literal with `matched_element` case (\"foo\" | \"bar\") as matched_element: print(f'Match {matched_element}') ","date":"2022-10-16","objectID":"/en/pattern-matching-in-python/:3:5","series":null,"tags":["Python"],"title":"Pattern Matching in Python 3.10","uri":"/en/pattern-matching-in-python/#as-pattern"},{"categories":["Programming-Languages"],"content":" Class patternPython is a dynamically typed language, and sometimes we need to decide whether to match based on the type. The intuitive way is using isinstance() to check if it is qualified, but there is a better way. Next, I will show you how to add type constraints step by step: python some_list = [\"foo\", 1, 3.14] match some_list: # match without type constraints case [s, v1, v2]: if isinstance(s, str) and isinstance(v1, int) and isinstance(v2, float): print(f'Match {s} - {v1} - {v2}') Match foo - 1 - 3.14 The intuitive way: we use the Capture pattern to bind values, and use isinstance to check the type in the code block python some_list = [\"foo\", 1, 3.14] match some_list: # match with type constraints case [str() as s, int() as v1, float() as v2]: print(f'Match {s} - {v1} - {v2}') Match foo - 1 - 3.14 The syntax here is quite similar to the previous Literal pattern + As pattern. i.e. We declare the type we want to match in the corresponding position. At the same time, we use the as keyword to bind the value. Less typing but still less elegant :(. Fortunately, python provides us with syntactic sugar üç¨ python some_list = [\"foo\", 1, 3.14] match some_list: # match with type constraints case [str(s), int(v1), float(v2)]: print(f'Match {s} - {v1} - {v2}') Match foo - 1 - 3.14 ","date":"2022-10-16","objectID":"/en/pattern-matching-in-python/:3:6","series":null,"tags":["Python"],"title":"Pattern Matching in Python 3.10","uri":"/en/pattern-matching-in-python/#class-pattern"},{"categories":["Programming-Languages"],"content":" Mapping patternThe previous ones are all matching against a sequence, here we are matching against the dict. I believe that after reading the previous examples, it is not difficult to understand the following example. But there are a few things to keep in mind: we match dict based on its present keys. The keys here must be a literal value or a value of enum type (for performance considerations), values do not have this restriction we can use **\u003cname\u003e to capture the key-value pair we didn‚Äôt write in pattern. Otherwise the undeclared key-value pairs will be ignored python some_dict = { 'first_name': 'foo', 'second_name': 'bar' } match some_dict: case {'first_name': first_name}: print(f'[First match] The first_name: {first_name}') match some_dict: case {'first_name': first_name, **rest}: print(f'[Second match] The rest: {rest}') [First match] The first_name: foo [Second match] The rest: {'second_name': 'bar'} ","date":"2022-10-16","objectID":"/en/pattern-matching-in-python/:3:7","series":null,"tags":["Python"],"title":"Pattern Matching in Python 3.10","uri":"/en/pattern-matching-in-python/#mapping-pattern"},{"categories":["Programming-Languages"],"content":" Value patternIt‚Äôs good practice to use ‚Äúnamed variables‚Äù as parameter values or to clarify the meaning of specific values. e.g. case (HttpStatus.OK, body) is better than case (200, body) The challenge of implementing the Value pattern in Python is to distinguish it from the previous Capture pattern. A discussion of this can be found at 1 The final solution provided by python is a restricted Value pattern that only supports Value pattern of the form foo.bar. Common usage will be combined with the enum type, see the following example python from enum import Enum class HttpStatusCode(Enum): CONTINUE = 100 OK = 200 some_list = [HttpStatusCode[\"OK\"]] match some_list: case [HttpStatusCode.OK as status_code]: print(f\"Receive {status_code}\") Receive HttpStatusCode.OK ","date":"2022-10-16","objectID":"/en/pattern-matching-in-python/:3:8","series":null,"tags":["Python"],"title":"Pattern Matching in Python 3.10","uri":"/en/pattern-matching-in-python/#value-pattern"},{"categories":["Programming-Languages"],"content":" Use pattern matching on a classIf we can only use pattern matching on built-in types, it doesn‚Äôt seem to be that useful. But in fact, Python also allows us to use pattern matching on objects of our own custom classes. Considering the application scenario, when we use pattern matching on an object, we often want to check whether the object is a certain class type. We may also care about some of its fields and want to extract the values. But in Python, this is difficult to implement1, mainly because the class has a lot of fields, most of which are special methods like __repr__, and these fields are unordered. Because it is unordered, we can‚Äôt directly bind variables by position in pattern, see the following example: python class Point: \"\"\" A simple class represents a Point in a 2D\"\"\" def __init__(x: int, y: int): self.x = x self.y = y some_point = Point(1, 2) match some_point: # the intuitive way, we want to match a Point type # , and we want to bind the `x` and `y` and their two fields respectively case Point(x, y): print(f\"The x: {x}\") print(f\"The y: {y}\") --------------------------------------------------------------------------- TypeError Traceback (most recent call last) Input In [17], in \u003ccell line: 7\u003e() 4 self.x = x 5 self.y = y ----\u003e 7 some_point = Point(1, 2) 9 match some_point: 10 # the intuitive way, we want to match a Point type 11 # , and we want to bind the `x` and `y` and their two fields respectively 12 case Point(x, y): 13 print(f\"The x: {x}\") 14 print(f\"The y: {y}\") TypeError: Point.__init__() takes 2 positional arguments but 3 were given Python provides two solutions, which are syntactically very similar to calling a function: we can choose to pass arguments by position, or we can choose to use the form foo=bar Let‚Äôs talk about the simple one first: add constraints by using foo=bar, which means that the object should have a field called foo and we want to bind bar to it. python class Point: \"\"\" A simple class represents a Point in a 2D\"\"\" def __init__(self, x: int, y: int): self.x = x self.y = y some_point = Point(1, 2) match some_point: # the intuitive way, we want to match a Point type # , and we want to bind the `x` and `y` and their two fields respectively case Point(x=x, y=y): print(f\"The x: {x}\") print(f\"The y: {y}\") The x: 1 The y: 2 Another solution is to modify the __match_args__ attribute of the class, which specifies the order of the fields python class Point: \"\"\" A simple class represents a Point in a 2D\"\"\" # we tell python that the order is first \"x\" and then \"y\" __match_args__ = (\"x\", \"y\") def __init__(self, x: int, y: int): self.x = x self.y = y some_point = Point(1, 2) match some_point: # the intuitive way, we want to match a Point type # , and we want to bind the `x` and `y` and their two fields respectively case Point(x, y): print(f\"The x: {x}\") print(f\"The y: {y}\") The x: 1 The y: 2 if you are familiar with @dataclass2, you can do this: python from dataclasses import dataclass @dataclass(match_args=True) class Point: \"\"\" A simple class represents a Point in a 2D\"\"\" x: int y: int print(f\"The order is {Point.__match_args__}\") some_point = Point(1, 2) match some_point: # the intuitive way, we want to match a Point type # , and we want to bind the `x` and `y` and their two fields respectively case Point(x, y): print(f\"The x: {x}\") print(f\"The y: {y}\") The order is ('x', 'y') The x: 1 The y: 2 ","date":"2022-10-16","objectID":"/en/pattern-matching-in-python/:4:0","series":null,"tags":["Python"],"title":"Pattern Matching in Python 3.10","uri":"/en/pattern-matching-in-python/#use-pattern-matching-on-a-class"},{"categories":["Programming-Languages"],"content":" GuardSometimes we not only care about whether the pattern matches, but we also want to impose certain restrictions. Consider such a situation where we want to match a sequence containing two int values, but we require the first element shoudld be larger than the second. How would you write it? Combined with the previous Class pattern, it is not difficult for us to write the following code: python some_list = [3, 4] match some_list: case [int(first), int(second)]: if first \u003e second: ... else: print(\"Expect first \u003e second. Match failed\") Expect first \u003e second. Match failed The above solution is fine, we definitely can use the if statement in the code block to add constraints. But just like type constraints, Python has taken this requirement into account, so it provides a Guard üíÇ‚Äç‚ôÄÔ∏è mechanism, which allows us to move the if statement to the end of the pattern for readability. The syntax rules to follow: python match subject: case \u003cpattern\u003e if \u003cexpression\u003e: ... \u003cpattern\u003e followed by an if statement Note how python evaluates this here: Check if \u003cpattern\u003e matches If it matches, bind values if we declared Check if the if \u003cexpression\u003e statement returns True. The \u003cexpression\u003e here can use the previously bound variable in step 2 The code inside the code block will be executed if and only if \u003cpattern\u003e matches + if statement returns True. Otherwise, it will fail and try to match the next \u003cpattern\u003e python some_list = [3, 4] match some_list: case [int(first), int(second)] if first \u003e second: print(\"Match successfully!\") ","date":"2022-10-16","objectID":"/en/pattern-matching-in-python/:5:0","series":null,"tags":["Python"],"title":"Pattern Matching in Python 3.10","uri":"/en/pattern-matching-in-python/#guard"},{"categories":["Programming-Languages"],"content":" Wrap upI would prefer pattern matching to the if...elif...elif...else for several reasons: We can easily bind values for subsequent processing when matching For better readabilityg The various patterns of pattern matching can actually be nested and combined, that‚Äôs what makes pattern matching a shining point. The above is a brief introduction to pattern matching introduced in Python 3.10 üöÄ ","date":"2022-10-16","objectID":"/en/pattern-matching-in-python/:6:0","series":null,"tags":["Python"],"title":"Pattern Matching in Python 3.10","uri":"/en/pattern-matching-in-python/#wrap-up"},{"categories":["Programming-Languages"],"content":" Refs PEP 635 ‚Äì Structural Pattern Matching: Motivation and Rationale¬†‚Ü©Ô∏é¬†‚Ü©Ô∏é dataclasses - documentation¬†‚Ü©Ô∏é ","date":"2022-10-16","objectID":"/en/pattern-matching-in-python/:7:0","series":null,"tags":["Python"],"title":"Pattern Matching in Python 3.10","uri":"/en/pattern-matching-in-python/#refs"},{"categories":["System-Programming"],"content":"the differences between the stack and the heap","date":"2022-09-19","objectID":"/en/what-is-the-heap-and-stack/","series":null,"tags":["System-programming"],"title":"What is stack and heap","uri":"/en/what-is-the-heap-and-stack/"},{"categories":["System-Programming"],"content":" IntroIf you‚Äôve been using dynamic languages like Python, Javascript, etc., you probably won‚Äôt notice the difference between stack and heap. Because these languages have garbage collectors (GCs) that will automatically manage memory for you, you just need to program at a high level without considering the details. The bad news is that GC is not a cost-free design. No matter how well designed a GC algorithm is, the performance of the code will be degraded to some extent. If you have been in programming for a long time, you may have heard something like ‚Äúthe recursion explodes the stack‚Äù. You may or may not click on the search engine to understand the difference between stack and heap. Chances are you just clicked into this article :) üìí Although GC will degrade the performance, it removes the mental burden of manually managing memory for developers, which can greatly speed up software development. This is sacrificing performance for development speed. However, when the performance bottleneck occurs in the later stage of the software, it is necessary to study how to refactor or even rewrite the key parts of code to improve performance. The stack and heap I mentioned here are not the heap and stack in the data structure, but the two mechanisms of memory management. Understanding the detailed differences between stack and heap helps us understand some programming languages that are closer to the low-level, such as Rust, C, C++, etc. In Rust, the most important concept is ownership. Mastering the ownership can make you feel easier when you are learning other designs in rustüòÑ. ","date":"2022-09-19","objectID":"/en/what-is-the-heap-and-stack/:1:0","series":null,"tags":["System-programming"],"title":"What is stack and heap","uri":"/en/what-is-the-heap-and-stack/#intro"},{"categories":["System-Programming"],"content":" The layout of a program in memoryTo run a program, it must be loaded into the memory. During the process of the program running, the data also needs to be read into the memory, so have you ever wondered how all this is distributed in the memory? I will give you a rough illustration below1: In the image above, the meanings of different parts: text: store code data: store the initialized static variables. such as global variable, static variable bss: store the uninitialized static data, such as the declaration static int i in C heap stack What is stored on the heap and stack will be discussed later. üìí The thing to remember here is that the stack and the heap are moving closer to each other as they are growing. The stack grows from high address -\u003e low address, and the heap grows from low address -\u003e high address. After understanding this, you will get a better understanding when you see that the sp pointer is got subtracted in the assembly code. üìí It seems that as we allocate more and more memory, the stack and heap may collide (because they are getting closer to each other). However, there is no need to worry about this problem, because: 1) This layout is happening in virtual memory. Today‚Äôs processors are generally 64-bit, and the capacity is very large. 2) Before the conflict, it is very likely that your physical memory has been exhausted long ago, this should be your first concern. ","date":"2022-09-19","objectID":"/en/what-is-the-heap-and-stack/:2:0","series":null,"tags":["System-programming"],"title":"What is stack and heap","uri":"/en/what-is-the-heap-and-stack/#the-layout-of-a-program-in-memory"},{"categories":["System-Programming"],"content":" Stack","date":"2022-09-19","objectID":"/en/what-is-the-heap-and-stack/:3:0","series":null,"tags":["System-programming"],"title":"What is stack and heap","uri":"/en/what-is-the-heap-and-stack/#stack"},{"categories":["System-Programming"],"content":" Terms Stack pointer(SP): the value of a specific register, which stores the address of the top of the stack Stack frame: created as function calls are made, it is a frame of data(for one function call) that gets pushed onto the stack. push: allocating space on the stack pop: free space on the stack ","date":"2022-09-19","objectID":"/en/what-is-the-heap-and-stack/:3:1","series":null,"tags":["System-programming"],"title":"What is stack and heap","uri":"/en/what-is-the-heap-and-stack/#terms"},{"categories":["System-Programming"],"content":" Stack allocationThe biggest feature of the stack is the last in first out (LIFO), which is also the pattern we follow when allocating and freeing space on the stack. Allocating space on the stack is quite simple, we just need to modify the value of the stack pointer. Naturally, from the bottom of the stack (A in the figure below) to the top of the stack (the position pointed to by sp) is the space we have allocated. The following figure1 shows the simple logic behind: It should be emphasized again here that the stack grows from high address -\u003e low address, so from left to right in the above figure is high address -\u003e low address. How does the function call work(simplified version)? Function call: subtract the value of sp -\u003e construct the stack frame for the called function, push them to the stack -\u003e enter the callee Function exit: just reverse the above process The full procedure of function call can be found on 2 üìí The problem to be worried about when allocating space on the stack is: do not keep allocating which causes the stack to blow up (that is, the famous Stack Overflow problem). Keep this in mind when writing recursive functions. You can choose to implement the function in an iterative way or consider increasing the size limit of the stack. For example, in Python, you can use sys.getrecursionlimit() to modify the size limit of the stack. In some programming languages, we can also change the recursive function to the tail recursion version, which can benefit from the optimizations. ","date":"2022-09-19","objectID":"/en/what-is-the-heap-and-stack/:3:2","series":null,"tags":["System-programming"],"title":"What is stack and heap","uri":"/en/what-is-the-heap-and-stack/#stack-allocation"},{"categories":["System-Programming"],"content":" An example: fibonacci sequenceWhen explaining recursion in CS courses, we usually use the Fibonacci sequence as an example. Now we use F(n) to represent the nth value of the Fibonacci sequence, then the formulas are: F(0) = 0 F(1) = 1 F(n) = F(n - 1) + F(n - 2) Take F(4) as the example, the process of the recursive function call is as follows: text F(4) = F(3) + F(2) = F(2) + F(1) + F(1) + F(0) = F(1) + F(0) + F(1) + F(1) + F(0) = 3 * F(1) + 2 * F(0) If we ignore some details and illustrate the changes in the stack, it will look like this: ps: the F(n) is a stack frame python stack: F(4) stack: F(4) | F(3) # F(4): enter F(3) stack: F(4) | F(3) | F(2) # F(3): enter F(2) stack: F(4) | F(3) | F(2) | F(1) # F(2): enter F(1), F(1) is the base case, ready to exit function call stack: F(4) | F(3) | F(2) # Function return, return to the body of F(2) stack: F(4) | F(3) | F(2) | F(0) # F(2): enter F(0), F(0) is the base case, ready to exit function call stack: F(4) | F(3) | F(2) # Function return, return to the body of F(2) stack: F(4) | F(3) | F(1) # F(3): enter F(1), F(1) is the base case, ready to exit function call stack: F(4) | F(3) # Function return, return to the body of F(3) stack: F(4) # Function return, return to the body of F(4) stack: F(4) | F(2) # F(4): enter F(2) stack: F(4) | F(2) | F(1) # F(2): enter F(1), F(1) is the base case, ready to exit function call stack: F(4) | F(2) # Function return, return to the body of F(2) stack: F(4) | F(2) | F(0) # F(2): enter F(0), F(0) is the base case, ready to exit function call stack: F(4) | F(2) # Function return, return to the body of F(2) stack: F(4) # Function return, return to the body of F(4) ","date":"2022-09-19","objectID":"/en/what-is-the-heap-and-stack/:3:3","series":null,"tags":["System-programming"],"title":"What is stack and heap","uri":"/en/what-is-the-heap-and-stack/#an-example-fibonacci-sequence"},{"categories":["System-Programming"],"content":" The data on the stackMemory space management on the stack is achieved by modifying the value of the sp pointer, so we can conclude that: It is very efficient when allocating or freeing the space on the stack. We can think of it as O(1) complexity. The logic of this LIFO of the stack is relatively simple. The compiler can shandle it for us. As developers, we do not need to intervene in this process. To modify the sp pointer, we need to know how much space will be used, so the data on the stack should be a fixed and known size(at compile time). As for data of variable size, this is the problem to be solved by the heap. ","date":"2022-09-19","objectID":"/en/what-is-the-heap-and-stack/:3:4","series":null,"tags":["System-programming"],"title":"What is stack and heap","uri":"/en/what-is-the-heap-and-stack/#the-data-on-the-stack"},{"categories":["System-Programming"],"content":" HeapThe disadvantage of the stack allocation is: it can not handle variable size data, and we can‚Äôt know how much the value of sp needs to be modified at this time. How do you bridge the gap between variable-sized data and stack? This requires the use of pointers. Although the size of the actual data stored is unknown, the size of the pointer is fixed (usually, it is equal to the word size of the underlying machine), so we can store a fixed-size pointer on the stack, let it point to the real data stored on the heap. ","date":"2022-09-19","objectID":"/en/what-is-the-heap-and-stack/:4:0","series":null,"tags":["System-programming"],"title":"What is stack and heap","uri":"/en/what-is-the-heap-and-stack/#heap"},{"categories":["System-Programming"],"content":" Heap allocationAs mentioned earlier, allocating memory on the heap is finding a large enough space on the heap, returning a pointer to this location, and then pushing the pointer onto the stack. Later, when we want to access this data, we can dereference the pointer. The * operator in C or Rust is used for this purpose. Hopefully understanding this will make it easier for you to learn pointers. :) Unlike simply modifying the sp value on stack allocation, memory management on the heap is much more complicated. Including the following points: The location and size of the memory that can be allocated on the heap are arbitrary (within the physical memory size limit), we need to invent some algorithm and data structure to trace the usage. This brings great difficulties to memory management on the heap. The efficiency of allocating space on the heap is also relatively low. We need to find a space of sufficient size. This process of finding is more time-consuming than directly modifying the value of sp. We must also deal with the problem of ‚Äúfragmentation‚Äù. Because the allocated space on the heap is scattered everywhere, a lot of fragments will be left in the memory in the process of heap allocation. The extreme case is: the total size of the fragments meets your requirements, but because they are scattered all over the memory and cannot be used together, the program throws an out-of-memory warning. üìí The memory that can be allocated on the heap is way larger than the stack, but better management mechanisms are needed to handle this more complex situation. For developers, it also causes a certain burden. We can‚Äôt rely on the compiler to automatically handle it for us, we have to manage the memory manually. If you forget to call free() after allocating space, then your program will have a memory leak problem. Not to mention other issues such as dangling pointers and double-free. ","date":"2022-09-19","objectID":"/en/what-is-the-heap-and-stack/:4:1","series":null,"tags":["System-programming"],"title":"What is stack and heap","uri":"/en/what-is-the-heap-and-stack/#heap-allocation"},{"categories":["System-Programming"],"content":" The data on the heapAfter having a certain understanding of the allocation of memory space on the heap, it is not difficult for us to draw the following conclusions: Variable-size data is stored on the heap. More flexibility at the expense of a little performance Sometimes it can be fixed-size data, but you don‚Äôt want to put it on the stack. Why is this the case? For example, in Rust, data on the stack is copied by default. Sometimes for performance considerations, you may want to put large data on the heap to avoid the overhead of multiple copies. I don‚Äôt know if this reminds you of the optimization that we often did. i.e. passing function parameter by reference rather than value. ","date":"2022-09-19","objectID":"/en/what-is-the-heap-and-stack/:4:2","series":null,"tags":["System-programming"],"title":"What is stack and heap","uri":"/en/what-is-the-heap-and-stack/#the-data-on-the-heap"},{"categories":["System-Programming"],"content":" Wrap up Stack and heap are concepts in memory management, they are different from the concept of stack and heap in the data structure. The reason why the stack is called the stack is because we follow the classical LIFO pattern when we manage the memory on the stack, and the name of the heap implies disorganization. Generally speaking, it is more efficient to allocate and free memory space on the stack. For this reason, Rust operates on the stack by default. Data of ‚Äúfixed size‚Äù is generally placed on the stack, and data of ‚Äúvariable size‚Äù is generally placed on the heap. However, sometimes for performance considerations, fixed-size data can also be stored on the heap. In the subject of CS, you can often see the layered design. For example, OSI model in the computer network. Programming languages themselves can also be divided into high-level languages and low-level languages. I would like to share with you a sentence from a performance engineering teacher1 - ‚ÄúMany times, if you want to learn this level well, you must understand the underlying level. You don‚Äôt have to work at that level, but after knowing the details of that level. It will help you learn this level quite well‚Äù. At least for me, after knowing the difference between stack and heap, the following questions seem to me to have a very reasonable explanation: What are pointers in C/C++ language used for? Why do they exist? Why does tail recursion optimization exist? Why do we have to consider the problem of deep recursion when writing recursive functions? Why does Rust put data on the stack by default? Why did I see someone recommend passing references when implementing a function? üìí In my humble opinion, the abstraction layer design is the most important concept in CS. Should you choose a language with GC that is easy to use but less efficient, or choose to manually manage memory yourself to make your code more efficient? It depends on the job at hand. If you want to develop speed, of course, it is the former, and if you focus on performance, it is the latter. Of course, in the middle is no GC + basically no need to manually manage memory by yourself + efficient = Rust language üöÄ. Why not learn some Rust üòâ ‚ö†Ô∏è Some details are ignored when I write this article. I only wrote down what I think is important. If you want to learn more, you may check the refs. ","date":"2022-09-19","objectID":"/en/what-is-the-heap-and-stack/:5:0","series":null,"tags":["System-programming"],"title":"What is stack and heap","uri":"/en/what-is-the-heap-and-stack/#wrap-up"},{"categories":["System-Programming"],"content":" Refs 6.172. Performance engineering of software systems - Lecture 11 \u0026\u0026 Lecture 12¬†‚Ü©Ô∏é¬†‚Ü©Ô∏é¬†‚Ü©Ô∏é Stack frame¬†‚Ü©Ô∏é ","date":"2022-09-19","objectID":"/en/what-is-the-heap-and-stack/:6:0","series":null,"tags":["System-programming"],"title":"What is stack and heap","uri":"/en/what-is-the-heap-and-stack/#refs"},{"categories":["Vim-Neovim"],"content":"How to use vim's macro system","date":"2022-07-02","objectID":"/en/vim-macro-101/","series":null,"tags":["Vim-Neovim"],"title":"Vim Macro 101","uri":"/en/vim-macro-101/"},{"categories":["Vim-Neovim"],"content":" IntroIn the process of learning Vim, the most enlightening sentence for me is : Vim is a kind of programming language I once tried to learn Vim a long time ago. However, the keystroke combinations are very difficult to memorize in my opinion. So I later gave up learning Vim and switched to a normal text editor. My view of Vim changed when I took this course: Missing semester. I started to regard Vim as a kind of programming language rather than just a text editor. Then I find that the combinations of various operations of Vim are the syntax of programming language. It seems that I am talking about something unrelated to this blog post. That‚Äôs not true. As programmers, we often avoid doing repetitive tasks by programming. Different people have different favorites. Vim is one of the options you probably do not know. I assume you have a basic understanding of basic Vim usage : ) ","date":"2022-07-02","objectID":"/en/vim-macro-101/:1:0","series":null,"tags":["Vim-Neovim"],"title":"Vim Macro 101","uri":"/en/vim-macro-101/#intro"},{"categories":["Vim-Neovim"],"content":" What is macro in Vim?We know that we can use . to repeat the last change. However, what if we want to apply many changes? Macro comes to the rescue. :) By using macro, we can record our operations and then store them in a register which can be executed later. If you check the content of the corresponding register, you may find that it is just a sequence of characters. ","date":"2022-07-02","objectID":"/en/vim-macro-101/:2:0","series":null,"tags":["Vim-Neovim"],"title":"Vim Macro 101","uri":"/en/vim-macro-101/#what-is-macro-in-vim"},{"categories":["Vim-Neovim"],"content":" Macro-how?","date":"2022-07-02","objectID":"/en/vim-macro-101/:3:0","series":null,"tags":["Vim-Neovim"],"title":"Vim Macro 101","uri":"/en/vim-macro-101/#macro-how"},{"categories":["Vim-Neovim"],"content":" How to record a macroSteps to follow: In normal mode, press q\u003cregister\u003e. It means you first press q and then choose a \u003cregister\u003e you like to store your macro. The regitsers you can use are: 0-9, a-z, and \". Start typing. If everything goes right, you will see recording @\u003cregister\u003e in the bottom left. From now on, everything you type will be recorded. Press q again to quit the recording. ","date":"2022-07-02","objectID":"/en/vim-macro-101/:3:1","series":null,"tags":["Vim-Neovim"],"title":"Vim Macro 101","uri":"/en/vim-macro-101/#how-to-record-a-macro"},{"categories":["Vim-Neovim"],"content":" How to inspect a macroI previously mentioned that the macro is just a sequence of characters stored in a specific register. We can use the following command to inspect the content: sh :reg \u003cregister\u003e You may see some strange characters: ^[ means \u003cESC\u003e \u003c80\u003ekb means BAKESPACE ","date":"2022-07-02","objectID":"/en/vim-macro-101/:3:2","series":null,"tags":["Vim-Neovim"],"title":"Vim Macro 101","uri":"/en/vim-macro-101/#how-to-inspect-a-macro"},{"categories":["Vim-Neovim"],"content":" How to execute a macro Within a file @\u003cregister\u003e: execute the macro in \u003cregister\u003e @@: execute the last executed macro What if we want to execute a macro many times? Well, it is easy. We just add [COUNT] before @@ or @\u003cregister\u003e. Remember, Vim is a kind of programming language. Do all these make sense if you consider it as a kind of programming language? e.g. 100@@ means executing the last executed macro 100 times Calculating what the value of [COUNT] should be is tedious. Luckily, we can set it to a large value. The exceeding part will be ignored. A bunch of filesThings got complicated when you tried to modify multiple files. Opening each file and applying a macro repeatedly would be unreasonable. It is a violation of the DRY(Don‚Äôt repeat yourself) principle. Vim allows us to open multiple files at the same time and edit them one by one. What‚Äôs more, we can apply our recorded macro to all files with a single command. For example, you may want to edit all the txt files in the current directory. Typing vim *.txt in your terminal will open all these files. At first glance, it looks like you are editing a file, except that if you try to type :x to save and exit you will get an error! The naive way is modifying the file content and then typing :wn to save the changes and go to the next file. Now I will tell you how to do this more cleverly. Record your macro first then drop the changes by typing :edit! in the 1-st file because we will change all files including the 1-st file later. Without this cancellation, the 1st file will be modified twice. In normal mode, type :bufdo execute \"normal @\u003cregister\u003e\" | update. More details can be found here ","date":"2022-07-02","objectID":"/en/vim-macro-101/:3:3","series":null,"tags":["Vim-Neovim"],"title":"Vim Macro 101","uri":"/en/vim-macro-101/#how-to-execute-a-macro"},{"categories":["Vim-Neovim"],"content":" How to execute a macro Within a file @: execute the macro in @@: execute the last executed macro What if we want to execute a macro many times? Well, it is easy. We just add [COUNT] before @@ or @. Remember, Vim is a kind of programming language. Do all these make sense if you consider it as a kind of programming language? e.g. 100@@ means executing the last executed macro 100 times Calculating what the value of [COUNT] should be is tedious. Luckily, we can set it to a large value. The exceeding part will be ignored. A bunch of filesThings got complicated when you tried to modify multiple files. Opening each file and applying a macro repeatedly would be unreasonable. It is a violation of the DRY(Don‚Äôt repeat yourself) principle. Vim allows us to open multiple files at the same time and edit them one by one. What‚Äôs more, we can apply our recorded macro to all files with a single command. For example, you may want to edit all the txt files in the current directory. Typing vim *.txt in your terminal will open all these files. At first glance, it looks like you are editing a file, except that if you try to type :x to save and exit you will get an error! The naive way is modifying the file content and then typing :wn to save the changes and go to the next file. Now I will tell you how to do this more cleverly. Record your macro first then drop the changes by typing :edit! in the 1-st file because we will change all files including the 1-st file later. Without this cancellation, the 1st file will be modified twice. In normal mode, type :bufdo execute \"normal @\" | update. More details can be found here ","date":"2022-07-02","objectID":"/en/vim-macro-101/:3:3","series":null,"tags":["Vim-Neovim"],"title":"Vim Macro 101","uri":"/en/vim-macro-101/#within-a-file"},{"categories":["Vim-Neovim"],"content":" How to execute a macro Within a file @: execute the macro in @@: execute the last executed macro What if we want to execute a macro many times? Well, it is easy. We just add [COUNT] before @@ or @. Remember, Vim is a kind of programming language. Do all these make sense if you consider it as a kind of programming language? e.g. 100@@ means executing the last executed macro 100 times Calculating what the value of [COUNT] should be is tedious. Luckily, we can set it to a large value. The exceeding part will be ignored. A bunch of filesThings got complicated when you tried to modify multiple files. Opening each file and applying a macro repeatedly would be unreasonable. It is a violation of the DRY(Don‚Äôt repeat yourself) principle. Vim allows us to open multiple files at the same time and edit them one by one. What‚Äôs more, we can apply our recorded macro to all files with a single command. For example, you may want to edit all the txt files in the current directory. Typing vim *.txt in your terminal will open all these files. At first glance, it looks like you are editing a file, except that if you try to type :x to save and exit you will get an error! The naive way is modifying the file content and then typing :wn to save the changes and go to the next file. Now I will tell you how to do this more cleverly. Record your macro first then drop the changes by typing :edit! in the 1-st file because we will change all files including the 1-st file later. Without this cancellation, the 1st file will be modified twice. In normal mode, type :bufdo execute \"normal @\" | update. More details can be found here ","date":"2022-07-02","objectID":"/en/vim-macro-101/:3:3","series":null,"tags":["Vim-Neovim"],"title":"Vim Macro 101","uri":"/en/vim-macro-101/#a-bunch-of-files"},{"categories":["Vim-Neovim"],"content":" How to modify a macro Simple caseIf you are recording a quite long macro and you press q unexpectedly, you definitely do not want to start from the beginning. Vim has a feature to save us from this trouble. In Vim, if we press q\u003cREIGSTER\u003e(\u003cREGISTER\u003e means A-Z) in normal mode. Everything we typed now will be appended to the corresponding register. For example, we may have recorded macro in register a, then we can press qA to append operations to this marco. That is how we continue recording a half-finished macro. Complex caseWhat if we want to change the operations in the middle rather than appending them? The secret is that we can just treat the macro as a text sequence. After editing, we can store it back: Press G to jump to the last line, then type :put \u003cregister\u003e. The content of the register will appear in the next line. Just edit this mysterious text sequence. After you have edited the content, you can type :d \u003cregister\u003e to put back the content(make sure your cursor is still in this line). e.g. The following gif shows the procedure of modifying a macro. I have a dumb macro in the register y which can append world in the current line. I change it to append hello world instead. ","date":"2022-07-02","objectID":"/en/vim-macro-101/:3:4","series":null,"tags":["Vim-Neovim"],"title":"Vim Macro 101","uri":"/en/vim-macro-101/#how-to-modify-a-macro"},{"categories":["Vim-Neovim"],"content":" How to modify a macro Simple caseIf you are recording a quite long macro and you press q unexpectedly, you definitely do not want to start from the beginning. Vim has a feature to save us from this trouble. In Vim, if we press q( means A-Z) in normal mode. Everything we typed now will be appended to the corresponding register. For example, we may have recorded macro in register a, then we can press qA to append operations to this marco. That is how we continue recording a half-finished macro. Complex caseWhat if we want to change the operations in the middle rather than appending them? The secret is that we can just treat the macro as a text sequence. After editing, we can store it back: Press G to jump to the last line, then type :put . The content of the register will appear in the next line. Just edit this mysterious text sequence. After you have edited the content, you can type :d to put back the content(make sure your cursor is still in this line). e.g. The following gif shows the procedure of modifying a macro. I have a dumb macro in the register y which can append world in the current line. I change it to append hello world instead. ","date":"2022-07-02","objectID":"/en/vim-macro-101/:3:4","series":null,"tags":["Vim-Neovim"],"title":"Vim Macro 101","uri":"/en/vim-macro-101/#simple-case"},{"categories":["Vim-Neovim"],"content":" How to modify a macro Simple caseIf you are recording a quite long macro and you press q unexpectedly, you definitely do not want to start from the beginning. Vim has a feature to save us from this trouble. In Vim, if we press q( means A-Z) in normal mode. Everything we typed now will be appended to the corresponding register. For example, we may have recorded macro in register a, then we can press qA to append operations to this marco. That is how we continue recording a half-finished macro. Complex caseWhat if we want to change the operations in the middle rather than appending them? The secret is that we can just treat the macro as a text sequence. After editing, we can store it back: Press G to jump to the last line, then type :put . The content of the register will appear in the next line. Just edit this mysterious text sequence. After you have edited the content, you can type :d to put back the content(make sure your cursor is still in this line). e.g. The following gif shows the procedure of modifying a macro. I have a dumb macro in the register y which can append world in the current line. I change it to append hello world instead. ","date":"2022-07-02","objectID":"/en/vim-macro-101/:3:4","series":null,"tags":["Vim-Neovim"],"title":"Vim Macro 101","uri":"/en/vim-macro-101/#complex-case"},{"categories":["Vim-Neovim"],"content":" Wrap upThis is a simple tutorial about the macro in Vim, which is just the tip of the iceberg in Vim. Only when you master Vim do you make the most of it. It would be great if this blog got you interested in learning Vim. Hope this tutorial will be helpful üòâ ","date":"2022-07-02","objectID":"/en/vim-macro-101/:4:0","series":null,"tags":["Vim-Neovim"],"title":"Vim Macro 101","uri":"/en/vim-macro-101/#wrap-up"},{"categories":["Compiler"],"content":"use the semantic actions to generate the symbol tables in ANTLR4","date":"2022-05-28","objectID":"/en/how-to-use-antlr4-to-make-semantic-actions/","series":null,"tags":["Compiler","Course"],"title":"How to use the semantic actions to generate the symbol tables in ANTLR4","uri":"/en/how-to-use-antlr4-to-make-semantic-actions/"},{"categories":["Compiler"],"content":" What are the semantic actionsWhen the parser processes the input code, it not only determines whether the syntax is correct but also performs some useful actions. These actions are called semantic actions. In fact, it is a piece of code, which is generally embedded in the rules of the grammar file. Then when the parser applies this specific rule, the code you set will be executed. From another perspective, semantic actions are actually ‚Äútriggers‚Äù, and the trigger condition is that the parser applies the corresponding rules. Today‚Äôs post is about an application of semantic actions-implementing a simple symbol table, the tool used here is ANTLR4. ","date":"2022-05-28","objectID":"/en/how-to-use-antlr4-to-make-semantic-actions/:1:0","series":null,"tags":["Compiler","Course"],"title":"How to use the semantic actions to generate the symbol tables in ANTLR4","uri":"/en/how-to-use-antlr4-to-make-semantic-actions/#what-are-the-semantic-actions"},{"categories":["Compiler"],"content":" What‚Äôs the symbol tableWhen the compiler processes our code, it will maintain a symbol table internally, which is used to store all the information about variables in the program: variable name, data type, scope to which the variable belongs, etc. The symbol table can be of this form: Symbol name Type Scope bar function, double extern x double function parameter foo function, double global count int function parameter sum double block local i int for-loop statement ","date":"2022-05-28","objectID":"/en/how-to-use-antlr4-to-make-semantic-actions/:2:0","series":null,"tags":["Compiler","Course"],"title":"How to use the semantic actions to generate the symbol tables in ANTLR4","uri":"/en/how-to-use-antlr4-to-make-semantic-actions/#whats-the-symbol-table"},{"categories":["Compiler"],"content":" How to use actions in the ANTLR4ANTLR4 is a powerful parse generator. As long as we provide the grammar file, it can automatically generate a parser for us. The generated parser can support multiple target languages. For example, I use [Python](https://pypi .org/project/antlr4-python3-runtime) as my target language, then the final generated parser is a xxxParser.py file. The xxx is your grammar filename. ANTLR4 also provides methods that allow us to insert actions into the grammar file, and these actions will eventually be injected into the generated parser file. Therefore, the programming language in which the action is written depends on the target language of your output parser ‚ö†Ô∏èIt is assumed here that you have a basic understanding of how to write ANTLR4 grammar files (*.g4), and will not go into details about this. The article only focuses on how to insert actions into grammar files. ","date":"2022-05-28","objectID":"/en/how-to-use-antlr4-to-make-semantic-actions/:3:0","series":null,"tags":["Compiler","Course"],"title":"How to use the semantic actions to generate the symbol tables in ANTLR4","uri":"/en/how-to-use-antlr4-to-make-semantic-actions/#how-to-use-actions-in-the-antlr4"},{"categories":["Compiler"],"content":" Basic overviewBelow is a simplified code template for the generated parser file. In general, the locations we can inject are as follows(\u003c...\u003e in the code): python \u003cheader\u003e class xxxParser(Parser): ... \u003cmember\u003e def rule(self): ... \u003caction\u003e I will explain the different syntax for each location: \u003cheader\u003eThe ANTLR4 is originally written in Java, so if the target language you use is also Java, this will be more useful. Usually, it is used to place import statements. The format of the code to be injected into this location is as follows (in the *.g4 file, the same below) antlr @header{ everything here will go to \u003cheader\u003e } \u003cmember\u003eThis position is used to put the member of the class, which can be a field or a method. The ANTLR4 supports injecting code into Lexer and Parser separately or simultaneously. The format for injecting code into this location is as follows: antlr @members { everything here will go to \u003cmember\u003e in xxxLexer \u0026\u0026 xxxParser } @Lexer::members { everything here will go to \u003cmember\u003e in xxxLexer } @Parser::members { everything here will go to \u003cmember\u003e in xxxParser } ‚ö†Ô∏èIn the antlr4-python3-runtime edition I use (4.10), it is not yet possible to annotate the fields. You can‚Äôt put # comments like this. \u003caction\u003eIn ANTLR4, an action is a code enclosed in **curly braces {\u003cspecific-language-here\u003e}. As mentioned earlier, it is depending on what language your final output parser wants to be. Actions are generally placed after a symbol in a rule. When the parser applies the rule, the corresponding action will be executed after finishing matching the symbol. The symbol here can be terminal or nonterminal. We can use $symbol.attr to access the corresponding attributes, there are the following: python $terminal.text # origin text $terminal.type # an integer stands for type $terminal.attributes $terminal.line # the line number $terminal.pos # the position of the first char in the lineÔºå0-based $terminal.index $terminal.channel # the channel of this terminal, won't discuss in this post $terminal.int # return an interger if this terminal is an integer $nonterminal.text # origin text $nonterminal.start # 1st Token $nonterminal.stop # last Token $nonterminal.ctx # return context object ","date":"2022-05-28","objectID":"/en/how-to-use-antlr4-to-make-semantic-actions/:3:1","series":null,"tags":["Compiler","Course"],"title":"How to use the semantic actions to generate the symbol tables in ANTLR4","uri":"/en/how-to-use-antlr4-to-make-semantic-actions/#basic-overview"},{"categories":["Compiler"],"content":" Basic overviewBelow is a simplified code template for the generated parser file. In general, the locations we can inject are as follows(\u003c...\u003e in the code): python class xxxParser(Parser): ... def rule(self): ... I will explain the different syntax for each location: The ANTLR4 is originally written in Java, so if the target language you use is also Java, this will be more useful. Usually, it is used to place import statements. The format of the code to be injected into this location is as follows (in the *.g4 file, the same below) antlr @header{ everything here will go to } This position is used to put the member of the class, which can be a field or a method. The ANTLR4 supports injecting code into Lexer and Parser separately or simultaneously. The format for injecting code into this location is as follows: antlr @members { everything here will go to in xxxLexer \u0026\u0026 xxxParser } @Lexer::members { everything here will go to in xxxLexer } @Parser::members { everything here will go to in xxxParser } ‚ö†Ô∏èIn the antlr4-python3-runtime edition I use (4.10), it is not yet possible to annotate the fields. You can‚Äôt put # comments like this. In ANTLR4, an action is a code enclosed in **curly braces {}. As mentioned earlier, it is depending on what language your final output parser wants to be. Actions are generally placed after a symbol in a rule. When the parser applies the rule, the corresponding action will be executed after finishing matching the symbol. The symbol here can be terminal or nonterminal. We can use $symbol.attr to access the corresponding attributes, there are the following: python $terminal.text # origin text $terminal.type # an integer stands for type $terminal.attributes $terminal.line # the line number $terminal.pos # the position of the first char in the lineÔºå0-based $terminal.index $terminal.channel # the channel of this terminal, won't discuss in this post $terminal.int # return an interger if this terminal is an integer $nonterminal.text # origin text $nonterminal.start # 1st Token $nonterminal.stop # last Token $nonterminal.ctx # return context object ","date":"2022-05-28","objectID":"/en/how-to-use-antlr4-to-make-semantic-actions/:3:1","series":null,"tags":["Compiler","Course"],"title":"How to use the semantic actions to generate the symbol tables in ANTLR4","uri":"/en/how-to-use-antlr4-to-make-semantic-actions/#header"},{"categories":["Compiler"],"content":" Basic overviewBelow is a simplified code template for the generated parser file. In general, the locations we can inject are as follows(\u003c...\u003e in the code): python class xxxParser(Parser): ... def rule(self): ... I will explain the different syntax for each location: The ANTLR4 is originally written in Java, so if the target language you use is also Java, this will be more useful. Usually, it is used to place import statements. The format of the code to be injected into this location is as follows (in the *.g4 file, the same below) antlr @header{ everything here will go to } This position is used to put the member of the class, which can be a field or a method. The ANTLR4 supports injecting code into Lexer and Parser separately or simultaneously. The format for injecting code into this location is as follows: antlr @members { everything here will go to in xxxLexer \u0026\u0026 xxxParser } @Lexer::members { everything here will go to in xxxLexer } @Parser::members { everything here will go to in xxxParser } ‚ö†Ô∏èIn the antlr4-python3-runtime edition I use (4.10), it is not yet possible to annotate the fields. You can‚Äôt put # comments like this. In ANTLR4, an action is a code enclosed in **curly braces {}. As mentioned earlier, it is depending on what language your final output parser wants to be. Actions are generally placed after a symbol in a rule. When the parser applies the rule, the corresponding action will be executed after finishing matching the symbol. The symbol here can be terminal or nonterminal. We can use $symbol.attr to access the corresponding attributes, there are the following: python $terminal.text # origin text $terminal.type # an integer stands for type $terminal.attributes $terminal.line # the line number $terminal.pos # the position of the first char in the lineÔºå0-based $terminal.index $terminal.channel # the channel of this terminal, won't discuss in this post $terminal.int # return an interger if this terminal is an integer $nonterminal.text # origin text $nonterminal.start # 1st Token $nonterminal.stop # last Token $nonterminal.ctx # return context object ","date":"2022-05-28","objectID":"/en/how-to-use-antlr4-to-make-semantic-actions/:3:1","series":null,"tags":["Compiler","Course"],"title":"How to use the semantic actions to generate the symbol tables in ANTLR4","uri":"/en/how-to-use-antlr4-to-make-semantic-actions/#member"},{"categories":["Compiler"],"content":" Basic overviewBelow is a simplified code template for the generated parser file. In general, the locations we can inject are as follows(\u003c...\u003e in the code): python class xxxParser(Parser): ... def rule(self): ... I will explain the different syntax for each location: The ANTLR4 is originally written in Java, so if the target language you use is also Java, this will be more useful. Usually, it is used to place import statements. The format of the code to be injected into this location is as follows (in the *.g4 file, the same below) antlr @header{ everything here will go to } This position is used to put the member of the class, which can be a field or a method. The ANTLR4 supports injecting code into Lexer and Parser separately or simultaneously. The format for injecting code into this location is as follows: antlr @members { everything here will go to in xxxLexer \u0026\u0026 xxxParser } @Lexer::members { everything here will go to in xxxLexer } @Parser::members { everything here will go to in xxxParser } ‚ö†Ô∏èIn the antlr4-python3-runtime edition I use (4.10), it is not yet possible to annotate the fields. You can‚Äôt put # comments like this. In ANTLR4, an action is a code enclosed in **curly braces {}. As mentioned earlier, it is depending on what language your final output parser wants to be. Actions are generally placed after a symbol in a rule. When the parser applies the rule, the corresponding action will be executed after finishing matching the symbol. The symbol here can be terminal or nonterminal. We can use $symbol.attr to access the corresponding attributes, there are the following: python $terminal.text # origin text $terminal.type # an integer stands for type $terminal.attributes $terminal.line # the line number $terminal.pos # the position of the first char in the lineÔºå0-based $terminal.index $terminal.channel # the channel of this terminal, won't discuss in this post $terminal.int # return an interger if this terminal is an integer $nonterminal.text # origin text $nonterminal.start # 1st Token $nonterminal.stop # last Token $nonterminal.ctx # return context object ","date":"2022-05-28","objectID":"/en/how-to-use-antlr4-to-make-semantic-actions/:3:1","series":null,"tags":["Compiler","Course"],"title":"How to use the semantic actions to generate the symbol tables in ANTLR4","uri":"/en/how-to-use-antlr4-to-make-semantic-actions/#action"},{"categories":["Compiler"],"content":" An example ‚ö†Ô∏èOnly part of the code is given below, the complete code is in my Github repo ‚ö†Ô∏èBecause this project requires printing warnings before other outputs, so I use warning_list and output_list to store them temporarily, and then finally print them together. The following is an example of the [project assignment] (https://engineering.purdue.edu/~milind/ece573/2015fall/project/step3/step3.html) of the compiler course offered by Purdue University in 2015. The entire project requires to Implementing a compiler for Micro language. The grammar of the Micro language can be found here. Below I will give a brief introduction to the homework requirements. In this assignment we need to build a symbol table and print relevant information at the corresponding moment: Whenever we enter a new scope (which can be a function or a code block) Whenever we encounter variable declarations If the declared variable has been declared in the outer scope, print: SHADOW WARNING \u003cvar_name\u003e If there is already a variable with the same name in the current scope, print: DECLARATION ERROR \u003cvar_name\u003e. If this is the case, then the final program only outputs this information text Symbol table \u003cscope_name\u003e name \u003cvar_name\u003e type \u003ctype_name\u003e name \u003cvar_name\u003e type \u003ctype_name\u003e value \u003cstring_value\u003e ","date":"2022-05-28","objectID":"/en/how-to-use-antlr4-to-make-semantic-actions/:4:0","series":null,"tags":["Compiler","Course"],"title":"How to use the semantic actions to generate the symbol tables in ANTLR4","uri":"/en/how-to-use-antlr4-to-make-semantic-actions/#an-example"},{"categories":["Compiler"],"content":" What data structure should I useü§îThe first question to be solved is, what data structure should be used to represent the symbol table? A symbol table should meet the following characteristics: Efficient query Efficient insertion Record the scope of the variable It is not difficult to figure out that the data structure that supports efficient query and insertion is the ‚Äúhash table‚Äù. To maintain the scope of variables, We can put variables in the same hash table, and use a list to remember all scopes. The structure should be like: [{scope1} , {scope2},...]. In order to remember the current scope, I use the self.current_scope variable. Whenever a new scope appears, save the current scope and insert a new scope into the list. Don‚Äôt forget to update the self.current_scope also. üìíConceptually, the list here is a stack ü§îWhat method are we going to implement? lookup(identifier, value): Insert a variable into the current symbol table. According to the requirements of this assignment, we should also query whether the variable has been declared before enter_new_scope(): Save the current symbol table, enter the new scope, and initialize it. exit_scope(): Clear the current symbol table and find the previous symbol table(the top of the stack) So the corresponding code in @parser::members are as follows python @parser::members { def init(self): self.current_scope = None self.block_count = 0 self.warning_list = [] # just for printing self.output_list = [] # just for printing self.declaration_error = '' def enter_new_scope(self): if not hasattr(self, '_scopes'): setattr(self, '_scopes', []) # save the current_scope import copy if len(self._scopes) \u003e 0: self._scopes.append(copy.deepcopy(self.current_scope)) self._scopes.append({}) self.current_scope = self._scopes[-1] def exit_scope(self): del self._scopes[-1] if len(self._scopes) \u003e 0: self.current_scope = self._scopes[-1] def lookup(self, identifier, value): # check all scopes found = False for scope in self._scopes[:-1][::-1]: #print(f\"the scope: {scope}\") if identifier in scope: found = True if found: self.warning_list.append(f\"SHADOW WARNING {identifier}\") # only record the 1st declaration error if identifier in self.current_scope and self.declaration_error == '': self.declaration_error = f\"DECLARATION ERROR {identifier}\" self.current_scope[identifier] = value } ","date":"2022-05-28","objectID":"/en/how-to-use-antlr4-to-make-semantic-actions/:4:1","series":null,"tags":["Compiler","Course"],"title":"How to use the semantic actions to generate the symbol tables in ANTLR4","uri":"/en/how-to-use-antlr4-to-make-semantic-actions/#what-data-structure-should-i-use"},{"categories":["Compiler"],"content":" Inject actions into the grammar ruleü§îThe next step is to inject actions into the corresponding grammar rules. We want to output relevant information when variable declarations happen, so we must first observe what the rules of variable declaration in the Micro language are. The corresponding grammar rules are as follows antlr ... var_decl : var_type id_list ';' ; var_type : 'FLOAT' | 'INT' ; any_type : var_type | 'VOID' ; id_list : id id_tail ; id_tail : ',' id id_tail | ; ... As you can see, the var_decl rule shows the basic structure to declare variables. You can declare one or more variables at a time, and each variable is separated by ,, so we can inject the following action code at the end of this rule. ‚ö†Ô∏èNote that if you are also using python, the indentation here is a bit weird, because each line starts from the leftmost, but the final generated code is fine. the ANTLR4 will take care of this. antlr ... var_decl : var_type id_list ';' { # NOTE: the indentation is correct, ANLTR4 will handle this for us :) # for all variable declarations, we should output the name \u0026\u0026 type # in the same variable declaration, it means all of the variables have the same type for variable in $id_list.text.split(','): self.lookup(variable, None) self.output_list.append(f\"name {variable} type {$var_type.text}\") } ; ... We use $id_list.text to get the text corresponding to the variable declaration, and $var_type.text to get the corresponding variable type. ","date":"2022-05-28","objectID":"/en/how-to-use-antlr4-to-make-semantic-actions/:4:2","series":null,"tags":["Compiler","Course"],"title":"How to use the semantic actions to generate the symbol tables in ANTLR4","uri":"/en/how-to-use-antlr4-to-make-semantic-actions/#inject-actions-into-the-grammar-rule"},{"categories":["Compiler"],"content":" How to solve the scope problemTakes the program rule as an example (functions and code blocks are similar). The program rule is the starting rule of the Micro grammar, which specifies the big framework that a Micro program should have. The rule is as follows: antlr program : 'PROGRAM' id 'BEGIN' pgm_body 'END' ; After processing the PROGRAM token, we can create and initialize the first scope (global scope), and finally, exit the global scope after finishing processing. So we can quickly figure out where to inject the action antlr program : 'PROGRAM' id 'BEGIN' pgm_body 'END' ; ^ ^ | 2 The final code should be like this: antlr program : 'PROGRAM' { self.init() self.output_list.append(\"Symbol table GLOBAL\") self.enter_new_scope() } id 'BEGIN' pgm_body 'END' { self.exit_scope() # output everything after we parsing this program if self.declaration_error != '': print(self.declaration_error) else: if len(self.warning_list) \u003e 0: print('\\n'.join(self.warning_list)) print('\\n'.join(self.output_list)) } ; ","date":"2022-05-28","objectID":"/en/how-to-use-antlr4-to-make-semantic-actions/:4:3","series":null,"tags":["Compiler","Course"],"title":"How to use the semantic actions to generate the symbol tables in ANTLR4","uri":"/en/how-to-use-antlr4-to-make-semantic-actions/#how-to-solve-the-scope-problem"},{"categories":["Compiler"],"content":" Extended readingThe aforementioned example only involves simple actions injection, but ANTLR4 supports more powerful ways: For example, we can make a nonterminal return value If there are multiple nonterminals with the same name in the same rule, you can alias them Here‚Äôs an example from the book that nicely demonstrates the above two usages: antlr e returns [int v] : a=e op=('*'|'/') b=e {$v = self.eval($a.v, $op, $b.v)} | a=e op=('+'|'-') b=e {$v = self.eval($a.v, $op, $b.v)} | INT {$v = $INT.int} | ID ","date":"2022-05-28","objectID":"/en/how-to-use-antlr4-to-make-semantic-actions/:5:0","series":null,"tags":["Compiler","Course"],"title":"How to use the semantic actions to generate the symbol tables in ANTLR4","uri":"/en/how-to-use-antlr4-to-make-semantic-actions/#extended-reading"},{"categories":["Compiler"],"content":" Wrap upFrom this example, we can learn how to use actions in ANTLR4. Generating the symbol table is just one of the applications. Injecting actions into the code is a very intuitive way to quickly implement the functions you want. However, the disadvantage is also obvious. It is language-dependent, which means that once you change the target language output by ANTLR, all the actions you have written must be changed. Also, The grammar file will be a mess ","date":"2022-05-28","objectID":"/en/how-to-use-antlr4-to-make-semantic-actions/:6:0","series":null,"tags":["Compiler","Course"],"title":"How to use the semantic actions to generate the symbol tables in ANTLR4","uri":"/en/how-to-use-antlr4-to-make-semantic-actions/#wrap-up"},{"categories":["Compiler"],"content":" Refs Symbol table - wiki The Definitive ANTLR 4 Reference ","date":"2022-05-28","objectID":"/en/how-to-use-antlr4-to-make-semantic-actions/:7:0","series":null,"tags":["Compiler","Course"],"title":"How to use the semantic actions to generate the symbol tables in ANTLR4","uri":"/en/how-to-use-antlr4-to-make-semantic-actions/#refs"},{"categories":["Algorithm"],"content":"A simple explanation of the boyer-moore majority voting algorithm","date":"2022-03-24","objectID":"/en/boyer-moore-majority-voting-algorithm-explained/","series":null,"tags":["Algorithm"],"title":"Boyer-Moore Majority Voting Algorithm Explained","uri":"/en/boyer-moore-majority-voting-algorithm-explained/"},{"categories":["Algorithm"],"content":" Intro Today I coded the Leetcode 169. Majority Element again. I vaguely remember what the optimal solution is called Boyer-Moore Majority Voting Algorithm. However, I have no idea what is except for its name. So I plan to systematically learn the principle of this algorithm and summarize it to write this blog. I once heard that: If you want to master something, teach it :) So, I‚Äôm here today to share this algorithm with you, and try to teach you this method in plain language, so let‚Äôs get started :) ","date":"2022-03-24","objectID":"/en/boyer-moore-majority-voting-algorithm-explained/:1:0","series":null,"tags":["Algorithm"],"title":"Boyer-Moore Majority Voting Algorithm Explained","uri":"/en/boyer-moore-majority-voting-algorithm-explained/#intro"},{"categories":["Algorithm"],"content":" Let‚Äôs start from the baselines If you have never heard of the Boyer-Moore Majority Voting Algorithm, how would you try to solve this problem? I think these methods should come to your mind: Exchange space for time efficiency, that is, we use a hash table to record the number of occurrences of each element in the array, and then we check our hash table again to find the number of occurrences that is greater than $\\lfloor n/2\\rfloor$. Apparently, the time complexity and space complexity are both $O(n)$ Try to sort the array, because the element we are looking for exceeds the half-length of the array, which means it must appear in the middle of the array after sorting. However, although the space complexity is $O( 1)$, the time complexity is still greater than $O(n)$. For example, if you use quicksort, the time complexity is $O(nlogn)$ So is there a way to achieve a time complexity of $O(n)$ and a space complexity of $O(1)$? That is to combine the advantages of the above two methods. Yes, the answer is the Boyer-Moore Majority Voting Algorithm! ","date":"2022-03-24","objectID":"/en/boyer-moore-majority-voting-algorithm-explained/:2:0","series":null,"tags":["Algorithm"],"title":"Boyer-Moore Majority Voting Algorithm Explained","uri":"/en/boyer-moore-majority-voting-algorithm-explained/#lets-start-from-the-baselines"},{"categories":["Algorithm"],"content":" Boyer-Moore Majority Voting Algorithm Problem description: Suppose our array has $n$ elements, and we want to find the elements that appear more than $\\lfloor n/2\\rfloor$ times. Algorithm: Choose one of these $n$ elements as a candidate and record its votes as votes = 1. At this point there are $n-1$ elements in our array, we take out one element each time (denoted as current), and repeat the following steps (a total of n-1 times) Compare it to our current candidate, if they have the same value, then votes++, which is an affirmative vote If their values are different, votes--, that is, a dissenting vote. If we get votes = 0 at this time, then candidate \u003c- current, which means that we make current the new candidate, and reset votes = 1 The final value of the candidate is maybe the element that appears more than half of the times we want, at this point, we have to traverse the array again to check if it is After reading the above algorithm procedure, you may be as confused as I was. Why do we finally find the elements with more than half of the occurrences? In order to answer this question, we need to understand this: üí° If there is an element that appears more than $\\lfloor n/2\\rfloor$ times, then the other elements in the array must appear less than $\\lfloor n/2\\rfloor$ in all. Why it is useful? ‚¨ÜÔ∏è Because what this algorithm does is actually voting: It can be an affirmative vote, which is equal to the occurrences times of this element It can be a dissenting vote, which is equivalent to canceling one affirmative vote But the number of votes (affirmative votes) for the elements that appear more than $\\lfloor n/2\\rfloor$ times \u003e the remaining all that are not (dissenting votes) is always to be true, so no matter what, the final winner will always be the element we are searching(if it exists) :) To get a intuitive understanding ‚¨áÔ∏è ","date":"2022-03-24","objectID":"/en/boyer-moore-majority-voting-algorithm-explained/:3:0","series":null,"tags":["Algorithm"],"title":"Boyer-Moore Majority Voting Algorithm Explained","uri":"/en/boyer-moore-majority-voting-algorithm-explained/#boyer-moore-majority-voting-algorithm"},{"categories":["Algorithm"],"content":" Code java class Solution { public int majorityElement(int[] nums) { if (nums.length \u003c 2) { return nums[0]; } int candidates = nums[0]; int votes = 1; // step 1. start to vote for (int i = 0; i \u003c nums.length; i++) { if (nums[i] != candidates) { votes -= 1; if (votes == 0) { candidates = nums[i]; votes = 1; } } else { votes += 1; } } // step2. check int occurs = 0; for (var val: nums) { if (candidates == val) { occurs += 1; } } if (occurs \u003e= nums.length / 2) { return candidates; } else { return -1; } } } ","date":"2022-03-24","objectID":"/en/boyer-moore-majority-voting-algorithm-explained/:4:0","series":null,"tags":["Algorithm"],"title":"Boyer-Moore Majority Voting Algorithm Explained","uri":"/en/boyer-moore-majority-voting-algorithm-explained/#code"},{"categories":["Algorithm"],"content":" FAQ Q: Why do you need a second round of for-loop? Can we just check the votes directly? A: No, first of all, the element that ‚Äúoccurs more than $\\lfloor n/2\\rfloor$ times‚Äù does not always exist. e.g. [1,2,3]. In addition, even if it exists, after traversing the array for the first time, the votes does not necessarily equal to it real occurrence times. e.g. [1, 2, 2, 2, 3] ","date":"2022-03-24","objectID":"/en/boyer-moore-majority-voting-algorithm-explained/:5:0","series":null,"tags":["Algorithm"],"title":"Boyer-Moore Majority Voting Algorithm Explained","uri":"/en/boyer-moore-majority-voting-algorithm-explained/#faq"},{"categories":["Course"],"content":"The solution of proj3.Ants vs. SomeBees of CS61A","date":"2022-03-10","objectID":"/en/proj3.ants-vs-somebees-of-cs61a-of-ucb/","series":null,"tags":["Course","Python"],"title":"Solution of Proj3.Ants vs SomeBees of CS61A (2021-Fall)","uri":"/en/proj3.ants-vs-somebees-of-cs61a-of-ucb/"},{"categories":["Course"],"content":" Intro I have finished the first two projects - Hog and Cats. The first two projects are relatively simple and uncomplicated. But today, the difficulty of the third project has indeed increased (you can see how complicated this is by looking at the rules of the game). It feels like Plants vs. Zombies So I‚Äôm going to write a blog to sort out the ideas when writing code. ü§ó ","date":"2022-03-10","objectID":"/en/proj3.ants-vs-somebees-of-cs61a-of-ucb/:1:0","series":null,"tags":["Course","Python"],"title":"Solution of Proj3.Ants vs SomeBees of CS61A (2021-Fall)","uri":"/en/proj3.ants-vs-somebees-of-cs61a-of-ucb/#intro"},{"categories":["Course"],"content":" Phase 1: Basic gameplay ","date":"2022-03-10","objectID":"/en/proj3.ants-vs-somebees-of-cs61a-of-ucb/:2:0","series":null,"tags":["Course","Python"],"title":"Solution of Proj3.Ants vs SomeBees of CS61A (2021-Fall)","uri":"/en/proj3.ants-vs-somebees-of-cs61a-of-ucb/#phase-1-basic-gameplay"},{"categories":["Course"],"content":" Problem 1 (1 pt) Part A: Currently, there is no cost for placing any type of Ant, and so there is no challenge to the game. The base class Ant has a food_cost of zero. Override this class attribute for HarvesterAnt and ThrowerAnt according to the ‚ÄúFood Cost‚Äù column in the table below. Part B: Now that placing an Ant costs food, we need to be able to gather more food! To fix this issue, implement the HarvesterAnt class. A HarvesterAnt is a type of Ant that adds one food to the gamestate.food total as its action. Set the properties of HarversterAnt and ThrowerAnt according to the requirements of the description, and implement the action method of HarvesterAnt, so that it can give food + 1 each time it acts python class HarvesterAnt(Ant): \"\"\"HarvesterAnt produces 1 additional food per turn for the colony.\"\"\" name = 'Harvester' implemented = True food_cost = 2 def action(self, gamestate): \"\"\"Produce 1 additional food for the colony. gamestate -- The GameState, used to access game state information. \"\"\" gamestate.food += 1 class ThrowerAnt(Ant): \"\"\"ThrowerAnt throws a leaf each turn at the nearest Bee in its range.\"\"\" name = 'Thrower' implemented = True damage = 1 food_cost = 3 ","date":"2022-03-10","objectID":"/en/proj3.ants-vs-somebees-of-cs61a-of-ucb/:2:1","series":null,"tags":["Course","Python"],"title":"Solution of Proj3.Ants vs SomeBees of CS61A (2021-Fall)","uri":"/en/proj3.ants-vs-somebees-of-cs61a-of-ucb/#problem-1-1-pt"},{"categories":["Course"],"content":" Problem 2 (1 pt) In this problem, you‚Äôll complete Place.__init__ by adding code that tracks entrances. Right now, a Place keeps track only of its exit. We would like a Place to keep track of its entrance as well. A Place needs to track only one entrance. Tracking entrances will be useful when an Ant needs to see what Bees are in front of it in the tunnel. However, simply passing an entrance to a Place constructor will be problematic; we would need to have both the exit and the entrance before creating a Place! (It‚Äôs a chicken or the egg problem.) To get around this problem, we will keep track of entrances in the following way instead. Place.__init__ should use this logic: A newly created Place always starts with its entrance as None. If the Place has an exit, then the exit‚Äôs entrance is set to that Place. In fact, this colony is a bit like the structure of a doubly linked list in the data structure. Use .exit to go to the left and .entrance method to go to the right. python class Place: \"\"\"A Place holds insects and has an exit to another Place.\"\"\" is_hive = False def __init__(self, name, exit=None): \"\"\"Create a Place with the given NAME and EXIT. name -- A string; the name of this Place. exit -- The Place reached by exiting this Place (may be None). \"\"\" self.name = name self.exit = exit self.bees = [] # A list of Bees self.ant = None # An Ant self.entrance = None # A Place # Phase 1: Add an entrance to the exit if exit is not None: self.exit.entrance = self ","date":"2022-03-10","objectID":"/en/proj3.ants-vs-somebees-of-cs61a-of-ucb/:2:2","series":null,"tags":["Course","Python"],"title":"Solution of Proj3.Ants vs SomeBees of CS61A (2021-Fall)","uri":"/en/proj3.ants-vs-somebees-of-cs61a-of-ucb/#problem-2-1-pt"},{"categories":["Course"],"content":" Problem 3 (1 pt) In order for a ThrowerAnt to throw a leaf, it must know which bee to hit. The provided implementation of the nearest_bee method in the ThrowerAnt class only allows them to hit bees in the same Place. Your job is to fix it so that a ThrowerAnt will throw_at the nearest bee in front of it that is not still in the Hive. This includes bees that are in the same Place as a ThrowerAnt Hint: All Places have an is_hive attribute which is True when that place is the Hive. Change nearest_bee so that it returns a random Bee from the nearest place that contains bees. Your implementation should follow this logic: Start from the current Place of the ThrowerAnt. For each place, return a random bee if there is any, and if not, inspect the place in front of it (stored as the current place‚Äôs entrance). If there is no bee to attack, return None. Now we have to add a function to ThrowerAnt, so that it can attack the closest beeüêù. Note that if the bee is in the same place as it, it can also attack the üêù. Our job requirement is to traverse each grid (just like you traverse the linked list) to find the first place that contains at least a bee, and return a random bee python def nearest_bee(self): \"\"\"Return the nearest Bee in a Place that is not the HIVE, connected to the ThrowerAnt's Place by following entrances. This method returns None if there is no such Bee (or none in range). \"\"\" pos = self.place while pos.entrance is not None: if not pos.is_hive: if len(pos.bees) \u003e 0: return random_bee(pos.bees) pos = pos.entrance return None ","date":"2022-03-10","objectID":"/en/proj3.ants-vs-somebees-of-cs61a-of-ucb/:2:3","series":null,"tags":["Course","Python"],"title":"Solution of Proj3.Ants vs SomeBees of CS61A (2021-Fall)","uri":"/en/proj3.ants-vs-somebees-of-cs61a-of-ucb/#problem-3-1-pt"},{"categories":["Course"],"content":" Phase 2: Ants! ","date":"2022-03-10","objectID":"/en/proj3.ants-vs-somebees-of-cs61a-of-ucb/:3:0","series":null,"tags":["Course","Python"],"title":"Solution of Proj3.Ants vs SomeBees of CS61A (2021-Fall)","uri":"/en/proj3.ants-vs-somebees-of-cs61a-of-ucb/#phase-2-ants"},{"categories":["Course"],"content":" Problem 4 (2 pt) A ThrowerAnt is a powerful threat to the bees, but it has a high food cost. In this problem, you‚Äôll implement two subclasses of ThrowerAnt that are less costly but have constraints on the distance they can throw: The LongThrower can only throw_at a Bee that is found after following at least 5 entrance transitions. It cannot hit Bees that are in the same Place as it or the first 4 Places in front of it. If there are two Bees, one too close to the LongThrower and the other within its range, the LongThrower should only throw at the farther Bee, which is within its range, instead of trying to hit the closer Bee. The ShortThrower can only throw_at a Bee that is found after following at most 3 entrance transitions. It cannot throw at any bees further than 3 Places in front of it. Neither of these specialized throwers can throw_at a Bee that is exactly 4 Places away. Now we have to implement two classes, LongThrower and ShortThrower. Both of them are subclasses of ThrowererAnt . In fact, it can be seen from their names that the differences are the attack range. How do we express the concept of attack range? In fact, it is very simple. In problem 3, when we find the nearest bee, we move forward one place at a time, and we can calculate the number of steps at the same time, then we will get the distance. Then we may check whether the distance is fall between the min_range and max_range (class variables, indicating the attack range of the ants corresponding to this class) Also, note that we cannot affect the results in problem 3. Just need to do some simple modifications. We let min_range=-1, max_range=float('inf'), which is equivalent to no limit ~! Because of The advantages of OOP, we save a lot of code. python # In problem 3 class ThrowerAnt(Ant): \"\"\"ThrowerAnt throws a leaf each turn at the nearest Bee in its range.\"\"\" name = 'Thrower' implemented = True damage = 1 food_cost = 3 min_range = -1 max_range = float('inf') def nearest_bee(self): \"\"\"Return the nearest Bee in a Place that is not the HIVE, connected to the ThrowerAnt's Place by following entrances. This method returns None if there is no such Bee (or none in range). \"\"\" steps_cnt = 0 pos = self.place while pos.entrance is not None: if steps_cnt \u003e self.max_range: return None if not pos.is_hive: if len(pos.bees) \u003e 0 and steps_cnt \u003e= self.min_range: return random_bee(pos.bees) pos = pos.entrance steps_cnt += 1 return None class ShortThrower(ThrowerAnt): \"\"\"A ThrowerAnt that only throws leaves at Bees at most 3 places away.\"\"\" name = 'Short' food_cost = 2 # OVERRIDE CLASS ATTRIBUTES HERE implemented = True # Change to True to view in the GUI max_range = 3 class LongThrower(ThrowerAnt): \"\"\"A ThrowerAnt that only throws leaves at Bees at least 5 places away.\"\"\" name = 'Long' food_cost = 2 # OVERRIDE CLASS ATTRIBUTES HERE implemented = True # Change to True to view in the GUI min_range = 5 ","date":"2022-03-10","objectID":"/en/proj3.ants-vs-somebees-of-cs61a-of-ucb/:3:1","series":null,"tags":["Course","Python"],"title":"Solution of Proj3.Ants vs SomeBees of CS61A (2021-Fall)","uri":"/en/proj3.ants-vs-somebees-of-cs61a-of-ucb/#problem-4-2-pt"},{"categories":["Course"],"content":" Problem 5 (3 pt) Implement the FireAnt, which does damage when it receives damage. Specifically, if it is damaged by amount health units, it does a damage of amount to all bees in its place (this is called reflected damage). If it dies, it does an additional amount of damage, as specified by its damage attribute, which has a default value of 3 as defined in the FireAnt class. To implement this, override FireAnt‚Äôs reduce_health method. Your overriden method should call the reduce_health method inherited from the superclass (Ant) to reduce the current FireAnt instance‚Äôs health. Calling the inherited reduce_health method on a FireAnt instance reduces the insect‚Äôs health by the given amount and removes the insect from its place if its health reaches zero or lower. When the FireAnt receives damage, it will reflect the damage it has received to all bees in the current place, and if it dies because of the bee‚Äôs attack, it can also deal its damage to these bees again (depending on the damage of the FireAnt) Details: All the bees in the current place are stored as a list. As a result, **we may mutate the list while we are iterating it, so we need to traverse its copy(slice) The final code is as follows: python class FireAnt(Ant): \"\"\"FireAnt cooks any Bee in its Place when it expires.\"\"\" name = 'Fire' damage = 3 food_cost = 5 implemented = True # Change to True to view in the GUI def __init__(self, health=3): \"\"\"Create an Ant with a HEALTH quantity.\"\"\" super().__init__(health) def reduce_health(self, amount): \"\"\"Reduce health by AMOUNT, and remove the FireAnt from its place if it has no health remaining. Make sure to reduce the health of each bee in the current place, and apply the additional damage if the fire ant dies. \"\"\" # FireAnt attack bees for bee in self.place.bees[:]: bee.reduce_health(amount) # FireAnt will be dead if self.health \u003c= amount: for bee in self.place.bees[:]: bee.reduce_health(self.damage) super().reduce_health(amount) else: super().reduce_health(amount) ","date":"2022-03-10","objectID":"/en/proj3.ants-vs-somebees-of-cs61a-of-ucb/:3:2","series":null,"tags":["Course","Python"],"title":"Solution of Proj3.Ants vs SomeBees of CS61A (2021-Fall)","uri":"/en/proj3.ants-vs-somebees-of-cs61a-of-ucb/#problem-5-3-pt"},{"categories":["Course"],"content":" Phase 3: More Ants! ","date":"2022-03-10","objectID":"/en/proj3.ants-vs-somebees-of-cs61a-of-ucb/:4:0","series":null,"tags":["Course","Python"],"title":"Solution of Proj3.Ants vs SomeBees of CS61A (2021-Fall)","uri":"/en/proj3.ants-vs-somebees-of-cs61a-of-ucb/#phase-3-more-ants"},{"categories":["Course"],"content":" Problem 6 (1 pt) We are going to add some protection to our glorious home base by implementing the WallAnt, an ant that does nothing each turn. A WallAnt is useful because it has a large health value. Unlike with previous ants, we have not provided you with a class header. Implement the WallAnt class from scratch. Give it a class attribute name with the value 'Wall' (so that the graphics work) and a class attributeimplemented with the value True (so that you can use it in a game). Implement a WallAnt from scratch. This one is easy ! python class WallAnt(Ant): \"\"\"WallAnt has a large health value\"\"\" name = 'Wall' damage = 0 food_cost = 4 implemented = True def __init__(self, health=4): super().__init__(health) ","date":"2022-03-10","objectID":"/en/proj3.ants-vs-somebees-of-cs61a-of-ucb/:4:1","series":null,"tags":["Course","Python"],"title":"Solution of Proj3.Ants vs SomeBees of CS61A (2021-Fall)","uri":"/en/proj3.ants-vs-somebees-of-cs61a-of-ucb/#problem-6-1-pt"},{"categories":["Course"],"content":" Problem 7 (3 pt) Implement the HungryAnt, which will select a random Bee from its place and eat it whole. After eating a Bee, a HungryAnt must spend 3 turns chewing before eating again. If there is no bee available to eat, HungryAnt will do nothing. Give HungryAnt a chew_duration class attribute that stores the number of turns that it will take a HungryAnt to chew (set to 3). Also, give each HungryAnt an instance attribute chew_countdown that counts the number of turns it has left to chew (initialized to 0, since it hasn‚Äôt eaten anything at the beginning. You can also think of chew_countdown as the number of turns until a HungryAnt can eat another Bee). Implement the action method of the HungryAnt: First, check if it is chewing; if so, decrement its chew_countdown. Otherwise, eat a random Bee in its place by reducing the Bee‚Äôs health to 0. Make sure to set the chew_countdownwhen a Bee is eaten! Implementing a HungryAnt from scratch that can swallow a whole bee at random!!!! But it takes chew_duration to chew before the next attack. Isn‚Äôt this the piranha in Plants vs. Zombies!!! We only need to judge whether it is currently in the chewing state. Note that the value of chew_duration may be modified in the runtime. python class HungryAnt(Ant): \"\"\"HungryAnt will select a random bee from its place and eat it whole\"\"\" name = 'Hungry' damage = 0 food_cost = 4 implemented = True chew_duration = 3 def __init__(self, health=1): super().__init__(health) self.chew_countdown = 0 def action(self, gamestate): # it is chewing if self.chew_countdown != 0: self.chew_countdown -= 1 # it is not chewing else: if len(self.place.bees) \u003e 0: # WARNING: the test cases may change the chew_duration variable in runtime self.chew_countdown = self.chew_duration bee = random_bee(self.place.bees) bee.reduce_health(bee.health) ","date":"2022-03-10","objectID":"/en/proj3.ants-vs-somebees-of-cs61a-of-ucb/:4:2","series":null,"tags":["Course","Python"],"title":"Solution of Proj3.Ants vs SomeBees of CS61A (2021-Fall)","uri":"/en/proj3.ants-vs-somebees-of-cs61a-of-ucb/#problem-7-3-pt"},{"categories":["Course"],"content":" Problem 8 (3 pt) A BodyguardAnt differs from a normal ant because it is a ContainerAnt; it can contain another ant and protect it, all in one Place. When a Bee stings the ant in a Place where one ant contains another, only the container is damaged. The ant inside the container can still perform its original action. If the container perishes, the contained ant still remains in the place (and can then be damaged). Each ContainerAnt has an instance attribute ant_contained that stores the ant it contains. This ant, ant_contained, initially starts off as None to indicate that there is no ant being stored yet. Implement the store_ant method so that it sets the ContainerAnt‚Äôs ant_contained instance attribute to the passed in antargument. Also implement the ContainerAnt‚Äôs action method to perform its ant_contained‚Äôs action if it is currently containing an ant. The ant to be implemented here is also very interesting, it can protect an ant. It can even stay in the same place with the protected ant inside. Note a few details here: BodyguardAnt cannot protect BodyguardAnt! When BodyguardAnt and the ant inside are in the same place, make place.ant always point to BodyguardAnt There are actually a lot of things to be changed here (some code changes may be missed below, see my repo) python class Ant(Insect): \"\"\"An Ant occupies a place and does work for the colony.\"\"\" implemented = False # Only implemented Ant classes should be instantiated food_cost = 0 is_container = False ... def add_to(self, place): if place.ant is None: place.ant = self else: assert ( (place.ant is None) or self.can_contain(place.ant) or place.ant.can_contain(self) ), 'Two ants in {0}'.format(place) if place.ant.is_container and place.ant.can_contain(self): place.ant.store_ant(self) elif self.is_container and self.can_contain(place.ant): self.store_ant(place.ant) # the place.ant should refer to the container ant place.ant = self Insect.add_to(self, place) class ContainerAnt(Ant): \"\"\" ContainerAnt can share a space with other ants by containing them. \"\"\" is_container = True def __init__(self, *args, **kwargs): super().__init__(*args, **kwargs) self.ant_contained = None def can_contain(self, other): # we can't have two BodyguardAnt in the same place if self.ant_contained is None and not other.is_container: return True def store_ant(self, ant): self.ant_contained = ant def remove_ant(self, ant): if self.ant_contained is not ant: assert False, \"{} does not contain {}\".format(self, ant) self.ant_contained = None def remove_from(self, place): # Special handling for container ants (this is optional) if place.ant is self: # Container was removed. Contained ant should remain in the game place.ant = place.ant.ant_contained Insect.remove_from(self, place) else: # default to normal behavior Ant.remove_from(self, place) def action(self, gamestate): if self.ant_contained is not None: return self.ant_contained.action(gamestate) class BodyguardAnt(ContainerAnt): \"\"\"BodyguardAnt provides protection to other Ants.\"\"\" name = 'Bodyguard' food_cost = 4 implemented = True # Change to True to view in the GUI def __init__(self, health=2): super().__init__(health) ","date":"2022-03-10","objectID":"/en/proj3.ants-vs-somebees-of-cs61a-of-ucb/:4:3","series":null,"tags":["Course","Python"],"title":"Solution of Proj3.Ants vs SomeBees of CS61A (2021-Fall)","uri":"/en/proj3.ants-vs-somebees-of-cs61a-of-ucb/#problem-8-3-pt"},{"categories":["Course"],"content":" Problem 9 (1 pt) The BodyguardAnt provides great defense, but they say the best defense is a good offense. The TankAnt is a container that protects an ant in its place and also deals 1 damage to all bees in its place each turn. We have not provided you with a class header. Implement the TankAnt class from scratch. Give it a class attribute name with the value 'Tank' (so that the graphics work) and a class attribute implemented with the value True (so that you can use it in a game). You should not need to modify any code outside of the TankAnt class. If you find yourself needing to make changes elsewhere, look for a way to write your code for the previous question such that it applies not just to BodyguardAnt and TankAnt objects, but to container ants in general. According to the description, we can know that TankAnt is a special kind of ContainerAntI its attack method is quite special: the attack method of the ant it protects + deals its damage to all the bees in the same place python class TankAnt(ContainerAnt): name = 'Tank' damage = 1 food_cost = 6 implemented = True def __init__(self, health=2): super().__init__(health) def action(self, gamestate): if self.ant_contained is not None: self.ant_contained.action(gamestate) # 1 damage for all the bees for bee in self.place.bees[:]: bee.reduce_health(self.damage) ","date":"2022-03-10","objectID":"/en/proj3.ants-vs-somebees-of-cs61a-of-ucb/:4:4","series":null,"tags":["Course","Python"],"title":"Solution of Proj3.Ants vs SomeBees of CS61A (2021-Fall)","uri":"/en/proj3.ants-vs-somebees-of-cs61a-of-ucb/#problem-9-1-pt"},{"categories":["Course"],"content":" Phase 4: Water and Might ","date":"2022-03-10","objectID":"/en/proj3.ants-vs-somebees-of-cs61a-of-ucb/:5:0","series":null,"tags":["Course","Python"],"title":"Solution of Proj3.Ants vs SomeBees of CS61A (2021-Fall)","uri":"/en/proj3.ants-vs-somebees-of-cs61a-of-ucb/#phase-4-water-and-might"},{"categories":["Course"],"content":" Problem 10 (1 pt) Let‚Äôs add water to the colony! Currently there are only two types of places, the Hive and a basic Place. To make things more interesting, we‚Äôre going to create a new type of Place called Water. Only an insect that is waterproof can be placed in Water. In order to determine whether an Insect is waterproof, add a new class attribute to the Insect class named is_waterproof that is set to False. Since bees can fly, set their is_waterproof attribute to True, overriding the inherited value. Now, implement the add_insect method for Water. First, add the insect to the place regardless of whether it is waterproof. Then, if the insect is not waterproof, reduce the insect‚Äôs health to 0. Do not repeat code from elsewhere in the program. Instead, use methods that have already been defined. In order to make the game more interesting, we will add a new kind of Place - Water, only creatures with is_waterproof = True can be placed in(Of course, bees can fly, ants can‚Äôt) Add the class attribute is_waterproof in many classes, I will only put the code of the Water class below python class Water(Place): \"\"\"Water is a place that can only hold waterproof insects.\"\"\" def add_insect(self, insect): \"\"\"Add an Insect to this place. If the insect is not waterproof, reduce its health to 0.\"\"\" super().add_insect(insect) if not insect.is_waterproof: insect.reduce_health(insect.health) ","date":"2022-03-10","objectID":"/en/proj3.ants-vs-somebees-of-cs61a-of-ucb/:5:1","series":null,"tags":["Course","Python"],"title":"Solution of Proj3.Ants vs SomeBees of CS61A (2021-Fall)","uri":"/en/proj3.ants-vs-somebees-of-cs61a-of-ucb/#problem-10-1-pt"},{"categories":["Course"],"content":" Problem 11 (1 pt) Currently there are no ants that can be placed on Water. Implement the ScubaThrower, which is a subclass of ThrowerAnt that is more costly and waterproof, but otherwise identical to its base class. A ScubaThrower should not lose its health when placed in Water. We have not provided you with a class header. Implement the ScubaThrower class from scratch. Give it a class attribute name with the value 'Scuba' (so that the graphics work) and remember to set the class attributeimplemented with the value True (so that you can use it in a game). Implementing a ScubaThrower from scratch, it can be seen from the name that it should be a special ThrowerAnt. It can be placed in Water ! python class ScubaThrower(ThrowerAnt): name = 'Scuba' food_cost = 6 is_waterproof = True implemented = True def __init__(self, health=1): super().__init__(health) ","date":"2022-03-10","objectID":"/en/proj3.ants-vs-somebees-of-cs61a-of-ucb/:5:2","series":null,"tags":["Course","Python"],"title":"Solution of Proj3.Ants vs SomeBees of CS61A (2021-Fall)","uri":"/en/proj3.ants-vs-somebees-of-cs61a-of-ucb/#problem-11-1-pt"},{"categories":["Course"],"content":" Problem 12 (3 pt) Finally, implement the QueenAnt. The queen is a waterproof ScubaThrower that inspires her fellow ants through her bravery. In addition to the standard ScubaThrower action, the QueenAnt doubles the damage of all the ants behind her each time she performs an action. Once an ant‚Äôs damage has been doubled, it is not doubled again for subsequent turns. However, with great power comes great responsibility. The QueenAnt is governed by three special rules: If the queen ever has its health reduced to 0, the ants lose. You will need to override Ant.reduce_health in QueenAnt and call ants_lose() in that case in order to signal to the simulator that the game is over. (The ants also still lose if any bee reaches the end of a tunnel.) There can be only one queen. A second queen cannot be constructed. To check if an Ant can be constructed, we use the Ant.construct() class method to either construct an Ant if possible, or return None if not. You will need to override Ant.construct as a class method of QueenAnt in order to add this check. To keep track of whether a queen has already been created, you can use an instance variable added to the current GameState. The queen cannot be removed. Attempts to remove the queen should have no effect (but should not cause an error). You will need to override Ant.remove_from in QueenAnt to enforce this condition. Finally, we came to the last question (except the extra questions), we have to implement a queen antüêú. It has the following features: It can be placed in water Thought: The description also said that it is a kind of ScrubaThrower After it moves, it will double the attack power of the ants behind it, but not multiple times!!! Thought: How to express the relationship of ‚Äúbehind‚Äù? From the previous topic, we know the colony is a double linked list. The right side is the positive direction, so ‚Äúbehind‚Äù is actually corresponding to the left side. We can access the .exit method of Place to get all the ants behind. Thought: How to indicate that it cannot be doubled multiple times? It is easy to think that we need to set a flag to indicate whether the current ant has doubled its attack power. So we can directly add an instance variable to the Ant class Thought: Pay attention to how to deal with the GuardAnt here, because the ant it contains may be replaced by a new one. At this time we have to double the attack power of this new ant inside. There can only be one queen antüêú Thought: How to make it possible that even if we call the constructor of queen ants üêú many times, there will be exactly only one queen antüêú? This depends on a class called GameState. We can add a has_queen variable to the GameState class to indicate whether the queen antüêú has been created. Queen Ant üêú cannot be removed That‚Äôs easy. The final code is probably as follows: python class QueenAnt(ScubaThrower): \"\"\"The Queen of the colony. The game is over if a bee enters her place.\"\"\" name = 'Queen' food_cost = 7 implemented = True # Change to True to view in the GUI @classmethod def construct(cls, gamestate): \"\"\" Returns a new instance of the Ant class if it is possible to construct, or returns None otherwise. Remember to call the construct() method of the superclass! \"\"\" if cls.food_cost \u003e gamestate.food: print('Not enough food remains to place ' + cls.__name__) return # I add a class variable to indict if we have created a QueenAnt() if not gamestate.has_queen: gamestate.has_queen = True return super().construct(gamestate) else: return None def action(self, gamestate): \"\"\"A queen ant throws a leaf, but also doubles the damage of ants in her tunnel. \"\"\" super().action(gamestate) pos = self.place.exit while pos: if pos.ant is not None: if not pos.ant.is_doubled: pos.ant.is_doubled = True pos.ant.buff() if pos.ant.is_container and pos.ant.ant_contained is not None: # the pos.ant.ant_contained may change if not pos.ant.ant_contained.is_doubled: pos.ant.ant_contained.buff() pos.ant.ant_contained.is_doubled = True pos = pos.e","date":"2022-03-10","objectID":"/en/proj3.ants-vs-somebees-of-cs61a-of-ucb/:5:3","series":null,"tags":["Course","Python"],"title":"Solution of Proj3.Ants vs SomeBees of CS61A (2021-Fall)","uri":"/en/proj3.ants-vs-somebees-of-cs61a-of-ucb/#problem-12-3-pt"},{"categories":["Course"],"content":" Extra Credit (2 pt) Implement two final thrower ants that do zero damage, but instead apply a temporary ‚Äústatus‚Äù on the actionmethod of a Bee instance that they throw_at. This ‚Äústatus‚Äù lasts for a certain number of turns, after which it ceases to take effect. We will be implementing two new ants that inherit from ThrowerAnt. SlowThrower throws sticky syrup at a bee, slowing it for 3 turns. When a bee is slowed, it can only move on turns when gamestate.time is even, and can do nothing otherwise. If a bee is hit by syrup while it is already slowed, it is slowed for an additional 3 turns. ScaryThrower intimidates a nearby bee, causing it to back away instead of advancing. (If the bee is already right next to the Hive and cannot go back further, it should not move. To check if a bee is next to the Hive, you might find the is_hive instance attribute of Places useful). Bees remain scared until they have tried to back away twice. Bees cannot try to back away if they are slowed and gamestate.time is odd. Once a bee has been scared once, it can‚Äôt be scared ever again. Implement two special types of ants, which do no damage themselves, but add debuffs to bees. SlowThrower can slow down the bees, so that they can only move forward when the current time is even. This effect can last for 3 turns, but **we can slow the bees as many times as we want. ScaryThrower will make the bee move back(if you can‚Äôt move back, just keep still). This effect lasts for 2 turns. But if it is slowed, it will continue to stay still. This kind of debuff only can last time This question, really, is completely difficult. I debug the code for a long time before I succeeded. Let me talk about the design ideas: SlowThrower Set the is_slow variable to indicate whether the current bee is being slowed down, and set another variable called slow_turns to remember how many turns left to cancel this state Every turn, if the current bee is slowed down, it needs to check if the current gametime is an even number, if it is, it can move forward, otherwise stay in place, but no matter if you are moving, slow_turns -= 1 forever established ScaryThrower is_scared and scared_turns are set like is_slow and slow_turns Firstly, we don‚Äôt consider whether the current bee is slowed down for now (it‚Äôs easier to think about it this way). Obviously, what we need to do every turn is to let scared_turns -= 1, and the is_scared state actually determines the bee‚Äôs destination. Now, we will add more complexity to this. It‚Äôs problematic that we didn‚Äôt consider whether we were being slowed down. The description says that if it is slowed down while it is in scared state, it will keep still in its place. However, we let scared_turns -= 1 anyway, so we need to add one more judgment here, that is, in the case of being decelerated + being scared, if we do not move successfully, then we need to undo our changes to scared_turns The code is as follows: python class Bee(Insect): \"\"\"A Bee moves from place to place, following exits and stinging ants.\"\"\" name = 'Bee' damage = 1 is_waterproof = True # 2 flags is_slow = False is_scared = False # turns remained slow_turns = 0 scared_turns = 0 # we can't scare a bee twice has_been_scared = False def action(self, gamestate): \"\"\"A Bee's action stings the Ant that blocks its exit if it is blocked, or moves to the exit of its current place otherwise. gamestate -- The GameState, used to access game state information. \"\"\" if self.is_scared: destination = self.place.entrance self.scared_turns -= 1 else: destination = self.place.exit if self.is_slow: self.slow_turns -= 1 if self.slow_turns == 0: self.is_slow = False if gamestate.time % 2 == 0 and self.health \u003e 0 and destination is not None: self.move_to(destination) elif self.is_scared: # is_slow + is_scared + gamestate.time is odd, we need to cancel `self.scared_turns -= 1` \\ # if we didn't move self.scared_turns += 1 else: if self.blocked(): self.sting(self.place.ant) elif self.health \u003e 0 and destination is not None:","date":"2022-03-10","objectID":"/en/proj3.ants-vs-somebees-of-cs61a-of-ucb/:5:4","series":null,"tags":["Course","Python"],"title":"Solution of Proj3.Ants vs SomeBees of CS61A (2021-Fall)","uri":"/en/proj3.ants-vs-somebees-of-cs61a-of-ucb/#extra-credit-2-pt"},{"categories":["Course"],"content":" Optional Problems ","date":"2022-03-10","objectID":"/en/proj3.ants-vs-somebees-of-cs61a-of-ucb/:6:0","series":null,"tags":["Course","Python"],"title":"Solution of Proj3.Ants vs SomeBees of CS61A (2021-Fall)","uri":"/en/proj3.ants-vs-somebees-of-cs61a-of-ucb/#optional-problems"},{"categories":["Course"],"content":" Optional Problem 1 Implement the NinjaAnt, which damages all Bees that pass by, but can never be stung. A NinjaAnt does not block the path of a Bee that flies by. To implement this behavior, first modify the Ant class to include a new class attribute blocks_path that is set to True, then override the value of blocks_path to Falsein the NinjaAnt class. Second, modify the Bee‚Äôs method blocked to return False if either there is no Ant in the Bee‚Äôs place or if there is an Ant, but its blocks_path attribute is False. Now Bees will just fly past NinjaAnts. Finally, we want to make the NinjaAnt damage all Bees that fly past. Implement the action method in NinjaAntto reduce the health of all Bees in the same place as the NinjaAnt by its damage attribute. Similar to the FireAnt, you must iterate over a potentially changing list of bees. Ninja Antü•∑üêú, pay attention to a few details: Cannot be attacked by bees It will not block the bees, but will cause harm to the passing bees This problem is relatively simple, and the solutions are indicated by the description. python class Bee(Insect): \"\"\"A Bee moves from place to place, following exits and stinging ants.\"\"\" def blocked(self): \"\"\"Return True if this Bee cannot advance to the next Place.\"\"\" if self.place.ant is None: return False if not self.place.ant.blocks_path: return False return True class NinjaAnt(Ant): \"\"\"NinjaAnt does not block the path and damages all bees in its place. This class is optional. \"\"\" name = 'Ninja' damage = 1 food_cost = 5 blocks_path = False implemented = True # Change to True to view in the GUI def action(self, gamestate): for bee in self.place.bees[:]: bee.reduce_health(self.damage) ","date":"2022-03-10","objectID":"/en/proj3.ants-vs-somebees-of-cs61a-of-ucb/:6:1","series":null,"tags":["Course","Python"],"title":"Solution of Proj3.Ants vs SomeBees of CS61A (2021-Fall)","uri":"/en/proj3.ants-vs-somebees-of-cs61a-of-ucb/#optional-problem-1"},{"categories":["Course"],"content":" Optional Problem 2 The LaserAnt shoots out a powerful laser, damaging all that dare to stand in its path. Both Bees and Ants, of all types, are at risk of being damaged by LaserAnt. When a LaserAnt takes its action, it will damage all Insects in its place (excluding itself, but including its container if it has one) and the Places in front of it, excluding the Hive. If that were it, LaserAnt would be too powerful for us to contain. The LaserAnt has a base damage of 2. But, LaserAnt‚Äôs laser comes with some quirks. The laser is weakened by 0.25 each place it travels away fromLaserAnt‚Äôs place. Additionally, LaserAnt has limited battery. Each time LaserAnt actually damages an Insect its laser‚Äôs total damage goes down by 0.0625 (1/16). If LaserAnt‚Äôs damage becomes negative due to these restrictions, it simply does 0 damage instead. Laser üêú, pay attention to several features: Damage all creatures in your own place, including all creatures in the entire colony But each time it deals damage to other creatures, the damage will decrease, minus 0.0625 each time The power of the laser is also related to its distance from the laser antsüêú. For each additional place, the distance will be subtracted by 0.25 Just handle two functions calculate_damage : Note that if the calculated damage is \u003c 0, then you need to return 0 instead. insects_in_front : This returns a dict indicating the distance of each creature from the laser üêú. I divided it into the current place and the remaining places to process, and I calculate the distance while traversing all places. python class LaserAnt(ThrowerAnt): name = 'Laser' food_cost = 10 implemented = True # Change to True to view in the GUI damage = 2 def __init__(self, health=1): super().__init__(health) self.insects_shot = 0 self.current_damage = LaserAnt.damage def insects_in_front(self): \"\"\"Return a dict contains every Insect\"\"\" dis = {} for bee in self.place.bees: dis[bee] = 0 # take care of the ContainerAnt if self.place.ant is not self: dis[self.place.ant] = 0 pos = self.place.entrance distance = 1 while pos.entrance is not None: if not pos.is_hive: for bee in pos.bees: dis[bee] = distance if pos.ant is not None: dis[pos.ant] = distance # take care of the ContainerAnt if pos.ant.is_container and pos.ant.ant_contained is not None: dis[pos.ant.ant_contained] = distance distance += 1 pos = pos.entrance return dis def calculate_damage(self, distance): damage_result = self.damage - 0.0625 * self.insects_shot - 0.25 * distance return damage_result if damage_result \u003e 0 else 0 def action(self, gamestate): insects_and_distances = self.insects_in_front() for insect, distance in insects_and_distances.items(): damage = self.calculate_damage(distance) insect.reduce_health(damage) if damage: self.insects_shot += 1 ","date":"2022-03-10","objectID":"/en/proj3.ants-vs-somebees-of-cs61a-of-ucb/:6:2","series":null,"tags":["Course","Python"],"title":"Solution of Proj3.Ants vs SomeBees of CS61A (2021-Fall)","uri":"/en/proj3.ants-vs-somebees-of-cs61a-of-ucb/#optional-problem-2"},{"categories":["Course"],"content":"the simple solutions for lab14 of CS61A of UCB","date":"2022-03-03","objectID":"/en/lab14-cs61a-of-ucb/","series":null,"tags":["Course","Python"],"title":"Lab14 - CS61A of UCB(2021-Fall)","uri":"/en/lab14-cs61a-of-ucb/"},{"categories":["Course"],"content":" Trees ","date":"2022-03-03","objectID":"/en/lab14-cs61a-of-ucb/:1:0","series":null,"tags":["Course","Python"],"title":"Lab14 - CS61A of UCB(2021-Fall)","uri":"/en/lab14-cs61a-of-ucb/#trees"},{"categories":["Course"],"content":" Q1: Prune Min Write a function that prunes a Tree t mutatively. t and its branches always have zero or two branches. For the trees with two branches, reduce the number of branches from two to one by keeping the branch that has the smaller label value. Do nothing with trees with zero branches. Prune the tree in a direction of your choosing (top down or bottom up). The result should be a linear tree. The details: the leaf node: It is the base case, we return a node with only one branch: the current node meets the requirements of the description. However, its subtree may violate. So we still need to recursively process the branches. a node with two branches: Find the smaller one, and del the bigger one. python def prune_min(t): \"\"\"Prune the tree mutatively. \"\"\" # base case: the leaf node has 0 children if t.is_leaf(): return # go deeper if it has 1 child if len(t.branches) == 1: prune_min(t.branches[0]) left, right = t.branches[0], t.branches[1] if left.label \u003c right.label: del t.branches[1] # prune right branch prune_min(left) else: del t.branches[0] # prune left branch prune_min(right) ","date":"2022-03-03","objectID":"/en/lab14-cs61a-of-ucb/:1:1","series":null,"tags":["Course","Python"],"title":"Lab14 - CS61A of UCB(2021-Fall)","uri":"/en/lab14-cs61a-of-ucb/#q1-prune-min"},{"categories":["Course"],"content":" Regex ","date":"2022-03-03","objectID":"/en/lab14-cs61a-of-ucb/:2:0","series":null,"tags":["Course","Python"],"title":"Lab14 - CS61A of UCB(2021-Fall)","uri":"/en/lab14-cs61a-of-ucb/#regex"},{"categories":["Course"],"content":" Q4: Address First Line Write a regular expression that parses strings and returns any expressions which contain the first line of a US mailing address. US mailing addresses typically contain a block number, which is a sequence of 3-5 digits, following by a street name. The street name can consist of multiple words but will always end with a street type abbreviation, which itself is a sequence of 2-5 English letters. The street name can also optionally start with a cardinal direction (‚ÄúN‚Äù, ‚ÄúE‚Äù, ‚ÄúW‚Äù, ‚ÄúS‚Äù). Everything should be properly capitalized. Proper capitalization means that the first letter of each name is capitalized. It is fine to have things like ‚ÄúWeirdCApitalization‚Äù match. See the doctests for some examples. The details of the regex: a block number has a sequence of 3-5 digits The street name may contain multiple words, but the last one should be the abbreviation(2-5 English letters) The street name may start with one of ‚ÄúN‚Äù, ‚ÄúE‚Äù, ‚ÄúW‚Äù, ‚ÄúS‚Äù ps. The word should be properly capitalized(check the description) Let‚Äôs break down this problem: a block number: \\d{2,5} is enough The possible prefix - ‚ÄúN‚Äù, ‚ÄúE‚Äù, ‚ÄúW‚Äù, ‚ÄúS‚Äù. Use (?:[NSWE] )?. Keep in mind that it has whitespace inside The street name: we should first have a word, then we can repeat the whitespace + word combination as many times as we want. ‚úÖ [A-Z][A-Za-z]*(?: [A-Z][A-Za-z]*)*. The abbreviation: Why do I use {1,4} instead of {2,5}? The length of the abbreviation is between 2 and 5. However, after excluding the first capitalized letter, it should be in the range of 1 - 4. python def address_oneline(text): \"\"\" Finds and returns expressions in text that represent the first line of a US mailing address. \"\"\" block_number = r'\\d{3,5}' cardinal_dir = r'(?:[NSWE] )?' # whitespace is important! street = r'[A-Z][A-Za-z]*(?: [A-Z][A-Za-z]*)*' type_abbr = r' [A-Z][A-Za-z]{1,4}\\b' street_name = f\"{cardinal_dir}{street}{type_abbr}\" return re.findall(f\"{block_number} {street_name}\", text) ","date":"2022-03-03","objectID":"/en/lab14-cs61a-of-ucb/:2:1","series":null,"tags":["Course","Python"],"title":"Lab14 - CS61A of UCB(2021-Fall)","uri":"/en/lab14-cs61a-of-ucb/#q4-address-first-line"},{"categories":["Course"],"content":" SQL ","date":"2022-03-03","objectID":"/en/lab14-cs61a-of-ucb/:3:0","series":null,"tags":["Course","Python"],"title":"Lab14 - CS61A of UCB(2021-Fall)","uri":"/en/lab14-cs61a-of-ucb/#sql"},{"categories":["Course"],"content":" Q5: Opening Times You‚Äôd like to have lunch before 1pm. Create a opening table with the names of all Pizza places that open before 1pm, listed in reverse alphabetical order. Find the pizza place whose opening time is before 1:00 pm. Note that the time in the database is the 24-hour clock sql CREATE TABLE opening AS SELECT name FROM pizzas WHERE open \u003c 13 ORDER BY name DESC; ","date":"2022-03-03","objectID":"/en/lab14-cs61a-of-ucb/:3:1","series":null,"tags":["Course","Python"],"title":"Lab14 - CS61A of UCB(2021-Fall)","uri":"/en/lab14-cs61a-of-ucb/#q5-opening-times"},{"categories":["Course"],"content":" Q6: Double Pizza If two meals are more than 6 hours apart, then there‚Äôs nothing wrong with going to the same pizza place for both, right? Create a double table with three columns. The first columns is the earlier meal, the second is the later meal, and the third is the name of a pizza place. Only include rows that describe two meals that are more than 6 hours apart and a pizza place that is open for both of the meals. The rows may appear in any order. The details: Two meals should be more than 6 hours apart. The start time of the first meal and the end time of the second meal must be within the business hours of the restaurant sql create TABLE double AS SELECT m1.meal, m2.meal, p.name FROM meals AS m1, meals AS m2, pizzas AS p WHERE m2.time - m1.time \u003e 6 AND m1.time \u003e= p.open AND m2.time \u003c= p.close; ","date":"2022-03-03","objectID":"/en/lab14-cs61a-of-ucb/:3:2","series":null,"tags":["Course","Python"],"title":"Lab14 - CS61A of UCB(2021-Fall)","uri":"/en/lab14-cs61a-of-ucb/#q6-double-pizza"},{"categories":["Course"],"content":" Objects ","date":"2022-03-03","objectID":"/en/lab14-cs61a-of-ucb/:4:0","series":null,"tags":["Course","Python"],"title":"Lab14 - CS61A of UCB(2021-Fall)","uri":"/en/lab14-cs61a-of-ucb/#objects"},{"categories":["Course"],"content":" Q7: Player First, let‚Äôs implement the Player class. Fill in the debate and speech methods, that take in another Player other, and implement the correct behavior as detailed above. Here are two additional things to keep in mind: In the debate method, you should call the provided random function, which returns a random float between 0 and 1. The player should gain 50 popularity if the random number is smaller than the probability described above, and lose 50 popularity otherwise. Neither players‚Äô popularity should ever become negative. If this happens, set it equal to 0 instead. The calculation method has been given in the description. Note that both of votes and popularity need to be modified in the speech method python class Player: def __init__(self, name): self.name = name self.votes = 0 self.popularity = 100 def debate(self, other): prob1 = max(0.1, self.popularity / (self.popularity + other.popularity)) #prob2 = max(0.1, other.popularity / (self.popularity + other.popularity)) if random() \u003e prob1: self.popularity -= 50 else: self.popularity += 50 if self.popularity \u003c 0: self.popularity = 0 def speech(self, other): self.votes += (self.popularity // 10) self.popularity += (self.popularity // 10) other.popularity -= (other.popularity // 10) def choose(self, other): return self.speech ","date":"2022-03-03","objectID":"/en/lab14-cs61a-of-ucb/:4:1","series":null,"tags":["Course","Python"],"title":"Lab14 - CS61A of UCB(2021-Fall)","uri":"/en/lab14-cs61a-of-ucb/#q7-player"},{"categories":["Course"],"content":" Q8: Game Now, implement the Game class. Fill in the play method, which should alternate between the two players, starting with p1, and have each player take one turn at a time. The choose method in the Player class returns the method, either debate or speech, that should be called to perform the action. In addition, fill in the winner property method, which should return the player with more votes, or None if the players are tied. We determine who is the current player based on whether self.turn is odd or even. Note that the choose method returns a function, so we need to pass the parameters python class Game: def __init__(self, player1, player2): self.p1 = player1 self.p2 = player2 self.turn = 0 def play(self): while not self.game_over: if self.turn % 2 == 0: self.p1.choose(self.p2)(self.p2) else: self.p2.choose(self.p1)(self.p1) self.turn += 1 return self.winner @property def game_over(self): return max(self.p1.votes, self.p2.votes) \u003e= 50 or self.turn \u003e= 10 @property def winner(self): if self.p1.votes \u003e self.p2.votes: return self.p1 else: return self.p2 ","date":"2022-03-03","objectID":"/en/lab14-cs61a-of-ucb/:4:2","series":null,"tags":["Course","Python"],"title":"Lab14 - CS61A of UCB(2021-Fall)","uri":"/en/lab14-cs61a-of-ucb/#q8-game"},{"categories":["Course"],"content":" Q9: New Players The choose method in the Player class is boring, because it always returns the speech method. Let‚Äôs implement two new classes that inherit from Player, but have more interesting choose methods. Implement the choose method in the AggressivePlayer class, which returns the debate method if the player‚Äôs popularity is less than or equal to other‚Äôs popularity, and speech otherwise. Also implement the choose method in the CautiousPlayer class, which returns the debate method if the player‚Äôs popularity is 0, and speech otherwise. :) python class AggressivePlayer(Player): def choose(self, other): if self.popularity \u003c= other.popularity: return self.debate else: return self.speech class CautiousPlayer(Player): def choose(self, other): if self.popularity == 0: return self.debate else: return self.speech ","date":"2022-03-03","objectID":"/en/lab14-cs61a-of-ucb/:4:3","series":null,"tags":["Course","Python"],"title":"Lab14 - CS61A of UCB(2021-Fall)","uri":"/en/lab14-cs61a-of-ucb/#q9-new-players"},{"categories":["Course"],"content":" Tree Recursion ","date":"2022-03-03","objectID":"/en/lab14-cs61a-of-ucb/:5:0","series":null,"tags":["Course","Python"],"title":"Lab14 - CS61A of UCB(2021-Fall)","uri":"/en/lab14-cs61a-of-ucb/#tree-recursion"},{"categories":["Course"],"content":" Q10: Add trees Define the function add_trees, which takes in two trees and returns a new tree where each corresponding node from the first tree is added with the node from the second tree. If a node at any particular position is present in one tree but not the other, it should be present in the new tree as well. Hint: You may want to use the built-in zip function to iterate over multiple sequences at once. This problem asks us to add one tree to another. Note who is the subject (useful for later thinking about how to solve it recursively). How to solve it with recursion? base case: We are adding the tree t2 to the tree t1. What if t2 is None, do t2 still need to be added? No, this is one of our base cases ü§ó. On the basis that t2 is not None, what if t1 is empty? Obviously, the result of adding two trees at this time is t2, so we can just return t2. recursive decomposition At this time, we can guarantee that t1 and t2 are both non-empty, but we can‚Äôt guarantee that they have the same number of children, so we can‚Äôt use zip according to the hint. Because when zip is processing the two sequences of different lengths, some elements of the longer one are ignored. The zip_longest in itertools should be used here, and None will be returned if a sequence is already empty. This way we can guarantee that this recursive call will eventually come to the base case we discussed earlier. (Don‚Äôt forget to write from itertools import zip_longest) Then what we do at the current node is: add the labels of the two nodes, and then recursively call add_trees on their subtrees. üöÄ python def add_trees(t1, t2): # base case: no need to add_trees anymore if t2 is None: return t1 if t1 is None: return t2 else: # both of t1 and t2 are not None # however, the number of children may not equal return Tree(t1.label + t2.label, [add_trees(x, y) for x, y in zip_longest(t1.branches, t2.branches)]) ","date":"2022-03-03","objectID":"/en/lab14-cs61a-of-ucb/:5:1","series":null,"tags":["Course","Python"],"title":"Lab14 - CS61A of UCB(2021-Fall)","uri":"/en/lab14-cs61a-of-ucb/#q10-add-trees"},{"categories":["Course"],"content":" Linked Lists ","date":"2022-03-03","objectID":"/en/lab14-cs61a-of-ucb/:6:0","series":null,"tags":["Course","Python"],"title":"Lab14 - CS61A of UCB(2021-Fall)","uri":"/en/lab14-cs61a-of-ucb/#linked-lists"},{"categories":["Course"],"content":" Q11: Fold Left Write the left fold function by filling in the blanks. This is calculated from top to bottom, that is, we will calculate the result before entering deeper recursive calls. When we reach the empty node (indicating that we have done all the operations), we get the z in the base case, but it is not the original z at the first call, but the z of the operation result we want to get at the end. python def foldl(link, fn, z): \"\"\" Left fold \u003e\u003e\u003e lst = Link(3, Link(2, Link(1))) \u003e\u003e\u003e foldl(lst, sub, 0) # (((0 - 3) - 2) - 1) -6 \u003e\u003e\u003e foldl(lst, add, 0) # (((0 + 3) + 2) + 1) 6 \u003e\u003e\u003e foldl(lst, mul, 1) # (((1 * 3) * 2) * 1) 6 \"\"\" if link is Link.empty: return z z = fn(z, link.first) return foldl(link.rest, fn, z) ","date":"2022-03-03","objectID":"/en/lab14-cs61a-of-ucb/:6:1","series":null,"tags":["Course","Python"],"title":"Lab14 - CS61A of UCB(2021-Fall)","uri":"/en/lab14-cs61a-of-ucb/#q11-fold-left"},{"categories":["Course"],"content":" Q12: Fold Right Now write the right fold function. In fact, this problem will be simpler than Q1, and it is more in line with our understanding of recursion. We return the result operation layer by layer from the bottom layer. You can see the following examples to understand this python def foldr(link, fn, z): \"\"\" Right fold \u003e\u003e\u003e lst = Link(3, Link(2, Link(1))) \u003e\u003e\u003e foldr(lst, sub, 0) # (3 - (2 - (1 - 0))) 2 \u003e\u003e\u003e foldr(lst, add, 0) # (3 + (2 + (1 + 0))) 6 \u003e\u003e\u003e foldr(lst, mul, 1) # (3 * (2 * (1 * 1))) 6 \"\"\" if link.rest is Link.empty: return fn(link.first, z) return fn(link.first, foldr(link.rest, fn, z)) ","date":"2022-03-03","objectID":"/en/lab14-cs61a-of-ucb/:6:2","series":null,"tags":["Course","Python"],"title":"Lab14 - CS61A of UCB(2021-Fall)","uri":"/en/lab14-cs61a-of-ucb/#q12-fold-right"},{"categories":["Course"],"content":" Regex ","date":"2022-03-03","objectID":"/en/lab14-cs61a-of-ucb/:8:0","series":null,"tags":["Course","Python"],"title":"Lab14 - CS61A of UCB(2021-Fall)","uri":"/en/lab14-cs61a-of-ucb/#regex-1"},{"categories":["Course"],"content":" Q13: Basic URL Validation In this problem, we will write a regular expression which matches a URL. URLs look like the following: For example, in the link https://cs61a.org/resources/#regular-expressions, we would have: Scheme: https Domain Name: cs61a.org Path to the file: /resources/ Anchor: #regular-expressions The port and parameters are not present in this example and you will not be required to match them for this problem. You can reference this documentation from MDN if you‚Äôre curious about the various parts of a URL. For this problem, a valid domain name consists of any sequence of letters, numbers, dashes, and periods. For a URL to be ‚Äúvalid,‚Äù it must contain a valid domain name and will optionally have a scheme, path, and anchor. A valid scheme will either be http or https. Valid paths start with a slash and then must be a valid path to a file or directory. This means they should match something like /composingprograms.html or path/to/file but not /composing.programs.html/. A valid anchor starts with #. While they are more complicated, for this problem assume that valid anchors will then be followed by letters, numbers, hyphens, or underscores. Hint 1: You can use \\ to escape special characters in regex. \u003eHint 2: The provided code already handles making the scheme, path, and anchor optional by using non-capturing groups. The details: scheme : Either http or https, which can be expressed by (?:...). domain : The www may show at the beginning of the domain, which can be expressed by (?:...)? path to the file: /path/to/file.extension, /path, /file.extension. They are all valid anchor : letters, numbers, hyphens, or underscores. python def match_url(text): scheme = r'(?:https|http)://' domain = r'(?:\\w+\\.)?\\w+\\.\\w+' path = r'(?:/\\w+|/(\\w+/)*)(\\w+\\.\\w+)?' anchor = r'#[\\w\\-_]*' return bool(re.match(rf\"^(?:{scheme})?{domain}(?:{path})?(?:{anchor})?$\", text)) ","date":"2022-03-03","objectID":"/en/lab14-cs61a-of-ucb/:8:1","series":null,"tags":["Course","Python"],"title":"Lab14 - CS61A of UCB(2021-Fall)","uri":"/en/lab14-cs61a-of-ucb/#q13-basic-url-validation"},{"categories":["Course"],"content":" BNF ","date":"2022-03-03","objectID":"/en/lab14-cs61a-of-ucb/:9:0","series":null,"tags":["Course","Python"],"title":"Lab14 - CS61A of UCB(2021-Fall)","uri":"/en/lab14-cs61a-of-ucb/#bnf"},{"categories":["Course"],"content":" Q14: Simple CSV CSV, which stands for ‚ÄúComma Separated Values,‚Äù is a file format to store columnar information. We will write a BNF grammar for a small subset of CSV, which we will call SimpleCSV. Create a grammar that reads SimpleCSV, where a file contains rows of words separated by commas. Words are characters [a-zA-Z] (and may be blank!) Spaces are not allowed in the file. Write the BNF of a simple csv file. It is simple because: the value can only be a word, and them should be seperated by , The details: There may be cases of ,,,, so we need to use | in word to count the cases where no characters are placed text lines: line (newline line)* | line newline | line line: word (\",\" word)* word: WORD | newline: \"\\n\" %import common.WORD ","date":"2022-03-03","objectID":"/en/lab14-cs61a-of-ucb/:9:1","series":null,"tags":["Course","Python"],"title":"Lab14 - CS61A of UCB(2021-Fall)","uri":"/en/lab14-cs61a-of-ucb/#q14-simple-csv"},{"categories":["Course"],"content":"The simple solutions of hw10 of CS61A of UCB","date":"2022-03-02","objectID":"/en/hw10-of-cs61a-of-ucb/","series":null,"tags":["Course","BNF","Mysql"],"title":"Hw10 - CS61A of UCB(2021-Fall)","uri":"/en/hw10-of-cs61a-of-ucb/"},{"categories":["Course"],"content":" BNF ","date":"2022-03-02","objectID":"/en/hw10-of-cs61a-of-ucb/:1:0","series":null,"tags":["Course","BNF","Mysql"],"title":"Hw10 - CS61A of UCB(2021-Fall)","uri":"/en/hw10-of-cs61a-of-ucb/#bnf"},{"categories":["Course"],"content":" Q1: Grouping and Pipes In this question, you will add support for grouping and piping. Recall that grouping allows for an entire regular expression to be treated as a single unit, and piping allows for a pattern to match an expression on either side. Combined, these will let us create patterns which match multiple strings! Define the group and pipe expressions in your grammar. A group consists of any regex expression surrounded by parentheses (()). A pipe operator consists of a regex expression, followed by a pipe (|) character, and lastly followed by another regex expression. For example, r\"apples\" would match exactly the phrase ‚Äúapples‚Äù in an input. If we wanted our pattern from before to match ‚Äúoranges‚Äù as well, we could expand our rstring to do so using groupings and pipes: r\"(apples)|(oranges)\". Hint: note that groups and pipes are valid regex expressions on their own! You may need to update a previously defined expression. The description indicates the way to solve this problem. Remember that the group and the pipe are a part of ?regex, so we should add them to ?regex. text ?start: rstring rstring: \"r\\\"\" regex* \"\\\"\" ?regex: character | word | group | pipe group: \"(\" regex* \")\" pipe: regex \"|\" regex character: LETTER | NUMBER word: WORD %ignore /\\s+/ %import common.LETTER %import common.NUMBER %import common.WORD ","date":"2022-03-02","objectID":"/en/hw10-of-cs61a-of-ucb/:1:1","series":null,"tags":["Course","BNF","Mysql"],"title":"Hw10 - CS61A of UCB(2021-Fall)","uri":"/en/hw10-of-cs61a-of-ucb/#q1-grouping-and-pipes"},{"categories":["Course"],"content":" Q2: Classes Now, we will add support for character classes. Recall that character classes allow for the pattern to match any singular character defined within the class. The class itself consists either of individual characters, or ranges of characters. Specifically, we define the following: A range consists of either NUMBERs or LETTERs separated by a hyphen (-). A class expression consists of any number of characters or character ranges surrounded by square brackets ([]). Note that for this question, a range may only consist of either NUMBERs or LETTERs; this means that while [0-9] and [A-Z] are valid ranges, [0-Z] would not be a valid range. In addition, the characters and ranges in a class may appear in any order and any number of times. For example, [ad-fc0-9], [ad-f0-9c], [a0-9d-fc], and [0-9ad-fc] are all valid classes. The details: range : character \"-\" character is wrong ‚ùå. For example, [0-z] is illegal. The class expression contains either range or character, which can be described as (range|character). Then we add * to indicate any number class itself is also a valid regular expression, so it should be placed inside ?regex text ?start: rstring rstring: \"r\\\"\" regex* \"\\\"\" ?regex: character | word | group | pipe | class group: \"(\" regex* \")\" pipe: regex \"|\" regex range: NUMBER \"-\" NUMBER | LETTER \"-\" LETTER class: \"[\" (range|character)* \"]\" character: LETTER | NUMBER word: WORD %ignore /\\s+/ %import common.LETTER %import common.NUMBER %import common.WORD ","date":"2022-03-02","objectID":"/en/hw10-of-cs61a-of-ucb/:1:2","series":null,"tags":["Course","BNF","Mysql"],"title":"Hw10 - CS61A of UCB(2021-Fall)","uri":"/en/hw10-of-cs61a-of-ucb/#q2-classes"},{"categories":["Course"],"content":" Q3: Quantifiers Lastly, we will add support for quantifiers. Recall that quantifiers allow for a pattern to match a specified number of a unit. Specifically, we define the following: A plus_quant expression consists of a group, a character, or a class, followed by a plus symbol (+). A star_quant expression consists of a group, a character, or a class, followed by a star symbol (*). A num_quant expression consists of either a group, a character, or a class, followed by one of the following: a NUMBER enclosed in curly braces ({}); a range of NUMBERs (separated by a comma (,), which may potentially be open on only one side. For example, {2,7}, {2,}, and {,7} are valid numeric quantifiers. {,} is not valid. Hint: these three quantifiers share many similarities. Consider defining additional expressions in this question! We can make a ?tmp: class | group | character to represent the similarities. Also, we can define ?quants: plus_quant | star_quant | num_quant and put it in ?regex. Trick: use (NUMBER (\",\" NUMBER)?) to represent {NUMBER} or {NUMBER,NUMBER} patterns. text rstring: \"r\\\"\" regex* \"\\\"\" ?regex: character | word | group | pipe | class | quants group: \"(\" regex* \")\" pipe: regex \"|\" regex range: NUMBER \"-\" NUMBER | LETTER \"-\" LETTER class: \"[\" range* character* range* character* \"]\" ?tmp: class | group | character plus_quant: tmp \"+\" star_quant: tmp \"*\" num_quant: tmp \"{\" ((NUMBER (\",\" NUMBER)?) | (NUMBER \",\") | (\",\" NUMBER)) \"}\" ?quants: plus_quant | star_quant | num_quant character: LETTER | NUMBER word: WORD %ignore /\\s+/ %import common.LETTER %import common.NUMBER %import common.WORD ","date":"2022-03-02","objectID":"/en/hw10-of-cs61a-of-ucb/:1:3","series":null,"tags":["Course","BNF","Mysql"],"title":"Hw10 - CS61A of UCB(2021-Fall)","uri":"/en/hw10-of-cs61a-of-ucb/#q3-quantifiers"},{"categories":["Course"],"content":" SQL ","date":"2022-03-02","objectID":"/en/hw10-of-cs61a-of-ucb/:2:0","series":null,"tags":["Course","BNF","Mysql"],"title":"Hw10 - CS61A of UCB(2021-Fall)","uri":"/en/hw10-of-cs61a-of-ucb/#sql"},{"categories":["Course"],"content":" Q4: Size of Dogs The F√©d√©ration Cynologique Internationale classifies a standard poodle as over 45 cm and up to 60 cm. The sizes table describes this and other such classifications, where a dog must be over the min and less than or equal to the max in height to qualify as a size. Create a size_of_dogs table with two columns, one for each dog‚Äôs name and another for its size. We need to determine the size of the dogs, which can be described as select ... from ... where. mysql CREATE TABLE size_of_dogs AS SELECT d.name, s.size FROM dogs as d, sizes as s where d.height \u003c= s.max and d.height \u003e s.min; ","date":"2022-03-02","objectID":"/en/hw10-of-cs61a-of-ucb/:2:1","series":null,"tags":["Course","BNF","Mysql"],"title":"Hw10 - CS61A of UCB(2021-Fall)","uri":"/en/hw10-of-cs61a-of-ucb/#q4-size-of-dogs"},{"categories":["Course"],"content":" Q5: By Parent Height Create a table by_parent_height that has a column of the names of all dogs that have a parent, ordered by the height of the parent from tallest parent to shortest parent. Sort results by height descending by using DESC keyword. mysql CREATE TABLE siblings AS SELECT p1.child AS dogone, p2.child AS dogtwo, s1.size AS dogonesize, s2.size AS dogtwosize FROM parents AS p1, parents AS p2, size_of_dogs AS s1, size_of_dogs AS s2 WHERE p1.parent = p2.parent AND p1.child \u003c p2.child AND p1.child = s1.name AND p2.child = s2.name; -- Use `\u003c` to filter the result -- `!=` is not enough, you will get `barack clinton` and `clinton barack` in the same time ","date":"2022-03-02","objectID":"/en/hw10-of-cs61a-of-ucb/:2:2","series":null,"tags":["Course","BNF","Mysql"],"title":"Hw10 - CS61A of UCB(2021-Fall)","uri":"/en/hw10-of-cs61a-of-ucb/#q5-by-parent-height"},{"categories":["Course"],"content":" Q6: Sentences There are two pairs of siblings that have the same size. Create a table that contains a row with a string for each of these pairs. Each string should be a sentence describing the siblings by their size. Each sibling pair should appear only once in the output, and siblings should be listed in alphabetical order (e.g. \"barack plus clinton...\" instead of \"clinton plus barack...\"), as follows: Hint: First, create a helper table containing each pair of siblings. This will make comparing the sizes of siblings when constructing the main table easier. Hint: If you join a table with itself, use AS within the FROM clause to give each table an alias. Hint: In order to concatenate two strings into one, use the || operator. After finishing Q5, this one should be much easier. mysql CREATE TABLE sentences AS SELECT \"The two siblings, \" || dogone || \" plus \" || dogtwo || \" have the same size: \" || dogonesize FROM siblings WHERE dogonesize = dogtwosize AND dogone \u003c dogtwo; ","date":"2022-03-02","objectID":"/en/hw10-of-cs61a-of-ucb/:2:3","series":null,"tags":["Course","BNF","Mysql"],"title":"Hw10 - CS61A of UCB(2021-Fall)","uri":"/en/hw10-of-cs61a-of-ucb/#q6-sentences"},{"categories":["Course"],"content":"the simple solutions for lab12 of CS61A of UCB","date":"2022-03-02","objectID":"/en/lab12-ca61a-of-ucb/","series":null,"tags":["Course","Python"],"title":"Lab12 - CS61A of UCB(2021-Fall)","uri":"/en/lab12-ca61a-of-ucb/"},{"categories":["Course"],"content":" Regular Expressions ","date":"2022-03-02","objectID":"/en/lab12-ca61a-of-ucb/:1:0","series":null,"tags":["Course","Python"],"title":"Lab12 - CS61A of UCB(2021-Fall)","uri":"/en/lab12-ca61a-of-ucb/#regular-expressions"},{"categories":["Course"],"content":" Q1: Calculator Ops Write a regular expression that parses strings written in the 61A Calculator language and returns any expressions which have two numeric operands, leaving out the parentheses around them. We need to write a regular expression to match a pattern - (operand operator1 operator2). The operands consist of +, -, *, /. We can use [] here. Don‚Äôt forget to put a \\ in front of - to escape it. python def calculator_ops(calc_str): \"\"\" Finds expressions from the Calculator language that have two numeric operands and returns the expression without the parentheses. \"\"\" return re.findall(r'[+\\-*/] \\d+ \\d+', calc_str) ","date":"2022-03-02","objectID":"/en/lab12-ca61a-of-ucb/:1:1","series":null,"tags":["Course","Python"],"title":"Lab12 - CS61A of UCB(2021-Fall)","uri":"/en/lab12-ca61a-of-ucb/#q1-calculator-ops"},{"categories":["Course"],"content":" BNF ","date":"2022-03-02","objectID":"/en/lab12-ca61a-of-ucb/:2:0","series":null,"tags":["Course","Python"],"title":"Lab12 - CS61A of UCB(2021-Fall)","uri":"/en/lab12-ca61a-of-ucb/#bnf"},{"categories":["Course"],"content":" Q3: Linked List BNF In this problem, we‚Äôre going to define a BNF that parses integer Linked Lists created in Python. We won‚Äôt be handling Link.empty. For reference, here are some examples of Linked Lists: Your implementation should be able to handle nested Linked Lists, such as the third example below. Link(2) Link(12, Link(2)) Link(5, Link(7, Link(Link(8, Link(9))))) The idea: The beginning of the linked list must be Link(, and then we can divide the linked list into link_first and link_rest parts, which are either numbers or another linked list(nested). The link_rest can be empty ! text link: \"Link(\" link_first \")\" | \"Link(\" link_first \",\" link_rest \")\" ?link_first: NUMBER | link ?link_rest: NUMBER | link %ignore /\\s+/ %import common.NUMBER ","date":"2022-03-02","objectID":"/en/lab12-ca61a-of-ucb/:2:1","series":null,"tags":["Course","Python"],"title":"Lab12 - CS61A of UCB(2021-Fall)","uri":"/en/lab12-ca61a-of-ucb/#q3-linked-list-bnf"},{"categories":["Course"],"content":" Q4: Tree BNF Now, we will define a BNF to parse Trees with integer leaves created in Python. Here are some examples of Trees: Your implementation should be able to handle Trees with no branches and one or more branches. Tree(2) Tree(6, [Tree(1), Tree(3, [Tree(1), Tree(2)])]) The BNF of a tree: tree_node: It can a tree with only one node, or a tree with nodes and branches. The number of the branches can by [0, ‚àû), so we can use the * in the regular expression. ?label: NUMBER branches: It can be only one node, or there are multiple nodes (in this case, we need to match the , signs) text tree_node: \"Tree(\" label \")\" | \"Tree(\" label \",\" branches* \")\" ?label: NUMBER branches: \"[\" tree_node \"]\" | \"[\" tree_node \",\" tree_node+ \"]\" %ignore /\\s+/ %import common.NUMBER ","date":"2022-03-02","objectID":"/en/lab12-ca61a-of-ucb/:2:2","series":null,"tags":["Course","Python"],"title":"Lab12 - CS61A of UCB(2021-Fall)","uri":"/en/lab12-ca61a-of-ucb/#q4-tree-bnf"},{"categories":["Course"],"content":"The simple solutions of hw09 of CS61A of UCB","date":"2022-03-01","objectID":"/en/hw09-of-cs61a-of-ucb/","series":null,"tags":["Course","Python"],"title":"Hw09 - CS61A of UCB(2021-Fall)","uri":"/en/hw09-of-cs61a-of-ucb/"},{"categories":["Course"],"content":" Q2: Roman Numerals Write a regular expression that finds any string of letters that resemble a Roman numeral and aren‚Äôt part of another word. A Roman numeral is made up of the letters I, V, X, L, C, D, M and is at least one letter long. For the purposes of this problem, don‚Äôt worry about whether or not a Roman numeral is valid. For example, ‚ÄúVIIIII‚Äù is not a Roman numeral, but it is fine if your regex matches it. The details: The letters contain I, V, X, L, C, D, M. We can use [] to represent the logical OR The roman NUmerals is at least one letter long. We can use + to match 1 or more repetitions. The roman NUmerals can not be a part of another word. After checking the documentation, I found \\b is quite useful, which means matching the empty string, but only at the beginning or end of a word. That‚Äôs exactly what we want. python def roman_numerals(text): \"\"\" Finds any string of letters that could be a Roman numeral (made up of the letters I, V, X, L, C, D, M). \"\"\" return re.findall(r'\\b[IVXLCDM]+\\b', text) ","date":"2022-03-01","objectID":"/en/hw09-of-cs61a-of-ucb/:0:1","series":null,"tags":["Course","Python"],"title":"Hw09 - CS61A of UCB(2021-Fall)","uri":"/en/hw09-of-cs61a-of-ucb/#q2-roman-numerals"},{"categories":["Course"],"content":" Q3: CS Classes On reddit.com, there is an /r/berkeley subreddit for discussions about everything UC Berkeley. However, there is such a large amount of CS-related posts that those posts are auto-tagged so that readers can choose to ignore them or read only them. Write a regular expression that finds strings that resemble a CS class- starting with ‚ÄúCS‚Äù, followed by a number, and then optionally followed by ‚ÄúA‚Äù, ‚ÄúB‚Äù, or ‚ÄúC‚Äù. Your search should be case insensitive, so both ‚ÄúCS61A‚Äù and ‚Äúcs61a‚Äù would match. The details: Either the CS or the ABC is case insensitive. We can enumerate all possible cases using []. A whitespace may exist between CS and the digits, which can be solved by ? python def cs_classes(post): \"\"\" Returns strings that look like a Berkeley CS class, starting with \"CS\", followed by a number, optionally ending with A, B, or C and potentially with a space between \"CS\" and the number. Case insensitive. \"\"\" return bool(re.search(r'[Cc][Ss] ?\\d+[ABCabc]?', post)) ","date":"2022-03-01","objectID":"/en/hw09-of-cs61a-of-ucb/:0:2","series":null,"tags":["Course","Python"],"title":"Hw09 - CS61A of UCB(2021-Fall)","uri":"/en/hw09-of-cs61a-of-ucb/#q3-cs-classes"},{"categories":["Course"],"content":" Q4: Time for Times You‚Äôre given a body of text and told that within it are some times. Write a regular expression which, for a few examples, would match the following: text ['05:24', '7:23', '23:59', '12:22', '00:00'] but would not match these invalid ‚Äútimes‚Äù text ['05:64', '70:23'] You may find non-capturing groups helpful to use for this question. The legal range of the time: 00:00 ~ 23:59 The details: The first digit and the second digit: The leading 0 may exist. When the first digit is 2, the second digit should be in the range of 0 ~ 3. (2?:?? ~ 23:59) The third digit and the 4th digit: 00 ~ 59. [0-5][0-9] It is a little complicated for a new beginner like me :( The hint shows the (?:) may be helpful, so I have a look at this and suddenly know how to make the regex work üëç. It means matching but not capturing. python def match_time(text): return re.findall(r'(?:[01]?\\d|2[0-3]):[0-5][0-9](?:AM)?', text) ","date":"2022-03-01","objectID":"/en/hw09-of-cs61a-of-ucb/:0:3","series":null,"tags":["Course","Python"],"title":"Hw09 - CS61A of UCB(2021-Fall)","uri":"/en/hw09-of-cs61a-of-ucb/#q4-time-for-times"},{"categories":["Course"],"content":" Q5: Most Common Area Code Write a function which takes in a body of text and finds the most common area code. Area codes must be part of a valid phone number. To solve this problem, we will first write a regular expression which finds valid phone numbers and captures the area code. See the docstring of area_codes for specifics on what qualifies as a valid phone number. We know the area code may appear in the front of a phone number. The task is to find the most common area code. First, we need to implement a function called area_codes to parse a string to get all potential area codes and return. After that, we use list.count to find the most common one. The details. A valid phone number should be 10-digit. The length of the area code is 3. Sometimes, it may have parentheses around. The hyphens and spaces may appear after the third and sixth digits How to match a potential () ? By (?:)? ü§ó python def area_codes(text): \"\"\" Finds all phone numbers in text and captures the area code. Phone numbers have 10 digits total and may have parentheses around the area code, and hyphens or spaces after the third and sixth digits. \"\"\" return re.findall(r'(?:\\()?(\\d{3})(?:\\)?)(?: |-)?\\d{3}(?: |-)?\\d{4}\\b', text) def most_common_code(text): \"\"\" Takes in an input string which contains at least one phone number (and may contain more) and returns the most common area code among all phone numbers in the input. If there are multiple area codes with the same frequency, return the first one that appears in the input text. \"\"\" area_codes_list = area_codes(text) # count every area_code cnts = [area_codes_list.count(e) for e in area_codes_list] # get the index of the max value max_cnt_idx = cnts.index(max(cnts)) return area_codes_list[max_cnt_idx] ","date":"2022-03-01","objectID":"/en/hw09-of-cs61a-of-ucb/:0:4","series":null,"tags":["Course","Python"],"title":"Hw09 - CS61A of UCB(2021-Fall)","uri":"/en/hw09-of-cs61a-of-ucb/#q5-most-common-area-code"},{"categories":["Course"],"content":"the simple solutions for lab11 of CS61A of UCB","date":"2022-03-01","objectID":"/en/lab11-cs61a-of-ucb/","series":null,"tags":["Course","Python"],"title":"Lab11 - CS61A of UCB(2021-Fall)","uri":"/en/lab11-cs61a-of-ucb/"},{"categories":["Course"],"content":" Context ","date":"2022-03-01","objectID":"/en/lab11-cs61a-of-ucb/:1:0","series":null,"tags":["Course","Python"],"title":"Lab11 - CS61A of UCB(2021-Fall)","uri":"/en/lab11-cs61a-of-ucb/#context"},{"categories":["Course"],"content":" Problem 1 Important: Your code for this part should go in buffer.py. Your job in this part is to implement the current and pop_first methods of the Buffer class. current should return the current token of the current line we‚Äôre on in the Buffer instance without removing it. If there are no more tokens in the current line, then current should move onto the next valid line, and return the first token of this line. If there are no more tokens left to return from the entire source (we‚Äôve reached the end of all input lines), then current should return None (this logic is already provided for you in the except StopIteration block). If we call current multiple times in a row, we should get the same result since calls to current won‚Äôt change what token we‚Äôre returning. You may find self.index helpful while implementing these functions, but you are not required to reference it in your solution. Hint: What instance attribute can we use to keep track of where we are in the current line? Hint: If we‚Äôve reached the end of the current line, then self.more_on_line() will return False. In that case, how do we ‚Äúreset‚Äù our position to the beginning of the next line? pop_first should return the current token of the Buffer instance, and move onto the next potential token (to be returned on the next call to pop_first). If there are no more tokens left to return from the entire source (we‚Äôve reached the end of all input lines), then pop_first should return None. Hint: Do we need to update anything to move onto the next potential token? We need to implement two functions in this problem: current and pop_first The requirements are listed in the description python class Buffer: \"\"\"A Buffer provides a way of accessing a sequence of tokens across lines. Its constructor takes an iterator, called \"the source\", that returns the next line of tokens as a list each time it is queried, or None to indicate the end of data. The Buffer in effect concatenates the sequences returned from its source and then supplies the items from them one at a time through its pop_first() method, calling the source for more sequences of items only when needed. In addition, Buffer provides a current method to look at the next item to be supplied, without sequencing past it. The __str__ method prints all tokens read so far, up to the end of the current line, and marks the current token with \u003e\u003e. \"\"\" def __init__(self, source): self.index = 0 self.source = source self.current_line = () self.current() def pop_first(self): \"\"\"Remove the next item from self and return it. If self has exhausted its source, returns None.\"\"\" current = self.current() self.index += 1 return current def current(self): \"\"\"Return the current element, or None if none exists.\"\"\" # if there are any token in current line we don't return while not self.more_on_line(): self.index = 0 try: self.current_line = next(self.source) except StopIteration: self.current_line = () return None return self.current_line[self.index] def more_on_line(self): return self.index \u003c len(self.current_line) ","date":"2022-03-01","objectID":"/en/lab11-cs61a-of-ucb/:1:1","series":null,"tags":["Course","Python"],"title":"Lab11 - CS61A of UCB(2021-Fall)","uri":"/en/lab11-cs61a-of-ucb/#problem-1"},{"categories":["Course"],"content":" Internal Representations ","date":"2022-03-01","objectID":"/en/lab11-cs61a-of-ucb/:2:0","series":null,"tags":["Course","Python"],"title":"Lab11 - CS61A of UCB(2021-Fall)","uri":"/en/lab11-cs61a-of-ucb/#internal-representations"},{"categories":["Course"],"content":" Problem 2 Important: Your code for this part should go in scheme_reader.py. Your job in this part is to write the parsing functionality, which consists of two mutually recursive functions:scheme_read and read_tail. Each function takes in a single src parameter, which is a Buffer instance. scheme_read removes enough tokens from src to form a single expression and returns that expression in the correct internal representation. read_tail expects to read the rest of a list or Pair, assuming the open parenthesis of that list or Pair has already been removed by scheme_read. It will read expressions (and thus remove tokens) until the matching closing parenthesis ) is seen. This list of expressions is returned as a linked list of Pair instances. In short, scheme_read returns the next single complete expression in the buffer and read_tail returns the rest of a list or Pair in the buffer. Both functions mutate the buffer, removing the tokens that have already been processed. The behavior of both functions depends on the first token currently in src. They should be implemented as follows: scheme_read: If the current token is the string \"nil\", return the nil object. If the current token is (, the expression is a pair or list. Call read_tail on the rest of src and return its result. If the current token is ', the rest of the buffer should be processed as a quote expression. You will implement this portion in the next problem. If the next token is not a delimiter, then it must be a primitive expression (i.e. a number, boolean). Return it. Provided If none of the above cases apply, raise an error. Provided read_tail: If there are no more tokens, then the list is missing a close parenthesis and we should raise an error. Provided If the token is ), then we‚Äôve reached the end of the list or pair. Remove this token from the buffer and return the nil object. If none of the above cases apply, the next token is the operator in a combination. For example, src could contain + 2 3). To parse this: scheme_read the next complete expression in the buffer. Call read_tail to read the rest of the combination until the matching closing parenthesis. Return the results as a Pair instance, where the first element is the next complete expression from (1) and the second element is the rest of the combination from (2). The code for this question is put together with the next question :) ","date":"2022-03-01","objectID":"/en/lab11-cs61a-of-ucb/:2:1","series":null,"tags":["Course","Python"],"title":"Lab11 - CS61A of UCB(2021-Fall)","uri":"/en/lab11-cs61a-of-ucb/#problem-2"},{"categories":["Course"],"content":" Problem 3 Important: Your code for this part should go in scheme_reader.py. Your task in this problem is to complete the implementation of scheme_read by allowing the function to now be able to handle quoted expressions. In Scheme, quoted expressions such as '\u003cexpr\u003e are equivalent to (quote \u003cexpr\u003e). That means that we need to wrap the expression following ' (which you can get by recursively calling scheme_read) into the quote special form, which is a Scheme list (as with all special forms). In our representation, a Pair represents a Scheme list. You should therefore wrap the expression following ' in a Pair. For example, 'bagel, or [\"'\", \"bagel\"] after being tokenized, should be represented as Pair('quote', Pair('bagel', nil)). '(1 2) (or [\"'\", \"(\", 1, 2, \")\"]) should be represented as Pair('quote', Pair(Pair(1, Pair(2, nil)), nil)). We need to implement the ' in the scheme language. Actually, the description indicates the way to solve this problem: which you can get by recursively calling scheme_read. We need to make a new Pair, whose first element is quote, and recursively call scheme_reader to handle the expression. python def scheme_read(src): \"\"\"Read the next expression from SRC, a Buffer of tokens. \"\"\" if src.current() is None: raise EOFError val = src.pop_first() # Get and remove the first token if val == 'nil': return nil elif val == '(': return read_tail(src) elif val == \"'\": return Pair('quote', Pair(scheme_read(src), nil)) elif val not in DELIMITERS: return val else: raise SyntaxError('unexpected token: {0}'.format(val)) def read_tail(src): \"\"\"Return the remainder of a list in SRC, starting before an element or ). \"\"\" try: if src.current() is None: raise SyntaxError('unexpected end of file') elif src.current() == ')': src.pop_first() return nil else: return Pair(scheme_read(src), read_tail(src)) except EOFError: raise SyntaxError('unexpected end of file') ","date":"2022-03-01","objectID":"/en/lab11-cs61a-of-ucb/:2:2","series":null,"tags":["Course","Python"],"title":"Lab11 - CS61A of UCB(2021-Fall)","uri":"/en/lab11-cs61a-of-ucb/#problem-3"},{"categories":["Course"],"content":"The simple solutions of hw08 of CS61A of UCB","date":"2022-02-28","objectID":"/en/hw08-of-cs61a-of-ucb/","series":null,"tags":["Course","Scheme"],"title":"Hw08 - CS61A of UCB(2021-Fall)","uri":"/en/hw08-of-cs61a-of-ucb/"},{"categories":["Course"],"content":" Q1: My Filter Write a procedure my-filter, which takes a predicate func and a list lst, and returns a new list containing only elements of the list that satisfy the predicate. The output should contain the elements in the same order that they appeared in the original list. Note: Make sure that you are not just calling the built-in filter function in Scheme - we are asking you to re-implement this! We need to implement a function that contains elements which are qualified (func e) = #t in the list. The base case: an empty list. Otherwise, we check if (car lst) can be kept. scheme (define (my-filter func lst) (cond ((null? lst) '()) ((func (car lst)) (cons (car lst) (my-filter func (cdr lst)))) (else (my-filter func (cdr lst)))) ) ","date":"2022-02-28","objectID":"/en/hw08-of-cs61a-of-ucb/:0:1","series":null,"tags":["Course","Scheme"],"title":"Hw08 - CS61A of UCB(2021-Fall)","uri":"/en/hw08-of-cs61a-of-ucb/#q1-my-filter"},{"categories":["Course"],"content":" Q2: Interleave Implement the function interleave, which takes a two lists s1 and s2 as arguments. interleave should return a new list that interleaves the elements of the two lists. (In other words, the resulting list should contain elements alternating between s1 and s2.) If one of the input lists to interleave is shorter than the other, then interleave should alternate elements from both lists until one list has no more elements, and then the remaining elements from the longer list should be added to the end of the new list. It can be solved recursively. The base case: both lists are empty. We need to return nil Notion: the first parameter of interleave - first_param, the second parameter of interleave - second_param We always add (car fist_param) to our result. And then we will recursively call (interleave second_param (cdr first_param)). Apparently, we will add the first element of second_param to our result. Repeat this procedure we will get the correct answer. What if the first list is empty? We call (interleave second_param first_param) instead ü§ó scheme (define (interleave s1 s2) (cond ((and (null? s1) (null? s2)) nil) ; base case: return nil if both are empty ((null? s1) (interleave s2 s1)) ; change the positions of s1 and s2 (else (cons (car s1) (interleave s2 (cdr s1))))) ; we always insert (car s1) to the result :) ) ","date":"2022-02-28","objectID":"/en/hw08-of-cs61a-of-ucb/:0:2","series":null,"tags":["Course","Scheme"],"title":"Hw08 - CS61A of UCB(2021-Fall)","uri":"/en/hw08-of-cs61a-of-ucb/#q2-interleave"},{"categories":["Course"],"content":" Q3: Accumulate Fill in the definition for the procedure accumulate, which merges the first n natural numbers (ie. 1 to n, inclusive) according to the following parameters: merger: a function of two arguments start: a number with which we start merging with n: the number of natural numbers to merge term: a function of one argument that computes the nth term of a sequence For example, we can find the product of all the numbers from 1 to 5 by using the multiplication operator as the merger, and starting our product at 1: We need to calculate the ‚Äúsum‚Äù of the first n natural numbers([1, n]). The definitin of ‚Äúsum‚Äù is defined by merger. We also have term to compute the ith term of a sequence. We can‚Äôt use while loop in scheme(If you don‚Äôt have implement this by yourself). So we need a recursive solution. The base case: n = 1, we merge 1 and start. Otherwise, we will call (accumulate merger start (- n 1) term) :) scheme (define (accumulate merger start n term) (cond ((= n 1) (merger (term n) start)) ; base case: n = 1 (else (merger (term n) (accumulate merger start (- n 1) term)))) ) ","date":"2022-02-28","objectID":"/en/hw08-of-cs61a-of-ucb/:0:3","series":null,"tags":["Course","Scheme"],"title":"Hw08 - CS61A of UCB(2021-Fall)","uri":"/en/hw08-of-cs61a-of-ucb/#q3-accumulate"},{"categories":["Course"],"content":" Q4: No Repeats Implement no-repeats, which takes a list of numbers lst as input and returns a list that has all of the unique elements of lst in the order that they first appear, but no repeats. For example, (no-repeats (list 5 4 5 4 2 2))evaluates to (5 4 2). Hint: How can you make the first time you see an element in the input list be the first and only time you see the element in the resulting list you return? Hint: You may find it helpful to use the my-filter procedure with a helper lambda function to use as a filter. To test if two numbers are equal, use the = procedure. To test if two numbers are not equal, use the notprocedure in combination with =. The base case: an empty list. We will return nil. Otherwise, we need to delete all elements that are equal to (car lst) in (cdr lst), which can implemented by the my-filter procedure in Q1. (ps. I have been looking for bugs for a long time because of an extra set of parentheses. üò¢) scheme (define (no-repeats lst) (cond ((null? lst) nil) (else (cons (car lst) (no-repeats ; choose the elements that are not equal to `car lst` (my-filter (lambda (x) (not (= x (car lst)))) (cdr lst)))))) ) ","date":"2022-02-28","objectID":"/en/hw08-of-cs61a-of-ucb/:0:4","series":null,"tags":["Course","Scheme"],"title":"Hw08 - CS61A of UCB(2021-Fall)","uri":"/en/hw08-of-cs61a-of-ucb/#q4-no-repeats"},{"categories":["Course"],"content":"The simple solutions of hw07 of CS61A of UCB","date":"2022-02-27","objectID":"/en/hw07-of-cs61a-of-ucb/","series":null,"tags":["Course","Scheme"],"title":"Hw07 of CS61A of UCB(2021-Fall)","uri":"/en/hw07-of-cs61a-of-ucb/"},{"categories":["Course"],"content":" Q1: Thane of Cadr Define the procedures cadr and caddr, which return the second and third elements of a list, respectively. If you would like a quick refresher on scheme syntax consider looking at Lab 10 Scheme Refresher. We need to implement the function c???r. To have a better understanding of this notation, you should look from back to the front in ???. For example, the cadr function will call cdr then call car on the input. scheme (define (cadr s) (car (cdr s)) ) (define (caddr s) (car (cdr (cdr s))) ) ","date":"2022-02-27","objectID":"/en/hw07-of-cs61a-of-ucb/:0:1","series":null,"tags":["Course","Scheme"],"title":"Hw07 of CS61A of UCB(2021-Fall)","uri":"/en/hw07-of-cs61a-of-ucb/#q1-thane-of-cadr"},{"categories":["Course"],"content":" Q2: Ordered Implement a procedure called ordered?, which takes a list of numbers and returns True if the numbers are in nondescending order, and False otherwise. Numbers are considered nondescending if each subsequent number is either larger or equal to the previous, that is: text 1 2 3 3 4 Is nondescending, but: text 1 2 3 3 2 Is not. Hint: The built-in null? function returns whether its argument is nil. We need to solve this problem recursively: base case: an empty list or a list with a size 1 Recursive decomposition: the current node is less than or equal to the first node of the sub-linked list, and the sub-linked list must also be in non-descending order scheme (define (ordered? s) (cond ( (null? s) #t) ( (null? (cdr s)) #t) ( else (and (\u003c= (car s) (cadr s)) (ordered? (cdr s))))) ) ","date":"2022-02-27","objectID":"/en/hw07-of-cs61a-of-ucb/:0:2","series":null,"tags":["Course","Scheme"],"title":"Hw07 of CS61A of UCB(2021-Fall)","uri":"/en/hw07-of-cs61a-of-ucb/#q2-ordered"},{"categories":["Course"],"content":" Q3: Pow Implement a procedure pow for raising the number base to the power of a nonnegative integer exp for which the number of operations grows logarithmically, rather than linearly (the number of recursive calls should be much smaller than the input exp). For example, for (pow 2 32) should take 5 recursive calls rather than 32 recursive calls. Similarly, (pow 2 64) should take 6 recursive calls. Hint: Consider the following observations: $x^{2y} = (x^y)2$ $x^{2y+1} = x(x^y)2$ For example we see that 232 is (216)2, 216 is (28)2, etc. You may use the built-in predicates even? and odd?. Scheme doesn‚Äôt support iteration in the same manner as Python, so consider another way to solve this problem. The procedure of calculating this (pow base exp) has been provided in the description. scheme (define (pow base exp) (cond ( (= exp 1) base ) ; base^1 = base ( (= exp 0) 1) ; base^0 = 1 ( (= 0 (modulo exp 2)) (begin (define tmp (pow base (quotient exp 2))) ; store the value temporarily (* tmp tmp) ) ) ( (= 1 (modulo exp 2)) (begin (define tmp (pow base (quotient exp 2))) ; store the value temporarily (* tmp tmp base) ) ) ) ) ","date":"2022-02-27","objectID":"/en/hw07-of-cs61a-of-ucb/:0:3","series":null,"tags":["Course","Scheme"],"title":"Hw07 of CS61A of UCB(2021-Fall)","uri":"/en/hw07-of-cs61a-of-ucb/#q3-pow"},{"categories":["Course"],"content":"The simple solutions of hw06 of CS61A of UCB","date":"2022-02-27","objectID":"/en/hw06-of-cs61a-of-ucb/","series":null,"tags":["Course","Python"],"title":"Hw06 - CS61A of UCB(2021-Fall)","uri":"/en/hw06-of-cs61a-of-ucb/"},{"categories":["Course"],"content":" OOP ","date":"2022-02-27","objectID":"/en/hw06-of-cs61a-of-ucb/:1:0","series":null,"tags":["Course","Python"],"title":"Hw06 - CS61A of UCB(2021-Fall)","uri":"/en/hw06-of-cs61a-of-ucb/#oop"},{"categories":["Course"],"content":" Q1: Vending Machine In this question you‚Äôll create a vending machine that only outputs a single product and provides change when needed. Create a class called VendingMachine that represents a vending machine for some product. A Vending Machineobject returns strings describing its interactions. Remember to match exactly the strings in the doctests ‚Äì including punctuation and spacing! Fill in the VendingMachine class, adding attributes and methods as appropriate, such that its behavior matches the following doctests: According to the wiki, a vending machine is an automated machine that provides items to consumers after cash, or other forms of payment are inserted into the machine or otherwise made. To make this problem easier, the description indicates that the vending machine only has one product. Take care of the details: restock. The simplest function in Q1. add_funds Memorize the fund you add if it has stocks. Refund if there are no stocks at all vend Stocks available You can buy it if you have enough üí∞ It asks you to add more funds if your funds is not enough Don‚Äôt forget to decrease the stocks after you get the product. No stocks Restocks! python class VendingMachine: \"\"\"A vending machine that vends some product for some price. \"\"\" def __init__(self, product, price): self.product = product self.price = price self.balance = 0 self.stocks = 0 def restock(self, num): \"\"\"Restock num items to our vending machine\"\"\" self.stocks += num return f\"Current {self.product} stock: {self.stocks}\" def add_funds(self, fund): \"\"\"Add funds to balance, return funds if no stocks\"\"\" if self.stocks != 0: self.balance += fund return f\"Current balance: ${self.balance}\" else: return f\"Nothing left to vend. Please restock. Here is your ${fund}.\" def vend(self): \"\"\"Vend a product\"\"\" if self.stocks == 0: return 'Nothing left to vend. Please restock.' else: if self.balance \u003c self.price: return f\"You must add ${self.price - self.balance} more funds.\" else: change = self.balance - self.price self.balance = 0 self.stocks -= 1 if change == 0: return f\"Here is your {self.product}.\" else: return f\"Here is your {self.product} and ${change} change.\" ","date":"2022-02-27","objectID":"/en/hw06-of-cs61a-of-ucb/:1:1","series":null,"tags":["Course","Python"],"title":"Hw06 - CS61A of UCB(2021-Fall)","uri":"/en/hw06-of-cs61a-of-ucb/#q1-vending-machine"},{"categories":["Course"],"content":" Q2: Mint A mint is a place where coins are made. In this question, you‚Äôll implement a Mint class that can output a Coin with the correct year and worth. Each Mint instance has a year stamp. The update method sets the year stamp to the present_year class attribute of the Mint class. The create method takes a subclass of Coin and returns an instance of that class stamped with the mint‚Äôs year (which may be different from Mint.present_year if it has not been updated.) A Coin‚Äôs worth method returns the cents value of the coin plus one extra cent for each year of age beyond 50. A coin‚Äôs age can be determined by subtracting the coin‚Äôs year from the present_year class attribute of the Mint class. :) python class Mint: \"\"\"A mint creates coins by stamping on years. \"\"\" present_year = 2021 def __init__(self): self.update() def create(self, kind): return kind(self.year) def update(self): self.year = Mint.present_year class Coin: def __init__(self, year): self.year = year def worth(self): age = Mint.present_year - self.year if age \u003e 50: return self.cents + (age - 50) else: return self.cents ","date":"2022-02-27","objectID":"/en/hw06-of-cs61a-of-ucb/:1:2","series":null,"tags":["Course","Python"],"title":"Hw06 - CS61A of UCB(2021-Fall)","uri":"/en/hw06-of-cs61a-of-ucb/#q2-mint"},{"categories":["Course"],"content":" Linked Lists ","date":"2022-02-27","objectID":"/en/hw06-of-cs61a-of-ucb/:2:0","series":null,"tags":["Course","Python"],"title":"Hw06 - CS61A of UCB(2021-Fall)","uri":"/en/hw06-of-cs61a-of-ucb/#linked-lists"},{"categories":["Course"],"content":" Q3: Store Digits Write a function store_digits that takes in an integer n and returns a linked list where each element of the list is a digit of n. Important: Do not use any string manipulation functions like str and reversed We can solve this problem iteratively. By calculating n % 10, we can get the last digit of the number, then we make a new node and insert it to the front of the linked list. python def store_digits(n): \"\"\"Stores the digits of a positive number n in a linked list. \"\"\" sentinel = Link(0) while n \u003e 0: all_but_last, last = n // 10, n % 10 # every time we insert node in the front of the linklist new_node = Link(n % 10, sentinel.rest) sentinel.rest = new_node n = all_but_last return sentinel.rest ","date":"2022-02-27","objectID":"/en/hw06-of-cs61a-of-ucb/:2:1","series":null,"tags":["Course","Python"],"title":"Hw06 - CS61A of UCB(2021-Fall)","uri":"/en/hw06-of-cs61a-of-ucb/#q3-store-digits"},{"categories":["Course"],"content":" Q4: Mutable Mapping Implement deep_map_mut(fn, link), which applies a function fn onto all elements in the given linked list link. If an element is itself a linked list, apply fn to each of its elements, and so on. Your implementation should mutate the original linked list. Do not create any new linked lists. Hint: The built-in isinstance function may be useful. text \u003e\u003e\u003e s = Link(1, Link(2, Link(3, Link(4)))) \u003e\u003e\u003e isinstance(s, Link) True \u003e\u003e\u003e isinstance(s, int) False It is a recursive problem that needs to be solved recursively ü§ó. Check the comments below. python def deep_map_mut(fn, link): \"\"\"Mutates a deep link by replacing each item found with the result of calling fn on the item. Does NOT create new Links (so no use of Link's constructor) \"\"\" # base case 1. do thing if it is empty if link is Link.empty: return # base case 2. if it is an integer if isinstance(link, int): link = fn(link) if isinstance(link.first, int): link.first = fn(link.first) else: deep_map_mut(fn, link.first) deep_map_mut(fn, link.rest) ","date":"2022-02-27","objectID":"/en/hw06-of-cs61a-of-ucb/:2:2","series":null,"tags":["Course","Python"],"title":"Hw06 - CS61A of UCB(2021-Fall)","uri":"/en/hw06-of-cs61a-of-ucb/#q4-mutable-mapping"},{"categories":["Course"],"content":" Q5: Two List Implement a function two_list that takes in two lists and returns a linked list. The first list contains the values that we want to put in the linked list, and the second list contains the number of each corresponding value. Assume both lists are the same size and have a length of 1 or greater. Assume all elements in the second list are greater than 0. Unlike the previous problem(Q3), we insert the new node after the last node of the linked list. python def two_list(vals, amounts): \"\"\" Returns a linked list according to the two lists that were passed in. Assume vals and amounts are the same size. Elements in vals represent the value, and the corresponding element in amounts represents the number of this value desired in the final linked list. Assume all elements in amounts are greater than 0. Assume both lists have at least one element. \"\"\" idx = 0 sentinel = Link(0) pos = sentinel while idx \u003c len(vals): val, amount = vals[idx], amounts[idx] for _ in range(amount): new_node = Link(val) pos.rest = new_node pos = pos.rest idx += 1 return sentinel.rest ","date":"2022-02-27","objectID":"/en/hw06-of-cs61a-of-ucb/:2:3","series":null,"tags":["Course","Python"],"title":"Hw06 - CS61A of UCB(2021-Fall)","uri":"/en/hw06-of-cs61a-of-ucb/#q5-two-list"},{"categories":["Course"],"content":" Extra Questions ","date":"2022-02-27","objectID":"/en/hw06-of-cs61a-of-ucb/:3:0","series":null,"tags":["Course","Python"],"title":"Hw06 - CS61A of UCB(2021-Fall)","uri":"/en/hw06-of-cs61a-of-ucb/#extra-questions"},{"categories":["Course"],"content":" Q6: Next Virahanka Fibonacci Object Implement the next method of the VirFib class. For this class, the value attribute is a Fibonacci number. The next method returns a VirFib instance whose value is the next Fibonacci number. The next method should take only constant time. Note that in the doctests, nothing is being printed out. Rather, each call to .next() returns a VirFib instance. The way each VirFib instance is displayed is determined by the return value of its __repr__ method. Hint: Keep track of the previous number by setting a new instance attribute inside next. You can create new instance attributes for objects at any point, even outside the __init__ method. :) python class VirFib(): \"\"\"A Virahanka Fibonacci number. \"\"\" def __init__(self, value=0): self.value = value self.prev = 1 def next(self): new_value = self.value + self.prev next_fin = VirFib(new_value) next_fin.prev = self.value return next_fin def __repr__(self): return \"VirFib object, value \" + str(self.value) ","date":"2022-02-27","objectID":"/en/hw06-of-cs61a-of-ucb/:3:1","series":null,"tags":["Course","Python"],"title":"Hw06 - CS61A of UCB(2021-Fall)","uri":"/en/hw06-of-cs61a-of-ucb/#q6-next-virahanka-fibonacci-object"},{"categories":["Course"],"content":" Q7: Is BST Write a function is_bst, which takes a Tree t and returns True if, and only if, t is a valid binary search tree, which means that: Each node has at most two children (a leaf is automatically a valid binary search tree) The children are valid binary search trees For every node, the entries in that node‚Äôs left child are less than or equal to the label of the node For every node, the entries in that node‚Äôs right child are greater than the label of the node An example of a BST is: Note that, if a node has only one child, that child could be considered either the left or right child. You should take this into consideration. Hint: It may be helpful to write helper functions bst_min and bst_max that return the minimum and maximum, respectively, of a Tree if it is a valid binary search tree. Notable details: the minimal value of the left child should be \u003c= the value of the current node rather than \u003c. If a node has only one child, it can be considered either the left or right child. python def is_bst(t): \"\"\"Returns True if the Tree t has the structure of a valid BST. \"\"\" def bst_min(t): \"\"\"Return the min value of the tree t\"\"\" if t.is_leaf(): return t.label sub_branch_min = min([bst_min(b) for b in t.branches]) return min(t.label, sub_branch_min) def bst_max(t): \"\"\"Return the max value of the tree t\"\"\" if t.is_leaf(): return t.label sub_branch_max = max([bst_max(b) for b in t.branches]) return max(t.label, sub_branch_max) # base case 1. a leaf node is a BST if t.is_leaf(): return True # base case 2. each node has at most 2 children if len(t.branches) \u003e 2: return False # base case 3. a node with a single child # it can be considered either the left or the right if len(t.branches) == 1: return (bst_max(t.branches[0]) \u003c t.label or bst_min(t.branches[0]) \u003e t.label) \\ and is_bst(t.branches[0]) left_max = bst_max(t.branches[0]) right_min = bst_min(t.branches[1]) return left_max \u003c= t.label \u003c right_min and is_bst(t.branches[0]) and is_bst(t.branches[1]) ","date":"2022-02-27","objectID":"/en/hw06-of-cs61a-of-ucb/:3:2","series":null,"tags":["Course","Python"],"title":"Hw06 - CS61A of UCB(2021-Fall)","uri":"/en/hw06-of-cs61a-of-ucb/#q7-is-bst"},{"categories":["Course"],"content":"the simple solutions for lab10 of CS61A of UCB","date":"2022-02-27","objectID":"/en/lab10-cs61a-of-ucb/","series":null,"tags":["Course","Scheme"],"title":"Lab10 - CS61A of UCB(2021-Fall)","uri":"/en/lab10-cs61a-of-ucb/"},{"categories":["Course"],"content":" Coding Questions ","date":"2022-02-27","objectID":"/en/lab10-cs61a-of-ucb/:1:0","series":null,"tags":["Course","Scheme"],"title":"Lab10 - CS61A of UCB(2021-Fall)","uri":"/en/lab10-cs61a-of-ucb/#coding-questions"},{"categories":["Course"],"content":" Q2: Over or Under Define a procedure over-or-under which takes in a number num1 and a number num2 and returns the following: -1 if num1 is less than num2 0 if num1 is equal to num2 1 if num1 is greater than num2 Challenge: Implement this in 2 different ways using if and cond! text (define (over-or-under num1 num2) 'YOUR-CODE-HERE ) The problem itself is not difficult. We just need to get used to the grammar of the scheme language. If we want to indicate the conditional branches, we may use: (if \u003cpredicate\u003e \u003cconsequent\u003e \u003calternative\u003e) (cond (\u003ccondition\u003e \u003cconsequent\u003e) ...) scheme (define (over-or-under num1 num2) (if (\u003c num1 num2) (print -1)) (if (= num1 num2) (print 0)) (if (\u003e num1 num2) (print 1)) ) (define (over-or-under num1 num2) (cond ( (\u003c num1 num2) (print -1) ) ( (= num1 num2) (print 0) ) ( (\u003e num1 num2) (print 1) )) ) ","date":"2022-02-27","objectID":"/en/lab10-cs61a-of-ucb/:1:1","series":null,"tags":["Course","Scheme"],"title":"Lab10 - CS61A of UCB(2021-Fall)","uri":"/en/lab10-cs61a-of-ucb/#q2-over-or-under"},{"categories":["Course"],"content":" Q3: Make Adder Write the procedure make-adder which takes in an initial number, num, and then returns a procedure. This returned procedure takes in a number inc and returns the result of num + inc. Hint: To return a procedure, you can either return a lambda expression or define another nested procedure. Remember that Scheme will automatically return the last clause in your procedure. You can find documentation on the syntax of lambda expressions in the 61A scheme specification! We once saw make-adder written in python in the course. Now we have to translate it to the scheme language. I will use the lambda function to implement the high-order function. scheme (define (make-adder num) (lambda (inc) (+ num inc)) ) ","date":"2022-02-27","objectID":"/en/lab10-cs61a-of-ucb/:1:2","series":null,"tags":["Course","Scheme"],"title":"Lab10 - CS61A of UCB(2021-Fall)","uri":"/en/lab10-cs61a-of-ucb/#q3-make-adder"},{"categories":["Course"],"content":" Q4: Compose Write the procedure composed, which takes in procedures f and g and outputs a new procedure. This new procedure takes in a number x and outputs the result of calling f on g of x. Is is similar to Q3. scheme (define (composed f g) (lambda (x) (f (g x) ) ) ) ","date":"2022-02-27","objectID":"/en/lab10-cs61a-of-ucb/:1:3","series":null,"tags":["Course","Scheme"],"title":"Lab10 - CS61A of UCB(2021-Fall)","uri":"/en/lab10-cs61a-of-ucb/#q4-compose"},{"categories":["Course"],"content":" Q5: Make a List In this problem you will create the list with the following box-and-pointer diagram: Challenge: try to create this list in multiple ways, and using multiple list constructors!Ë¶ÅÊ±Ç This problem asks us to make a list depending on the structure provided. We can implement this in many different ways: cons, the basic way to define a list in scheme. I felt a little dizzy after finishing this üò¢ list, the code is shorter. Notice that every time we call (list ...), it is equivalent to making a sublist in the list(a new direction) scheme (define lst (cons (cons 1 nil) (cons 2 (cons (cons 3 (cons 4 nil)) (cons 5 nil)))) ) (define lst (list (list 1) 2 (list 3 4) 5) ) ","date":"2022-02-27","objectID":"/en/lab10-cs61a-of-ucb/:1:4","series":null,"tags":["Course","Scheme"],"title":"Lab10 - CS61A of UCB(2021-Fall)","uri":"/en/lab10-cs61a-of-ucb/#q5-make-a-list"},{"categories":["Course"],"content":" Optional Questions ","date":"2022-02-27","objectID":"/en/lab10-cs61a-of-ucb/:2:0","series":null,"tags":["Course","Scheme"],"title":"Lab10 - CS61A of UCB(2021-Fall)","uri":"/en/lab10-cs61a-of-ucb/#optional-questions"},{"categories":["Course"],"content":" Q6: Remove Implement a procedure remove that takes in a list and returns a new list with all instances of item removed from lst. You may assume the list will only consist of numbers and will not have nested lists. Hint: You might find the built-in filter procedure useful (though it is definitely possible to complete this question without it). You can find information about how to use filter in the 61A Scheme builtin specification! In face, the list of the scheme language is a linklist. So the problem is removing elements whose value are equal to item. Apparently, We can solve this problem recursively. The assumption that there are no nested lists in Q6 makes the problem easier. The base case is a empty list, we will return '(). Otherwise, The value of current node = item, exclude it and process sublist recursively. The value of current node != item, include it and process sublist recursively. scheme (define (remove item lst) (cond ( (null? lst) '() ) ; base case ( (= item (car lst)) (remove item (cdr lst))) ; exclude item ( else (cons (car lst) (remove item (cdr lst))))) ; include item ) ","date":"2022-02-27","objectID":"/en/lab10-cs61a-of-ucb/:2:1","series":null,"tags":["Course","Scheme"],"title":"Lab10 - CS61A of UCB(2021-Fall)","uri":"/en/lab10-cs61a-of-ucb/#q6-remove"},{"categories":["Course"],"content":"the simple solutions for lab09 of CS61A of UCB","date":"2022-02-26","objectID":"/en/lab09-cs61a-of-ucb/","series":null,"tags":["Course","Python"],"title":"Lab09 - CS61A of UCB(2021-Fall)","uri":"/en/lab09-cs61a-of-ucb/"},{"categories":["Course"],"content":" Recursion and Tree Recursion ","date":"2022-02-26","objectID":"/en/lab09-cs61a-of-ucb/:1:0","series":null,"tags":["Course","Python"],"title":"Lab09 - CS61A of UCB(2021-Fall)","uri":"/en/lab09-cs61a-of-ucb/#recursion-and-tree-recursion"},{"categories":["Course"],"content":" Q1: Subsequences A subsequence of a sequence S is a subset of elements from S, in the same order they appear in S. Consider the list [1, 2, 3]. Here are a few of it‚Äôs subsequences [], [1, 3], [2], and [1, 2, 3]. Write a function that takes in a list and returns all possible subsequences of that list. The subsequences should be returned as a list of lists, where each nested list is a subsequence of the original input. In order to accomplish this, you might first want to write a function insert_into_all that takes an item and a list of lists, adds the item to the beginning of each nested list, and returns the resulting list. This problem requires us to write a function which can return all possible subsequences of its input. The hint says that we should implement the insert_into_all function first. We can do this by a simple list comprehension. python def insert_into_all(item, nested_list): \"\"\"Return a new list consisting of all the lists in nested_list, but with item added to the front of each. You can assume that nested_list is a list of lists. \"\"\" return [[item] + l for l in nested_list] The insert_into_all function indicates the way to solve this problem. We need to ask ourseleves what we can do with this function. We can solve it recursively. The input can be broken down into 2 parts: the first element and the rest part of the input. Let‚Äôs assume we have already calculated the subsequences of the rest part of the input(denoted as tmp). Now the problem becomes - how to generate new subsequences that contain the first element? The answer is: just add the first element to each subsequence in tmp. Then we do list concatenation and return. Finally, what is the base case? It is an empty list or a list with a size of 1. python def subseqs(s): \"\"\"Return a nested list (a list of lists) of all subsequences of S. The subsequences can appear in any order. You can assume S is a list. \"\"\" if len(s) \u003c= 1: return [[], s] if s !=[] else [[]] else: tmp = subseqs(s[1:]) return insert_into_all(s[0], tmp) + tmp ","date":"2022-02-26","objectID":"/en/lab09-cs61a-of-ucb/:1:1","series":null,"tags":["Course","Python"],"title":"Lab09 - CS61A of UCB(2021-Fall)","uri":"/en/lab09-cs61a-of-ucb/#q1-subsequences"},{"categories":["Course"],"content":" Q2: Non-Decreasing Subsequences Just like the last question, we want to write a function that takes a list and returns a list of lists, where each individual list is a subsequence of the original input. This time we have another condition: we only want the subsequences for which consecutive elements are nondecreasing. For example, [1, 3, 2] is a subsequence of [1, 3, 2, 4], but since 2 \u003c 3, this subsequence would not be included in our result. Fill in the blanks to complete the implementation of the non_decrease_subseqs function. You may assume that the input list contains no negative elements. You may use the provided helper function insert_into_all, which takes in an item and a list of lists and inserts the item to the front of each list. In Q1, we wrote the function that can return all the possible subsequences. Now Q2 puts forward higher requirements. This hint says that we may use the insert_into_all function, so let‚Äôs ponder on a critical question: what should we pay attention to when calling this function? By definition, we know that all subsequences of the rest part of the input should be non-decreasing. Now we figure out the answer - the first element should be less or equal to the first element of each subsequence. What if it is not true? We can simply remove it. Now let‚Äôs check the subseq_helper function, the meaning of the prev argument becomes clearer. It represents the minimum allowed value of all subsequences. python def non_decrease_subseqs(s): \"\"\"Assuming that S is a list, return a nested list of all subsequences of S (a list of lists) for which the elements of the subsequence are strictly nondecreasing. The subsequences can appear in any order. \"\"\" def subseq_helper(s, prev): if not s: return [[]] elif s[0] \u003c prev: return subseq_helper(s[1:], prev) else: a = subseq_helper(s[1:], s[0]) # include s[0] b = subseq_helper(s[1:], prev) # exclude s[0] return insert_into_all(s[0], a) + b return subseq_helper(s, 0) ","date":"2022-02-26","objectID":"/en/lab09-cs61a-of-ucb/:1:2","series":null,"tags":["Course","Python"],"title":"Lab09 - CS61A of UCB(2021-Fall)","uri":"/en/lab09-cs61a-of-ucb/#q2-non-decreasing-subsequences"},{"categories":["Course"],"content":" Q3: Number of Trees A full binary tree is a tree where each node has either 2 branches or 0 branches, but never 1 branch. Write a function which returns the number of unique full binary tree structures that have exactly n leaves. For those interested in combinatorics, this problem does have a closed form solution): The answer is the Catalan number. So we need to write a function to calculate the ith Catalan number. As for why it is a catalan number, I can barely understand this. I found the simple explanation: the subtrees of a full binary tree must also be full binary trees. Assuming that we have 1 leaf node in the left subtree, then we have n - 1 leaf nodes in the right subtree. Then there are f(1) * f(n - 1) possibilities. Similarly, we need to calculate f(2) * f(n - 2) ‚Ä¶ ps: The definition of a full binary tree here is not strict. Actually, it means all the degrees of nodes in the tree should be either 0 or 2. python def num_trees(n): \"\"\"Returns the number of unique full binary trees with exactly n leaves. E.g., \"\"\" if n == 1 or n == 2: return 1 # catalan number ans = 0 for i in range(1, n): ans += num_trees(i) * num_trees(n - i) return ans ","date":"2022-02-26","objectID":"/en/lab09-cs61a-of-ucb/:1:3","series":null,"tags":["Course","Python"],"title":"Lab09 - CS61A of UCB(2021-Fall)","uri":"/en/lab09-cs61a-of-ucb/#q3-number-of-trees"},{"categories":["Course"],"content":" Generators ","date":"2022-02-26","objectID":"/en/lab09-cs61a-of-ucb/:2:0","series":null,"tags":["Course","Python"],"title":"Lab09 - CS61A of UCB(2021-Fall)","uri":"/en/lab09-cs61a-of-ucb/#generators"},{"categories":["Course"],"content":" Q4: Merge Implement merge(incr_a, incr_b), which takes two iterables incr_a and incr_b whose elements are ordered. merge yields elements from incr_a and incr_b in sorted order, eliminating repetition. You may assume incr_aand incr_b themselves do not contain repeats, and that none of the elements of either are None. You may notassume that the iterables are finite; either may produce an infinite stream of results. You will probably find it helpful to use the two-argument version of the built-in next function: next(incr, v) is the same as next(incr), except that instead of raising StopIteration when incr runs out of elements, it returns v. See the doctest for examples of behavior. What the merge do is merging two iterable objects. It can be assumed that the two iterable objects have no duplicate elements individually, and none of the elements is None. Because we can‚Äôt assume that the two iterable objects are finite, we can‚Äôt solve this in a brute-force way(Merge them and sort and use set to move duplicates). The procedure is: If both of the two iterable objects are non-empty Compare the first element each to compare They are equivalent: yield one, and move the two iterators backward. yield the smaller element, move its iterator Repeat until one of the two iterable objects is empty. Then we only need to iterate the non-empty one instead. python def merge(incr_a, incr_b): \"\"\"Yield the elements of strictly increasing iterables incr_a and incr_b, removing repeats. Assume that incr_a and incr_b have no repeats. incr_a or incr_b may or may not be infinite sequences. \"\"\" iter_a, iter_b = iter(incr_a), iter(incr_b) next_a, next_b = next(iter_a, None), next(iter_b, None) # both are non-empty while next_a is not None and next_b is not None: val_a, val_b = next_a, next_b if val_a == val_b: yield next_a next_a, next_b = next(iter_a, None), next(iter_b, None) elif val_a \u003c val_b: yield next_a next_a = next(iter_a, None) else: yield next_b next_b = next(iter_b, None) # incr_a is not empty while next_a: yield next_a next_a = next(iter_a, None) # incr_b is not empty while next_b: yield next_b next_b = next(iter_b, None) ","date":"2022-02-26","objectID":"/en/lab09-cs61a-of-ucb/:2:1","series":null,"tags":["Course","Python"],"title":"Lab09 - CS61A of UCB(2021-Fall)","uri":"/en/lab09-cs61a-of-ucb/#q4-merge"},{"categories":["Course"],"content":" Objects ","date":"2022-02-26","objectID":"/en/lab09-cs61a-of-ucb/:3:0","series":null,"tags":["Course","Python"],"title":"Lab09 - CS61A of UCB(2021-Fall)","uri":"/en/lab09-cs61a-of-ucb/#objects"},{"categories":["Course"],"content":" Q5: Bank Account Implement the class Account, which acts as a a Bank Account. Account should allow the account holder to deposit money into the account, withdraw money from the account, and view their transaction history. The Bank Account should also prevents a user from withdrawing more than the current balance. Transaction history should be stored as a list of tuples, where each tuple contains the type of transaction and the transaction amount. For example a withdrawal of 500 should be stored as (‚Äòwithdraw‚Äô, 500) Hint: You can call the str function on an integer to get a string representation of the integer. You might find this function useful when implementing the __repr__ and __str__ methods. Hint: You can alternatively use fstrings to implement the __repr__ and __str__ methods cleanly. The Account should be able to: deposit withdraw check the history of what we have done. Looking into the __repr__ method, we know we need to know the number of times the deposits and the withdrawals. So we can define two variables to memorize them. python class Account: \"\"\"A bank account that allows deposits and withdrawals. It tracks the current account balance and a transaction history of deposits and withdrawals. \"\"\" interest = 0.02 def __init__(self, account_holder): self.balance = 0 self.holder = account_holder self.transactions = [] self.withdraw_cnt = 0 self.deposit_cnt = 0 def deposit(self, amount): \"\"\"Increase the account balance by amount, add the deposit to the transaction history, and return the new balance. \"\"\" self.balance += amount self.transactions.append(('deposit', amount)) self.deposit_cnt += 1 return self.balance def withdraw(self, amount): \"\"\"Decrease the account balance by amount, add the withdraw to the transaction history, and return the new balance. \"\"\" if self.balance \u003e amount: self.balance -= amount self.transactions.append(('withdraw', amount)) self.withdraw_cnt += 1 return self.balance # prevent illegal withdraw return self.balance def __str__(self): return f\"{self.holder}'s Balance: ${self.balance}\" def __repr__(self): return f\"Accountholder: {self.holder}, Deposits: {self.deposit_cnt}, Withdraws: {self.withdraw_cnt}\" ","date":"2022-02-26","objectID":"/en/lab09-cs61a-of-ucb/:3:1","series":null,"tags":["Course","Python"],"title":"Lab09 - CS61A of UCB(2021-Fall)","uri":"/en/lab09-cs61a-of-ucb/#q5-bank-account"},{"categories":["Course"],"content":" Mutable Lists ","date":"2022-02-26","objectID":"/en/lab09-cs61a-of-ucb/:4:0","series":null,"tags":["Course","Python"],"title":"Lab09 - CS61A of UCB(2021-Fall)","uri":"/en/lab09-cs61a-of-ucb/#mutable-lists"},{"categories":["Course"],"content":" Q6: Trade In the integer market, each participant has a list of positive integers to trade. When two participants meet, they trade the smallest non-empty prefix of their list of integers. A prefix is a slice that starts at index 0. Write a function trade that exchanges the first m elements of list first with the first n elements of list second, such that the sums of those elements are equal, and the sum is as small as possible. If no such prefix exists, return the string 'No deal!' and do not change either list. Otherwise change both lists and return 'Deal!'. A partial implementation is provided. Hint: You can mutate a slice of a list using slice assignment. To do so, specify a slice of the list [i:j] on the left-hand side of an assignment statement and another list on the right-hand side of the assignment statement. The operation will replace the entire given slice of the list from i inclusive to j exclusive with the elements from the given list. The slice and the given list need not be the same length. text \u003e\u003e\u003e a = [1, 2, 3, 4, 5, 6] \u003e\u003e\u003e b = a \u003e\u003e\u003e a[2:5] = [10, 11, 12, 13] \u003e\u003e\u003e a [1, 2, 10, 11, 12, 13, 6] \u003e\u003e\u003e b [1, 2, 10, 11, 12, 13, 6] Additionally, recall that the starting and ending indices for a slice can be left out and Python will use a default value. lst[i:] is the same as lst[i:len(lst)], and lst[:j] is the same as lst[0:j]. It has provided us with some code that can exchange elements. All we have to do is to make m and n stop in right place. We need to make sure that the m and n are leal indices. python def trade(first, second): \"\"\"Exchange the smallest prefixes of first and second that have equal sum. \"\"\" m, n = 1, 1 equal_prefix = lambda: sum(first[:m]) == sum(second[:n]) while m \u003c= len(first) and n \u003c= len(second) and not equal_prefix(): if sum(first[:m]) \u003c sum(second[:n]): m += 1 else: n += 1 if equal_prefix(): first[:m], second[:n] = second[:n], first[:m] return 'Deal!' else: return 'No deal!' ","date":"2022-02-26","objectID":"/en/lab09-cs61a-of-ucb/:4:1","series":null,"tags":["Course","Python"],"title":"Lab09 - CS61A of UCB(2021-Fall)","uri":"/en/lab09-cs61a-of-ucb/#q6-trade"},{"categories":["Course"],"content":" Q7: Shuffle Define a function shuffle that takes a sequence with an even number of elements (cards) and creates a new list that interleaves the elements of the first half with the elements of the second half. To interleave two sequences s0 and s1 is to create a new sequence such that the new sequence contains (in this order) the first element of s0, the first element of s1, the second element of s0, the second element of s1, and so on. If the two lists are not the same length, then the leftover elements of the longer list should still appear at the end. Note: If you‚Äôre running into an issue where the special heart / diamond / spades / clubs symbols are erroring in the doctests, feel free to copy paste the below doctests into your file as these don‚Äôt use the special characters and should not give an ‚Äúillegal multibyte sequence‚Äù error. This problem requires us to implement the shuffle function. For example, [0, 1, 2, 3, 4, 5] = [0, 3, 1, 4, 2, 5]. The key: the relationship between the indices - [0, 1, ..., len(cards) // 2, len(cards) // 2 + 1, ...]. You can find that the indices of the elements in the corresponding positions of the first half and the second half differ by len(cards) // 2 python def shuffle(cards): \"\"\"Return a shuffled list that interleaves the two halves of cards. \"\"\" assert len(cards) % 2 == 0, 'len(cards) must be even' half = len(cards) // 2 shuffled = [] for i in range(half): shuffled.append(cards[i]) shuffled.append(cards[i + half]) return shuffled ","date":"2022-02-26","objectID":"/en/lab09-cs61a-of-ucb/:4:2","series":null,"tags":["Course","Python"],"title":"Lab09 - CS61A of UCB(2021-Fall)","uri":"/en/lab09-cs61a-of-ucb/#q7-shuffle"},{"categories":["Course"],"content":" Linked Lists ","date":"2022-02-26","objectID":"/en/lab09-cs61a-of-ucb/:5:0","series":null,"tags":["Course","Python"],"title":"Lab09 - CS61A of UCB(2021-Fall)","uri":"/en/lab09-cs61a-of-ucb/#linked-lists"},{"categories":["Course"],"content":" Q8: Insert Implement a function insert that takes a Link, a value, and an index, and inserts the value into the Link at the given index. You can assume the linked list already has at least one element. Do not return anything ‚Äì insert should mutate the linked list. Note: If the index is out of bounds, you should raise an IndexError with: text raise IndexError('Out of bounds!') It is strange that if we insert a new node(the index = 0), we won‚Äôt pass the link is other_link test(because we have changed the head of the link). So I change my way to insert: I make a copy of the current node and then change the value of the origin node. python def insert(link, value, index): \"\"\"Insert a value into a Link at the given index. \"\"\" pos = link current_index = 0 while pos is not Link.empty: if current_index == index: # make a copy of current node, and modify the current node's value \\ # which is equal to insert a new node :) current_copy = Link(pos.first, pos.rest) origin_next = pos.rest pos.first = value pos.rest = current_copy #print(f\"link: {link.first}\") return pos = pos.rest current_index += 1 raise IndexError('Out of bounds!') ","date":"2022-02-26","objectID":"/en/lab09-cs61a-of-ucb/:5:1","series":null,"tags":["Course","Python"],"title":"Lab09 - CS61A of UCB(2021-Fall)","uri":"/en/lab09-cs61a-of-ucb/#q8-insert"},{"categories":["Course"],"content":" Q9: Deep Linked List Length A linked list that contains one or more linked lists as elements is called a deep linked list. Write a function deep_len that takes in a (possibly deep) linked list and returns the deep length of that linked list. The deep length of a linked list is the total number of non-link elements in the list, as well as the total number of elements contained in all contained lists. See the function‚Äôs doctests for examples of the deep length of linked lists. Hint: Use isinstance to check if something is an instance of an object. Deep Linked List Length is a nested list. We need to calculate how many nodes are in it. To solve the problem of the nested linklist, we can solve it recursively. The base case is an empty linklist or it is not a linklist. Otherwise, we will check the lnk.first(it may be a linklist) and the lnk.rest python def deep_len(lnk): \"\"\" Returns the deep length of a possibly deep linked list. \"\"\" # base case 1. an empty node if lnk is Link.empty: return 0 # base case 2. an integer elif isinstance(lnk, int): return 1 else: return deep_len(lnk.first) + deep_len(lnk.rest) ","date":"2022-02-26","objectID":"/en/lab09-cs61a-of-ucb/:5:2","series":null,"tags":["Course","Python"],"title":"Lab09 - CS61A of UCB(2021-Fall)","uri":"/en/lab09-cs61a-of-ucb/#q9-deep-linked-list-length"},{"categories":["Course"],"content":" Q10: Linked Lists as Strings Kevin and Jerry like different ways of displaying the linked list structure in Python. While Kevin likes box and pointer diagrams, Jerry prefers a more futuristic way. Write a function make_to_string that returns a function that converts the linked list to a string in their preferred style. Hint: You can convert numbers to strings using the str function, and you can combine strings together using +. text \u003e\u003e\u003e str(4) '4' \u003e\u003e\u003e 'cs ' + str(61) + 'a' 'cs 61a' The format: front + the value of the current node + mid + the string of lnk.rest + back python def make_to_string(front, mid, back, empty_repr): \"\"\" Returns a function that turns linked lists to strings. \"\"\" def printer(lnk): if lnk is Link.empty: return empty_repr else: return front + str(lnk.first) + mid + printer(lnk.rest) + back return printer ","date":"2022-02-26","objectID":"/en/lab09-cs61a-of-ucb/:5:3","series":null,"tags":["Course","Python"],"title":"Lab09 - CS61A of UCB(2021-Fall)","uri":"/en/lab09-cs61a-of-ucb/#q10-linked-lists-as-strings"},{"categories":["Course"],"content":" Trees ","date":"2022-02-26","objectID":"/en/lab09-cs61a-of-ucb/:6:0","series":null,"tags":["Course","Python"],"title":"Lab09 - CS61A of UCB(2021-Fall)","uri":"/en/lab09-cs61a-of-ucb/#trees"},{"categories":["Course"],"content":" Q11: Long Paths Implement long_paths, which returns a list of all paths in a tree with length at least n. A path in a tree is a list of node labels that starts with the root and ends at a leaf. Each subsequent element must be from a label of a branch of the previous value‚Äôs node. The length of a path is the number of edges in the path (i.e. one less than the number of nodes in the path). Paths are ordered in the output list from left to right in the tree. See the doctests for some examples. We need to return a nested list, each one of them represents a path with a length at least n. Notice that the path must end in a leaf node. Actually, it is a classical problem that can be solved by recursion and backtrace. The skeleton is like: python def function_name(p): # base case ... dothing thing ... # recursively solve this problem undo what you have done We need to add the label of the current node in our current_path list when we are about to go deepr in the tree and undo what our modifications when we are about move up in the tree. python def long_paths(t, n): \"\"\"Return a list of all paths in t with length at least n. \"\"\" path_list = [] def helper(t, current_path, length): nonlocal path_list if t.is_leaf(): current_path.append(t.label) if length \u003e= n: # warning: we need to pass a copy instead fo a ref path_list.append(current_path[:]) current_path.pop() return current_path.append(t.label) for b in t.branches: helper(b, current_path, length + 1) current_path.pop() helper(t, [], 0) return path_list ","date":"2022-02-26","objectID":"/en/lab09-cs61a-of-ucb/:6:1","series":null,"tags":["Course","Python"],"title":"Lab09 - CS61A of UCB(2021-Fall)","uri":"/en/lab09-cs61a-of-ucb/#q11-long-paths"},{"categories":["Course"],"content":"the simple solutions for lab08 of CS61A of UCB","date":"2022-02-24","objectID":"/en/lab08-cs61a-of-ucb/","series":null,"tags":["Course","Python"],"title":"Lab08 - CS61A of UCB(2021-Fall)","uri":"/en/lab08-cs61a-of-ucb/"},{"categories":["Course"],"content":" Q2: Convert Link Write a function convert_link that takes in a linked list and returns the sequence as a Python list. You may assume that the input list is shallow; that is none of the elements is another linked list. Try to find both an iterative and recursive solution for this problem! It is easy to solve this problem iteratively. All we have to do is to make a list to store these nodes we have visited while we iterating this linklist. python def convert_link(link): \"\"\"Takes a linked list and returns a Python list with the same elements. \"\"\" result = [] while link is not Link.empty: result.append(int(link.first)) link = link.rest return result The recursive algorithm is also easy. The base case is that when we encounter an empty node, an empty list will be returned. Otherwise, we will break down this problem: current node + the rest of tinkliest python def convert_link(link): \"\"\"Takes a linked list and returns a Python list with the same elements. \"\"\" # recursive solution if link is Link.empty: return [] else: return [int(link.first)] + convert_link(link.rest) ","date":"2022-02-24","objectID":"/en/lab08-cs61a-of-ucb/:0:1","series":null,"tags":["Course","Python"],"title":"Lab08 - CS61A of UCB(2021-Fall)","uri":"/en/lab08-cs61a-of-ucb/#q2-convert-link"},{"categories":["Course"],"content":" Trees ","date":"2022-02-24","objectID":"/en/lab08-cs61a-of-ucb/:1:0","series":null,"tags":["Course","Python"],"title":"Lab08 - CS61A of UCB(2021-Fall)","uri":"/en/lab08-cs61a-of-ucb/#trees"},{"categories":["Course"],"content":" Q4: Square Write a function label_squarer that mutates a Tree with numerical labels so that each label is squared. python def label_squarer(t): \"\"\"Mutates a Tree t by squaring all its elements. \"\"\" # base case if t.is_leaf(): t.label = t.label ** 2 # check every branch for b in t.branches: t.label = t.label ** 2 # change the current node's label label_squarer(b) # change branches ","date":"2022-02-24","objectID":"/en/lab08-cs61a-of-ucb/:1:1","series":null,"tags":["Course","Python"],"title":"Lab08 - CS61A of UCB(2021-Fall)","uri":"/en/lab08-cs61a-of-ucb/#q4-square"},{"categories":["Course"],"content":" Q5: Cumulative Mul Write a function cumulative_mul that mutates the Tree t so that each node‚Äôs label becomes the product of its label and all labels in the subtrees rooted at the node. The description indicates that we should make the label of the node equal to the product of its label and all labels in the subtrees in the tree. The base is the leaf node, which has no subtrees. We will return its label. Otherwise, we check every subtree of the current node. The procedure of changing is bottom-up ü§ó To make the code simple, I use math.prod here. If you also want to use this, you will need to import math at the beginning of the code. python def cumulative_mul(t): \"\"\"Mutates t so that each node's label becomes the product of all labels in \"\"\" # base case if t.is_leaf(): return t.label # get all label value in subtree vals = [cumulative_mul(b) for b in t.branches] # calculate t.label *= math.prod(vals) ","date":"2022-02-24","objectID":"/en/lab08-cs61a-of-ucb/:1:2","series":null,"tags":["Course","Python"],"title":"Lab08 - CS61A of UCB(2021-Fall)","uri":"/en/lab08-cs61a-of-ucb/#q5-cumulative-mul"},{"categories":["Course"],"content":" Q6: Add Leaves Implement add_d_leaves, a function that takes in a Tree instance t and a number v. We define the depth of a node in t to be the number of edges from the root to that node. The depth of root is therefore 0. For each node in the tree, you should add d leaves to it, where d is the depth of the node. Every added leaf should have a label of v. If the node at this depth has existing branches, you should add these leaves to the end of that list of branches. For example, you should be adding 1 leaf with label v to each node at depth 1, 2 leaves to each node at depth 2, and so on. Here is an example of a tree t(shown on the left) and the result after add_d_leaves is applied with v as 5. We have to some details into account: How to get the height of the current node? We need to add leaves depending on the height, we can define a helper function with an additional parameter to represent height. Every time we go deeper in the tree, we will +1. How to solve it recursively? The base is the leaf node. We will add leaves to it and return here. Otherwise, we need to repeat the procedure to all its subtrees, and also determine whether the current node needs to add leaves. python def add_d_leaves(t, v): \"\"\"Add d leaves containing v to each node at every depth d. \"\"\" def helper(t, v, depth): # base case if t.is_leaf(): for i in range(depth): t.branches.append(Tree(v)) return # check every branch for b in t.branches: helper(b, v, depth + 1) # check current node for i in range(depth): t.branches.append(Tree(v)) helper(t, v, 0) ","date":"2022-02-24","objectID":"/en/lab08-cs61a-of-ucb/:1:3","series":null,"tags":["Course","Python"],"title":"Lab08 - CS61A of UCB(2021-Fall)","uri":"/en/lab08-cs61a-of-ucb/#q6-add-leaves"},{"categories":["Course"],"content":" Optional Questions ","date":"2022-02-24","objectID":"/en/lab08-cs61a-of-ucb/:2:0","series":null,"tags":["Course","Python"],"title":"Lab08 - CS61A of UCB(2021-Fall)","uri":"/en/lab08-cs61a-of-ucb/#optional-questions"},{"categories":["Course"],"content":" Q7: Every Other Implement every_other, which takes a linked list s. It mutates s such that all of the odd-indexed elements (using 0-based indexing) are removed from the list. For example: text \u003e\u003e\u003e s = Link('a', Link('b', Link('c', Link('d')))) \u003e\u003e\u003e every_other(s) \u003e\u003e\u003e s.first 'a' \u003e\u003e\u003e s.rest.first 'c' \u003e\u003e\u003e s.rest.rest is Link.empty True If s contains fewer than two elements, s remains unchanged. Do not return anything! every_other should mutate the original list. First, If the length of the linklist is less than 2, we will keep it unchanged. Otherwise, we will solve this problem iteratively. We maintain 2 pointers - last_pos and pos, which indicate the current position and the last position we visited. If the current node is odd-indexed, we let last_pos.rest = post.rest and add the pointers. python def every_other(s): \"\"\"Mutates a linked list so that all the odd-indiced elements are removed \"\"\" # if it contains fewer than 2, do nothing if s is Link.empty or s.rest is Link.empty: return last_pos, pos = s, s.rest current_index = 1 # start from 2nd position while pos is not Link.empty: if current_index % 2 == 1: last_pos.rest = pos.rest last_pos = pos pos = pos.rest current_index += 1 ","date":"2022-02-24","objectID":"/en/lab08-cs61a-of-ucb/:2:1","series":null,"tags":["Course","Python"],"title":"Lab08 - CS61A of UCB(2021-Fall)","uri":"/en/lab08-cs61a-of-ucb/#q7-every-other"},{"categories":["Course"],"content":" Q8: Prune Small Complete the function prune_small that takes in a Tree t and a number n and prunes t mutatively. If t or any of its branches has more than n branches, the n branches with the smallest labels should be kept and any other branches should be pruned, or removed, from the tree. Before we start to write the code, we need to think about what is the fast way to prune? The bottom-up way or the up-down way? The latter is the answer. Because we don‚Äôt have to check the nodes in the subtrees we have pruned. You may figure out this by observing the template provided in the hint. ü§ó python def prune_small(t, n): \"\"\"Prune the tree mutatively, keeping only the n branches of each node with the smallest label. \"\"\" while len(t.branches) \u003e n: largest = max(t.branches, key=lambda x: x.label) t.branches.remove(largest) for b in t.branches: prune_small(b, n) ","date":"2022-02-24","objectID":"/en/lab08-cs61a-of-ucb/:2:2","series":null,"tags":["Course","Python"],"title":"Lab08 - CS61A of UCB(2021-Fall)","uri":"/en/lab08-cs61a-of-ucb/#q8-prune-small"},{"categories":["Course"],"content":"the simple solutions for lab07 of CS61A of UCB","date":"2022-02-24","objectID":"/en/lab07-cs61a-of-ucb/","series":null,"tags":["Course","Python"],"title":"Lab07 - CS61A of UCB(2021-Fall)","uri":"/en/lab07-cs61a-of-ucb/"},{"categories":["Course"],"content":" Accounts ","date":"2022-02-24","objectID":"/en/lab07-cs61a-of-ucb/:1:0","series":null,"tags":["Course","Python"],"title":"Lab07 - CS61A of UCB(2021-Fall)","uri":"/en/lab07-cs61a-of-ucb/#accounts"},{"categories":["Course"],"content":" Q2: Retirement Add a time_to_retire method to the Account class. This method takes in an amount and returns how many years the holder would need to wait in order for the current balance to grow to at least amount, assuming that the bank adds balance times the interest rate to the total balance at the end of every year. The description tells us that: We will add our balance every year, so when may we retire? Both the math and code are simple. python def time_to_retire(self, amount): \"\"\"Return the number of years until balance would grow to amount.\"\"\" assert self.balance \u003e 0 and amount \u003e 0 and self.interest \u003e 0 year, curAmount = 0, self.balance while True: year += 1 curAmount *= (1 + self.interest) if curAmount \u003e amount: return year ","date":"2022-02-24","objectID":"/en/lab07-cs61a-of-ucb/:1:1","series":null,"tags":["Course","Python"],"title":"Lab07 - CS61A of UCB(2021-Fall)","uri":"/en/lab07-cs61a-of-ucb/#q2-retirement"},{"categories":["Course"],"content":" Q3: FreeChecking Implement the FreeChecking class, which is like the Account class from lecture except that it charges a withdraw fee after 2 withdrawals. If a withdrawal is unsuccessful, it still counts towards the number of free withdrawals remaining, but no fee for the withdrawal will be charged. We need to check an additional parameter(free_withdrawals) compare with withdraw, which indicates the number of times we can withdraw without being charged the fee. There are 2 points to note here: The number of free_wighdrawals will be reduced even if we fail to withdraw. The sum of the fee and the amount should be bigger than the balance so that we can withdraw successfully when we need to pay the fee. python def withdraw(self, amount): if self.free_withdrawals \u003e 0: if amount \u003e self.balance: self.free_withdrawals -= 1 return \"Insufficient funds\" if amount \u003e self.max_withdrawal: self.free_withdrawals -= 1 return \"Can't withdraw that amount\" self.free_withdrawals -= 1 self.balance = self.balance - amount else: if amount + self.withdraw_fee \u003e self.balance: self.free_withdrawals -= 1 return \"Insufficient funds\" if amount + self.withdraw_fee \u003e self.max_withdrawal: self.free_withdrawals -= 1 return \"Can't withdraw that amount\" self.balance = self.balance - amount - self.withdraw_fee ","date":"2022-02-24","objectID":"/en/lab07-cs61a-of-ucb/:1:2","series":null,"tags":["Course","Python"],"title":"Lab07 - CS61A of UCB(2021-Fall)","uri":"/en/lab07-cs61a-of-ucb/#q3-freechecking"},{"categories":["Course"],"content":" Magic: the Lambda-ing ","date":"2022-02-24","objectID":"/en/lab07-cs61a-of-ucb/:2:0","series":null,"tags":["Course","Python"],"title":"Lab07 - CS61A of UCB(2021-Fall)","uri":"/en/lab07-cs61a-of-ucb/#magic-the-lambda-ing"},{"categories":["Course"],"content":" DescriptionWe will be implementing a card game in the lab. You can check the rules here ","date":"2022-02-24","objectID":"/en/lab07-cs61a-of-ucb/:2:1","series":null,"tags":["Course","Python"],"title":"Lab07 - CS61A of UCB(2021-Fall)","uri":"/en/lab07-cs61a-of-ucb/#description"},{"categories":["Course"],"content":" Q4: Making Cards To play a card game, we‚Äôre going to need to have cards, so let‚Äôs make some! We‚Äôre gonna implement the basics of the Card class first. First, implement the Card class constructor in classes.py. This constructor takes three arguments: a string as the name of the card an integer as the attack value of the card an integer as the defense value of the card Each Card instance should keep track of these values using instance attributes called name, attack, and defense. You should also implement the power method in Card, which takes in another card as an input and calculates the current card‚Äôs power. Refer to the Rules of the Game if you‚Äôd like a refresher on how power is calculated. We need to implement the constructor and the power functions. python class Card: cardtype = 'Staff' def __init__(self, name, attack, defense): \"\"\" Create a Card object with a name, attack, and defense. \"\"\" self.name = name self.attack = attack self.defense = defense def power(self, opponent_card): \"\"\" Calculate power as: (player card's attack) - (opponent card's defense)/2 \"\"\" return self.attack - opponent_card.defense / 2 ","date":"2022-02-24","objectID":"/en/lab07-cs61a-of-ucb/:2:2","series":null,"tags":["Course","Python"],"title":"Lab07 - CS61A of UCB(2021-Fall)","uri":"/en/lab07-cs61a-of-ucb/#q4-making-cards"},{"categories":["Course"],"content":" Q5: Making a Player Now that we have cards, we can make a deck, but we still need players to actually use them. We‚Äôll now fill in the implementation of the Player class. A Player instance has three instance attributes: name is the player‚Äôs name. When you play the game, you can enter your name, which will be converted into a string to be passed to the constructor. deck is an instance of the Deck class. You can draw from it using its .draw() method. hand is a list of Card instances. Each player should start with 5 cards in their hand, drawn from their deck. Each card in the hand can be selected by its index in the list during the game. When a player draws a new card from the deck, it is added to the end of this list. Complete the implementation of the constructor for Player so that self.hand is set to a list of 5 cards drawn from the player‚Äôs deck. Next, implement the draw and play methods in the Player class. The draw method draws a card from the deck and adds it to the player‚Äôs hand. The play method removes and returns a card from the player‚Äôs hand at the given index. Call deck.draw() when implementing Player.__init__ and Player.draw. Don‚Äôt worry about how this function works - leave it all to the abstraction! The tasks are as follow: We have 5 cards at the beginning of the game. We need to implement these: the constructor. We need to draw 5 cards from the deck. For the simplicity, we can use list comprehension here. the draw function. Use deck.draw() is enough. the play function. We need to play card at the given index. You should distinguish between .remove() and .pop(). python def __init__(self, deck, name): \"\"\"Initialize a Player object. \"\"\" self.deck = deck self.name = name self.hand = [deck.draw() for i in range(5)] def draw(self): \"\"\"Draw a card from the player's deck and add it to their hand. \"\"\" assert not self.deck.is_empty(), 'Deck is empty!' self.hand.append(self.deck.draw()) def play(self, card_index): \"\"\"Remove and return a card from the player's hand at the given index. \"\"\" card = self.hand[card_index] self.hand.pop(card_index) return card ","date":"2022-02-24","objectID":"/en/lab07-cs61a-of-ucb/:2:3","series":null,"tags":["Course","Python"],"title":"Lab07 - CS61A of UCB(2021-Fall)","uri":"/en/lab07-cs61a-of-ucb/#q5-making-a-player"},{"categories":["Course"],"content":" Optional Questions","date":"2022-02-24","objectID":"/en/lab07-cs61a-of-ucb/:3:0","series":null,"tags":["Course","Python"],"title":"Lab07 - CS61A of UCB(2021-Fall)","uri":"/en/lab07-cs61a-of-ucb/#optional-questions"},{"categories":["Course"],"content":" Q6: AIs: Defenders Implement the effect method for AIs, which reduces the opponent card‚Äôs attack by the opponent card‚Äôs defense, and then doubles the opponent card‚Äôs defense. Note: The opponent card‚Äôs resulting attack value cannot be negative. Note that if the attack is less than zero, we need to set it to zero. python def effect(self, opponent_card, player, opponent): \"\"\" Reduce the opponent's card's attack by its defense, then double its defense. \"\"\" opponent_card.attack -= opponent_card.defense if opponent_card.attack \u003c 0: opponent_card.attack = 0 opponent_card.defense *= 2 ","date":"2022-02-24","objectID":"/en/lab07-cs61a-of-ucb/:3:1","series":null,"tags":["Course","Python"],"title":"Lab07 - CS61A of UCB(2021-Fall)","uri":"/en/lab07-cs61a-of-ucb/#q6-ais-defenders"},{"categories":["Course"],"content":" Q7: Tutors: Flummox Implement the effect method for TAs, which swaps the attack and defense of the opponent‚Äôs card. We should discard our cards without breaking the abstraction. So we can use .play and .draw methods here. python def effect(self, opponent_card, player, opponent): \"\"\" Discard the first 3 cards in the opponent's hand and have them draw the same number of cards from their deck. \"\"\" # discard 3 cards for i in range(3): opponent.play(i) # draw 3 cards for i in range(3): opponent.draw() # You should add your implementation above this. print('{} discarded and re-drew 3 cards!'.format(opponent.name)) ","date":"2022-02-24","objectID":"/en/lab07-cs61a-of-ucb/:3:2","series":null,"tags":["Course","Python"],"title":"Lab07 - CS61A of UCB(2021-Fall)","uri":"/en/lab07-cs61a-of-ucb/#q7-tutors-flummox"},{"categories":["Course"],"content":" Q8: TAs: Shift Implement the effect method for TAs, which swaps the attack and defense of the opponent‚Äôs card. Just swap the attack and the defense python def effect(self, opponent_card, player, opponent): \"\"\" Swap the attack and defense of an opponent's card. \"\"\" opponent_card.attack, opponent_card.defense = opponent_card.defense, opponent_card.attack ","date":"2022-02-24","objectID":"/en/lab07-cs61a-of-ucb/:3:3","series":null,"tags":["Course","Python"],"title":"Lab07 - CS61A of UCB(2021-Fall)","uri":"/en/lab07-cs61a-of-ucb/#q8-tas-shift"},{"categories":["Course"],"content":" Q9: The Instructor Arrives A new challenger has appeared! Implement the effect method for the Instructors, who add the opponent card‚Äôs attack and defense to all cards in the player‚Äôs deck and then removes all cards in the opponent‚Äôs deck that have the same attack or defense as the opponent‚Äôs card. Note: If you mutate a list while iterating through it, you may run into trouble. Try iterating through a copy of the list instead. You can use slicing to make a copy of a list: text \u003e\u003e\u003e original = [1, 2, 3, 4] \u003e\u003e\u003e copy = original[:] \u003e\u003e\u003e copy [1, 2, 3, 4] \u003e\u003e\u003e copy is original False This one is a little more difficult compared with the other ones. The key of this question is how can we mutate the list while we iterate it. You may check this python def effect(self, opponent_card, player, opponent): \"\"\" Adds the attack and defense of the opponent's card to all cards in the player's deck, then removes all cards in the opponent's deck that share an attack or defense stat with the opponent's card. \"\"\" orig_opponent_deck_length = len(opponent.deck.cards) # add the attack and defense of the opponent's card ... for card in player.deck.cards: card.attack += opponent_card.attack card.defense += opponent_card.defense # remove all cards in the opponent's deck that share ... for card in opponent.deck.cards[:]: if card.attack == opponent_card.attack and card.defense == opponent_card.defense: opponent.deck.cards.remove(card) # You should add your implementation above this. discarded = orig_opponent_deck_length - len(opponent.deck.cards) if discarded: print('{} cards were discarded from {}\\'s deck!'.format(discarded, opponent.name)) return ","date":"2022-02-24","objectID":"/en/lab07-cs61a-of-ucb/:3:4","series":null,"tags":["Course","Python"],"title":"Lab07 - CS61A of UCB(2021-Fall)","uri":"/en/lab07-cs61a-of-ucb/#q9-the-instructor-arrives"},{"categories":["Course"],"content":"The simple solutions of hw05 of CS61A of UCB","date":"2022-02-22","objectID":"/en/hw05-of-cs61a-of-ucb/","series":null,"tags":["Course","Python"],"title":"Hw05 of CS61A of UCB(2021-Fall)","uri":"/en/hw05-of-cs61a-of-ucb/"},{"categories":["Course"],"content":" Q1: Generate Permutations Given a sequence of unique elements, a permutation of the sequence is a list containing the elements of the sequence in some arbitrary order. For example, [2, 1, 3], [1, 3, 2], and [3, 2, 1] are some of the permutations of the sequence [1, 2, 3]. Implement gen_perms, a generator function that takes in a sequence seq and returns a generator that yields all permutations of seq. For this question, assume that seq will not be empty. Permutations may be yielded in any order. Note that the doctests test whether you are yielding all possible permutations, but not in any particular order. The built-in sorted function takes in an iterable object and returns a list containing the elements of the iterable in non-decreasing order. Hint: If you had the permutations of all the elements in seq not including the first element, how could you use that to generate the permutations of the full seq? Hint: Remember, it‚Äôs possible to loop over generator objects because generators are iterators! This problem asks us to return a generator that will return all the permutations of the list. We can learn from the hint that we need to solve this problem recursively. It‚Äôs easy to figure out the base case of this problem: python def gen_perms(seq): if len(seq) \u003c= 1: yield seq ... Now, the problem is how can we break down this problem into simpler ones? We can learn from the hint that we should recursively process elements other than the element in the first position. Try to think about a question like this: If we have already got the permutations of l[1:], what should we do with l[0]. The answer is quite intuitive: we insert l[0] to every possible position in the permutations of l[1:]. For example, we have [2, 3], whose permutations are [[2, 3], [3, 2]]. First, we insert 1 to [2, 3], which give us [1, 2, 3], [2, 1, 3], [2, 3, 1]. Then we repeat the procedure on [3, 2]. So we can write the following code: python def gen_perms(seq): \"\"\"Generates all permutations of the given sequence. Each permutation is a list of the elements in SEQ in a different order. The permutations may be yielded in any order. \u003e\u003e\u003e perms = gen_perms([100]) \u003e\u003e\u003e type(perms) \u003cclass 'generator'\u003e \u003e\u003e\u003e next(perms) [100] \u003e\u003e\u003e try: #this piece of code prints \"No more permutations!\" if calling next would cause an error ... next(perms) ... except StopIteration: ... print('No more permutations!') No more permutations! \u003e\u003e\u003e sorted(gen_perms([1, 2, 3])) # Returns a sorted list containing elements of the generator [[1, 2, 3], [1, 3, 2], [2, 1, 3], [2, 3, 1], [3, 1, 2], [3, 2, 1]] \u003e\u003e\u003e sorted(gen_perms((10, 20, 30))) [[10, 20, 30], [10, 30, 20], [20, 10, 30], [20, 30, 10], [30, 10, 20], [30, 20, 10]] \u003e\u003e\u003e sorted(gen_perms(\"ab\")) [['a', 'b'], ['b', 'a']] \"\"\" # This problem requires list type, see example above if type(seq) != list: seq = list(seq) # base case if len(seq) \u003c= 1: yield seq else: # iterate every permutation in the generator for perm in gen_perms(seq[1:]): # enumerate every position for insertation for i in range(len(seq)): yield perm[:i] + seq[:1] + perm[i:] ","date":"2022-02-22","objectID":"/en/hw05-of-cs61a-of-ucb/:0:1","series":null,"tags":["Course","Python"],"title":"Hw05 of CS61A of UCB(2021-Fall)","uri":"/en/hw05-of-cs61a-of-ucb/#q1-generate-permutations"},{"categories":["Course"],"content":" Q2: Yield Paths Define a generator function path_yielder which takes in a tree t, a value value, and returns a generator object which yields each path from the root of t to a node that has label value. Each path should be represented as a list of the labels along that path in the tree. You may yield the paths in any order. We have provided a skeleton for you. You do not need to use this skeleton, but if your implementation diverges significantly from it, you might want to think about how you can get it to fit the skeleton. The problem asks us to yield all possible path leads us to value. Pay a attention to the hint. The template of the code looks like this: python def path_yielder(t, value): \"*** YOUR CODE HERE ***\" for _______________ in _________________: for _______________ in _________________: \"*** YOUR CODE HERE ***\" You can find it that the template is quite similar to the solution in Q1 if you observe it carefully. First, we should ask ourselves the most important question? - What is the base case? Well, apparently, we meet the base case when we encounter the node with the value label. It can be any branch of the current node, so we need to check each branch. When we find the sub-path, we return it and add the label of the current node. For example, check the example in the doctoring. We want all the paths to lead us to 3. First, we start from the root node(1). It has 2 branches - 2 and 5. In the first branch of 1, we can find 3, at this point we yield [3]. When we backtrack to 2, we get the sub-path - [2, 3]. Finally, we will get [1] + [2, 3] = [1, 2, 3] when we come back to the root node(1) The code shows as below: python def path_yielder(t, value): \"\"\"Yields all possible paths from the root of t to a node with the label value as a list. \u003e\u003e\u003e t1 = tree(1, [tree(2, [tree(3), tree(4, [tree(6)]), tree(5)]), tree(5)]) \u003e\u003e\u003e print_tree(t1) 1 2 3 4 6 5 5 \u003e\u003e\u003e next(path_yielder(t1, 6)) [1, 2, 4, 6] \u003e\u003e\u003e path_to_5 = path_yielder(t1, 5) \u003e\u003e\u003e sorted(list(path_to_5)) [[1, 2, 5], [1, 5]] \u003e\u003e\u003e t2 = tree(0, [tree(2, [t1])]) \u003e\u003e\u003e print_tree(t2) 0 2 1 2 3 4 6 5 5 \u003e\u003e\u003e path_to_2 = path_yielder(t2, 2) \u003e\u003e\u003e sorted(list(path_to_2)) [[0, 2], [0, 2, 1, 2]] \"\"\" if label(t) == value: yield [label(t)] for b in branches(t): for path in path_yielder(b, value): yield [label(t)] + path ","date":"2022-02-22","objectID":"/en/hw05-of-cs61a-of-ucb/:0:2","series":null,"tags":["Course","Python"],"title":"Hw05 of CS61A of UCB(2021-Fall)","uri":"/en/hw05-of-cs61a-of-ucb/#q2-yield-paths"},{"categories":["Course"],"content":" Q3: Preorder Define the function preorder, which takes in a tree as an argument and returns a list of all the entries in the tree in the order that print_tree would print them. The following diagram shows the order that the nodes would get printed, with the arrows representing function calls. Again, we need to solve the problem of the preorder traversal of the tree. We have to recursively visit all nodes of this tree, starting from the root node. Note that we first memorize the value of the root node and then look at its subtrees, and handle such problems recursively. python def preorder(t): \"\"\"Return a list of the entries in this tree in the order that they would be visited by a preorder traversal (see problem description). \u003e\u003e\u003e numbers = tree(1, [tree(2), tree(3, [tree(4), tree(5)]), tree(6, [tree(7)])]) \u003e\u003e\u003e preorder(numbers) [1, 2, 3, 4, 5, 6, 7] \u003e\u003e\u003e preorder(tree(2, [tree(4, [tree(6)])])) [2, 4, 6] \"\"\" result = [] def helper(t): if t is not None: result.append(label(t)) for b in branches(t): helper(b) helper(t) return result ","date":"2022-02-22","objectID":"/en/hw05-of-cs61a-of-ucb/:0:3","series":null,"tags":["Course","Python"],"title":"Hw05 of CS61A of UCB(2021-Fall)","uri":"/en/hw05-of-cs61a-of-ucb/#q3-preorder"},{"categories":["Course"],"content":" Q4: Generate Preorder Similarly to preorder in Question 3, define the function generate_preorder, which takes in a tree as an argument and now instead yields the entries in the tree in the order that print_tree would print them. Hint: How can you modify your implementation of preorder to yield from your recursive calls instead of returning them? The overall solution is very similar to Q3, but now we don‚Äôt need to use a result to store the traversed sequence, because what we want to return is a generator. However, the logic of this algorithm is still the same. If you want to have a deeper understanding of yield from, we can look at this person‚Äôs [this article](http://simeonvisser.com/posts/python-3-using-yield- from-in-generators-part-1.html) python def generate_preorder(t): \"\"\"Yield the entries in this tree in the order that they would be visited by a preorder traversal (see problem description). \u003e\u003e\u003e numbers = tree(1, [tree(2), tree(3, [tree(4), tree(5)]), tree(6, [tree(7)])]) \u003e\u003e\u003e gen = generate_preorder(numbers) \u003e\u003e\u003e next(gen) 1 \u003e\u003e\u003e list(gen) [2, 3, 4, 5, 6, 7] \"\"\" yield label(t) for b in branches(t): yield from generate_preorder(b) ","date":"2022-02-22","objectID":"/en/hw05-of-cs61a-of-ucb/:0:4","series":null,"tags":["Course","Python"],"title":"Hw05 of CS61A of UCB(2021-Fall)","uri":"/en/hw05-of-cs61a-of-ucb/#q4-generate-preorder"},{"categories":["Course"],"content":" Q5: Remainder Generator Like functions, generators can also be higher-order. For this problem, we will be writing remainders_generator, which yields a series of generator objects. remainders_generator takes in an integer m, and yields m different generators. The first generator is a generator of multiples of m, i.e. numbers where the remainder is 0. The second is a generator of natural numbers with remainder 1 when divided by m. The last generator yields natural numbers with remainder m - 1 when divided by m. Hint: To create a generator of infinite natural numbers, you can call the naturals function that‚Äôs provided in the starter code. Hint: Consider defining an inner generator function. Each yielded generator varies only in that the elements of each generator have a particular remainder when divided by m. What does that tell you about the argument(s) that the inner function should take in? If you have no idea what is the generator in python, you will find it difficult to figure out the solution. I will recommend this article After reading the article aforementioned, we may start to try to solve this problem. What the problem wants are m generators, the ith yielded generator yields natural numbers whose remainder is i when divided by m. If we know how to get the first generator, then we know how to get all the generators. I believe that it is easy to write a function that returns natural numbers whose remainder is i when divided by m. With the help of yield, we don‚Äôt need a list to store the numbers(Just like what I did in Q3). python def helper(i, m): num = 1 # loop variable while True: if num % m == i: yield num num += 1 # you can give it a test \u003e\u003e\u003e it = helper(2, 3) \u003e\u003e\u003e next(it) 2 # 2 % 3 == 2 \u003e\u003e\u003e next(it) 5 # 5 % 3 == 2 \u003e\u003e\u003e next(it) 8 # 8 % 3 == 2 Then how can we get a list of generators. for loop !ü§ó python def remainders_generator(m): \"\"\" Yields m generators. The ith yielded generator yields natural numbers whose remainder is i when divided by m. \u003e\u003e\u003e import types \u003e\u003e\u003e [isinstance(gen, types.GeneratorType) for gen in remainders_generator(5)] [True, True, True, True, True] \u003e\u003e\u003e remainders_four = remainders_generator(4) \u003e\u003e\u003e for i in range(4): ... print(\"First 3 natural numbers with remainder {0} when divided by 4:\".format(i)) ... gen = next(remainders_four) ... for _ in range(3): ... print(next(gen)) First 3 natural numbers with remainder 0 when divided by 4: 4 8 12 First 3 natural numbers with remainder 1 when divided by 4: 1 5 9 First 3 natural numbers with remainder 2 when divided by 4: 2 6 10 First 3 natural numbers with remainder 3 when divided by 4: 3 7 11 \"\"\" def helper(i, m): num = 1 # loop variable while True: if num % m == i: yield num num += 1 for i in range(m): yield helper(i, m) ","date":"2022-02-22","objectID":"/en/hw05-of-cs61a-of-ucb/:0:5","series":null,"tags":["Course","Python"],"title":"Hw05 of CS61A of UCB(2021-Fall)","uri":"/en/hw05-of-cs61a-of-ucb/#q5-remainder-generator"},{"categories":["Course"],"content":"the simple solutions for lab06 of CS61A of UCB","date":"2022-02-20","objectID":"/en/lab06-cs61a-of-ucb/","series":null,"tags":["Course","Python"],"title":"Lab06 CS61A of UCB(2021-Fall)","uri":"/en/lab06-cs61a-of-ucb/"},{"categories":["Course"],"content":" Mutability Write a function which takes in a list lst, an argument entry, and another argument elem. This function will check through each item in lst to see if it is equal to entry. Upon finding an item equal to entry, the function should modify the list by placing elem into lst right after the item. At the end of the function, the modified list should be returned. See the doctests for examples on how this function is utilized. Important: Use list mutation to modify the original list. No new lists should be created or returned. Note: If the values passed into entry and elem are equivalent, make sure you‚Äôre not creating an infinitely long list while iterating through it. If you find that your code is taking more than a few seconds to run, the function may be in a loop of inserting new values. Note that we can‚Äôt insert elements when we iterate using for loop. I remember I once saw this in Effective Python. You can find out by debugging yourself. Because the range of i is determined when we use for i in range(len (lst)). But when we insert new values inside the for loop, the list actually becomes longer (but the i is still in the original range). Therefore, elements that exceed the original length will not be accessed. Note that the code below is wrong üôÖ‚Äç‚ôÇÔ∏è python def insert_items(lst, entry, elem): is_the_same = (entry == elem) while True: no_entry = True for i in range(len(lst)): if lst[i] == entry: if i == len(lst) - 1: lst.append(elem) else: lst.insert(i + 1, elem) no_entry = False # avoid infinite loop if is_the_same: i += 1 if no_entry: return lst The correct solution should be to use the while loop with the list.index(x[, start[, end]]) method, the code is as follows: python def insert_items(lst, entry, elem): \"\"\"Inserts elem into lst after each occurence of entry and then returns lst. \u003e\u003e\u003e test_lst = [1, 5, 8, 5, 2, 3] \u003e\u003e\u003e new_lst = insert_items(test_lst, 5, 7) \u003e\u003e\u003e new_lst [1, 5, 7, 8, 5, 7, 2, 3] \u003e\u003e\u003e double_lst = [1, 2, 1, 2, 3, 3] \u003e\u003e\u003e double_lst = insert_items(double_lst, 3, 4) \u003e\u003e\u003e double_lst [1, 2, 1, 2, 3, 4, 3, 4] \u003e\u003e\u003e large_lst = [1, 4, 8] \u003e\u003e\u003e large_lst2 = insert_items(large_lst, 4, 4) \u003e\u003e\u003e large_lst2 [1, 4, 4, 8] \u003e\u003e\u003e large_lst3 = insert_items(large_lst2, 4, 6) \u003e\u003e\u003e large_lst3 [1, 4, 6, 4, 6, 8] \u003e\u003e\u003e large_lst3 is large_lst True \u003e\u003e\u003e # Ban creating new lists \u003e\u003e\u003e from construct_check import check \u003e\u003e\u003e check(HW_SOURCE_FILE, 'insert_items', ... ['List', 'ListComp', 'Slice']) True \"\"\" pos, cnt = 0, 0 for i in lst: if i == entry: cnt += 1 while cnt \u003e 0: idx = lst.index(entry, pos) pos = idx + 1 if idx == len(lst) - 1: lst.append(elem) else: lst.insert(idx + 1, elem) cnt -= 1 return lst ","date":"2022-02-20","objectID":"/en/lab06-cs61a-of-ucb/:1:0","series":null,"tags":["Course","Python"],"title":"Lab06 CS61A of UCB(2021-Fall)","uri":"/en/lab06-cs61a-of-ucb/#mutability"},{"categories":["Course"],"content":" Iterators ","date":"2022-02-20","objectID":"/en/lab06-cs61a-of-ucb/:2:0","series":null,"tags":["Course","Python"],"title":"Lab06 CS61A of UCB(2021-Fall)","uri":"/en/lab06-cs61a-of-ucb/#iterators"},{"categories":["Course"],"content":" Q4: Count Occurrences Implement count_occurrences, which takes in an iterator t and returns the number of times the value x appears in the first n elements of t. A value appears in a sequence of elements if it is equal to an entry in the sequence. Note: You can assume that t will have at least n elements. This question is mainly to let us learn to use the two functions: iter and next. We can use while n \u003e 0 to control access to only the first n elements. We will iterate the range while counting occurrences. python def count_occurrences(t, n, x): \"\"\"Return the number of times that x appears in the first n elements of iterator t. \u003e\u003e\u003e s = iter([10, 9, 10, 9, 9, 10, 8, 8, 8, 7]) \u003e\u003e\u003e count_occurrences(s, 10, 9) 3 \u003e\u003e\u003e s2 = iter([10, 9, 10, 9, 9, 10, 8, 8, 8, 7]) \u003e\u003e\u003e count_occurrences(s2, 3, 10) 2 \u003e\u003e\u003e s = iter([3, 2, 2, 2, 1, 2, 1, 4, 4, 5, 5, 5]) \u003e\u003e\u003e count_occurrences(s, 1, 3) 1 \u003e\u003e\u003e count_occurrences(s, 4, 2) 3 \u003e\u003e\u003e next(s) 2 \u003e\u003e\u003e s2 = iter([4, 1, 6, 6, 7, 7, 8, 8, 2, 2, 2, 5]) \u003e\u003e\u003e count_occurrences(s2, 6, 6) 2 \"\"\" it = iter(t) cnt = 0 while n \u003e 0: val = next(it) if val == x: cnt += 1 n -= 1 return cnt ","date":"2022-02-20","objectID":"/en/lab06-cs61a-of-ucb/:2:1","series":null,"tags":["Course","Python"],"title":"Lab06 CS61A of UCB(2021-Fall)","uri":"/en/lab06-cs61a-of-ucb/#q4-count-occurrences"},{"categories":["Course"],"content":" Q5: Repeated Implement repeated, which takes in an iterator t and returns the first value in t that appears k times in a row. Note: You can assume that the iterator t will have a value that appears at least k times in a row. If you are receiving a StopIteration, your repeated function is likely not identifying the correct value. Your implementation should iterate through the items in a way such that if the same iterator is passed into repeated twice, it should continue in the second call at the point it left off in the first. An example of this behavior is in the doctests. We address two important issues in this problem: How to find consecutive k values? We need to set last_val to remember what the previous value was, so that it can be compared with the current value(while we iterate the list). How to ensure that the next call will start from the point it left off in the first? If you have followed the course carefully, you may remember how to do it. We should use a higher-order function, define another function in repeated and bind the iterator to this nested function. This way we can guarantee that we can start from the previous position every time. If you forget, you can look at this [link](http://composingprograms.com/pages/24-mutable -data.html)(2.4.4 Local state) python def repeated(t, k): \"\"\"Return the first value in iterator T that appears K times in a row. Iterate through the items such that if the same iterator is passed into the function twice, it continues in the second call at the point it left off in the first. \u003e\u003e\u003e s = iter([10, 9, 10, 9, 9, 10, 8, 8, 8, 7]) \u003e\u003e\u003e repeated(s, 2) 9 \u003e\u003e\u003e s2 = iter([10, 9, 10, 9, 9, 10, 8, 8, 8, 7]) \u003e\u003e\u003e repeated(s2, 3) 8 \u003e\u003e\u003e s = iter([3, 2, 2, 2, 1, 2, 1, 4, 4, 5, 5, 5]) \u003e\u003e\u003e repeated(s, 3) 2 \u003e\u003e\u003e repeated(s, 3) 5 \u003e\u003e\u003e s2 = iter([4, 1, 6, 6, 7, 7, 8, 8, 2, 2, 2, 5]) \u003e\u003e\u003e repeated(s2, 3) 2 \"\"\" assert k \u003e 1 last_val, it = None, iter(t) def helper(k): nonlocal last_val nonlocal it cnt = 0 while True: val = next(it) if last_val is None or val != last_val: last_val, cnt = val, 1 else: cnt += 1 if cnt == k: return val return helper(k) ","date":"2022-02-20","objectID":"/en/lab06-cs61a-of-ucb/:2:2","series":null,"tags":["Course","Python"],"title":"Lab06 CS61A of UCB(2021-Fall)","uri":"/en/lab06-cs61a-of-ucb/#q5-repeated"},{"categories":["Course"],"content":"The simple solutions of hw04 of CS61A of UCB","date":"2022-02-20","objectID":"/en/hw04-of-cs61a-of-ucb/","series":null,"tags":["Course","Python"],"title":"Hw04 - CS61A of UCB(2021-Fall)","uri":"/en/hw04-of-cs61a-of-ucb/"},{"categories":["Course"],"content":" Mobiles ","date":"2022-02-20","objectID":"/en/hw04-of-cs61a-of-ucb/:1:0","series":null,"tags":["Course","Python"],"title":"Hw04 - CS61A of UCB(2021-Fall)","uri":"/en/hw04-of-cs61a-of-ucb/#mobiles"},{"categories":["Course"],"content":" Q2: Weights Implement the planet data abstraction by completing the planet constructor and the size selector so that a planet is represented using a two-element list where the first element is the string 'planet' and the second element is its size. From the description, we can know what is planet. It is a ['planet', size]. Then we can take a look at the mobile function, the solution is quite similar. python def planet(size): \"\"\"Construct a planet of some size.\"\"\" assert size \u003e 0 return ['planet', size] def size(w): \"\"\"Select the size of a planet.\"\"\" assert is_planet(w), 'must call size on a planet' return w[1] ","date":"2022-02-20","objectID":"/en/hw04-of-cs61a-of-ucb/:1:1","series":null,"tags":["Course","Python"],"title":"Hw04 - CS61A of UCB(2021-Fall)","uri":"/en/hw04-of-cs61a-of-ucb/#q2-weights"},{"categories":["Course"],"content":" Q3: Balanced Implement the balanced function, which returns whether m is a balanced mobile. A mobile is balanced if both of the following conditions are met: The torque applied by its left arm is equal to that applied by its right arm. The torque of the left arm is the length of the left rod multiplied by the total weight hanging from that rod. Likewise for the right. For example, if the left arm has a length of 5, and there is a mobile hanging at the end of the left arm of weight 10, the torque on the left side of our mobile is 50. Each of the mobiles hanging at the end of its arms is balanced. Planets themselves are balanced, as there is nothing hanging off of them. This problem is a little tricky. We need to solve this problem recursively. We can call a mobile is balanced if: It is a planet. THE BASE CASE!! It is a arm and the total_weight(left_arm) == total_weight(right_arm). And, the sub-mobile itself should be balanced The key: distinguish arm, planet, mobile these 3 concepts. üò¢ python def balanced(m): \"\"\"Return whether m is balanced. \u003e\u003e\u003e t, u, v = examples() \u003e\u003e\u003e balanced(t) True \u003e\u003e\u003e balanced(v) True \u003e\u003e\u003e w = mobile(arm(3, t), arm(2, u)) \u003e\u003e\u003e balanced(w) False \u003e\u003e\u003e balanced(mobile(arm(1, v), arm(1, w))) False \u003e\u003e\u003e balanced(mobile(arm(1, w), arm(1, v))) False \u003e\u003e\u003e from construct_check import check \u003e\u003e\u003e # checking for abstraction barrier violations by banning indexing \u003e\u003e\u003e check(HW_SOURCE_FILE, 'balanced', ['Index']) True \"\"\" # planet is balanced if is_planet(m): return True left_arm, right_arm = left(m), right(m) # end(...arm) will is a mobile or a planet left_val = length(left_arm) * total_weight(end(left_arm)) right_val = length(right_arm) * total_weight(end(right_arm)) return left_val == right_val and balanced(end(left_arm)) and balanced(end(right_arm)) ","date":"2022-02-20","objectID":"/en/hw04-of-cs61a-of-ucb/:1:2","series":null,"tags":["Course","Python"],"title":"Hw04 - CS61A of UCB(2021-Fall)","uri":"/en/hw04-of-cs61a-of-ucb/#q3-balanced"},{"categories":["Course"],"content":" Q4: Totals Implement totals_tree, which takes in a mobile or planet and returns a tree whose root is the total weight of the input. For a planet, totals_tree should return a leaf. For a mobile, totals_tree should return a tree whose label is that mobile‚Äôs total weight, and whose branches are totals_trees for the ends of its arms. As a reminder, the description of the tree data abstraction can be found here. What we want to do is convert the mobile into a tree. The base case is to make a leaf when we encounter the planet, otherwise, we make a sub-tree instead. python def totals_tree(m): \"\"\"Return a tree representing the mobile with its total weight at the root. \u003e\u003e\u003e t, u, v = examples() \u003e\u003e\u003e print_tree(totals_tree(t)) 3 2 1 \u003e\u003e\u003e print_tree(totals_tree(u)) 6 1 5 3 2 \u003e\u003e\u003e print_tree(totals_tree(v)) 9 3 2 1 6 1 5 3 2 \u003e\u003e\u003e from construct_check import check \u003e\u003e\u003e # checking for abstraction barrier violations by banning indexing \u003e\u003e\u003e check(HW_SOURCE_FILE, 'totals_tree', ['Index']) True \"\"\" if is_planet(m): return tree(size(m)) return tree(total_weight(m), [totals_tree(i) for i in [end(left(m)), end(right(m))]]) ","date":"2022-02-20","objectID":"/en/hw04-of-cs61a-of-ucb/:1:3","series":null,"tags":["Course","Python"],"title":"Hw04 - CS61A of UCB(2021-Fall)","uri":"/en/hw04-of-cs61a-of-ucb/#q4-totals"},{"categories":["Course"],"content":" More trees ","date":"2022-02-20","objectID":"/en/hw04-of-cs61a-of-ucb/:2:0","series":null,"tags":["Course","Python"],"title":"Hw04 - CS61A of UCB(2021-Fall)","uri":"/en/hw04-of-cs61a-of-ucb/#more-trees"},{"categories":["Course"],"content":" Q5: Replace Loki at Leaf Define replace_loki_at_leaf, which takes a tree t and a value lokis_replacement. replace_loki_at_leaf returns a new tree that‚Äôs the same as t except that every leaf label equal to \"loki\" has been replaced with lokis_replacement. If you want to learn about the Norse mythology referenced in this problem, you can read about it here. The base case is the leaf node. We need to check if its label is equal to ‚Äôloki‚Äô. If it is the truth, we will make a new leaf, otherwise, we will just return the original leaf. python def replace_loki_at_leaf(t, lokis_replacement): \"\"\"Returns a new tree where every leaf value equal to \"loki\" has been replaced with lokis_replacement. \u003e\u003e\u003e yggdrasil = tree('odin', ... [tree('balder', ... [tree('loki'), ... tree('freya')]), ... tree('frigg', ... [tree('loki')]), ... tree('loki', ... [tree('sif'), ... tree('loki')]), ... tree('loki')]) \u003e\u003e\u003e laerad = copy_tree(yggdrasil) # copy yggdrasil for testing purposes \u003e\u003e\u003e print_tree(replace_loki_at_leaf(yggdrasil, 'freya')) odin balder freya freya frigg freya loki sif freya freya \u003e\u003e\u003e laerad == yggdrasil # Make sure original tree is unmodified True \"\"\" if is_leaf(t): if label(t) == 'loki': return tree(lokis_replacement) return t return tree(label(t), [replace_loki_at_leaf(b, lokis_replacement) for b in branches(t)]) ","date":"2022-02-20","objectID":"/en/hw04-of-cs61a-of-ucb/:2:1","series":null,"tags":["Course","Python"],"title":"Hw04 - CS61A of UCB(2021-Fall)","uri":"/en/hw04-of-cs61a-of-ucb/#q5-replace-loki-at-leaf"},{"categories":["Course"],"content":" Q6: Has Path Write a function has_path that takes in a tree t and a string word. It returns True if there is a path that starts from the root where the entries along the path spell out the word, and False otherwise. (This data structure is called a trie, and it has a lot of cool applications, such as autocomplete). You may assume that every node‚Äôs labelis exactly one character. What is the base case ? We need to memorize the current word along the path. For example, we got label(t) when we start from the root of the tree(h). When we pay a visit to the tree('i')(the first branch), the current word will be h + i = hi. So we need to define a helper function. The base case is either the current word is equal to the target(word) or the current word is not in target(word), which means we don‚Äôt need to go deeper into this tree How to break down the current problem into simpler ones ? We use any in python to check if any of the branches contain the word we want. python def has_path(t, word): \"\"\"Return whether there is a path in a tree where the entries along the path spell out a particular word. \u003e\u003e\u003e greetings = tree('h', [tree('i'), ... tree('e', [tree('l', [tree('l', [tree('o')])]), ... tree('y')])]) \u003e\u003e\u003e print_tree(greetings) h i e l l o y \u003e\u003e\u003e has_path(greetings, 'h') True \u003e\u003e\u003e has_path(greetings, 'i') False \u003e\u003e\u003e has_path(greetings, 'hi') True \u003e\u003e\u003e has_path(greetings, 'hello') True \u003e\u003e\u003e has_path(greetings, 'hey') True \u003e\u003e\u003e has_path(greetings, 'bye') False \u003e\u003e\u003e has_path(greetings, 'hint') False \"\"\" assert len(word) \u003e 0, 'no path for empty word.' def helper(t, cur): if cur == word: return True if cur not in word: return False return any([helper(b, cur + label(b)) for b in branches(t)]) return helper(t, label(t)) ","date":"2022-02-20","objectID":"/en/hw04-of-cs61a-of-ucb/:2:2","series":null,"tags":["Course","Python"],"title":"Hw04 - CS61A of UCB(2021-Fall)","uri":"/en/hw04-of-cs61a-of-ucb/#q6-has-path"},{"categories":["Course"],"content":" Trees ","date":"2022-02-20","objectID":"/en/hw04-of-cs61a-of-ucb/:3:0","series":null,"tags":["Course","Python"],"title":"Hw04 - CS61A of UCB(2021-Fall)","uri":"/en/hw04-of-cs61a-of-ucb/#trees"},{"categories":["Course"],"content":" Q7: Preorder Define the function preorder, which takes in a tree as an argument and returns a list of all the entries in the tree in the order that print_tree would print them. The following diagram shows the order that the nodes would get printed, with the arrows representing function calls. The preorder function is one of the basic methods when we want to visit every node in a tree. We need to memorize the label of the root before we visit its sub-tree. python def preorder(t): \"\"\"Return a list of the entries in this tree in the order that they would be visited by a preorder traversal (see problem description). \u003e\u003e\u003e numbers = tree(1, [tree(2), tree(3, [tree(4), tree(5)]), tree(6, [tree(7)])]) \u003e\u003e\u003e preorder(numbers) [1, 2, 3, 4, 5, 6, 7] \u003e\u003e\u003e preorder(tree(2, [tree(4, [tree(6)])])) [2, 4, 6] \"\"\" result = [] def helper(t): if t is not None: result.append(label(t)) for b in branches(t): helper(b) helper(t) return result ","date":"2022-02-20","objectID":"/en/hw04-of-cs61a-of-ucb/:3:1","series":null,"tags":["Course","Python"],"title":"Hw04 - CS61A of UCB(2021-Fall)","uri":"/en/hw04-of-cs61a-of-ucb/#q7-preorder"},{"categories":["Course"],"content":" Data Abstraction ","date":"2022-02-20","objectID":"/en/hw04-of-cs61a-of-ucb/:4:0","series":null,"tags":["Course","Python"],"title":"Hw04 - CS61A of UCB(2021-Fall)","uri":"/en/hw04-of-cs61a-of-ucb/#data-abstraction"},{"categories":["Course"],"content":" Q8: Interval Abstraction Acknowledgements. This interval arithmetic example is based on a classic problem from Structure and Interpretation of Computer Programs, Section 2.1.4. Introduction. Alyssa P. Hacker is designing a system to help people solve engineering problems. One feature she wants to provide in her system is the ability to manipulate inexact quantities (such as measurements from physical devices) with known precision, so that when computations are done with such approximate quantities the results will be numbers of known precision. For example, if a measured quantity x lies between two numbers a and b, Alyssa would like her system to use this range in computations involving x. Alyssa‚Äôs idea is to implement interval arithmetic as a set of arithmetic operations for combining ‚Äúintervals‚Äù (objects that represent the range of possible values of an inexact quantity). The result of adding, subracting, multiplying, or dividing two intervals is also an interval, one that represents the range of the result. Alyssa suggests the existence of an abstraction called an ‚Äúinterval‚Äù that has two endpoints: a lower bound and an upper bound. She also presumes that, given the endpoints of an interval, she can create the interval using data abstraction. Using this constructor and the appropriate selectors, she defines the following operations: Alyssa‚Äôs program is incomplete because she has not specified the implementation of the interval abstraction. She has implemented the constructor for you; fill in the implementation of the selectors. The calculation system of this question is actually used to calculate the resistance. We know that there will be tolerance in the resistor (such as $\\pm5%$), so the real resistance value should be in an interval. This is the interval indicates. The interval is just a list with size 2. To get the lower bound and the upper bound. We just need to return x[0] or x[1] python def interval(a, b): \"\"\"Construct an interval from a to b.\"\"\" assert a \u003c= b, 'Lower bound cannot be greater than upper bound' return [a, b] def lower_bound(x): \"\"\"Return the lower bound of interval x.\"\"\" return x[0] def upper_bound(x): \"\"\"Return the upper bound of interval x.\"\"\" return x[1] ","date":"2022-02-20","objectID":"/en/hw04-of-cs61a-of-ucb/:4:1","series":null,"tags":["Course","Python"],"title":"Hw04 - CS61A of UCB(2021-Fall)","uri":"/en/hw04-of-cs61a-of-ucb/#q8-interval-abstraction"},{"categories":["Course"],"content":" Q9: Interval Arithmetic After implementing the abstraction, Alyssa decided to implement a few interval arithmetic functions. This is her current implementation for interval multiplication. Unfortunately there are some data abstraction violations, so your task is to fix this code before someone sets it on fire. python def mul_interval(x, y): \"\"\"Return the interval that contains the product of any value in x and any value in y.\"\"\" p1 = x[0] * y[0] p2 = x[0] * y[1] p3 = x[1] * y[0] p4 = x[1] * y[1] return [min(p1, p2, p3, p4), max(p1, p2, p3, p4)] There are many data abstraction violations in mul_interval. We can‚Äôt use x[0] or x[1] to get the lower bound and the upper bound. We should use the function lower_bound() and the upper_bound() instead. In addition, we can‚Äôt use [...] to make an interval. That‚Äôs a violation too! python def mul_interval(x, y): \"\"\"Return the interval that contains the product of any value in x and any value in y.\"\"\" p1 = lower_bound(x) * lower_bound(y) p2 = lower_bound(x) * upper_bound(y) p3 = upper_bound(x) * lower_bound(y) p4 = upper_bound(x) * upper_bound(y) return interval(min(p1, p2, p3, p4), max(p1, p2, p3, p4)) Interval Subtraction Using a similar approach as mul_interval and add_interval, define a subtraction function for intervals. If you find yourself repeating code, see if you can reuse functions that have already been implemented. This solution is almost identical to the mul_interval. If you are using vim as your editor, you just need to copy the content of mul_interval and use visual mode to select * then press r- to substitute them. python def sub_interval(x, y): \"\"\"Return the interval that contains the difference between any value in x and any value in y.\"\"\" p1 = lower_bound(x) - lower_bound(y) p2 = lower_bound(x) - upper_bound(y) p3 = upper_bound(x) - lower_bound(y) p4 = upper_bound(x) - upper_bound(y) return interval(min(p1, p2, p3, p4), max(p1, p2, p3, p4)) Interval Division Alyssa implements division below by multiplying by the reciprocal of y. A systems programmer looks over Alyssa‚Äôs shoulder and comments that it is not clear what it means to divide by an interval that spans zero. Add an assertstatement to Alyssa‚Äôs code to ensure that no such interval is used as a divisor: To avoid the divisor span zero, all we have to do is check if lower_bound(y) \u003e 0 ü§ó python def div_interval(x, y): \"\"\"Return the interval that contains the quotient of any value in x divided by any value in y. Division is implemented as the multiplication of x by the reciprocal of y.\"\"\" assert lower_bound(y) \u003e 0, \"AssertionError!\" reciprocal_y = interval(1 / upper_bound(y), 1 / lower_bound(y)) return mul_interval(x, reciprocal_y) ","date":"2022-02-20","objectID":"/en/hw04-of-cs61a-of-ucb/:4:2","series":null,"tags":["Course","Python"],"title":"Hw04 - CS61A of UCB(2021-Fall)","uri":"/en/hw04-of-cs61a-of-ucb/#q9-interval-arithmetic"},{"categories":["Course"],"content":" Q9: Interval Arithmetic After implementing the abstraction, Alyssa decided to implement a few interval arithmetic functions. This is her current implementation for interval multiplication. Unfortunately there are some data abstraction violations, so your task is to fix this code before someone sets it on fire. python def mul_interval(x, y): \"\"\"Return the interval that contains the product of any value in x and any value in y.\"\"\" p1 = x[0] * y[0] p2 = x[0] * y[1] p3 = x[1] * y[0] p4 = x[1] * y[1] return [min(p1, p2, p3, p4), max(p1, p2, p3, p4)] There are many data abstraction violations in mul_interval. We can‚Äôt use x[0] or x[1] to get the lower bound and the upper bound. We should use the function lower_bound() and the upper_bound() instead. In addition, we can‚Äôt use [...] to make an interval. That‚Äôs a violation too! python def mul_interval(x, y): \"\"\"Return the interval that contains the product of any value in x and any value in y.\"\"\" p1 = lower_bound(x) * lower_bound(y) p2 = lower_bound(x) * upper_bound(y) p3 = upper_bound(x) * lower_bound(y) p4 = upper_bound(x) * upper_bound(y) return interval(min(p1, p2, p3, p4), max(p1, p2, p3, p4)) Interval Subtraction Using a similar approach as mul_interval and add_interval, define a subtraction function for intervals. If you find yourself repeating code, see if you can reuse functions that have already been implemented. This solution is almost identical to the mul_interval. If you are using vim as your editor, you just need to copy the content of mul_interval and use visual mode to select * then press r- to substitute them. python def sub_interval(x, y): \"\"\"Return the interval that contains the difference between any value in x and any value in y.\"\"\" p1 = lower_bound(x) - lower_bound(y) p2 = lower_bound(x) - upper_bound(y) p3 = upper_bound(x) - lower_bound(y) p4 = upper_bound(x) - upper_bound(y) return interval(min(p1, p2, p3, p4), max(p1, p2, p3, p4)) Interval Division Alyssa implements division below by multiplying by the reciprocal of y. A systems programmer looks over Alyssa‚Äôs shoulder and comments that it is not clear what it means to divide by an interval that spans zero. Add an assertstatement to Alyssa‚Äôs code to ensure that no such interval is used as a divisor: To avoid the divisor span zero, all we have to do is check if lower_bound(y) \u003e 0 ü§ó python def div_interval(x, y): \"\"\"Return the interval that contains the quotient of any value in x divided by any value in y. Division is implemented as the multiplication of x by the reciprocal of y.\"\"\" assert lower_bound(y) \u003e 0, \"AssertionError!\" reciprocal_y = interval(1 / upper_bound(y), 1 / lower_bound(y)) return mul_interval(x, reciprocal_y) ","date":"2022-02-20","objectID":"/en/hw04-of-cs61a-of-ucb/:4:2","series":null,"tags":["Course","Python"],"title":"Hw04 - CS61A of UCB(2021-Fall)","uri":"/en/hw04-of-cs61a-of-ucb/#interval-subtraction"},{"categories":["Course"],"content":" Q9: Interval Arithmetic After implementing the abstraction, Alyssa decided to implement a few interval arithmetic functions. This is her current implementation for interval multiplication. Unfortunately there are some data abstraction violations, so your task is to fix this code before someone sets it on fire. python def mul_interval(x, y): \"\"\"Return the interval that contains the product of any value in x and any value in y.\"\"\" p1 = x[0] * y[0] p2 = x[0] * y[1] p3 = x[1] * y[0] p4 = x[1] * y[1] return [min(p1, p2, p3, p4), max(p1, p2, p3, p4)] There are many data abstraction violations in mul_interval. We can‚Äôt use x[0] or x[1] to get the lower bound and the upper bound. We should use the function lower_bound() and the upper_bound() instead. In addition, we can‚Äôt use [...] to make an interval. That‚Äôs a violation too! python def mul_interval(x, y): \"\"\"Return the interval that contains the product of any value in x and any value in y.\"\"\" p1 = lower_bound(x) * lower_bound(y) p2 = lower_bound(x) * upper_bound(y) p3 = upper_bound(x) * lower_bound(y) p4 = upper_bound(x) * upper_bound(y) return interval(min(p1, p2, p3, p4), max(p1, p2, p3, p4)) Interval Subtraction Using a similar approach as mul_interval and add_interval, define a subtraction function for intervals. If you find yourself repeating code, see if you can reuse functions that have already been implemented. This solution is almost identical to the mul_interval. If you are using vim as your editor, you just need to copy the content of mul_interval and use visual mode to select * then press r- to substitute them. python def sub_interval(x, y): \"\"\"Return the interval that contains the difference between any value in x and any value in y.\"\"\" p1 = lower_bound(x) - lower_bound(y) p2 = lower_bound(x) - upper_bound(y) p3 = upper_bound(x) - lower_bound(y) p4 = upper_bound(x) - upper_bound(y) return interval(min(p1, p2, p3, p4), max(p1, p2, p3, p4)) Interval Division Alyssa implements division below by multiplying by the reciprocal of y. A systems programmer looks over Alyssa‚Äôs shoulder and comments that it is not clear what it means to divide by an interval that spans zero. Add an assertstatement to Alyssa‚Äôs code to ensure that no such interval is used as a divisor: To avoid the divisor span zero, all we have to do is check if lower_bound(y) \u003e 0 ü§ó python def div_interval(x, y): \"\"\"Return the interval that contains the quotient of any value in x divided by any value in y. Division is implemented as the multiplication of x by the reciprocal of y.\"\"\" assert lower_bound(y) \u003e 0, \"AssertionError!\" reciprocal_y = interval(1 / upper_bound(y), 1 / lower_bound(y)) return mul_interval(x, reciprocal_y) ","date":"2022-02-20","objectID":"/en/hw04-of-cs61a-of-ucb/:4:2","series":null,"tags":["Course","Python"],"title":"Hw04 - CS61A of UCB(2021-Fall)","uri":"/en/hw04-of-cs61a-of-ucb/#interval-division"},{"categories":["Course"],"content":" Q10: Par Diff After considerable work, Alyssa P. Hacker delivers her finished system. Several years later, after she has forgotten all about it, she gets a frenzied call from an irate user, Lem E. Tweakit. It seems that Lem has noticed that theformula for parallel resistors can be written in two algebraically equivalent ways: text par1(r1, r2) = (r1 * r2) / (r1 + r2) or text par2(r1, r2) = 1 / (1/r1 + 1/r2) He has written the following two programs, each of which computes the parallel_resistors formula differently: python def par2(r1, r2): one = interval(1, 1) rep_r1 = div_interval(one, r1) rep_r2 = div_interval(one, r2) return div_interval(one, add_interval(rep_r1, rep_r2)) Lem points out that Alyssa‚Äôs program gives different answers for the two ways of computing. Find two intervals r1 and r2 that demonstrate the difference in behavior between par1 and par2 when passed into each of the two functions. Demonstrate that Lem is right. Investigate the behavior of the system on a variety of arithmetic expressions. Make some intervals r1 and r2, and show that par1 and par2 can give different results. If you want to understand the mechanism why this happens, you may check this link python def check_par(): \"\"\"Return two intervals that give different results for parallel resistors. \u003e\u003e\u003e r1, r2 = check_par() \u003e\u003e\u003e x = par1(r1, r2) \u003e\u003e\u003e y = par2(r1, r2) \u003e\u003e\u003e lower_bound(x) != lower_bound(y) or upper_bound(x) != upper_bound(y) True \"\"\" r1 = interval(5, 7) r2 = interval(5, 7) return r1, r2 ","date":"2022-02-20","objectID":"/en/hw04-of-cs61a-of-ucb/:4:3","series":null,"tags":["Course","Python"],"title":"Hw04 - CS61A of UCB(2021-Fall)","uri":"/en/hw04-of-cs61a-of-ucb/#q10-par-diff"},{"categories":["Course"],"content":"the simple solutions for lab05 of CS61A of UCB","date":"2022-02-19","objectID":"/en/lab05-cs61a-of-ucb/","series":null,"tags":["Course","Python"],"title":"Lab05 CS61A of UCB(2021-Fall)","uri":"/en/lab05-cs61a-of-ucb/"},{"categories":["Course"],"content":" Lists ","date":"2022-02-19","objectID":"/en/lab05-cs61a-of-ucb/:1:0","series":null,"tags":["Course","Python"],"title":"Lab05 CS61A of UCB(2021-Fall)","uri":"/en/lab05-cs61a-of-ucb/#lists"},{"categories":["Course"],"content":" Q1: Factors List Write factors_list, which takes a number n and returns a list of its factors in ascending order. We can know such a basic mathematical fact: the factor of a number can only be up to half of it (when the number is even). So we use for i in range(1, n // 2 + 1) python def factors_list(n): \"\"\"Return a list containing all the numbers that divide `n` evenly, except for the number itself. Make sure the list is in ascending order. \u003e\u003e\u003e factors_list(6) [1, 2, 3] \u003e\u003e\u003e factors_list(8) [1, 2, 4] \u003e\u003e\u003e factors_list(28) [1, 2, 4, 7, 14] \"\"\" all_factors = [] # the biggest number which can divide `n` evenly will be `n // 2` for i in range(1, n // 2 + 1): if n % i == 0: all_factors.append(i) return all_factors ","date":"2022-02-19","objectID":"/en/lab05-cs61a-of-ucb/:1:1","series":null,"tags":["Course","Python"],"title":"Lab05 CS61A of UCB(2021-Fall)","uri":"/en/lab05-cs61a-of-ucb/#q1-factors-list"},{"categories":["Course"],"content":" Q2: Flatten Write a function flatten that takes a list and ‚Äúflattens‚Äù it. The list could be a deep list, meaning that there could be a multiple layers of nesting within the list. For example, one use case of flatten could be the following: text \u003e\u003e\u003e lst = [1, [[2], 3], 4, [5, 6]] \u003e\u003e\u003e flatten(lst) [1, 2, 3, 4, 5, 6] Make sure your solution does not mutate the input list. Apparently, we can solve this probelm recursively. For nested list, we need to recursively decompose it. What is the base case ? If we get a empty list then we return [] How to break down the current problem into simpler ones ? That is how we can reduce the size of the problem, we can try to process the element in the first position of the nested list each time, depending on whether they are list type, which can break down this probelm into 2 cases. Finally, the code will be like: python def flatten(s): \"\"\"Returns a flattened version of list s. \u003e\u003e\u003e flatten([1, 2, 3]) # normal list [1, 2, 3] \u003e\u003e\u003e x = [1, [2, 3], 4] # deep list \u003e\u003e\u003e flatten(x) [1, 2, 3, 4] \u003e\u003e\u003e x # Ensure x is not mutated [1, [2, 3], 4] \u003e\u003e\u003e x = [[1, [1, 1]], 1, [1, 1]] # deep list \u003e\u003e\u003e flatten(x) [1, 1, 1, 1, 1, 1] \u003e\u003e\u003e x [[1, [1, 1]], 1, [1, 1]] \"\"\" if s == []: return [] elif type(s[0]) == list: return flatten(s[0]) + flatten(s[1:]) else: return s[:1] + flatten(s[1:]) ","date":"2022-02-19","objectID":"/en/lab05-cs61a-of-ucb/:1:2","series":null,"tags":["Course","Python"],"title":"Lab05 CS61A of UCB(2021-Fall)","uri":"/en/lab05-cs61a-of-ucb/#q2-flatten"},{"categories":["Course"],"content":" Data Abstraction ","date":"2022-02-19","objectID":"/en/lab05-cs61a-of-ucb/:2:0","series":null,"tags":["Course","Python"],"title":"Lab05 CS61A of UCB(2021-Fall)","uri":"/en/lab05-cs61a-of-ucb/#data-abstraction"},{"categories":["Course"],"content":" Q3: Distance We will now implement the function distance, which computes the distance between two city objects. Recall that the distance between two coordinate pairs (x1, y1) and (x2, y2) can be found by calculating the sqrt of (x1 - x2)**2 + (y1 - y2)**2. We have already imported sqrt for your convenience. Use the latitude and longitude of a city as its coordinates; you‚Äôll need to use the selectors to access this info! We just need to call get_lat and get_lon on the arguments to get the value and then calculate it ü§ó python def distance(city_a, city_b): \"\"\" \u003e\u003e\u003e city_a = make_city('city_a', 0, 1) \u003e\u003e\u003e city_b = make_city('city_b', 0, 2) \u003e\u003e\u003e distance(city_a, city_b) 1.0 \u003e\u003e\u003e city_c = make_city('city_c', 6.5, 12) \u003e\u003e\u003e city_d = make_city('city_d', 2.5, 15) \u003e\u003e\u003e distance(city_c, city_d) 5.0 \"\"\" x = (get_lat(city_a) - get_lat(city_b)) ** 2 y = (get_lon(city_a) - get_lon(city_b)) ** 2 return sqrt(x + y) ","date":"2022-02-19","objectID":"/en/lab05-cs61a-of-ucb/:2:1","series":null,"tags":["Course","Python"],"title":"Lab05 CS61A of UCB(2021-Fall)","uri":"/en/lab05-cs61a-of-ucb/#q3-distance"},{"categories":["Course"],"content":" Q4: Closer city Next, implement closer_city, a function that takes a latitude, longitude, and two cities, and returns the name of the city that is relatively closer to the provided latitude and longitude. You may only use the selectors and constructors introduced above and the distance function you just defined for this question. Hint: How can you use your distance function to find the distance between the given location and each of the given cities? According to the Hint and our distance function wrote in Q3, we know that we should build a virtual city based on lat and lon, and then use the distance function to calculate and compare the distance. This saves you from writing a lot of repetitive code. python def closer_city(lat, lon, city_a, city_b): \"\"\" Returns the name of either city_a or city_b, whichever is closest to coordinate (lat, lon). If the two cities are the same distance away from the coordinate, consider city_b to be the closer city. \u003e\u003e\u003e berkeley = make_city('Berkeley', 37.87, 112.26) \u003e\u003e\u003e stanford = make_city('Stanford', 34.05, 118.25) \u003e\u003e\u003e closer_city(38.33, 121.44, berkeley, stanford) 'Stanford' \u003e\u003e\u003e bucharest = make_city('Bucharest', 44.43, 26.10) \u003e\u003e\u003e vienna = make_city('Vienna', 48.20, 16.37) \u003e\u003e\u003e closer_city(41.29, 174.78, bucharest, vienna) 'Bucharest' \"\"\" tmp = make_city('tmp', lat, lon) if distance(tmp, city_a) \u003c distance(tmp, city_b): return get_name(city_a) else: return get_name(city_b) ","date":"2022-02-19","objectID":"/en/lab05-cs61a-of-ucb/:2:2","series":null,"tags":["Course","Python"],"title":"Lab05 CS61A of UCB(2021-Fall)","uri":"/en/lab05-cs61a-of-ucb/#q4-closer-city"},{"categories":["Course"],"content":" Trees ","date":"2022-02-19","objectID":"/en/lab05-cs61a-of-ucb/:3:0","series":null,"tags":["Course","Python"],"title":"Lab05 CS61A of UCB(2021-Fall)","uri":"/en/lab05-cs61a-of-ucb/#trees"},{"categories":["Course"],"content":" Q6: Finding Berries! The squirrels on campus need your help! There are a lot of trees on campus and the squirrels would like to know which ones contain berries. Define the function berry_finder, which takes in a tree and returns True if the tree contains a node with the value 'berry' and False otherwise. Hint: To iterate through each of the branches of a particular tree, you can consider using a for loop to get each branch. This is a very classic tree recursion problem. We need to find the node whose label is berry in all nodes. The recursive idea is as follows: What is the base case ? Apparently, we come to the base case when we come to the leaf node. All we have to do here is to check the label of it. How to break down the current problem into simpler ones ? It is easy to figure out that we only need to have berry in a node of any branch, or the label of our current branch(root node in this branch) is berry. python def berry_finder(t): \"\"\"Returns True if t contains a node with the value 'berry' and False otherwise. \u003e\u003e\u003e scrat = tree('berry') \u003e\u003e\u003e berry_finder(scrat) True \u003e\u003e\u003e sproul = tree('roots', [tree('branch1', [tree('leaf'), tree('berry')]), tree('branch2')]) \u003e\u003e\u003e berry_finder(sproul) True \u003e\u003e\u003e numbers = tree(1, [tree(2), tree(3, [tree(4), tree(5)]), tree(6, [tree(7)])]) \u003e\u003e\u003e berry_finder(numbers) False \u003e\u003e\u003e t = tree(1, [tree('berry',[tree('not berry')])]) \u003e\u003e\u003e berry_finder(t) True \"\"\" if is_leaf(t): return label(t) == 'berry' return any([berry_finder(b) for b in branches(t)]) or label(t) == 'berry' ","date":"2022-02-19","objectID":"/en/lab05-cs61a-of-ucb/:3:1","series":null,"tags":["Course","Python"],"title":"Lab05 CS61A of UCB(2021-Fall)","uri":"/en/lab05-cs61a-of-ucb/#q6-finding-berries"},{"categories":["Course"],"content":" Q7: Sprout leaves Define a function sprout_leaves that takes in a tree, t, and a list of leaves, leaves. It produces a new tree that is identical to t, but where each old leaf node has new branches, one for each leaf in leaves. For example, say we have the tree t = tree(1, [tree(2), tree(3, [tree(4)])]): text 1 / \\ 2 3 | 4 If we call sprout_leaves(t, [5, 6]), the result is the following tree: text 1 / \\ 2 3 / \\ | 5 6 4 / \\ 5 6 This is also a problem can be solved recursively. Obviously, the base case is the leaf node again. When we encounter a leaf node, we need to add leaves. If it is a branch, then we have to check each of its subtrees. python def sprout_leaves(t, leaves): \"\"\"Sprout new leaves containing the data in leaves at each leaf in the original tree t and return the resulting tree. \u003e\u003e\u003e t1 = tree(1, [tree(2), tree(3)]) \u003e\u003e\u003e print_tree(t1) 1 2 3 \u003e\u003e\u003e new1 = sprout_leaves(t1, [4, 5]) \u003e\u003e\u003e print_tree(new1) 1 2 4 5 3 4 5 \u003e\u003e\u003e t2 = tree(1, [tree(2, [tree(3)])]) \u003e\u003e\u003e print_tree(t2) 1 2 3 \u003e\u003e\u003e new2 = sprout_leaves(t2, [6, 1, 2]) \u003e\u003e\u003e print_tree(new2) 1 2 3 6 1 2 \"\"\" if is_leaf(t): return tree(label(t), [tree(leaf) for leaf in leaves]) return tree(label(t), [sprout_leaves(b, leaves) for b in branches(t)]) ","date":"2022-02-19","objectID":"/en/lab05-cs61a-of-ucb/:3:2","series":null,"tags":["Course","Python"],"title":"Lab05 CS61A of UCB(2021-Fall)","uri":"/en/lab05-cs61a-of-ucb/#q7-sprout-leaves"},{"categories":["Course"],"content":"the simple solutions for lab04 of CS61A of UCB","date":"2022-02-03","objectID":"/en/lab04-cs61a-of-ucb/","series":null,"tags":["Course","Python"],"title":"Lab04 CS61A of UCB(2021-Fall)","uri":"/en/lab04-cs61a-of-ucb/"},{"categories":["Course"],"content":" Intro I find it really interesting to solve recursive problems. I like this way of solving problems, the code is concise and intuitive, which is why I wrote this blog. üìí How to solve a recursive problem ? What is the base case ? How to break down the current problem into simpler ones ? Later, I will follow this idea to solve the recursion problem in this lab. ","date":"2022-02-03","objectID":"/en/lab04-cs61a-of-ucb/:1:0","series":null,"tags":["Course","Python"],"title":"Lab04 CS61A of UCB(2021-Fall)","uri":"/en/lab04-cs61a-of-ucb/#intro"},{"categories":["Course"],"content":" Recursion ","date":"2022-02-03","objectID":"/en/lab04-cs61a-of-ucb/:2:0","series":null,"tags":["Course","Python"],"title":"Lab04 CS61A of UCB(2021-Fall)","uri":"/en/lab04-cs61a-of-ucb/#recursion"},{"categories":["Course"],"content":" Q2: Summation Write a recursive implementation of summation, which takes a positive integer n and a function term. It applies term to every number from 1 to n including n and returns the sum. Important: Use recursion; the tests will fail if you use any loops (for, while). What is the base case ? This is easy to think, because we have to calculate from 1 to n. Apparently, n = 1 is the base case, which returns term(n) How to break down the current problem into simpler ones ? We call summation(n - 1) to make this problem simpler. python def summation(n, term): \"\"\"Return the sum of numbers 1 through n (including n) w√≠th term applied to each number. Implement using recursion! \u003e\u003e\u003e summation(5, lambda x: x * x * x) # 1^3 + 2^3 + 3^3 + 4^3 + 5^3 225 \u003e\u003e\u003e summation(9, lambda x: x + 1) # 2 + 3 + 4 + 5 + 6 + 7 + 8 + 9 + 10 54 \u003e\u003e\u003e summation(5, lambda x: 2**x) # 2^1 + 2^2 + 2^3 + 2^4 + 2^5 62 \u003e\u003e\u003e # Do not use while/for loops! \u003e\u003e\u003e from construct_check import check \u003e\u003e\u003e # ban iteration \u003e\u003e\u003e check(HW_SOURCE_FILE, 'summation', ... ['While', 'For']) True \"\"\" assert n \u003e= 1 # base case: n = 1 if n == 1: return term(n) else: return term(n) + summation(n - 1, term) ","date":"2022-02-03","objectID":"/en/lab04-cs61a-of-ucb/:2:1","series":null,"tags":["Course","Python"],"title":"Lab04 CS61A of UCB(2021-Fall)","uri":"/en/lab04-cs61a-of-ucb/#q2-summation"},{"categories":["Course"],"content":" Tree Recursion ","date":"2022-02-03","objectID":"/en/lab04-cs61a-of-ucb/:3:0","series":null,"tags":["Course","Python"],"title":"Lab04 CS61A of UCB(2021-Fall)","uri":"/en/lab04-cs61a-of-ucb/#tree-recursion"},{"categories":["Course"],"content":" Q3: Pascal‚Äôs Triangle Here‚Äôs a part of the Pascal‚Äôs trangle: text 1 1 1 1 2 1 1 3 3 1 1 4 6 4 1 Every number in Pascal‚Äôs triangle is defined as the sum of the item above it and the item above and to the left of it. Use 0 if the item does not exist. Define the procedure pascal(row, column) which takes a row and a column, and finds the value of the item at that position in Pascal‚Äôs triangle. Rows and columns are zero-indexed; that is, the first row is row 0 instead of 1 and the first column is column 0 instead of column 1. For example, the item at row 2, column 1 in Pascal‚Äôs triangle is 2. This probelm is a classical Problem. According to the definition, we know Pascal(i, j) = Pascal(i - 1, j) + Pascal(i - 1, j - 1). Apparently, the definition gives us a way to make this recursive problem easier. Then we have to ask us what is the base case ? By looking closely at Pascal‚Äôs triangle above, we will find it is always 1 when j = 0 and i == j. Remember that we have to take care of empty entry. ü§î python def pascal(row, column): \"\"\"returns the value of the item in pascal's triangle whose position is specified by row and column. \u003e\u003e\u003e pascal(0, 0) 1 \u003e\u003e\u003e pascal(0, 5) # empty entry; outside of pascal's triangle 0 \u003e\u003e\u003e pascal(3, 2) # row 3 (1 3 3 1), column 2 3 \u003e\u003e\u003e pascal(4, 2) # row 4 (1 4 6 4 1), column 2 6 \"\"\" # in pascal's triangle, \\ # pascal(i, j) = pascal(i - 1, j - 1) + pascal(i - 1, j) # base case 1. empty entry if column \u003e row: return 0 # base case 2. pascal(i, 0) if column == 0: return 1 # base case 3. pascal(i, i) elif row == column: return 1 return pascal(row - 1, column) + pascal(row - 1, column - 1) ","date":"2022-02-03","objectID":"/en/lab04-cs61a-of-ucb/:3:1","series":null,"tags":["Course","Python"],"title":"Lab04 CS61A of UCB(2021-Fall)","uri":"/en/lab04-cs61a-of-ucb/#q3-pascals-triangle"},{"categories":["Course"],"content":" Q4: Insect Combinatorics Consider an insect in an M by N grid. The insect starts at the bottom left corner, (0, 0), and wants to end up at the top right corner, (M-1, N-1). The insect is only capable of moving right or up. Write a function paths that takes a grid length and width and returns the number of different paths the insect can take from the start to the goal. (There is a closed-form solution to this problem, but try to answer it procedurally using recursion.) For example, the 2 by 2 grid has a total of two ways for the insect to move from the start to the goal. For the 3 by 3 grid, the insect has 6 diferent paths (only 3 are shown above). Hint: What happens if we hit the top or rightmost edge? From the description, we know that we can only move right or up. Suppose we are in paths(i, j), we know we can only come from the left or the bottom. So we can draw a conclusion: path(i, j - 1) + path(i - 1, j). (the bottom left = (0, 0)). Then, what is the base case ?„Äç, see the table below: 1 1 1 1 1 According to the above formula, we can know that the complete table should be like this: 1 3 6 1 2 3 1 1 1 To make this problem easier, we let the index start at 1 ü§ó python def paths(m, n): \"\"\"Return the number of paths from one corner of an M by N grid to the opposite corner. \u003e\u003e\u003e paths(2, 2) 2 \u003e\u003e\u003e paths(5, 7) 210 \u003e\u003e\u003e paths(117, 1) 1 \u003e\u003e\u003e paths(1, 157) 1 \"\"\" # base case path(i, 0) or path(0, i) if m == 1 or n == 1: return 1 return paths(m, n - 1) + paths(m - 1, n) ","date":"2022-02-03","objectID":"/en/lab04-cs61a-of-ucb/:3:2","series":null,"tags":["Course","Python"],"title":"Lab04 CS61A of UCB(2021-Fall)","uri":"/en/lab04-cs61a-of-ucb/#q4-insect-combinatorics"},{"categories":["Course"],"content":" List Comprehensions ","date":"2022-02-03","objectID":"/en/lab04-cs61a-of-ucb/:4:0","series":null,"tags":["Course","Python"],"title":"Lab04 CS61A of UCB(2021-Fall)","uri":"/en/lab04-cs61a-of-ucb/#list-comprehensions"},{"categories":["Course"],"content":" Q5: Couple Implement the function couple, which takes in two lists and returns a list that contains lists with i-th elements of two sequences coupled together. You can assume the lengths of two sequences are the same. Try using a list comprehension. Hint: You may find the built in range function helpful. This is a simple question, because the two lists are the same length. We just need to use the same index to fetch numbers from the two lists. python def couple(s, t): \"\"\"Return a list of two-element lists in which the i-th element is [s[i], t[i]]. \u003e\u003e\u003e a = [1, 2, 3] \u003e\u003e\u003e b = [4, 5, 6] \u003e\u003e\u003e couple(a, b) [[1, 4], [2, 5], [3, 6]] \u003e\u003e\u003e c = ['c', 6] \u003e\u003e\u003e d = ['s', '1'] \u003e\u003e\u003e couple(c, d) [['c', 's'], [6, '1']] \"\"\" assert len(s) == len(t) return [[s[i], t[i]] for i in range(len(s))] ","date":"2022-02-03","objectID":"/en/lab04-cs61a-of-ucb/:4:1","series":null,"tags":["Course","Python"],"title":"Lab04 CS61A of UCB(2021-Fall)","uri":"/en/lab04-cs61a-of-ucb/#q5-couple"},{"categories":["Course"],"content":" Q6: Coordinates Implement a function coords that takes a function fn, a sequence seq, and a lower and upper bound on the output of the function. coords then returns a list of coordinate pairs (lists) such that: Each (x, y) pair is represented as [x, fn(x)] The x-coordinates are elements in the sequence The result contains only pairs whose y-coordinate is within the upper and lower bounds (inclusive) See the doctest for examples. Note: your answer can only be one line long. You should make use of list comprehensions! We need to add an if statement to filter out the results that do not meet the conditions. python def coords(fn, seq, lower, upper): \"\"\" \u003e\u003e\u003e seq = [-4, -2, 0, 1, 3] \u003e\u003e\u003e fn = lambda x: x**2 \u003e\u003e\u003e coords(fn, seq, 1, 9) [[-2, 4], [1, 1], [3, 9]] \"\"\" \"*** YOUR CODE HERE ***\" return [[i, fn(i)] for i in seq if lower \u003c= fn(i) \u003c= upper] ","date":"2022-02-03","objectID":"/en/lab04-cs61a-of-ucb/:4:2","series":null,"tags":["Course","Python"],"title":"Lab04 CS61A of UCB(2021-Fall)","uri":"/en/lab04-cs61a-of-ucb/#q6-coordinates"},{"categories":["Course"],"content":" Q7: Riffle Shuffle A common way of shuffling cards is known as the riffle shuffle. The shuffle produces a new configuration of cards in which the top card is followed by the middle card, then by the second card, then the card after the middle, and so forth. Write a list comprehension that riffle shuffles a sequence of items. You can assume the sequence contains an even number of items. Hint: There are two ways you can write this as a single list comprension: 1) You may find the expression k%2, which evaluates to 0 on even numbers and 1 on odd numbers, to be alternatively access the beginning and middle of the deck. 2) You can utilize an if expression in your comprehension for the odd and even numbers respectively. This problem will be a little more difficult. We are actually trying to find a way to get the correct index in List Comprehensions. Obviously, the situation is different when the index is odd and even. We can look at the following table to guess the rules‚¨áÔ∏è: Origin index 0 1 2 3 Real index for deck[‚Ä¶] 0 2 1 3 Guess ? (M = 2) 0 M 2 // 2 ? M + 1 = M + 3 // 2 ? odd: 0, 1, 2, ‚Ä¶ -\u003e i // 2 even: M+0, M+1, M+2, ‚Ä¶ -\u003e M + i // 2 python def riffle(deck): \"\"\"Produces a single, perfect riffle shuffle of DECK, consisting of DECK[0], DECK[M], DECK[1], DECK[M+1], ... where M is position of the second half of the deck. Assume that len(DECK) is even. \u003e\u003e\u003e riffle([3, 4, 5, 6]) [3, 5, 4, 6] \u003e\u003e\u003e riffle(range(20)) [0, 10, 1, 11, 2, 12, 3, 13, 4, 14, 5, 15, 6, 16, 7, 17, 8, 18, 9, 19] \"\"\" return [deck[i // 2 + (i % 2) * (len(deck) // 2)] for i in range(len(deck))] ","date":"2022-02-03","objectID":"/en/lab04-cs61a-of-ucb/:4:3","series":null,"tags":["Course","Python"],"title":"Lab04 CS61A of UCB(2021-Fall)","uri":"/en/lab04-cs61a-of-ucb/#q7-riffle-shuffle"},{"categories":["Course"],"content":"The simple solutions of hw03 of CS61A of UCB","date":"2022-01-24","objectID":"/en/hw03-of-cs61a-of-ucb/","series":null,"tags":["Course","Python"],"title":"Hw03 of CS61A of UCB(2021-Fall)","uri":"/en/hw03-of-cs61a-of-ucb/"},{"categories":["Course"],"content":" hw03. Recursion, Tree Recursion ","date":"2022-01-24","objectID":"/en/hw03-of-cs61a-of-ucb/:1:0","series":null,"tags":["Course","Python"],"title":"Hw03 of CS61A of UCB(2021-Fall)","uri":"/en/hw03-of-cs61a-of-ucb/#hw03-recursion-tree-recursion"},{"categories":["Course"],"content":" Q1: Num eights Write a recursive function num_eights that takes a positive integer pos and returns the number of times the digit 8 appears in pos. Important: Use recursion; the tests will fail if you use any assignment statements. (You can however use function definitions if you so wish.) It is easy to think of the answer to this question, for we have seen a similar one in lecture. We can split the pos into all_bust_last and last. When we arrive at the base case, we just need to check if it is equals to 8. Because we can not use = in this problem, we need to use function instead. python def is_single_digit(digits): return digits // 10 == 0 def is_eight(digit): return int(digit == 8) def num_eights(pos): \"\"\"Returns the number of times 8 appears as a digit of pos. \u003e\u003e\u003e num_eights(3) 0 \u003e\u003e\u003e num_eights(8) 1 \u003e\u003e\u003e num_eights(88888888) 8 \u003e\u003e\u003e num_eights(2638) 1 \u003e\u003e\u003e num_eights(86380) 2 \u003e\u003e\u003e num_eights(12345) 0 \u003e\u003e\u003e from construct_check import check \u003e\u003e\u003e # ban all assignment statements \u003e\u003e\u003e check(HW_SOURCE_FILE, 'num_eights', ... ['Assign', 'AnnAssign', 'AugAssign', 'NamedExpr']) True \"\"\" # base case: if pos is a single digit, check if it == 8 if is_single_digit(pos): return is_eight(pos) else: return is_eight(pos % 10) + num_eights(pos // 10) ","date":"2022-01-24","objectID":"/en/hw03-of-cs61a-of-ucb/:1:1","series":null,"tags":["Course","Python"],"title":"Hw03 of CS61A of UCB(2021-Fall)","uri":"/en/hw03-of-cs61a-of-ucb/#q1-num-eights"},{"categories":["Course"],"content":" Q2: Ping-pong The ping-pong sequence counts up starting from 1 and is always either counting up or counting down. At element k, the direction switches if k is a multiple of 8 or contains the digit 8. The first 30 elements of the ping-pong sequence are listed below, with direction swaps marked using brackets at the 8th, 16th, 18th, 24th, and 28th elements: Index 1 2 3 4 5 6 7 [8] 9 10 11 12 13 14 15 [16] 17 [18] 19 20 21 22 23 PingPong Value 1 2 3 4 5 6 7 [8] 7 6 5 4 3 2 1 [0] 1 [2] 1 0 -1 -2 -3 Index (cont.) [24] 25 26 27 [28] 29 30 PingPong Value [-4] -3 -2 -1 [0] -1 -2 Implement a function pingpong that returns the nth element of the ping-pong sequence without using any assignment statements. (You are allowed to use function definitions.) You may use the function num_eights, which you defined in the previous question. Important: Use recursion; the tests will fail if you use any assignment statements. (You can however use function definitions if you so wish.) At first, we need to define what is the base case in this problem. Let‚Äôs solve this problem from scratch. The iterative solutioin is quite easy and intuitive. We need to track these things‚¨áÔ∏è index(i), we need to count it to n. value(val), we need to keep track of this state. When we count i to n, this is the expected output. direction, this is a variable that is either equal to -1 or 1. We maintain this variable to indicate counting up or counting down. If it is a multiple of 8 or contains the digit 8, we need to change its value. python def pingpong(n): i, direction = 0, 1 val = 0 while i \u003c n: val += direction i += 1 if num_eights(i) \u003e 0 or i % 8 == 0: direction = -direction return val The problem is how to convert this iterative solution to recursive solution. The parameters of this function should be these variables which changes in while loop. The next problem is: what is the base case? Apparently, the base case can be defined as index \u003c 8, then return index. Because in this range, index = value. Then, how can we know what the direction is? If we define direction(n) as the direction when the index = n, we can reason its value from direction(n-1). The base case are quite similar. Finally, the recursive solution will be like: python def pingpong(n): \"\"\"Return the nth element of the ping-pong sequence. \u003e\u003e\u003e pingpong(8) 8 \u003e\u003e\u003e pingpong(10) 6 \u003e\u003e\u003e pingpong(15) 1 \u003e\u003e\u003e pingpong(21) -1 \u003e\u003e\u003e pingpong(22) -2 \u003e\u003e\u003e pingpong(30) -2 \u003e\u003e\u003e pingpong(68) 0 \u003e\u003e\u003e pingpong(69) -1 \u003e\u003e\u003e pingpong(80) 0 \u003e\u003e\u003e pingpong(81) 1 \u003e\u003e\u003e pingpong(82) 0 \u003e\u003e\u003e pingpong(100) -6 \u003e\u003e\u003e from construct_check import check \u003e\u003e\u003e # ban assignment statements \u003e\u003e\u003e check(HW_SOURCE_FILE, 'pingpong', ... ['Assign', 'AnnAssign', 'AugAssign', 'NamedExpr']) True \"\"\" def direction(n): # the base case if n \u003c 8: return 1 elif num_eights(n - 1) \u003e 0 or (n - 1) % 8 == 0: return -1 * direction(n - 1) return direction(n - 1) # the base case if n \u003c 8: return n else: return pingpong(n - 1) + direction(n) ","date":"2022-01-24","objectID":"/en/hw03-of-cs61a-of-ucb/:1:2","series":null,"tags":["Course","Python"],"title":"Hw03 of CS61A of UCB(2021-Fall)","uri":"/en/hw03-of-cs61a-of-ucb/#q2-ping-pong"},{"categories":["Course"],"content":" Q3: Missing Digits Write the recursive function missing_digits that takes a number n that is sorted in non-decreasing order (for example, 12289 is valid but 15362 and 98764 are not). It returns the number of missing digits in n. A missing digit is a number between the first and last digit of n of a that is not in n. The solution of this problem is quite similiar to Q1: split this problem by n % 100 and n // 10. The procudure is(take 1248 for an example)‚¨áÔ∏è split 1248 into 12 and 48 check missing digits of 48 and 12 recursively. The reason why we split this problem by n % 100 and n // 10 rather than n % 10 and n // 10 is that we need to process 2 adjacent digits each time. n % 100 will give us last 2 digits. python def missing_digits(n): \"\"\"Given a number a that is in sorted, non-decreasing order, return the number of missing digits in n. A missing digit is a number between the first and last digit of a that is not in n. \u003e\u003e\u003e missing_digits(1248) # 3, 5, 6, 7 4 \u003e\u003e\u003e missing_digits(19) # 2, 3, 4, 5, 6, 7, 8 7 \u003e\u003e\u003e missing_digits(1122) # No missing numbers 0 \u003e\u003e\u003e missing_digits(123456) # No missing numbers 0 \u003e\u003e\u003e missing_digits(3558) # 4, 6, 7 3 \u003e\u003e\u003e missing_digits(35578) # 4, 6 2 \u003e\u003e\u003e missing_digits(12456) # 3 1 \u003e\u003e\u003e missing_digits(16789) # 2, 3, 4, 5 4 \u003e\u003e\u003e missing_digits(4) # No missing numbers between 4 and 4 0 \u003e\u003e\u003e from construct_check import check \u003e\u003e\u003e # ban while or for loops \u003e\u003e\u003e check(HW_SOURCE_FILE, 'missing_digits', ['While', 'For']) True \"\"\" if n \u003c 10: return 0 elif n \u003c 100: if n // 10 == n % 10: return 0 else: return n % 10 - n // 10 - 1 return missing_digits(n // 10) + missing_digits(n % 100) ","date":"2022-01-24","objectID":"/en/hw03-of-cs61a-of-ucb/:1:3","series":null,"tags":["Course","Python"],"title":"Hw03 of CS61A of UCB(2021-Fall)","uri":"/en/hw03-of-cs61a-of-ucb/#q3-missing-digits"},{"categories":["Course"],"content":" Q4: Count coins Given a positive integer change, a set of coins makes change for change if the sum of the values of the coins is change. Here we will use standard US Coin values: 1, 5, 10, 25. For example, the following sets make change for 15: 15 1-cent coins 10 1-cent, 1 5-cent coins 5 1-cent, 2 5-cent coins 5 1-cent, 1 10-cent coins 3 5-cent coins 1 5-cent, 1 10-cent coin Thus, there are 6 ways to make change for 15. Write a recursive function count_coins that takes a positive integer change and returns the number of ways to make change for change using coins. You can use either of the functions given to you: ascending_coin will return the next larger coin denomination from the input, i.e. ascending_coin(5) is 10. descending_coin will return the next smaller coin denomination from the input, i.e. descending_coin(5) is 1. There are two main ways in which you can approach this problem. One way uses ascending_coin, and another uses descending_coin. Important: Use recursion; the tests will fail if you use loops. Hint: Refer the implementation of count_partitions for an example of how to count the ways to sum up to a final value with smaller parts. If you need to keep track of more than one value across recursive calls, consider writing a helper function. Similiar to this implementation, we can slove this problem use tree-recursive function. For every coin value, we can pick or drop. So we can write code like this‚¨áÔ∏è python def count_coins(change): \"\"\"Return the number of ways to make change using coins of value of 1, 5, 10, 25. \u003e\u003e\u003e count_coins(15) 6 \u003e\u003e\u003e count_coins(10) 4 \u003e\u003e\u003e count_coins(20) 9 \u003e\u003e\u003e count_coins(100) # How many ways to make change for a dollar? 242 \u003e\u003e\u003e count_coins(200) 1463 \u003e\u003e\u003e from construct_check import check \u003e\u003e\u003e # ban iteration \u003e\u003e\u003e check(HW_SOURCE_FILE, 'count_coins', ['While', 'For']) True \"\"\" def helper(coin, n): if not coin: return 0 if coin == n: # 1 coin for n return 1 if coin \u003e n: # the coin value is too large return 0 pickcoin = helper(coin, n - coin) dropcoin = helper(ascending_coin(coin), n) return pickcoin + dropcoin return helper(1, change) ","date":"2022-01-24","objectID":"/en/hw03-of-cs61a-of-ucb/:1:4","series":null,"tags":["Course","Python"],"title":"Hw03 of CS61A of UCB(2021-Fall)","uri":"/en/hw03-of-cs61a-of-ucb/#q4-count-coins"},{"categories":["Tool"],"content":"Explain how to use hammerspoon to manage windows","date":"2022-01-21","objectID":"/en/how-to-manage-windows-using-hammerspoon/","series":null,"tags":["Tool"],"title":"How to Manage Windows Using Hammerspoon","uri":"/en/how-to-manage-windows-using-hammerspoon/"},{"categories":["Tool"],"content":" Intro I found that the windows management built in macOS is difficult to use. As a result, I always using my mouse to move and resize my window, which is less efficient. We should keep our hands on the keyboard as much as possible. After finishing the MIT-Missing-Semester, I came across the hammerspoon tool. I really like this one :) ","date":"2022-01-21","objectID":"/en/how-to-manage-windows-using-hammerspoon/:1:0","series":null,"tags":["Tool"],"title":"How to Manage Windows Using Hammerspoon","uri":"/en/how-to-manage-windows-using-hammerspoon/#intro"},{"categories":["Tool"],"content":" What is hammerspoon ? According to the official site‚Äôs introduction, hammerspoon is a tool for powerful automation of OS X, which is just a bridge between the operating system and a Lua scripting engine. The windows management is kind of automation. To be honest, I once heard the Lua language but I don‚Äôt know anything about it. I follow Learn Lua in Y minutes to have a basic understanding of this language. ","date":"2022-01-21","objectID":"/en/how-to-manage-windows-using-hammerspoon/:2:0","series":null,"tags":["Tool"],"title":"How to Manage Windows Using Hammerspoon","uri":"/en/how-to-manage-windows-using-hammerspoon/#what-is-hammerspoon-"},{"categories":["Tool"],"content":" How to manage windows ? I would like to have the following features: Move and resize my window to the left/right of screen. The full screen mode Move and resize my window to the top-left/top-right/bottom-left/bottom-right of screen Move current window to the center of screen My solution consists of 3 *.lua file(I have put this in my dotfiles) üëâconfig.lua lua MACBOOK_MONITOR = 'Built-in Retina Display' -- disable animations, default value = 0.2 hs.window.animationDuration = 0 üëâinit.lua lua require('config') require('window') üëâwindow.lua This is the main part of windows management. lua -- half of screen -- {frame.x, frame.y, window.w, window.h} -- First two elements: we decide the position of frame -- Last two elements: we decide the size of frame hs.hotkey.bind({'alt', 'cmd'}, 'left', function() hs.window.focusedWindow():moveToUnit({0, 0, 0.5, 1}) end) hs.hotkey.bind({'alt', 'cmd'}, 'right', function() hs.window.focusedWindow():moveToUnit({0.5, 0, 0.5, 1}) end) hs.hotkey.bind({'alt', 'cmd'}, 'up', function() hs.window.focusedWindow():moveToUnit({0, 0, 1, 0.5}) end) hs.hotkey.bind({'alt', 'cmd'}, 'down', function() hs.window.focusedWindow():moveToUnit({0, 0.5, 1, 0.5}) end) -- quarter of screen --[[ u i j k --]] hs.hotkey.bind({'ctrl', 'alt', 'cmd'}, 'u', function() hs.window.focusedWindow():moveToUnit({0, 0, 0.5, 0.5}) end) hs.hotkey.bind({'ctrl', 'alt', 'cmd'}, 'k', function() hs.window.focusedWindow():moveToUnit({0.5, 0.5, 0.5, 0.5}) end) hs.hotkey.bind({'ctrl', 'alt', 'cmd'}, 'i', function() hs.window.focusedWindow():moveToUnit({0.5, 0, 0.5, 0.5}) end) hs.hotkey.bind({'ctrl', 'alt', 'cmd'}, 'j', function() hs.window.focusedWindow():moveToUnit({0, 0.5, 0.5, 0.5}) end) -- full screen hs.hotkey.bind({'alt', 'cmd'}, 'f', function() hs.window.focusedWindow():moveToUnit({0, 0, 1, 1}) end) -- center screen hs.hotkey.bind({'alt', 'cmd'}, 'c', function() hs.window.focusedWindow():centerOnScreen() end) You shoule put these files in ~/.hammerspoon/ and then click on Reload config ü§ó ","date":"2022-01-21","objectID":"/en/how-to-manage-windows-using-hammerspoon/:3:0","series":null,"tags":["Tool"],"title":"How to Manage Windows Using Hammerspoon","uri":"/en/how-to-manage-windows-using-hammerspoon/#how-to-manage-windows-"},{"categories":["Tool"],"content":" Code Explained hs.hotkey.bind(mods, key, pressedfn) This is a simple function to create a new hotkey and bind it to pressedfn. We press and hold mods and use key to enable pressedfn. For example, If we want to make a window full screen. We first press and hold alt(option) and cmd, then we press f. pressedfn This is an anonymous function in Lua. The key of this function is hs.window.focusedWindow():moveToUnit({...}). Its job is get the focused window and make some changes of position and size. The parameters are a table in Lua. You may combine the previous comments in window.lua and the image below to understand this. ","date":"2022-01-21","objectID":"/en/how-to-manage-windows-using-hammerspoon/:4:0","series":null,"tags":["Tool"],"title":"How to Manage Windows Using Hammerspoon","uri":"/en/how-to-manage-windows-using-hammerspoon/#code-explained"},{"categories":["Tool"],"content":" Ref Anish‚Äôs Hammerspoon config ","date":"2022-01-21","objectID":"/en/how-to-manage-windows-using-hammerspoon/:5:0","series":null,"tags":["Tool"],"title":"How to Manage Windows Using Hammerspoon","uri":"/en/how-to-manage-windows-using-hammerspoon/#ref"},{"categories":["Course"],"content":"The simple solutions of hw02 of CS61A of UCB","date":"2022-01-20","objectID":"/en/hw02-of-cs61a-of-ucb/","series":null,"tags":["Course","Python"],"title":"Hw02 of CS61A of UCB(2021-Fall)","uri":"/en/hw02-of-cs61a-of-ucb/"},{"categories":["Course"],"content":" hw02. Higher Order Functions ","date":"2022-01-20","objectID":"/en/hw02-of-cs61a-of-ucb/:1:0","series":null,"tags":["Course","Python"],"title":"Hw02 of CS61A of UCB(2021-Fall)","uri":"/en/hw02-of-cs61a-of-ucb/#hw02-higher-order-functions"},{"categories":["Course"],"content":" Q1: Product The summation(n, term) function from the higher-order functions lecture adds up term(1) + ... + term(n). Write a similar function called product that returns term(1) * ... * term(n). This problem is quite easy, we just need to use * instead of +. The logic is similar to summation(n, term) function in the lecture. Remember to set ans = 1 at first, after all, 0 * any numbers is always equal to 0 ü§ó python def product(n, term): \"\"\"Return the product of the first n terms in a sequence. n: a positive integer term: a function that takes one argument to produce the term \u003e\u003e\u003e product(3, identity) # 1 * 2 * 3 6 \u003e\u003e\u003e product(5, identity) # 1 * 2 * 3 * 4 * 5 120 \u003e\u003e\u003e product(3, square) # 1^2 * 2^2 * 3^2 36 \u003e\u003e\u003e product(5, square) # 1^2 * 2^2 * 3^2 * 4^2 * 5^2 14400 \u003e\u003e\u003e product(3, increment) # (1+1) * (2+1) * (3+1) 24 \u003e\u003e\u003e product(3, triple) # 1*3 * 2*3 * 3*3 162 \"\"\" i, ans = 1, 1 while i \u003c= n: ans *= term(i) i += 1 return ans ","date":"2022-01-20","objectID":"/en/hw02-of-cs61a-of-ucb/:1:1","series":null,"tags":["Course","Python"],"title":"Hw02 of CS61A of UCB(2021-Fall)","uri":"/en/hw02-of-cs61a-of-ucb/#q1-product"},{"categories":["Course"],"content":" Q2: Accumulate Let‚Äôs take a look at how summation and product are instances of a more general function called accumulate, which we would like to implement: If you compare the code mentioned above with the following code, you may find that they are quite similar. The accumulate is a generalized version of prodcut python def accumulate(merger, base, n, term): \"\"\"Return the result of merging the first n terms in a sequence and base. The terms to be merged are term(1), term(2), ..., term(n). merger is a two-argument commutative function. \u003e\u003e\u003e accumulate(add, 0, 5, identity) # 0 + 1 + 2 + 3 + 4 + 5 15 \u003e\u003e\u003e accumulate(add, 11, 5, identity) # 11 + 1 + 2 + 3 + 4 + 5 26 \u003e\u003e\u003e accumulate(add, 11, 0, identity) # 11 11 \u003e\u003e\u003e accumulate(add, 11, 3, square) # 11 + 1^2 + 2^2 + 3^2 25 \u003e\u003e\u003e accumulate(mul, 2, 3, square) # 2 * 1^2 * 2^2 * 3^2 72 \u003e\u003e\u003e # 2 + (1^2 + 1) + (2^2 + 1) + (3^2 + 1) \u003e\u003e\u003e accumulate(lambda x, y: x + y + 1, 2, 3, square) 19 \u003e\u003e\u003e # ((2 * 1^2 * 2) * 2^2 * 2) * 3^2 * 2 \u003e\u003e\u003e accumulate(lambda x, y: 2 * x * y, 2, 3, square) 576 \u003e\u003e\u003e accumulate(lambda x, y: (x + y) % 17, 19, 20, square) 16 \"\"\" i, ans = 1, base while i \u003c= n: ans = merger(ans, term(i)) i += 1 return ans def summation_using_accumulate(n, term): \"\"\"Returns the sum: term(1) + ... + term(n), using accumulate. \u003e\u003e\u003e summation_using_accumulate(5, square) 55 \u003e\u003e\u003e summation_using_accumulate(5, triple) 45 \"\"\" return accumulate(add, 0, n, term) def product_using_accumulate(n, term): \"\"\"Returns the product: term(1) * ... * term(n), using accumulate. \u003e\u003e\u003e product_using_accumulate(4, square) 576 \u003e\u003e\u003e product_using_accumulate(6, triple) 524880 \"\"\" return accumulate(mul, 1, n, term) ","date":"2022-01-20","objectID":"/en/hw02-of-cs61a-of-ucb/:1:2","series":null,"tags":["Course","Python"],"title":"Hw02 of CS61A of UCB(2021-Fall)","uri":"/en/hw02-of-cs61a-of-ucb/#q2-accumulate"},{"categories":["Course"],"content":"The simple solutions of hw01 of CS61A of UCB","date":"2022-01-18","objectID":"/en/hw01-of-cs61a-of-ucb/","series":null,"tags":["Course","Python"],"title":"Hw01 of CS61A of UCB(2021-Fall)","uri":"/en/hw01-of-cs61a-of-ucb/"},{"categories":["Course"],"content":" hw01. Control ","date":"2022-01-18","objectID":"/en/hw01-of-cs61a-of-ucb/:1:0","series":null,"tags":["Course","Python"],"title":"Hw01 of CS61A of UCB(2021-Fall)","uri":"/en/hw01-of-cs61a-of-ucb/#hw01-control"},{"categories":["Course"],"content":" Q1. Welcome FormsSkip :) ","date":"2022-01-18","objectID":"/en/hw01-of-cs61a-of-ucb/:1:1","series":null,"tags":["Course","Python"],"title":"Hw01 of CS61A of UCB(2021-Fall)","uri":"/en/hw01-of-cs61a-of-ucb/#q1-welcome-forms"},{"categories":["Course"],"content":" Q2. A Plus Abs B Fill in the blanks in the following function for adding a to the absolute value of b, without calling abs. You may not modify any of the provided code other than the two blanks. This problem is easy if we know that we can bind names to functions. In this problem: When b \u003c 0, a + abs(b) = a - b, so we should use sub When b \u003e 0, a + abs(b) = a + b, so we should use add python def a_plus_abs_b(a, b): \"\"\"Return a+abs(b), but without calling abs. \u003e\u003e\u003e a_plus_abs_b(2, 3) 5 \u003e\u003e\u003e a_plus_abs_b(2, -3) 5 \"\"\" if b \u003c 0: f = sub # b \u003c 0 -\u003e a+abs(b) = a - b, using sub else: f = add # b \u003e 0 -\u003e a+abs(b) = a + b, using add return f(a, b) ","date":"2022-01-18","objectID":"/en/hw01-of-cs61a-of-ucb/:1:2","series":null,"tags":["Course","Python"],"title":"Hw01 of CS61A of UCB(2021-Fall)","uri":"/en/hw01-of-cs61a-of-ucb/#q2-a-plus-abs-b"},{"categories":["Course"],"content":" Q3. Two of Three Write a function that takes three positive numbers as arguments and returns the sum of the squares of the two smallest numbers. Use only a single line for the body of the function. The hint shows that we may need max or min in this problem. At first, I tried to enumerate all possibilities. The smallest numbers may be x and y, or x and z, or y and z. We can just code like this: return min(x**2 + y**2, x**2 + z**2, y**2 + z**2). We can also think about the problem from another angle ‚¨áÔ∏è python def two_of_three(x, y, z): \"\"\"Return a*a + b*b, where a and b are the two smallest members of the positive numbers x, y, and z. \u003e\u003e\u003e two_of_three(1, 2, 3) 5 \u003e\u003e\u003e two_of_three(5, 3, 1) 10 \u003e\u003e\u003e two_of_three(10, 2, 8) 68 \u003e\u003e\u003e two_of_three(5, 5, 5) 50 \"\"\" # by substracting largest-number * largest-number return x**2 + y**2 + z**2 - max(x, y, z)**2 ","date":"2022-01-18","objectID":"/en/hw01-of-cs61a-of-ucb/:1:3","series":null,"tags":["Course","Python"],"title":"Hw01 of CS61A of UCB(2021-Fall)","uri":"/en/hw01-of-cs61a-of-ucb/#q3-two-of-three"},{"categories":["Course"],"content":" Q4. Largest Factor Write a function that takes an integer n that is greater than 1 and returns the largest integer that is smaller than n and evenly divides n. With some basic knowledge of math, we can decompose this problem into two cases if n is an even number, the answer is n // 2 if n is an odd number, the answer can be found by check n % factor == 0. the range of factor is 1 ~ n // 2 python def largest_factor(n): \"\"\"Return the largest factor of n that is smaller than n. \u003e\u003e\u003e largest_factor(15) # factors are 1, 3, 5 5 \u003e\u003e\u003e largest_factor(80) # factors are 1, 2, 4, 5, 8, 10, 16, 20, 40 40 \u003e\u003e\u003e largest_factor(13) # factor is 1 since 13 is prime 1 \"\"\" if n % 2 == 0: return n // 2 else: factors = [i for i in range(n//2, 0, -1) if n % i == 0] # get all factors return factors[0] # the biggest one is the largest one ","date":"2022-01-18","objectID":"/en/hw01-of-cs61a-of-ucb/:1:4","series":null,"tags":["Course","Python"],"title":"Hw01 of CS61A of UCB(2021-Fall)","uri":"/en/hw01-of-cs61a-of-ucb/#q4-largest-factor"},{"categories":["Course"],"content":" Q5. If Function Refactor In this problem, we should refactor out code to avoid ZeroDivisionError The ZeroDivisionError happens when we call function expression. Python will try to evaluate the whole expression recursively. Although the hw01 says Your second job is to edit invert_short and change_short so that they have the same behavior as invert and change but still have just one line each. You will also need to edit limited. You don‚Äôt need to use and or or orif in invert; just pay attention to when the division takes place., I tried to solve this problem without editing limited functio and use if üòø python def limited(x, z, limit): \"\"\"Logic that is common to invert and change.\"\"\" if x != 0: return min(z, limit) else: return limit def invert_short(x, limit): \"\"\"Return 1/x, but with a limit. \u003e\u003e\u003e x = 0.2 \u003e\u003e\u003e 1/x 5.0 \u003e\u003e\u003e invert_short(x, 100) 5.0 \u003e\u003e\u003e invert_short(x, 2) # 2 is smaller than 5 2 \u003e\u003e\u003e x = 0 \u003e\u003e\u003e invert_short(x, 100) # No error, even though 1/x divides by 0! 100 \"\"\" # the ZeroDivisionError happens here when we call limited function return limited(x, 1 / x, limit) if x != 0 else limited(x, 0, limit) def change_short(x, y, limit): \"\"\"Return abs(y - x) as a fraction of x, but with a limit. \u003e\u003e\u003e x, y = 2, 5 \u003e\u003e\u003e abs(y - x) / x 1.5 \u003e\u003e\u003e change_short(x, y, 100) 1.5 \u003e\u003e\u003e change_short(x, y, 1) # 1 is smaller than 1.5 1 \u003e\u003e\u003e x = 0 \u003e\u003e\u003e change_short(x, y, 100) # No error, even though abs(y - x) / x divides by 0! 100 \"\"\" # the ZeroDivisionError happens here when we call limited function return limited(x, abs(y - x) / x, limit) if x != 0 else limited(x, 0, limit) ","date":"2022-01-18","objectID":"/en/hw01-of-cs61a-of-ucb/:1:5","series":null,"tags":["Course","Python"],"title":"Hw01 of CS61A of UCB(2021-Fall)","uri":"/en/hw01-of-cs61a-of-ucb/#q5-if-function-refactor"},{"categories":["Course"],"content":" Q6.Hailstone Douglas Hofstadter‚Äôs Pulitzer-prize-winning book, G√∂del, Escher, Bach, poses the following mathematical puzzle. Pick a positive integer n as the start. If n is even, divide it by 2. If n is odd, multiply it by 3 and add 1. Continue this process until n is 1. The number n will travel up and down but eventually end at 1 (at least for all numbers that have ever been tried ‚Äì nobody has ever proved that the sequence will terminate). Analogously, a hailstone travels up and down in the atmosphere before eventually landing on earth. This sequence of values of n is often called a Hailstone sequence. Write a function that takes a single argument with formal parameter name n, prints out the hailstone sequence starting at n, and returns the number of steps in the sequence: This problem is easy. We just follow the 4 steps and count. python def hailstone(n): \"\"\"Print the hailstone sequence starting at n and return its length. \u003e\u003e\u003e a = hailstone(10) 10 5 16 8 4 2 1 \u003e\u003e\u003e a 7 \"\"\" cnt = 0 while n != 1: print(n) if n % 2 == 0: n //= 2 else: n = n * 3 + 1 cnt += 1 print(n) # print 1 return cnt + 1 # +1 for `n=1` ","date":"2022-01-18","objectID":"/en/hw01-of-cs61a-of-ucb/:1:6","series":null,"tags":["Course","Python"],"title":"Hw01 of CS61A of UCB(2021-Fall)","uri":"/en/hw01-of-cs61a-of-ucb/#q6hailstone"},{"categories":["Course"],"content":"the simple solutions for exercise09 of Missingsemester 2020","date":"2022-01-10","objectID":"/en/exercise09-missingsemester-2020/","series":null,"tags":["Course"],"title":"The solutions for exercise09 of Missingsemester(2020)","uri":"/en/exercise09-missingsemester-2020/"},{"categories":["Course"],"content":" Lecture 09. Security and Cryptography ","date":"2022-01-10","objectID":"/en/exercise09-missingsemester-2020/:1:0","series":null,"tags":["Course"],"title":"The solutions for exercise09 of Missingsemester(2020)","uri":"/en/exercise09-missingsemester-2020/#lecture-09-security-and-cryptography"},{"categories":["Course"],"content":" Entropy Suppose a password is chosen as a concatenation of four lower-case dictionary words, where each word is selected uniformly at random from a dictionary of size 100,000. An example of such a password is correcthorsebatterystaple. How many bits of entropy does this have? In order to calculate the bits of entropy, we need to know how many possibilites there. We can easily know the combinations count are $100000^4$ and the bits of entropy are $log_2 (100000^4)\\approx 66\\ bit$ ü§ó Consider an alternative scheme where a password is chosen as a sequence of 8 random alphanumeric characters (including both lower-case and upper-case letters). An example is rg8Ql34g. How many bits of entropy does this have? We can calcaulte the bits of entropy are $log_2(62^8)\\approx 47\\ bit$ ü§ó Which is the stronger password? Apprarenty, correcthorsebatterystaple is the stronger one(its entropy is higher), which is kind of counter-intuitive. From a human perspective, rg8Ql34g is harder to memorize ü§î. Suppose an attacker can try guessing 10,000 passwords per second. On average, how long will it take to break each of the passwords? correcthorsebatterystaple: $100000^4/10000=10^{16}\\ seconds\\approx317097919\\ years$ ü§ß rg8Ql34g: $64^8/10000\\approx892\\ years$ ","date":"2022-01-10","objectID":"/en/exercise09-missingsemester-2020/:1:1","series":null,"tags":["Course"],"title":"The solutions for exercise09 of Missingsemester(2020)","uri":"/en/exercise09-missingsemester-2020/#entropy"},{"categories":["Course"],"content":" Cryptographic hash functions Download a Debian image from a mirror(e.g. from this Argentinean mirror). Cross-check the hash (e.g. using the sha256sum command) with the hash retrieved from the official Debian site (e.g. this file hosted at debian.org, if you‚Äôve downloaded the linked file from the Argentinean mirror). bash \u003e shasum -a -256 debian-mac-11.2.0-amd64-netinst.iso # 011f6754601985f46fcc670ce02faabcc8b5b8aadf51bc3d3fcfa3185b96b1df debian-mac-11.2.0-amd64-netinst.iso # correct one # 011f6754601985f46fcc670ce02faabcc8b5b8aadf51bc3d3fcfa3185b96b1df debian-mac-11.2.0-amd64-netinst.iso # you can check them manually, or you do something like this \u003e diff \u003c(shasum -a 256 debian-mac-11.2.0-amd64-netinst.iso) \u003c(echo \"011f6754601985f46fcc670ce02faabcc8b5b8aadf51bc3d3fcfa3185b96b1df debian-mac-11.2.0-amd64-netinst.iso\") ","date":"2022-01-10","objectID":"/en/exercise09-missingsemester-2020/:1:2","series":null,"tags":["Course"],"title":"The solutions for exercise09 of Missingsemester(2020)","uri":"/en/exercise09-missingsemester-2020/#cryptographic-hash-functions"},{"categories":["Course"],"content":" Symmetric cryptography Encrypt a file with AES encryption, usingOpenSSL: openssl aes-256-cbc -salt -in {input filename} -out {output filename}. Look at the contents using cat or hexdump. Decrypt it with openssl aes-256-cbc -d -in {input filename} -out {output filename} and confirm that the contents match the original using cmp bash \u003e echo \"Hello world\" \u003e\u003e sample.txt \u003e openssl aes-256-cbc -salt -in sample.txt -out sample.enc.txt # I use `password` as my password \u003e cat sample.enc.txt # Salted__nÔøΩÔøΩsiZÔøΩ\u003eo;w\u003eÔøΩÔøΩÔøΩÔøΩkÔøΩÔøΩ.% \u003e openssl aes-256-cbc -d --in sample.enc.txt --out recover.txt # Enter `password` \u003e cmp sample.txt recover.txt Set up SSH keys on a computer you have access to (not Athena, because Kerberos interacts weirdly with SSH keys). Make sure your private key is encrypted with a passphrase, so it is protected at rest. Set up GPG Send Anish an encrypted email (public key). Sign a Git commit with git commit -S or create a signed Git tag withgit tag -s. Verify the signature on the commit with git show --show-signature or on the tag with git tag -v. I have tried this. Skip :) Skip :) Skip :) ","date":"2022-01-10","objectID":"/en/exercise09-missingsemester-2020/:1:3","series":null,"tags":["Course"],"title":"The solutions for exercise09 of Missingsemester(2020)","uri":"/en/exercise09-missingsemester-2020/#symmetric-cryptography"},{"categories":["Course"],"content":"the simple solutions for exercise08 of Missingsemester 2020","date":"2022-01-08","objectID":"/en/exercise08-missingsemester-2020/","series":null,"tags":["Course","Makefile","Git"],"title":"The solutions for exercise08 of Missingsemester(2020)","uri":"/en/exercise08-missingsemester-2020/"},{"categories":["Course"],"content":" Lecture 08. Metaprogramming Most makefiles provide a target called clean. This isn‚Äôt intended to produce a file called clean, but instead to clean up any files that can be re-built by make. Think of it as a way to ‚Äúundo‚Äù all of the build steps. Implement a clean target for the paper.pdf Makefile above. You will have to make the target phony. You may find the git ls-filessubcommand useful. A number of other very common make targets are listed here. If you check the files in the folder after we run make, you will find that the new files are paper.aux, paper.log, paper.pdf and paper.png. These files are what we want to clean. In order to do this, we can modify Makefile like this ‚¨áÔ∏è makefile paper.pdf: paper.tex plot-data.png pdflatex paper.tex plot-%.png: %.dat plot.py ./plot.py -i $*.dat -o $@ .PHONY: clean cleanall: cleanaux cleanlog cleanpdf cleanpng cleanaux: rm *.aux cleanlog: rm *.log cleanpdf: rm *.pdf cleanpng: rm *.png Take a look at the various ways to specify version requirements for dependencies in Rust‚Äôs build system. Most package repositories support similar syntax. For each one (caret, tilde, wildcard, comparison, and multiple), try to come up with a use-case in which that particular kind of requirement makes sense. Caret requirements: It is used to update minor version and patch version. Tilde requirements: It is used to match the most recent patch version by freezing major version and minor version. Wildcard requirements: It is used to specify major version and accept any minor version and patch version. Both of comparison requirements and multiple requirements are used to give more control over packages. We may used them to overcome conflicts. Git can act as a simple CI system all by itself. In .git/hooks inside any git repository, you will find (currently inactive) files that are run as scripts when a particular action happens. Write a pre-commit hook that runs make paper.pdf and refuses the commit if the make command fails. This should prevent any commit from having an unbuildable version of the paper. After reading this tutorial above, You will find how git hooks work. So the solution will be ‚¨áÔ∏è Write a pre-commit hook in whatever languages you like. Here is my scipt. bash #!/usr/bin/env bash if ! make paper.pdf; then echo \"==\u003e Running make command fail :(\" exit 1 else echo \"==\u003e Running make command successfully :)\" exit 0 fi Change the file mode of hook you just wrote, make it executable. Type chmod u+x pre-commit in your terminal. mv the hook to .git/hooks. Type mv pre-commit .git/hooks/pre-commit Now it time to test if your hook works as you expected ü§ó ‚¨áÔ∏è bash \u003e git add . \u003e git commit -m \"Try to commit\" Set up a simple auto-published page using GitHub Pages. Add a GitHub Action to the repository to run shellcheck on any shell files in that repository (here is one way to do it). Check that it works! This blog is host by Github Pagesü§ó First, create a yml file in your .github/workflows/. My yml file looks like: yaml on: [push] name: 'Trigger: Push action' jobs: shellcheck: name: Shellcheck runs-on: ubuntu-latest steps: - uses: actions/checkout@v2 - name: Run ShellCheck uses: ludeeus/action-shellcheck@master git add \u0026\u0026 git commit -m \"\" \u0026\u0026 git push. Add your workflow to your remote repo. Now we can create a simple .sh file. I deliberately didn‚Äôt add shebang in sh file. sh date If you run shellcheck in your local machine, you should get a warning says: SC2148 (error): Tips depend on target shell and yours is unknown. Add a shebang or a 'shell' directive. git add \u0026\u0026 git commit -m \"\" \u0026\u0026 git push. Check if your workflow works by clicking Actions in your repo. You will see it didn‚Äôt pass the test. The output is: text Run ludeeus/action-shellcheck@master Run problem_matcher_file=\"/home/runner/work/_actions/ludeeus/action-shellcheck/master/.github/problem-matcher-gcc.json\" Run if [[ \"Linux\" == \"macOS\" ]]; then Run \"/home/runner/work/_actions/ludeeus/action-shellcheck/master/shellcheck\" --version ShellCheck - shell sc","date":"2022-01-08","objectID":"/en/exercise08-missingsemester-2020/:1:0","series":null,"tags":["Course","Makefile","Git"],"title":"The solutions for exercise08 of Missingsemester(2020)","uri":"/en/exercise08-missingsemester-2020/#lecture-08-metaprogramming"},{"categories":["Programming-Languages"],"content":"A simple guide to use logging module in python","date":"2022-01-07","objectID":"/en/how-to-use-logging-in-python/","series":null,"tags":["Python","Logging"],"title":"How to Use Logging in Python","uri":"/en/how-to-use-logging-in-python/"},{"categories":["Programming-Languages"],"content":" Intro Recently I was fine-tuning my deep learning model, and I habitually started to use print to print some key information on the terminal. So my workflow is like: I type some hyperparameters to train my model. I manually opened an Excel to record the hyperparameters used and the model evaluation results. And I will go back to step 1. If I am not satisfied with results. Soon, I became bored with this workflow (In fact, I kept this for quite a long time.). However, I suddenly forgot to record key information manually. As a result, I had to navigate in the history output of the the terminal slowly. At this time, I think I should use logging. I don‚Äôt want to tortue myself anymoreüôÖ‚Äç‚ôÇÔ∏è. That‚Äôs why I wrote this blog postü§ó ","date":"2022-01-07","objectID":"/en/how-to-use-logging-in-python/:1:0","series":null,"tags":["Python","Logging"],"title":"How to Use Logging in Python","uri":"/en/how-to-use-logging-in-python/#intro"},{"categories":["Programming-Languages"],"content":" Basic ","date":"2022-01-07","objectID":"/en/how-to-use-logging-in-python/:2:0","series":null,"tags":["Python","Logging"],"title":"How to Use Logging in Python","uri":"/en/how-to-use-logging-in-python/#basic"},{"categories":["Programming-Languages"],"content":" logger level DEBUG When you want to debug your python file INFO Make sure everything goes as expected WARNING Something unexpected happened. It may cause some problems in the future ERROR Some function may fail CRITICAL The program may stop running The 5 levels actually mean different severity. By default, tbe logging module will only record WARNING level or above(ERROR + CRITICAL) ","date":"2022-01-07","objectID":"/en/how-to-use-logging-in-python/:2:1","series":null,"tags":["Python","Logging"],"title":"How to Use Logging in Python","uri":"/en/how-to-use-logging-in-python/#logger-level"},{"categories":["Programming-Languages"],"content":" Best Practice ","date":"2022-01-07","objectID":"/en/how-to-use-logging-in-python/:3:0","series":null,"tags":["Python","Logging"],"title":"How to Use Logging in Python","uri":"/en/how-to-use-logging-in-python/#best-practice"},{"categories":["Programming-Languages"],"content":" Step 1. Import logging module and define your customized loggerOf course, you can use the default logger without configurations. See a qucik example ‚¨áÔ∏è python import logging logging.warning(\"WARNING!!!\") # output # WARNING:root:WARNING!!! How to customized your loggerUse logging.basicConfig(args). The logging module provides us some args to customize our own logger. For example: filename: the logfile filename level: it decides what type of level(or above)‚Äôs messages will be recorded format: the format of message filemode: By default, it is equal to a, which means append python import logging logging.basicConfig(level=logging.INFO) logging.info(\"Everything is ok\") # output # INFO:root:Everything is ok ","date":"2022-01-07","objectID":"/en/how-to-use-logging-in-python/:3:1","series":null,"tags":["Python","Logging"],"title":"How to Use Logging in Python","uri":"/en/how-to-use-logging-in-python/#step-1-import-logging-module-and-define-your-customized-logger"},{"categories":["Programming-Languages"],"content":" Step 1. Import logging module and define your customized loggerOf course, you can use the default logger without configurations. See a qucik example ‚¨áÔ∏è python import logging logging.warning(\"WARNING!!!\") # output # WARNING:root:WARNING!!! How to customized your loggerUse logging.basicConfig(args). The logging module provides us some args to customize our own logger. For example: filename: the logfile filename level: it decides what type of level(or above)‚Äôs messages will be recorded format: the format of message filemode: By default, it is equal to a, which means append python import logging logging.basicConfig(level=logging.INFO) logging.info(\"Everything is ok\") # output # INFO:root:Everything is ok ","date":"2022-01-07","objectID":"/en/how-to-use-logging-in-python/:3:1","series":null,"tags":["Python","Logging"],"title":"How to Use Logging in Python","uri":"/en/how-to-use-logging-in-python/#how-to-customized-your-logger"},{"categories":["Programming-Languages"],"content":" Step 2. Start logging messagesYou can logging whatever messages you like. The logging module provide us some LogRecord attributes. For example: %(asctime)s: Human-readable time %(levelname)s: Indicating the logginglevel %(message)s: logged message Usually, we will use these LogRecord attributes in aforementioned format arg. For example‚¨áÔ∏è python import logging logging.basicConfig(level=logging.INFO, format=\"%(asctime)s ==\u003e %(message)s\") logging.info(\"Everything is ok\") # output # 2022-01-08 00:32:11,579 ==\u003e Everything is ok ","date":"2022-01-07","objectID":"/en/how-to-use-logging-in-python/:3:2","series":null,"tags":["Python","Logging"],"title":"How to Use Logging in Python","uri":"/en/how-to-use-logging-in-python/#step-2-start-logging-messages"},{"categories":["Programming-Languages"],"content":" Advanced The previous article talks about how to debug in python. In fact, learning to use logging is also a powerful way to help debugging. For example, we can use logging to record the report when the program crashed. See a simple example‚¨áÔ∏è python import logging try: print(4 // 0) except Exception as e: logging.error(\"===\u003e Exception detected\", exc_info=True) # output: # ERROR:root:===\u003e Exception detected # Traceback (most recent call last): # File \"hello.py\", line 4, in \u003cmodule\u003e # print(4 // 0) # ZeroDivisionError: integer division or modulo by zero ","date":"2022-01-07","objectID":"/en/how-to-use-logging-in-python/:4:0","series":null,"tags":["Python","Logging"],"title":"How to Use Logging in Python","uri":"/en/how-to-use-logging-in-python/#advanced"},{"categories":["Programming-Languages"],"content":" Refs logging HOWTO logging docs ","date":"2022-01-07","objectID":"/en/how-to-use-logging-in-python/:5:0","series":null,"tags":["Python","Logging"],"title":"How to Use Logging in Python","uri":"/en/how-to-use-logging-in-python/#refs"},{"categories":["Course"],"content":"the simple solutions for exercise07 of Missingsemester 2020","date":"2022-01-03","objectID":"/en/exercise07-missingsemester-2020/","series":null,"tags":["Course","Profiling"],"title":"The solutions for exercise07 of Missingsemester(2020)","uri":"/en/exercise07-missingsemester-2020/"},{"categories":["Course"],"content":" debugging Use journalctl on Linux or log show on macOS to get the super user accesses and commands in the last day. If there aren‚Äôt any you can execute some harmless commands such as sudo ls and check again. When I run log show --last 1d, it keeps running for along time. I don‚Äôt know how long it make take, so I will just execute harmless sudo ls to check the log. bash \u003e sudo ls \u003e log show --last 10s | grep -E \"sudo\" # you should see the last line of output says # you once run ls in super user access Do this hands on pdb tutorial to familiarize yourself with the commands. For a more in depth tutorial read this. I have finished this tutorial. Actually, I fork this repo and add chinese translation. Install shellcheck and try checking the following script. What is wrong with the code? Fix it. Install a linter plugin in your editor so you can get your warnings automatically. bash #!/bin/sh ## Example: a typical script with several problems for f in $(ls *.m3u) do grep -qi hq.*mp3 $f \\ \u0026\u0026 echo -e 'Playlist $f contains a HQ file in mp3 format' done ERROR SC2045. In line 3, it says Iterating over ls output is fragile. Use globs. WARNINGS SC2062. In line 5, it says Quote the grep pattern so the shell won‚Äôt interpret it. SC3037. In line 6, it says In POSIX sh, echo flags are undefined. I think we can use bash instead of sh INFO SC2016. In line 6, it says Expressions don‚Äôt expand in single quotes, use double quotes for that. SC2086. In line 5, it says Double quote to prevent globbing and word splitting. SC3010. After following the guide of SC2045, I added a line([[ -e $f ]] || break) below do. SC3010 says In POSIX sh, [[ ]] is undefined. Then I change shebang to #!/bin/bash So the final version of sh file is ‚¨áÔ∏è bash #!/bin/bash ## Example: a typical script with several problems for f in *.m3u do [[ -e \"$f\" ]] || break # handle the case of no *.m3u files grep -qi \"hq.*mp3\" \"$f\" \\ \u0026\u0026 echo -e \"Playlist $f contains a HQ file in mp3 format\" done (Advanced) Read about reversible debugging and get a simple example working using rr or RevPDB. PASS :) ","date":"2022-01-03","objectID":"/en/exercise07-missingsemester-2020/:0:1","series":null,"tags":["Course","Profiling"],"title":"The solutions for exercise07 of Missingsemester(2020)","uri":"/en/exercise07-missingsemester-2020/#debugging"},{"categories":["Course"],"content":" Profiling Here are some sorting algorithm implementations. Use cProfile and line_profiler to compare the runtime of insertion sort and quicksort. What is the bottleneck of each algorithm? Use then memory_profiler to check the memory consumption, why is insertion sort better? Check now the inplace version of quicksort. Challenge: Use perf to look at the cycle counts and cache hits and misses of each algorithm. ü§îWe can type python -m cProfile -s tottime sorts.py 1000 in the terminal to get the runtime of insertion sort and quicksort. 1000 means that we will run this sorts.py 1000 times. Check documentations for more details. text ncalls tottime percall cumtime percall filename:lineno(function) ... 1000 0.045 0.000 0.045 0.000 sorts.py:12(insertionsort) 33218/1000 0.044 0.000 0.068 0.000 sorts.py:25(quicksort) ... ü§îIf you want to use line_profiler to compare the runtime of insertion sort and quicksort, you need to add @profile decorator above insertion sort and quicksort(You should install line_profiler fist by pip install line_profiler). The code will be like ‚¨áÔ∏è python @profile def insertionsort(array): ... @profile def quicksort(array): ... Then type kernprof -v -l sorts.py in your terminal. The output will look like: ‚¨áÔ∏è text Wrote profile results to sorts.py.lprof Timer unit: 1e-06 s Total time: 0.382157 s File: sorts.py Function: insertionsort at line 11 Line # Hits Time Per Hit % Time Line Contents ============================================================== 11 @profile 12 def insertionsort(array): 13 14 25881 10925.0 0.4 2.9 for i in range(len(array)): 15 24881 10814.0 0.4 2.8 j = i-1 16 24881 11411.0 0.5 3.0 v = array[i] 17 221660 133321.0 0.6 34.9 while j \u003e= 0 and v \u003c array[j]: 18 196779 113095.0 0.6 29.6 array[j+1] = array[j] 19 196779 88824.0 0.5 23.2 j -= 1 20 24881 13333.0 0.5 3.5 array[j+1] = v 21 1000 434.0 0.4 0.1 return array Total time: 0.162542 s File: sorts.py Function: quicksort at line 24 Line # Hits Time Per Hit % Time Line Contents ============================================================== 24 @profile 25 def quicksort(array): 26 33150 24083.0 0.7 14.8 if len(array) \u003c= 1: 27 17075 9918.0 0.6 6.1 return array 28 16075 10775.0 0.7 6.6 pivot = array[0] 29 16075 46333.0 2.9 28.5 left = [i for i in array[1:] if i \u003c pivot] 30 16075 46896.0 2.9 28.9 right = [i for i in array[1:] if i \u003e= pivot] 31 16075 24537.0 1.5 15.1 return quicksort(left) + [pivot] + quicksort(right) So we can easily find that the bottleneck(rows which have high % Time). More details can be found on this ü§îNow we come to the memory_profiler part. If you haven‚Äôt installed it, you may run pip install -U memory_profiler. The usage of memory_profiler is quite similar to the line_profiler. Both of them need to add @profile first, then you can run ``. The output will be like ‚¨áÔ∏è text Filename: sorts.py Line # Mem usage Increment Occurences Line Contents ============================================================ 11 38.176 MiB 38.176 MiB 1000 @profile 12 def insertionsort(array): 13 14 38.176 MiB 0.000 MiB 25694 for i in range(len(array)): 15 38.176 MiB 0.000 MiB 24694 j = i-1 16 38.176 MiB 0.000 MiB 24694 v = array[i] 17 38.176 MiB 0.000 MiB 223188 while j \u003e= 0 and v \u003c array[j]: 18 38.176 MiB 0.000 MiB 198494 array[j+1] = array[j] 19 38.176 MiB 0.000 MiB 198494 j -= 1 20 38.176 MiB 0.000 MiB 24694 array[j+1] = v 21 38.176 MiB 0.000 MiB 1000 return array Filename: sorts.py Line # Mem usage Increment Occurences Line Contents ============================================================ 24 38.172 MiB 38.148 MiB 33522 @profile 25 def quicksort(array): 26 38.172 MiB 0.000 MiB 33522 if len(array) \u003c= 1: 27 38.172 MiB 0.000 MiB 17261 return array 28 38.172 MiB 0.000 MiB 16261 pivot = array[0] 29 38.172 MiB 0.004 MiB 156337 left = [i for i in array[1:] if i \u003c pivot] 30 38.172 MiB 0.000 MiB 156337 right = [i for i in array[1:] if i \u003e= pivot] 31 38.172 MiB 0.020 MiB 16261 return quicksort(left) + [pivot] + quicksort(right) It is weird, insertion sort is no ","date":"2022-01-03","objectID":"/en/exercise07-missingsemester-2020/:0:2","series":null,"tags":["Course","Profiling"],"title":"The solutions for exercise07 of Missingsemester(2020)","uri":"/en/exercise07-missingsemester-2020/#profiling"},{"categories":["Course"],"content":"the solutions for exercise05 \u0026\u0026 exercise06 of MIT. Missing-semester(2020)","date":"2021-12-27","objectID":"/en/exercise05-06-missingsemester-2020/","series":null,"tags":["Course","Bash","Git"],"title":"The solutions for exercise 05\u002606 of MIT.Missing-semester(2020)","uri":"/en/exercise05-06-missingsemester-2020/"},{"categories":["Course"],"content":" Lecture05. Command-line Environment ","date":"2021-12-27","objectID":"/en/exercise05-06-missingsemester-2020/:1:0","series":null,"tags":["Course","Bash","Git"],"title":"The solutions for exercise 05\u002606 of MIT.Missing-semester(2020)","uri":"/en/exercise05-06-missingsemester-2020/#lecture05-command-line-environment"},{"categories":["Course"],"content":" Job control From what we have seen, we can use some ps aux | grep commands to get our jobs‚Äô pids and then kill them, but there are better ways to do it. Start a sleep 10000 job in a terminal, background it with Ctrl-Z and continue its execution with bg. Now use pgrep to find its pid and pkill to kill it without ever typing the pid itself. (Hint: use the -af flags). bash \u003e sleep 10000 # press Ctril-Z # output: [1] + 29705 suspended sleep 10000 \u003e bg %1 # output: [1] + 29705 continued sleep 10000 \u003e pgrep -af \"sleep\" # output: 29705 \u003e pkill -af \"sleep\" # output: [1] + 29705 terminated sleep 10000 Apparently, pgrep and pkill are quite handy. We won‚Äôt be bothered to find out the pid ourselves. Say you don‚Äôt want to start a process until another completes. How would you go about it? In this exercise, our limiting process will always be sleep 60 \u0026. One way to achieve this is to use the wait command. Try launching the sleep command and having an ls wait until the background process finishes. However, this strategy will fail if we start in a different bash session, since wait only works for child processes. One feature we did not discuss in the notes is that the kill command‚Äôs exit status will be zero on success and nonzero otherwise. kill -0 does not send a signal but will give a nonzero exit status if the process does not exist. Write a bash function called pidwait that takes a pid and waits until the given process completes. You should use sleep to avoid wasting CPU unnecessarily. We can use wait \u003cpid\u003e to wait for a process to complete before proceeding. Then the question is what is exactly the pid of sleep 60 \u0026. In last exercise, we know we can use pgrep to get the pid by process name. So the basic solution will be: bash \u003e sleep 60 \u0026 \u003e pgrep \"sleep\" | wait \u0026\u0026 ls However, the wait command is session-dependent. So we need to use kill -0. The pidwait() in pidwait.sh is like ‚¨áÔ∏è bash #!/bin/bash pidwait() { while kill -0 $1 2\u003e/dev/null # catch stderr to /dev/null do sleep 1 done ls } You can test like this ‚¨áÔ∏è bash \u003e source pidwait.sh \u003e sleep 60 \u0026 \u003e pidwait $(pgrep \"sleep\") ","date":"2021-12-27","objectID":"/en/exercise05-06-missingsemester-2020/:1:1","series":null,"tags":["Course","Bash","Git"],"title":"The solutions for exercise 05\u002606 of MIT.Missing-semester(2020)","uri":"/en/exercise05-06-missingsemester-2020/#job-control"},{"categories":["Course"],"content":" Terminal multiplexer Follow this tmux tutorial and then learn how to do some basic customizations following these steps Just follow the tutorial. ","date":"2021-12-27","objectID":"/en/exercise05-06-missingsemester-2020/:1:2","series":null,"tags":["Course","Bash","Git"],"title":"The solutions for exercise 05\u002606 of MIT.Missing-semester(2020)","uri":"/en/exercise05-06-missingsemester-2020/#terminal-multiplexer"},{"categories":["Course"],"content":" Aliases Create an alias dc that resolves to cd for when you type it wrongly. bash \u003e alias dc=cd Run history | awk '{$1=\"\";print substr($0,2)}' | sort | uniq -c | sort -n | tail -n 10 to get your top 10 most used commands and consider writing shorter aliases for them. Note: this works for Bash; if you‚Äôre using ZSH, use history 1 instead of just history. bash \u003e alias top10=\"history 1| awk '{\\$1=\\\"\\\";print substr(\\$0,2)}' | sort | uniq -c | sort -n | tail -n 10\" ‚ö†Ô∏è WARNING: You need to use \\ to escape \" and $n ","date":"2021-12-27","objectID":"/en/exercise05-06-missingsemester-2020/:1:3","series":null,"tags":["Course","Bash","Git"],"title":"The solutions for exercise 05\u002606 of MIT.Missing-semester(2020)","uri":"/en/exercise05-06-missingsemester-2020/#aliases"},{"categories":["Course"],"content":" Dotfiles Let‚Äôs get you up to speed with dotfiles. Create a folder for your dotfiles and set up version control. Add a configuration for at least one program, e.g. your shell, with some customization (to start off, it can be something as simple as customizing your shell prompt by setting $PS1). Set up a method to install your dotfiles quickly (and without manual effort) on a new machine. This can be as simple as a shell script that calls ln -sfor each file, or you could use a specialized utility. Test your installation script on a fresh virtual machine. Migrate all of your current tool configurations to your dotfiles repository. Publish your dotfiles on GitHub. It is weird. ü§î I created a folder and migrate all my configurations to it. And I also made soft links. However, it is just didn‚Äôt work. ","date":"2021-12-27","objectID":"/en/exercise05-06-missingsemester-2020/:1:4","series":null,"tags":["Course","Bash","Git"],"title":"The solutions for exercise 05\u002606 of MIT.Missing-semester(2020)","uri":"/en/exercise05-06-missingsemester-2020/#dotfiles"},{"categories":["Course"],"content":" Remote machines Install a Linux virtual machine (or use an already existing one) for this exercise. If you are not familiar with virtual machines check out this tutorial for installing one. Go to ~/.ssh/ and check if you have a pair of SSH keys there. If not, generate them with ssh-keygen -o -a 100 -t ed25519. It is recommended that you use a password and use ssh-agent , more info here. Edit .ssh/config to have an entry as follows text Host vm User username_goes_here HostName ip_goes_here IdentityFile ~/.ssh/id_ed25519 LocalForward 9999 localhost:8888 Use ssh-copy-id vm to copy your ssh key to the server. Start a webserver in your VM by executing python -m http.server 8888. Access the VM webserver by navigating to http://localhost:9999 in your machine. Edit your SSH server config by doing sudo vim /etc/ssh/sshd_configand disable password authentication by editing the value of PasswordAuthentication. Disable root login by editing the value of PermitRootLogin. Restart the ssh service with sudo service sshd restart. Try sshing in again. (Challenge) Install mosh in the VM and establish a connection. Then disconnect the network adapter of the server/VM. Can mosh properly recover from it? (Challenge) Look into what the -N and -f flags do in ssh and figure out a command to achieve background port forwarding. I don‚Äôt have enough disk space for a linux virtual machine :( ","date":"2021-12-27","objectID":"/en/exercise05-06-missingsemester-2020/:1:5","series":null,"tags":["Course","Bash","Git"],"title":"The solutions for exercise 05\u002606 of MIT.Missing-semester(2020)","uri":"/en/exercise05-06-missingsemester-2020/#remote-machines"},{"categories":["Course"],"content":" Lecture 06. Version Control(git) If you don‚Äôt have any past experience with Git, either try reading the first couple chapters of Pro Git or go through a tutorial like Learn Git Branching. As you‚Äôre working through it, relate Git commands to the data model. :) Clone the repository for the class website Explore the version history by visualizing it as a graph. Who was the last person to modify README.md? (Hint: use git log with an argument). What was the commit message associated with the last modification to the collections: line of _config.yml? (Hint: use git blame and git show). bash \u003e git clone git@github.com:missing-semester/missing-semester.git \u003e cd missing-semester # step 1. \u003e git log --oneline --all --graph --color # step 2. \u003e git log -1 README.md # -1 means showing last related commit # then we know Anish Athalye is the last person modify README.md # step 3. \u003e git blame _config.yml | grep -E \"collections:\" # then we know the commit's sha-1 value is a88b4eac # we can use `git show` command to get commit message \u003e git show -q a88b4eac # -q means --quiet, it will suppress diff output One common mistake when learning Git is to commit large files that should not be managed by Git or adding sensitive information. Try adding a file to a repository, making some commits and then deleting that file from history (you may want to look at this). I made a new repo and made some commits. Finally I found the correct command to delete a file from all history ü§ó Ths command we are going to use is git filter-repo. If you haven‚Äôt installed it, you may just run brew install git filter-repo (for mac users). Then use this ‚Äúmagic‚Äù command do finish this exercise. bash \u003e git filter-repo --invert-paths --force --path \u003cfile\u003e The reason why I use --force is that git filter-repo refuses to overwrite my repo. It says my repo doesn‚Äôt look like a fresh clone. The mechanism behind this command is: --invert-paths will only select files matching none of options which we specify by --path. So it will keep everything except \u003cfile\u003e, and overwrite this commit history. Clone some repository from GitHub, and modify one of its existing files. What happens when you do git stash? What do you see when running git log --all --oneline? Run git stash pop to undo what you did with git stash. In what scenario might this be useful? I tried to modify README.md is the repo for the class website. Then I ran git stash. The output is: Saved working directory and index state WIP on master: c2f9535 Merge pull request #172 from chapmanjacobd/patch-1 text * 96cca4b (refs/stash) WIP on master: c2f9535 Merge pull request #172 from chapmanjacobd/patch-1 |\\ | * a95c46f index on master: c2f9535 Merge pull request #172 from chapmanjacobd/patch-1 |/ * c2f9535 (HEAD -\u003e master, origin/master, origin/HEAD) Merge pull request #172 from chapmanjacobd/patch-1 Then I ran git stash pop. My modification has come back. The scenario of using git stash is that: For exmaple, say I have beening working on my project in master branch for quite a long time. Now I want to switch to another branch, but my working directory is in a mess. I don‚Äôt want to make a dirty commit to temporarily save my work. Here comes the git stash. I can use this command to temporarily save my half-finished work. ü§ó Like many command line tools, Git provides a configuration file (or dotfile) called ~/.gitconfig. Create an alias in ~/.gitconfig so that when you run git graph, you get the output of git log --all --graph --decorate --oneline. Information about git aliases can be found here. bash \u003e git config --global --add alias.graph 'log --all --graph --decorate --oneline' \u003e git graph You can define global ignore patterns in ~/.gitignore_global after running git config --global core.excludesfile ~/.gitignore_global. Do this, and set up your global gitignore file to ignore OS-specific or editor-specific temporary files, like .DS_Store. bash \u003e git config --global core.excludesfile ~/.gitignore_global \u003e echo \".DS_Store\" \u003e\u003e ~/.test","date":"2021-12-27","objectID":"/en/exercise05-06-missingsemester-2020/:2:0","series":null,"tags":["Course","Bash","Git"],"title":"The solutions for exercise 05\u002606 of MIT.Missing-semester(2020)","uri":"/en/exercise05-06-missingsemester-2020/#lecture-06-version-controlgit"},{"categories":["Course"],"content":"the solutions for exercise03 \u0026\u0026 exercise04 of MIT. Missing-semester(2020)","date":"2021-12-26","objectID":"/en/exercise03-04-missingsemester-2020/","series":null,"tags":["Course","Vim-Neovim"],"title":"The solutions for exercise 03\u002604 of MIT.Missing-semester(2020)","uri":"/en/exercise03-04-missingsemester-2020/"},{"categories":["Course"],"content":" Lecture 03. Editors (Vim) Complete vimtutor. Note: it looks best in a 80x24 (80 columns by 24 lines) terminal window. It is a tutorial for beginners of vim. I will just put some notes which are not mentioned in course here. U command: When we press u in normal mode, we can undo the last command. What U does is fixing a whole line. Ctrl + G: show your location in the file and the file status. Type the linenumber you want to go, then press G, then you are there. To search for a phrase in the backward direction, use ? instead of / . Type :! followed by an external command to execute that command. Select text to write Use visual mode to select text type :w \u003ctype_filename_here You can also type :!ls to verify this To insert the contents of a file, type :r FILENAME Furthermore, You can also read the output of an external command. For example, :r !ls reads the output of the ls command Type a capital R to replace more than one character. Download our basic vimrc and save it to ~/.vimrc. Read through the well-commented file (using Vim!), and observe how Vim looks and behaves slightly differently with the new config. I would recommend making your own configuration. Install and configure a plugin: ctrlp.vim Create the plugins directory with mkdir -p ~/.vim/pack/vendor/start Download the plugin: cd ~/.vim/pack/vendor/start; git clone https://github.com/ctrlpvim/ctrlp.vim Read the documentation for the plugin. Try using CtrlP to locate a file by navigating to a project directory, opening Vim, and using the Vim command-line to start :CtrlP. Customize CtrlP by adding configuration to your ~/.vimrc to open CtrlP by pressing Ctrl-P. PASS To practice using Vim, re-do the Demo from lecture on your own machine. PASS Use Vim for all your text editing for the next month. Whenever something seems inefficient, or when you think ‚Äúthere must be a better way‚Äù, try Googling it, there probably is. If you get stuck, come to office hours or send us an email. Configure your other tools to use Vim bindings (see instructions above). I have already enable vim mode in my Vscode and zsh. üí™ Further customize your ~/.vimrc and install more plugins. I have made my own configuration (Advanced) Convert XML to JSON (example file) using Vim macros. Try to do this on your own, but you can look at the macros section above if you get stuck. The steps: Press Gdd \u0026\u0026 ggdd to delete the first line and the last line Macro to format a single element (register e) Go to line with \u003cname\u003e qe^r\"f\u003es\": \"\u003cESC\u003ef\u003cC\"\u003cESC\u003eq Macro to format a person Go to line with \u003cperson\u003e qpS{\u003cESC\u003ej@eA,\u003cESC\u003ej@ejS},\u003cESC\u003eq Macro to format a person and go to the next person Go to line with \u003cperson\u003e qq@pjq Execute macro until end of file 999@q Manually remove last , and add [ and ] delimiters The solution above is provided by the official course site. ","date":"2021-12-26","objectID":"/en/exercise03-04-missingsemester-2020/:1:0","series":null,"tags":["Course","Vim-Neovim"],"title":"The solutions for exercise 03\u002604 of MIT.Missing-semester(2020)","uri":"/en/exercise03-04-missingsemester-2020/#lecture-03-editors-vim"},{"categories":["Course"],"content":" Lecture 04. Data Wrangling Take this short interactive regex tutorial. Just click this link to finish this regex tutorial. Find the number of words (in /usr/share/dict/words) that contain at least three as and don‚Äôt have a 's ending. What are the three most common last two letters of those words? sed‚Äôs y command, or the tr program, may help you with case insensitivity. How many of those two-letter combinations are there? And for a challenge: which combinations do not occur? The answers of questions in exercise are ‚¨áÔ∏è Q: Find the number of words (in /usr/share/dict/words) that contain at least three as and don‚Äôt have a 's ending. Answer: tr 'A-Z' 'a-z' \u003c /usr/share/dict/words | grep -E '.*a.*a.*a.*[^s]$' | wc -l, üëâ 5290 Use tr 'A-Z' 'a-z' \u003c /usr/share/dict/words to make text case-insensitive Use grep -E 'grep -E '.*a.*a.*a.*[^s]$' to find the words that contain at least three a and don‚Äôt have a 's ending The combination of .* means any character repeats any times. [s] will match the s character. We add a ^ in [], which mean we want to match any single character excepet s Use wc -l to count the number of lines in output. Q: What are the three most common last two letters of those words? A: tr 'A-Z' 'a-z' \u003c /usr/share/dict/words | grep -E '.*a.*a.*a.*[^s]$' | grep -E -o '.{2}$' | sort | uniq -c | sort | tail -n 1, üëâ 1039 al and 763 an and 637 ae Use grep -E -o '.{2}$' to get last 2 letters of these words -o means Prints only the matching part of the lines. In this case, what we want is the last 2 letters, so we type .{2}$ Use sort | uniq -c to get the two-letter combinations count This can ensure the combinations are uniq. Use sort | tail -n 3 to sort previous results according to their frequency counts Q: How many of those two-letter combinations are there? A: tr 'A-Z' 'a-z' \u003c /usr/share/dict/words | grep -E '.*a.*a.*a.*[^s]$' | grep -E -o '.{2}$' | sort | uniq -c | wc -l, üëâ 140 Q: And for a challenge: which combinations do not occur? bash diff \u003c(echo {a..z}{a..z} | tr \" \" \"\\n\") \\ \u003c(tr 'A-Z' 'a-z' \u003c /usr/share/dict/words | grep -E '.*a.*a.*a.*[^s]$' | grep -E -o '.{2}$' | sort | uniq -c | sort | awk '{print $2}' | sort) \\ | grep -E \"\u003c\" \\ | wc -l # output: 536 Use echo {a..z}{a..z} to get all two-letter combinations. However, in order to compare 2 sets of combinations(this one \u0026\u0026 Our previous results), we need to use \\n as delimiter of each combination. We can use tr \" \" \"\\n\". In the previous question, we can get every different combinations and their frequency counts. Each row looks like \u003cfrequency count\u003e combination. In order to get the combinations, we can use awk {print $2}, $2 means the second field in each row. After that, we need to Then we need a tool to compare the 2 sets of combinations. Here comes the diff command. diff will compare 2 files line by line. We also need Process substation to pass the 2 sets of combinations as arguments of diff To do in-place substitution it is quite tempting to do something like sed s/REGEX/SUBSTITUTION/ input.txt \u003e input.txt. However this is a bad idea, why? Is this particular to sed? Use man sed to find out how to accomplish this. This exercie remind me of the shellcheck tool. So I just type sed s/REGEX/SUBSTITUTION/ input.txt \u003e input.txt in a test.sh file and run shellcheck test.sh. Then I knew THIS IS A BAD IDEA. üìí We should not read and write the same file in the same pipeline. After checking man sed carefully, I found 2 flags helpful‚Äì-i and -I. Both of them can edit file in-place. More information, you may check Find your average, median, and max system boot time over the last ten boots. Use bash journalctl on Linux and bash log show on macOS, and look for log timestamps near the beginning and end of each boot. On Linux, they may look something like: bash Logs begin at ... and bash systemd[577]: Startup finished in ... On macOS, look for: bash === system boot: and bash Previous shutdown cause: 5 I am a macos user. I barely shutdown my Macbook Pro. So when I ran log show | grep -E \"","date":"2021-12-26","objectID":"/en/exercise03-04-missingsemester-2020/:2:0","series":null,"tags":["Course","Vim-Neovim"],"title":"The solutions for exercise 03\u002604 of MIT.Missing-semester(2020)","uri":"/en/exercise03-04-missingsemester-2020/#lecture-04-data-wrangling"},{"categories":["Course"],"content":" References Accessing last x characters of a string in Bash Process substitution ","date":"2021-12-26","objectID":"/en/exercise03-04-missingsemester-2020/:3:0","series":null,"tags":["Course","Vim-Neovim"],"title":"The solutions for exercise 03\u002604 of MIT.Missing-semester(2020)","uri":"/en/exercise03-04-missingsemester-2020/#references"},{"categories":["Programming-Languages"],"content":"A simple guide of drawing relation graph in python","date":"2021-12-25","objectID":"/en/how-to-draw-a-simple-relation-graph-in-python/","series":null,"tags":["Data-visualization","Python"],"title":"How to draw a simple relation graph in Python","uri":"/en/how-to-draw-a-simple-relation-graph-in-python/"},{"categories":["Programming-Languages"],"content":" Intro The process of drawing a simple relation graph in python can be broken down into 2 steps. Define a graph. Draw a graph. ","date":"2021-12-25","objectID":"/en/how-to-draw-a-simple-relation-graph-in-python/:1:0","series":null,"tags":["Data-visualization","Python"],"title":"How to draw a simple relation graph in Python","uri":"/en/how-to-draw-a-simple-relation-graph-in-python/#intro"},{"categories":["Programming-Languages"],"content":" Step 1. Define a graph In this step, we will use the networkx package. ","date":"2021-12-25","objectID":"/en/how-to-draw-a-simple-relation-graph-in-python/:2:0","series":null,"tags":["Data-visualization","Python"],"title":"How to draw a simple relation graph in Python","uri":"/en/how-to-draw-a-simple-relation-graph-in-python/#step-1-define-a-graph"},{"categories":["Programming-Languages"],"content":" Install tutorialIf you are using conda, you can just type conda install networkx If you are using pip, you can just type pip install networkx ","date":"2021-12-25","objectID":"/en/how-to-draw-a-simple-relation-graph-in-python/:2:1","series":null,"tags":["Data-visualization","Python"],"title":"How to draw a simple relation graph in Python","uri":"/en/how-to-draw-a-simple-relation-graph-in-python/#install-tutorial"},{"categories":["Programming-Languages"],"content":" NodesFirst of all, you need to create a graph. python import networkx as nx G = nx.Graph() You can use different ways to add nodes. Add one node at a time. Add nodes from any iterable container Add nodes along with node attributes. In this way, you can define many attributes of a node, such as color, size, etc. Add nodes from another graph directly python G.add_node(1) # method 1 G.add_nodes_from([2, 3, 4, 5]) # method 2 G.add_nodes_from([ # method 3 (6, {\"color\": \"red\"}), (7, {\"color\": \"blue\"}) ]) G2 = nx.Graph() # method 4 G2.add_nodes_from([8, 9, 10]) G.add_nodes_from(G2) # you can verify nodes by print(G.nodes) # NodeView((1, 2, 3, 4, 5, 6, 7, 8, 9, 10)) ","date":"2021-12-25","objectID":"/en/how-to-draw-a-simple-relation-graph-in-python/:2:2","series":null,"tags":["Data-visualization","Python"],"title":"How to draw a simple relation graph in Python","uri":"/en/how-to-draw-a-simple-relation-graph-in-python/#nodes"},{"categories":["Programming-Languages"],"content":" EdgesAlso, networkx has many ways to add edges, which is quite similar to add nodes. Let‚Äôs just jump to the codeü§ó python G.add_edge(1, 2) # method 1 G.add_edges_from([(1, 3), (1, 4)]) # method 2 G2.add_edge(8, 9) # method 3 G2.add_edge(8, 10) # WARNING: you can't just use G2 instead of G2.edges G.add_edges_from(G2.edges) # method 4 ","date":"2021-12-25","objectID":"/en/how-to-draw-a-simple-relation-graph-in-python/:2:3","series":null,"tags":["Data-visualization","Python"],"title":"How to draw a simple relation graph in Python","uri":"/en/how-to-draw-a-simple-relation-graph-in-python/#edges"},{"categories":["Programming-Languages"],"content":" Get some information about a graphUsually, we want to know some information about a graph. For example, we may want to know the number of nodes and edges, the degree of a node, etc. Of course, networkx implements this for us.‚¨áÔ∏è python # nodes information print(list(G.nodes)) # output: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] print(G.number_of_nodes()) # output: 10 # edges information print(list(G.edges)) # output: [(1, 2), (1, 3), (1, 4), (8, 9), (8, 10)] print(G.number_of_edges()) # output: 5 # neighbors of a node print(list(G.neighbors(1))) # output: [2, 3, 4] # degree information print(G.degree(1)) # output: 3, because we have edges: (1, 2), (1, 3), (1, 4) ","date":"2021-12-25","objectID":"/en/how-to-draw-a-simple-relation-graph-in-python/:2:4","series":null,"tags":["Data-visualization","Python"],"title":"How to draw a simple relation graph in Python","uri":"/en/how-to-draw-a-simple-relation-graph-in-python/#get-some-information-about-a-graph"},{"categories":["Programming-Languages"],"content":" manipulate nodes \u0026\u0026 edgesThe operation of removing is the inverse process of the operation of adding. python G.remove_node(5) G.remove_nodes_from(G2) # similar to remove_node \u0026\u0026 remove_nodes_from # you can add parameters you like # G.remove_edge() # G.remove_edges_from() ","date":"2021-12-25","objectID":"/en/how-to-draw-a-simple-relation-graph-in-python/:2:5","series":null,"tags":["Data-visualization","Python"],"title":"How to draw a simple relation graph in Python","uri":"/en/how-to-draw-a-simple-relation-graph-in-python/#manipulate-nodes--edges"},{"categories":["Programming-Languages"],"content":" ü§î üìí The node type doesn‚Äôt have to be an integer. It can also be a string. python new_G = nx.Graph() # Let's define a new graph new_G.add_node(\"abcd\") # Add a string node new_G.add_nodes_from(\"abcd\") # this line is different, we treat the string as an iterable cotainer print(list(new_G.nodes)) # output: ['abcd', 'a', 'n', 'c', 'd'] ","date":"2021-12-25","objectID":"/en/how-to-draw-a-simple-relation-graph-in-python/:2:6","series":null,"tags":["Data-visualization","Python"],"title":"How to draw a simple relation graph in Python","uri":"/en/how-to-draw-a-simple-relation-graph-in-python/#heading"},{"categories":["Programming-Languages"],"content":" Step 2. Draw a graph Although we can draw a graph defined by networkx in matplotlib.pyplot, the generated image is static and not pretty in my opinion. So I will just skip the tutorial of drawing in matplotlib.pyplot. I will use pyvis package instead. ","date":"2021-12-25","objectID":"/en/how-to-draw-a-simple-relation-graph-in-python/:3:0","series":null,"tags":["Data-visualization","Python"],"title":"How to draw a simple relation graph in Python","uri":"/en/how-to-draw-a-simple-relation-graph-in-python/#step-2-draw-a-graph"},{"categories":["Programming-Languages"],"content":" Install tutorialI didn‚Äôt find how to use conda to install pyvis, so you may just use pip install pyvis. I remember that we can use pip in conda environment, but we need to run conda install pip at first(Not quite sureüò®) ","date":"2021-12-25","objectID":"/en/how-to-draw-a-simple-relation-graph-in-python/:3:1","series":null,"tags":["Data-visualization","Python"],"title":"How to draw a simple relation graph in Python","uri":"/en/how-to-draw-a-simple-relation-graph-in-python/#install-tutorial-1"},{"categories":["Programming-Languages"],"content":" How to use pyvis python from pyvis.network import Network net = Network('500px', '500px') net.from_nx(G) # The G is defined in Step 1. net.show('net.html') Then you can open the net.html in your local machine to interact with it. It looks like this‚¨áÔ∏è I don‚Äôt know how to integrate my html file into this blog. You may check the result in this (If you follow my tutorial) ","date":"2021-12-25","objectID":"/en/how-to-draw-a-simple-relation-graph-in-python/:3:2","series":null,"tags":["Data-visualization","Python"],"title":"How to draw a simple relation graph in Python","uri":"/en/how-to-draw-a-simple-relation-graph-in-python/#how-to-use-pyvis"},{"categories":["Programming-Languages"],"content":" ü§î üìí In pyvis, the valid node attributes are‚¨áÔ∏è. So when we use networkx to add nodes, we can directly use these attributes. In this way, the pyvis will translate them for us. python ['size', 'value', 'title', 'x', 'y', 'label', 'color'] Similarly, if you want to customize your edges‚Äô attributes, you may check the docs Then you can use G.add_edge(a, b, attribute1=, attribute2, ...) ","date":"2021-12-25","objectID":"/en/how-to-draw-a-simple-relation-graph-in-python/:3:3","series":null,"tags":["Data-visualization","Python"],"title":"How to draw a simple relation graph in Python","uri":"/en/how-to-draw-a-simple-relation-graph-in-python/#heading-1"},{"categories":["Programming-Languages"],"content":" References visjs docs pyvis docs networkx tutorial ","date":"2021-12-25","objectID":"/en/how-to-draw-a-simple-relation-graph-in-python/:4:0","series":null,"tags":["Data-visualization","Python"],"title":"How to draw a simple relation graph in Python","uri":"/en/how-to-draw-a-simple-relation-graph-in-python/#references"},{"categories":["Course"],"content":"the solutions for exercise01 \u0026\u0026 exercise02 of MIT. Missing-semester(2020)","date":"2021-12-18","objectID":"/en/exercise01-02-missingsemester-2020/","series":null,"tags":["Course","Bash"],"title":"The solutions for exercise 01\u002602 of MIT. Missing-semester(2020)","uri":"/en/exercise01-02-missingsemester-2020/"},{"categories":["Course"],"content":" Lecture 01. Shell Create a new directory called missing under /tmp bash \u003e mkdir -p /tmp/missing üìí -p means Create intermediate directories as required Use touch to create a new file called semester in missing. bash \u003e cd ~/tmp/missing \u003e touch semester Write the following into that file, one line at a time: bash #!/bin/sh curl --head --silent https://missing.csail.mit.edu ‚ö†Ô∏è Make sure you are in the tmp/missing directory start from now. bash \u003e echo \"#\\!/bin/sh\" \u003e\u003e semester \u003e echo \"curl --head --silent https://missing.csail.mit.edu\" \u003e\u003e semester ‚ö†Ô∏è WarningÔºö! has a special meaning even within double-quoted(\") strings, so when we use echo \"...\" to append a string to a file, remember to use \\ to escape ! Try to execute the file bash \u003e ./semeseter # ... permission denied \u003e ls -l # you can see the permission bits are -rw-r--r-- # It suggests that we don't have execute(x) permission ## Solution 1. # run command below to, u means user, x means execute \u003e chmod u+x semester \u003e ./semester # You should see the outputs like: # HTTP/2 200 # server: GitHub.com # ... ## Solution 2. \u003e sh ./semester üìí use chmod to change the file permission, see man chmod for more information. I will suggest the tldr tool, which is quite handy, you may check tldr chmod by yourselfü§ó Use | and \u003e to write the ‚Äúlast modified‚Äù date output by semester into a file called last-modified.txt in your home directory. bash # Solution 1. \u003e date -r semester \u003e last-modified.txt # Solution 2. \u003e ls -l semester | awk '{print $6,$7,$8}' \u003e last-modified.txt Write a command that reads out your laptop battery‚Äôs power level or your desktop machine‚Äôs CPU temperature from /sys I am a macOS user, so I will just skip this exercise:) ","date":"2021-12-18","objectID":"/en/exercise01-02-missingsemester-2020/:1:0","series":null,"tags":["Course","Bash"],"title":"The solutions for exercise 01\u002602 of MIT. Missing-semester(2020)","uri":"/en/exercise01-02-missingsemester-2020/#lecture-01-shell"},{"categories":["Course"],"content":" lecture 02. Shell Tools and Scripting write an ls command that lists files in the following manner Includes all files, including hidden files Sizes are listed in human readable format (e.g. 454M instead of 454279954) Files are ordered by recency Output is colorized A sample output would look like this bash -rw-r--r-- 1 user group 1.1M Jan 14 09:53 baz drwxr-xr-x 5 user group 160 Jan 14 09:53 . -rw-r--r-- 1 user group 514 Jan 14 06:42 bar -rw-r--r-- 1 user group 106M Jan 13 12:12 foo drwx------+ 47 user group 1.5K Jan 12 18:08 .. Interpretation Usually, the filename of hidden files are begin with ., we can use -a flag to include them. If you want to list sizes in human readable format, use -lh According to the man lsÔºå-t means the output are sort by descending time modified (most recently modified first) In order to enable colorized output, use -G So the solution is‚¨áÔ∏è bash \u003e ls -a -lh -t -G Write bash functions marco and polo that do the following. Whenever you execute marco the current working directory should be saved in some manner, then when you execute polo, no matter what directory you are in, polo should cd you back to the directory where you executed marco. For ease of debugging you can write the code in a file marco.sh and (re)load the definitions to your shell by executing source marco.sh. The marco.sh‚¨áÔ∏è I store the output of pwd in ~/pwd.txt file. bash #!/bin/bash marco() { touch ~/pwd.txt pwd \u003e\u003e ~/pwd.txt } The poli.sh‚¨áÔ∏è Just use cat ~/pwd.txt to get the origin working directory. bash #!/bin/bash poli() { destination=$(cat ~/pwd.txt) cd \"$destination\" || exit } Quick test‚¨áÔ∏è bash \u003e source marco.sh \u003e source poli.sh \u003e marco \u003e cd .. # you can cd wherever you want \u003e poli # now you will go back to origin working directory üìí I highly recommend the shellcheck tool. Use it to check your *.sh file after you have finished your code. Say you have a command that fails rarely. In order to debug it you need to capture its output but it can be time consuming to get a failure run. Write a bash script that runs the following script until it fails and captures its standard output and error streams to files and prints everything at the end. Bonus points if you can also report how many runs it took for the script to fail. bash #!/usr/bin/env bash n=$(( RANDOM % 100 )) if [[ n -eq 42 ]]; then echo \"Something went wrong\" \u003e\u00262 echo \"The error was using magic numbers\" exit 1 fi echo \"Everything went according to plan\" The meaning of this script is judge if a random number(n) equal 42 or not. The random number ranges from 0 to 99, so we may need to run many many time until we get a 42. In order to debug this *.sh file, we can measure how many times we run this *.sh. Apparently, we can use do-while loop, which corresponds to until-loop in bash. I found this Link helpful. The solution is(test.sh)‚¨áÔ∏è bash #!/bin/bash count=0 # run random.sh until it goes wrong until [[ \"$?\" -ne 0 ]];do # $? will return the exit status of the most recently executed command count=$((count + 1)) bash ./random.sh \u0026\u003e result.txt # \u0026 means we run the random.sh in the background. done echo \"Error dectected: $count runs\" cat result.txt Quick test‚¨áÔ∏è bash \u003e bash test.sh As we covered in the lecture find‚Äôs -exec can be very powerful for performing operations over the files we are searching for. However, what if we want to do something with all the files, like creating a zip file? As you have seen so far commands will take input from both arguments and STDIN. When piping commands, we are connecting STDOUT to STDIN, but some commands like tar take inputs from arguments. To bridge this disconnect there‚Äôs the xargs command which will execute a command using STDIN as arguments. For example ls | xargs rm will delete the files in the current directory. Your task is to write a command that recursively finds all HTML files in the folder and makes a zip with them. Note that your command should work even if the files have spaces (hint: check -d flag for xargs). If you‚Äôre on macOS, note","date":"2021-12-18","objectID":"/en/exercise01-02-missingsemester-2020/:2:0","series":null,"tags":["Course","Bash"],"title":"The solutions for exercise 01\u002602 of MIT. Missing-semester(2020)","uri":"/en/exercise01-02-missingsemester-2020/#lecture-02-shell-tools-and-scripting"}]