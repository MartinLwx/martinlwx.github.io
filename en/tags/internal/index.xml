<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>Internal - Tag - MartinLwx&#39;s Blog</title>
        <link>https://martinlwx.github.io/en/tags/internal/</link>
        <description>Internal - Tag - MartinLwx&#39;s Blog</description>
        <generator>Hugo -- gohugo.io</generator><language>en</language><copyright>&lt;a rel=&#34;license noopener&#34; href=&#34;https://creativecommons.org/licenses/by-nc-nd/4.0/&#34; target=&#34;_blank&#34;&gt;CC BY-NC-ND 4.0&lt;/a&gt;</copyright><lastBuildDate>Wed, 19 Mar 2025 22:27:38 &#43;0800</lastBuildDate><atom:link href="https://martinlwx.github.io/en/tags/internal/" rel="self" type="application/rss+xml" /><item>
    <title>Class Hierarchy Analysis: a quick way to generate call graph</title>
    <link>https://martinlwx.github.io/en/call-graph-generation-using-class-hierarchy-analysis/</link>
    <pubDate>Wed, 19 Mar 2025 22:27:38 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/en/call-graph-generation-using-class-hierarchy-analysis/</guid>
    <description><![CDATA[<h2 id="the-key-to-call-graph-construction" class="headerLink">
    <a href="#the-key-to-call-graph-construction" class="header-mark" aria-label="Header mark for 'The key to call graph construction'"></a>The key to call graph construction</h2><p>For an OOP programming language, the key challenge in call graph construction is handling the virtual call, as it may involve <em>multiple target methods</em>, as shown in the following table<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>.</p>

<div class="table-wrapper">
  <table>
    <thead>
        <tr>
            <th style="text-align: "></th>
            <th style="text-align: ">Static Call</th>
            <th style="text-align: ">Special Call</th>
            <th style="text-align: ">Virtual Call</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td style="text-align: ">Instruction</td>
            <td style="text-align: "><code>invokestatic</code></td>
            <td style="text-align: "><code>invokespecial</code></td>
            <td style="text-align: "><code>invokeinterface, invokevirtual</code></td>
        </tr>
        <tr>
            <td style="text-align: ">Receiver Objects</td>
            <td style="text-align: ">‚ùå</td>
            <td style="text-align: ">‚úÖ</td>
            <td style="text-align: ">‚úÖ</td>
        </tr>
        <tr>
            <td style="text-align: ">Target Methods</td>
            <td style="text-align: ">Static Method</td>
            <td style="text-align: ">Constructor, Private Instance Method, Superclass Instance Method</td>
            <td style="text-align: ">Other Instance Method</td>
        </tr>
        <tr>
            <td style="text-align: ">Count of Possible Target Methods</td>
            <td style="text-align: ">1</td>
            <td style="text-align: ">1</td>
            <td style="text-align: ">$\ge 1$ (polymorphism)</td>
        </tr>
        <tr>
            <td style="text-align: ">Determinancy</td>
            <td style="text-align: ">Compile-time</td>
            <td style="text-align: ">Compile-time</td>
            <td style="text-align: ">Run-time</td>
        </tr>
    </tbody>
  </table>
</div>
<h2 id="the-method-call-and-method-signature" class="headerLink">
    <a href="#the-method-call-and-method-signature" class="header-mark" aria-label="Header mark for 'The method call and method signature'"></a>The method call and method signature</h2><p>Let&rsquo;s take Java as an example; a method call may have this form.</p>]]></description>
</item><item>
    <title>LoRA fine-tuning</title>
    <link>https://martinlwx.github.io/en/lora-finetuning/</link>
    <pubDate>Thu, 14 Sep 2023 22:57:06 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/en/lora-finetuning/</guid>
    <description><![CDATA[<h2 id="whats-lora" class="headerLink">
    <a href="#whats-lora" class="header-mark" aria-label="Header mark for 'What&rsquo;s LoRA'"></a>What&rsquo;s LoRA</h2><figure><img src="/img/lora.jpg">
</figure>

<p>Since the era of LLM(large language model) arrived, fine-tuning LLM has become a challenge because the LLM models are extremely large, making it difficult to perform full fine-tuning. There are mainly two approaches: freeze the entire LLM and perform prompt tuning or In-context Learning; freeze the entire LLM <em>but</em> inserting trainable modules. Today, I will introduce the LoRA(<strong>Lo</strong>w-<strong>R</strong>ank <strong>A</strong>daptation), which corresponds to the latter technical approach. This is a work proposed by the Microsoft team<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>]]></description>
</item><item>
    <title>TF-IDF model</title>
    <link>https://martinlwx.github.io/en/an-introduction-of-tf-idf-model/</link>
    <pubDate>Wed, 16 Aug 2023 22:23:26 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/en/an-introduction-of-tf-idf-model/</guid>
    <description><![CDATA[<h2 id="what-is-the-tf-idf-model" class="headerLink">
    <a href="#what-is-the-tf-idf-model" class="header-mark" aria-label="Header mark for 'What is the TF-IDF model'"></a>What is the TF-IDF model</h2><p>In previous <a href="https://martinlwx.github.io/en/an-introduction-of-bag-of-word-model/" rel="">post</a>, we talked about the bag-of-word model, which has many limitations. Today we take a step further to see if we can try to fix <em>one of the limitations</em> - Each word has the same importance.</p>
<div class="details admonition question open">
    <div class="details-summary admonition-title">
        <span class="icon"><svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M504 256c0 136.997-111.043 248-248 248S8 392.997 8 256C8 119.083 119.043 8 256 8s248 111.083 248 248zM262.655 90c-54.497 0-89.255 22.957-116.549 63.758-3.536 5.286-2.353 12.415 2.715 16.258l34.699 26.31c5.205 3.947 12.621 3.008 16.665-2.122 17.864-22.658 30.113-35.797 57.303-35.797 20.429 0 45.698 13.148 45.698 32.958 0 14.976-12.363 22.667-32.534 33.976C247.128 238.528 216 254.941 216 296v4c0 6.627 5.373 12 12 12h56c6.627 0 12-5.373 12-12v-1.333c0-28.462 83.186-29.647 83.186-106.667 0-58.002-60.165-102-116.531-102zM256 338c-25.365 0-46 20.635-46 46 0 25.364 20.635 46 46 46s46-20.636 46-46c0-25.365-20.635-46-46-46z"/></svg></span>Question<span class="details-icon"><svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></span>
    </div>
    <div class="details-content">
        <div class="admonition-content"><p>The crux of the problem - How to define the word importance?</p>]]></description>
</item><item>
    <title>Demystifying Pytorch&#39;s Strides Format</title>
    <link>https://martinlwx.github.io/en/how-to-reprensent-a-tensor-or-ndarray/</link>
    <pubDate>Fri, 14 Jul 2023 15:22:02 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/en/how-to-reprensent-a-tensor-or-ndarray/</guid>
    <description><![CDATA[<h2 id="intro" class="headerLink">
    <a href="#intro" class="header-mark" aria-label="Header mark for 'Intro'"></a>Intro</h2><p>Even though I have been using Numpy and Pytorch for a long time, I never really knew how they implemented the underlying tensors and why they are <strong>so efficient</strong>. Recently, while studying the course <a href="https://dlsyscourse.org/" target="_blank" rel="noopener noreferrer">Deep Learning Systems</a>, I finally got the opportunity to try implementing tensors on my own. After going through the process, my understanding of tensors is much better üßê</p>
<p>As a Pytorch user, is it necessary to understand the underlying tensor storage mechanism? I believe <strong>it is essential</strong>. In most cases, understanding the underlying principles helps you grasp higher-level concepts better. For example, understanding the tensor storage mechanism can help you answer the following questions:</p>]]></description>
</item><item>
    <title>Understanding GAT throught MPNN</title>
    <link>https://martinlwx.github.io/en/understanding-graph-attention-network-through-mpnn/</link>
    <pubDate>Sun, 21 May 2023 15:20:50 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/en/understanding-graph-attention-network-through-mpnn/</guid>
    <description><![CDATA[<h2 id="whats-mpnn" class="headerLink">
    <a href="#whats-mpnn" class="header-mark" aria-label="Header mark for 'What&rsquo;s MPNN'"></a>What&rsquo;s MPNN</h2><p>Justin Gilmer proposed the MPNN (Message Passing Neural Network) framework <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> for describing graph neural network models used in supervised learning on graphs. I found this to be a useful framework that provides a clear understanding of how different GNN models work and facilitates a quick grasp of the differences between them. Considering a node $v$ on the graph $G$, the update procedure for its vector representation $h_v$ is as follows:</p>]]></description>
</item></channel>
</rss>
