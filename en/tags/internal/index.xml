<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>Internal - Tag - MartinLwx&#39;s Blog</title>
        <link>https://martinlwx.github.io/en/tags/internal/</link>
        <description>Internal - Tag - MartinLwx&#39;s Blog</description>
        <generator>Hugo -- gohugo.io</generator><language>en</language><managingEditor>martinlwx@163.com (MartinLwx)</managingEditor>
            <webMaster>martinlwx@163.com (MartinLwx)</webMaster><copyright>&lt;a rel=&#34;license noopener&#34; href=&#34;https://creativecommons.org/licenses/by-nc-nd/4.0/&#34; target=&#34;_blank&#34;&gt;CC BY-NC-ND 4.0&lt;/a&gt;</copyright><lastBuildDate>Wed, 19 Mar 2025 22:27:38 &#43;0800</lastBuildDate><atom:link href="https://martinlwx.github.io/en/tags/internal/" rel="self" type="application/rss+xml" /><item>
    <title>Class Hierarchy Analysis: a quick way to generate call graph</title>
    <link>https://martinlwx.github.io/en/call-graph-generation-using-class-hierarchy-analysis/</link>
    <pubDate>Wed, 19 Mar 2025 22:27:38 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/en/call-graph-generation-using-class-hierarchy-analysis/</guid>
    <description><![CDATA[<h2 id="the-key-to-call-graph-construction" class="headerLink">
    <a href="#the-key-to-call-graph-construction" class="header-mark"></a>The key to call graph construction</h2><p>For an OOP programming language, the key challenge in call graph construction is handling the virtual call, as it may involve <em>multiple target methods</em>, as shown in the following table<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>.</p>
<table>
  <thead>
      <tr>
          <th></th>
          <th>Static Call</th>
          <th>Special Call</th>
          <th>Virtual Call</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Instruction</td>
          <td><code>invokestatic</code></td>
          <td><code>invokespecial</code></td>
          <td><code>invokeinterface, invokevirtual</code></td>
      </tr>
      <tr>
          <td>Receiver Objects</td>
          <td>‚ùå</td>
          <td>‚úÖ</td>
          <td>‚úÖ</td>
      </tr>
      <tr>
          <td>Target Methods</td>
          <td>Static Method</td>
          <td>Constructor, Private Instance Method, Superclass Instance Method</td>
          <td>Other Instance Method</td>
      </tr>
      <tr>
          <td>Count of Possible Target Methods</td>
          <td>1</td>
          <td>1</td>
          <td>$\ge 1$ (polymorphism)</td>
      </tr>
      <tr>
          <td>Determinancy</td>
          <td>Compile-time</td>
          <td>Compile-time</td>
          <td>Run-time</td>
      </tr>
  </tbody>
</table>
<h2 id="the-method-call-and-method-signature" class="headerLink">
    <a href="#the-method-call-and-method-signature" class="header-mark"></a>The method call and method signature</h2><p>Let&rsquo;s take Java as an example; a method call may have this form.</p>]]></description>
</item><item>
    <title>LoRA fine-tuning</title>
    <link>https://martinlwx.github.io/en/lora-finetuning/</link>
    <pubDate>Thu, 14 Sep 2023 22:57:06 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/en/lora-finetuning/</guid>
    <description><![CDATA[<h2 id="whats-lora" class="headerLink">
    <a href="#whats-lora" class="header-mark"></a>What&rsquo;s LoRA</h2><figure><img src="/img/lora.jpg">
</figure>

<p>Since the era of LLM(large language model) arrived, fine-tuning LLM has become a challenge because the LLM models are extremely large, making it difficult to perform full fine-tuning. There are mainly two approaches: freeze the entire LLM and perform prompt tuning or In-context Learning; freeze the entire LLM <em>but</em> inserting trainable modules. Today, I will introduce the LoRA(<strong>Lo</strong>w-<strong>R</strong>ank <strong>A</strong>daptation), which corresponds to the latter technical approach. This is a work proposed by the Microsoft team<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>]]></description>
</item><item>
    <title>TF-IDF model</title>
    <link>https://martinlwx.github.io/en/an-introduction-of-tf-idf-model/</link>
    <pubDate>Wed, 16 Aug 2023 22:23:26 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/en/an-introduction-of-tf-idf-model/</guid>
    <description><![CDATA[<div class="details admonition info open">
    <div class="details-summary admonition-title">
        <span class="icon"><svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M256 8C119.043 8 8 119.083 8 256c0 136.997 111.043 248 248 248s248-111.003 248-248C504 119.083 392.957 8 256 8zm0 110c23.196 0 42 18.804 42 42s-18.804 42-42 42-42-18.804-42-42 18.804-42 42-42zm56 254c0 6.627-5.373 12-12 12h-88c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h12v-64h-12c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h64c6.627 0 12 5.373 12 12v100h12c6.627 0 12 5.373 12 12v24z"/></svg></span>Info<span class="details-icon"><svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></span>
    </div>
    <div class="details-content">
        <div class="admonition-content"><p><em>Further reading</em></p>]]></description>
</item><item>
    <title>Demystifying Pytorch&#39;s Strides Format</title>
    <link>https://martinlwx.github.io/en/how-to-reprensent-a-tensor-or-ndarray/</link>
    <pubDate>Fri, 14 Jul 2023 15:22:02 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/en/how-to-reprensent-a-tensor-or-ndarray/</guid>
    <description><![CDATA[<h2 id="intro" class="headerLink">
    <a href="#intro" class="header-mark"></a>Intro</h2><p>Even though I have been using Numpy and Pytorch for a long time, I never really knew how they implemented the underlying tensors and why they are <strong>so efficient</strong>. Recently, while studying the course <a href="https://dlsyscourse.org/" target="_blank" rel="noopener noreferrer">Deep Learning Systems</a>, I finally got the opportunity to try implementing tensors on my own. After going through the process, my understanding of tensors is much better üßê</p>
<p>As a Pytorch user, is it necessary to understand the underlying tensor storage mechanism? I believe <strong>it is essential</strong>. In most cases, understanding the underlying principles helps you grasp higher-level concepts better. For example, understanding the tensor storage mechanism can help you answer the following questions:</p>]]></description>
</item><item>
    <title>Understanding GAT throught MPNN</title>
    <link>https://martinlwx.github.io/en/understanding-graph-attention-network-through-mpnn/</link>
    <pubDate>Sun, 21 May 2023 15:20:50 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/en/understanding-graph-attention-network-through-mpnn/</guid>
    <description><![CDATA[<h2 id="whats-mpnn" class="headerLink">
    <a href="#whats-mpnn" class="header-mark"></a>What&rsquo;s MPNN</h2><p>Justin Gilmer proposed the MPNN (Message Passing Neural Network) framework <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> for describing graph neural network models used in supervised learning on graphs. I found this to be a useful framework that provides a clear understanding of how different GNN models work and facilitates a quick grasp of the differences between them. Considering a node $v$ on the graph $G$, the update procedure for its vector representation $h_v$ is as follows:</p>]]></description>
</item></channel>
</rss>
