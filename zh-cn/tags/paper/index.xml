<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>Paper - 标签 - MartinLwx&#39;s Blog</title>
        <link>https://martinlwx.github.io/zh-cn/tags/paper/</link>
        <description>Paper - 标签 - MartinLwx&#39;s Blog</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><copyright>&lt;a rel=&#34;license noopener&#34; href=&#34;https://creativecommons.org/licenses/by-nc-nd/4.0/&#34; target=&#34;_blank&#34;&gt;CC BY-NC-ND 4.0&lt;/a&gt;</copyright><lastBuildDate>Mon, 23 Dec 2024 22:01:35 &#43;0800</lastBuildDate><atom:link href="https://martinlwx.github.io/zh-cn/tags/paper/" rel="self" type="application/rss+xml" /><item>
    <title>论文阅读: Generalization through Memorization: Nearest Neighbor Language Models</title>
    <link>https://martinlwx.github.io/zh-cn/what-is-knn-lm/</link>
    <pubDate>Mon, 23 Dec 2024 22:01:35 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/zh-cn/what-is-knn-lm/</guid>
    <description><![CDATA[<h2 id="motivation" class="headerLink">
    <a href="#motivation" class="header-mark" aria-label="Header mark for 'Motivation'"></a>Motivation</h2><p>语言模型解决 2 种问题</p>
<ol>
<li>用一个特征向量表示句子前缀</li>
<li>使用该特征向量预测下一个 token</li>
</ol>
<p>本文提出的 $k\texttt{NN-LM}$ 基于这么一个假设：<em>学习特征向量表示比预测下一个 token</em>，因此本文的方法主要基于该假设进行设计</p>]]></description>
</item><item>
    <title>论文阅读: In-Context Retrieval-Augmented Language Models</title>
    <link>https://martinlwx.github.io/zh-cn/in-context-ralm-paper-reading/</link>
    <pubDate>Wed, 04 Dec 2024 00:53:25 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/zh-cn/in-context-ralm-paper-reading/</guid>
    <description><![CDATA[<h2 id="the-idea" class="headerLink">
    <a href="#the-idea" class="header-mark" aria-label="Header mark for 'The idea'"></a>The idea</h2><p>In-Context RALM<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> 是用于 Autoregressive LM 上的 RAG 技术。RAG 说白了就是在模型推理的时候有个 Retriever 检索相关的文档，检索到的文档会和本来的输入拼接在一起</p>
<p>在 In-Context Learning 里面，会把一些例子放在用户输入的<em>前面</em>，再给 LLM。因此不难想象 In-Context RALM <em>也类似</em>：In-Context RALM 就是将检索到的<em>最相关</em>的文档直接拼在模型输入的<em>前面</em>，优势是<em>不需要再训练 LLM</em>，我用 mermaid 画了一个图，如下所示</p>]]></description>
</item><item>
    <title>论文阅读: REALM: Retrieval-Augmented Language Model Pre-Training</title>
    <link>https://martinlwx.github.io/zh-cn/rag-realm-paper-reading/</link>
    <pubDate>Sat, 30 Nov 2024 00:01:26 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/zh-cn/rag-realm-paper-reading/</guid>
    <description><![CDATA[<h2 id="引言" class="headerLink">
    <a href="#%e5%bc%95%e8%a8%80" class="header-mark" aria-label="Header mark for '引言'"></a>引言</h2><p>最近打算系统性学习 RAG 技术，开始看起了相关文献，目前的思路是按照 ACL 2023 Tutorial 的 <a href="https://acl2023-retrieval-lm.github.io/slides/3-architecture.pdf" target="_blank" rel="noopener noreferrer">Roadmap</a> 过一遍。本篇是对早期的 RAG 技术的 REALM 的介绍</p>
<div class="details admonition info open">
    <div class="details-summary admonition-title">
        <span class="icon"><svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M256 8C119.043 8 8 119.083 8 256c0 136.997 111.043 248 248 248s248-111.003 248-248C504 119.083 392.957 8 256 8zm0 110c23.196 0 42 18.804 42 42s-18.804 42-42 42-42-18.804-42-42 18.804-42 42-42zm56 254c0 6.627-5.373 12-12 12h-88c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h12v-64h-12c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h64c6.627 0 12 5.373 12 12v100h12c6.627 0 12 5.373 12 12v24z"/></svg></span>Info<span class="details-icon"><svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></span>
    </div>
    <div class="details-content">
        <div class="admonition-content"><p>本文采用的模型是 Masked LM 的 BERT，还不是 LLM。因此本文后续的部分内容需要你<em>对 BERT 有一定的了解</em>，包括 BERT 的预训练过程、BERT 微调等</p>]]></description>
</item><item>
    <title>LoRA 微调</title>
    <link>https://martinlwx.github.io/zh-cn/lora-finetuning/</link>
    <pubDate>Thu, 14 Sep 2023 22:57:06 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/zh-cn/lora-finetuning/</guid>
    <description><![CDATA[<h2 id="什么是-lora" class="headerLink">
    <a href="#%e4%bb%80%e4%b9%88%e6%98%af-lora" class="header-mark" aria-label="Header mark for '什么是 LoRA'"></a>什么是 LoRA</h2><figure><img src="/img/lora.jpg">
</figure>

<p>自从 LLM 时代到来之后，如何微调 LLM 成为了一个难题，因为 LLM 的模型实在是太大了，很难做全量微调更新所有参数。可选的路线有：冻结整个模型做 Prompt tuning 或者 In-context Learning；冻结整个模型<em>但是</em>会插入可训练的模块。今天要介绍的 LoRA(<strong>Lo</strong>w-<strong>R</strong>ank <strong>A</strong>daptation) 就对应了后者的技术路线，这是微软团队的工作<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>]]></description>
</item><item>
    <title>用 MPNN 框架解读 GAT</title>
    <link>https://martinlwx.github.io/zh-cn/understanding-graph-attention-network-through-mpnn/</link>
    <pubDate>Sun, 21 May 2023 15:20:50 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/zh-cn/understanding-graph-attention-network-through-mpnn/</guid>
    <description><![CDATA[<h2 id="什么是-mpnn-框架" class="headerLink">
    <a href="#%e4%bb%80%e4%b9%88%e6%98%af-mpnn-%e6%a1%86%e6%9e%b6" class="header-mark" aria-label="Header mark for '什么是 MPNN 框架'"></a>什么是 MPNN 框架</h2><p>Justin Gilmer 提出了 MPNN（Message Passing Neural Network）框架<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> ，用于描述被用来做图上的监督学习的图神经网络模型。我发现这是一个很好用的框架，可以很好理解不同的 GNN 模型是如何工作的，方便快速弄清楚不同的 GNN 模型之间的差别。我们考虑图 $G$ 上的一个节点 $v$，它的向量表示 $h_v$ 的更新方式如下：
$$m_v^{t+1}=\sum_{u\in \mathcal{N}(v)}M_t(h_v^t,h_u^t,e_{vu})$$
$$h_v^{t+1}=U_t(h_v^t,m_v^{t+1})$$</p>]]></description>
</item></channel>
</rss>
