<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>NLP - æ ‡ç­¾ - MartinLwx&#39;s Blog</title>
        <link>https://martinlwx.github.io/zh-cn/tags/nlp/</link>
        <description>NLP - æ ‡ç­¾ - MartinLwx&#39;s Blog</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>martinlwx@163.com (MartinLwx)</managingEditor>
            <webMaster>martinlwx@163.com (MartinLwx)</webMaster><copyright>&lt;a rel=&#34;license noopener&#34; href=&#34;https://creativecommons.org/licenses/by-nc-nd/4.0/&#34; target=&#34;_blank&#34;&gt;CC BY-NC-ND 4.0&lt;/a&gt;</copyright><lastBuildDate>Tue, 11 Mar 2025 19:05:30 &#43;0800</lastBuildDate><atom:link href="https://martinlwx.github.io/zh-cn/tags/nlp/" rel="self" type="application/rss+xml" /><item>
    <title>è¯­è¨€æ¨¡å‹ä¸­çš„ Weight Tying æŠ€æœ¯</title>
    <link>https://martinlwx.github.io/zh-cn/an-explanation-of-weight-tying/</link>
    <pubDate>Tue, 11 Mar 2025 19:05:30 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/zh-cn/an-explanation-of-weight-tying/</guid>
    <description><![CDATA[<h2 id="å¼•è¨€" class="headerLink">
    <a href="#%e5%bc%95%e8%a8%80" class="header-mark"></a>å¼•è¨€</h2><div class="details admonition quote open">
    <div class="details-summary admonition-title">
        <span class="icon"><svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M464 32H336c-26.5 0-48 21.5-48 48v128c0 26.5 21.5 48 48 48h80v64c0 35.3-28.7 64-64 64h-8c-13.3 0-24 10.7-24 24v48c0 13.3 10.7 24 24 24h8c88.4 0 160-71.6 160-160V80c0-26.5-21.5-48-48-48zm-288 0H48C21.5 32 0 53.5 0 80v128c0 26.5 21.5 48 48 48h80v64c0 35.3-28.7 64-64 64h-8c-13.3 0-24 10.7-24 24v48c0 13.3 10.7 24 24 24h8c88.4 0 160-71.6 160-160V80c0-26.5-21.5-48-48-48z"/></svg></span>Quote<span class="details-icon"><svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></span>
    </div>
    <div class="details-content">
        <div class="admonition-content"><p><em>In our model, we share the same weight matrix between the two embedding layers and the pre-softmax linear transformation</em> - <em>Attention is All You Need</em>, Section 3.4. Embeddings and Softmax<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>]]></description>
</item><item>
    <title>è®ºæ–‡é˜…è¯»: Generalization through Memorization: Nearest Neighbor Language Models</title>
    <link>https://martinlwx.github.io/zh-cn/what-is-knn-lm/</link>
    <pubDate>Mon, 23 Dec 2024 22:01:35 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/zh-cn/what-is-knn-lm/</guid>
    <description><![CDATA[<h2 id="motivation" class="headerLink">
    <a href="#motivation" class="header-mark"></a>Motivation</h2><p>è¯­è¨€æ¨¡å‹è§£å†³ 2 ç§é—®é¢˜</p>
<ol>
<li>ç”¨ä¸€ä¸ªç‰¹å¾å‘é‡è¡¨ç¤ºå¥å­å‰ç¼€</li>
<li>ä½¿ç”¨è¯¥ç‰¹å¾å‘é‡é¢„æµ‹ä¸‹ä¸€ä¸ª token</li>
</ol>
<p>æœ¬æ–‡æå‡ºçš„ $k\texttt{NN-LM}$ åŸºäºè¿™ä¹ˆä¸€ä¸ªå‡è®¾ï¼š<em>å­¦ä¹ ç‰¹å¾å‘é‡è¡¨ç¤ºæ¯”é¢„æµ‹ä¸‹ä¸€ä¸ª token</em>ï¼Œå› æ­¤æœ¬æ–‡çš„æ–¹æ³•ä¸»è¦åŸºäºè¯¥å‡è®¾è¿›è¡Œè®¾è®¡</p>]]></description>
</item><item>
    <title>è®ºæ–‡é˜…è¯»: In-Context Retrieval-Augmented Language Models</title>
    <link>https://martinlwx.github.io/zh-cn/in-context-ralm-paper-reading/</link>
    <pubDate>Wed, 04 Dec 2024 00:53:25 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/zh-cn/in-context-ralm-paper-reading/</guid>
    <description><![CDATA[<h2 id="the-idea" class="headerLink">
    <a href="#the-idea" class="header-mark"></a>The idea</h2><p>In-Context RALM<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> æ˜¯ç”¨äº Autoregressive LM ä¸Šçš„ RAG æŠ€æœ¯ã€‚RAG è¯´ç™½äº†å°±æ˜¯åœ¨æ¨¡å‹æ¨ç†çš„æ—¶å€™æœ‰ä¸ª Retriever æ£€ç´¢ç›¸å…³çš„æ–‡æ¡£ï¼Œæ£€ç´¢åˆ°çš„æ–‡æ¡£ä¼šå’Œæœ¬æ¥çš„è¾“å…¥æ‹¼æ¥åœ¨ä¸€èµ·</p>
<p>åœ¨ In-Context Learning é‡Œé¢ï¼Œä¼šæŠŠä¸€äº›ä¾‹å­æ”¾åœ¨ç”¨æˆ·è¾“å…¥çš„<em>å‰é¢</em>ï¼Œå†ç»™ LLMã€‚å› æ­¤ä¸éš¾æƒ³è±¡ In-Context RALM <em>ä¹Ÿç±»ä¼¼</em>ï¼šIn-Context RALM å°±æ˜¯å°†æ£€ç´¢åˆ°çš„<em>æœ€ç›¸å…³</em>çš„æ–‡æ¡£ç›´æ¥æ‹¼åœ¨æ¨¡å‹è¾“å…¥çš„<em>å‰é¢</em>ï¼Œä¼˜åŠ¿æ˜¯<em>ä¸éœ€è¦å†è®­ç»ƒ LLM</em>ï¼Œæˆ‘ç”¨ mermaid ç”»äº†ä¸€ä¸ªå›¾ï¼Œå¦‚ä¸‹æ‰€ç¤º</p>]]></description>
</item><item>
    <title>è®ºæ–‡é˜…è¯»: REALM: Retrieval-Augmented Language Model Pre-Training</title>
    <link>https://martinlwx.github.io/zh-cn/rag-realm-paper-reading/</link>
    <pubDate>Sat, 30 Nov 2024 00:01:26 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/zh-cn/rag-realm-paper-reading/</guid>
    <description><![CDATA[<h2 id="å¼•è¨€" class="headerLink">
    <a href="#%e5%bc%95%e8%a8%80" class="header-mark"></a>å¼•è¨€</h2><p>æœ€è¿‘æ‰“ç®—ç³»ç»Ÿæ€§å­¦ä¹  RAG æŠ€æœ¯ï¼Œå¼€å§‹çœ‹èµ·äº†ç›¸å…³æ–‡çŒ®ï¼Œç›®å‰çš„æ€è·¯æ˜¯æŒ‰ç…§ ACL 2023 Tutorial çš„ <a href="https://acl2023-retrieval-lm.github.io/slides/3-architecture.pdf" target="_blank" rel="noopener noreferrer">Roadmap</a> è¿‡ä¸€éã€‚æœ¬ç¯‡æ˜¯å¯¹æ—©æœŸçš„ RAG æŠ€æœ¯çš„ REALM çš„ä»‹ç»</p>
<div class="details admonition info open">
    <div class="details-summary admonition-title">
        <span class="icon"><svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M256 8C119.043 8 8 119.083 8 256c0 136.997 111.043 248 248 248s248-111.003 248-248C504 119.083 392.957 8 256 8zm0 110c23.196 0 42 18.804 42 42s-18.804 42-42 42-42-18.804-42-42 18.804-42 42-42zm56 254c0 6.627-5.373 12-12 12h-88c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h12v-64h-12c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h64c6.627 0 12 5.373 12 12v100h12c6.627 0 12 5.373 12 12v24z"/></svg></span>Info<span class="details-icon"><svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></span>
    </div>
    <div class="details-content">
        <div class="admonition-content"><p>æœ¬æ–‡é‡‡ç”¨çš„æ¨¡å‹æ˜¯ Masked LM çš„ BERTï¼Œè¿˜ä¸æ˜¯ LLMã€‚å› æ­¤æœ¬æ–‡åç»­çš„éƒ¨åˆ†å†…å®¹éœ€è¦ä½ <em>å¯¹ BERT æœ‰ä¸€å®šçš„äº†è§£</em>ï¼ŒåŒ…æ‹¬ BERT çš„é¢„è®­ç»ƒè¿‡ç¨‹ã€BERT å¾®è°ƒç­‰</p>]]></description>
</item><item>
    <title>LLM æ¨ç†åŠ é€Ÿ - KV Cache</title>
    <link>https://martinlwx.github.io/zh-cn/llm-inference-optimization-kv-cache/</link>
    <pubDate>Thu, 12 Oct 2023 16:38:18 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/zh-cn/llm-inference-optimization-kv-cache/</guid>
    <description><![CDATA[<h2 id="èƒŒæ™¯" class="headerLink">
    <a href="#%e8%83%8c%e6%99%af" class="header-mark"></a>èƒŒæ™¯</h2><p>LLM ç”¨äºæ¨ç†çš„æ—¶å€™å°±æ˜¯ä¸æ–­åŸºäºå‰é¢çš„æ‰€æœ‰ token ç”Ÿæˆä¸‹ä¸€ä¸ª token</p>
<p>å‡è®¾ç°åœ¨å·²ç»ç”Ÿæˆäº† $t$ ä¸ª tokenï¼Œç”¨ $x_{1:t}$ è¡¨ç¤ºã€‚åœ¨ä¸‹ä¸€è½®ï¼ŒLLM ä¼šç”Ÿæˆ $x_{1:t+1}$ï¼Œæ³¨æ„ä»–ä»¬çš„å‰ $t$ ä¸ª token æ˜¯<em>ä¸€æ ·çš„</em></p>]]></description>
</item><item>
    <title>BPE åˆ†è¯è§£å¯† - å®ç°æ–¹æ³•ä¸ç¤ºä¾‹è®²è§£</title>
    <link>https://martinlwx.github.io/zh-cn/the-bpe-tokenizer/</link>
    <pubDate>Thu, 24 Aug 2023 22:06:37 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/zh-cn/the-bpe-tokenizer/</guid>
    <description><![CDATA[<h2 id="bpe-ç®€ä»‹" class="headerLink">
    <a href="#bpe-%e7%ae%80%e4%bb%8b" class="header-mark"></a>BPE ç®€ä»‹</h2><p>åœ¨ NLP é‡Œé¢ï¼Œä¸€ä¸ªæ ¸å¿ƒçš„é—®é¢˜æ˜¯ï¼Œå¦‚ä½•å¯¹æ–‡æœ¬è¿›è¡Œåˆ†è¯ï¼Ÿä»åˆ†ç±»çš„è§’åº¦ä¸Šé¢æ¥è¯´ï¼Œå¯ä»¥åˆ†ä¸ºï¼š</p>
<ul>
<li>Char level</li>
<li>Word level</li>
<li>Subword level</li>
</ul>
<p>å…ˆçœ‹ Char level åˆ†è¯ï¼Œé¡¾åæ€ä¹‰ï¼Œå°±æ˜¯æŠŠæ–‡æœ¬æ‹†åˆ†æˆä¸€ä¸ªä¸ªå­—ç¬¦å•ç‹¬è¡¨ç¤ºï¼Œ<em>æ¯”å¦‚ <code>highest -&gt; h, i, g, h, e, s, t</code></em>ï¼Œä¸€ä¸ªæ˜¾ç„¶çš„å¥½å¤„æ˜¯ï¼ŒVocab ä¸ä¼šå¤ªå¤§ï¼ŒVocab çš„å¤§å°ä¸ºå­—ç¬¦é›†çš„å¤§å°ï¼Œä¹Ÿä¸ä¼šé‡åˆ° Out-of-vocabulary(OOV) çš„é—®é¢˜ï¼Œä½†æ˜¯<strong>å­—ç¬¦æœ¬èº«å¹¶æ²¡æœ‰ä¼ è¾¾å¤ªå¤šçš„è¯­ä¹‰</strong>ï¼Œè€Œä¸”<strong>åˆ†è¯ä¹‹åä¼šæœ‰å¤ªå¤šçš„ token</strong>ï¼Œ<em>å…‰æ˜¯ä¸€ä¸ª highest å°±å¯ä»¥å¾—åˆ° 7 ä¸ª tokenï¼Œéš¾ä»¥æƒ³è±¡å¾ˆé•¿çš„æ–‡æœ¬åˆ†å‡ºæ¥ä¼šæœ‰å¤šå°‘ä¸ª</em>ğŸ˜¨</p>]]></description>
</item><item>
    <title>TF-IDF æ¨¡å‹</title>
    <link>https://martinlwx.github.io/zh-cn/an-introduction-of-tf-idf-model/</link>
    <pubDate>Wed, 16 Aug 2023 22:23:26 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/zh-cn/an-introduction-of-tf-idf-model/</guid>
    <description><![CDATA[<h2 id="ä»€ä¹ˆæ˜¯-tf-idf-æ¨¡å‹" class="headerLink">
    <a href="#%e4%bb%80%e4%b9%88%e6%98%af-tf-idf-%e6%a8%a1%e5%9e%8b" class="header-mark"></a>ä»€ä¹ˆæ˜¯ TF-IDF æ¨¡å‹</h2><p>åœ¨ä¹‹å‰çš„ <a href="https://martinlwx.github.io/zh-cn/an-introduction-of-bag-of-word-model/" rel="">æ–‡ç« </a> ä¸­è°ˆåˆ°äº†è¯è¢‹æ¨¡å‹ï¼Œä¹Ÿè®²åˆ°äº†å®ƒçš„è®¸å¤šä¸è¶³ï¼Œåœ¨ä»Šå¤©çš„è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬è¦å°è¯•è§£å†³è¯è¢‹æ¨¡å‹çš„<em>ç¼ºç‚¹</em>ä¹‹ä¸€ï¼šæ¯ä¸ªè¯çš„é‡è¦æ€§æ˜¯ä¸€æ ·çš„</p>
<div class="details admonition quesstion open">
    <div class="details-summary admonition-title">
        <span class="icon"><svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M497.9 142.1l-46.1 46.1c-4.7 4.7-12.3 4.7-17 0l-111-111c-4.7-4.7-4.7-12.3 0-17l46.1-46.1c18.7-18.7 49.1-18.7 67.9 0l60.1 60.1c18.8 18.7 18.8 49.1 0 67.9zM284.2 99.8L21.6 362.4.4 483.9c-2.9 16.4 11.4 30.6 27.8 27.8l121.5-21.3 262.6-262.6c4.7-4.7 4.7-12.3 0-17l-111-111c-4.8-4.7-12.4-4.7-17.1 0zM124.1 339.9c-5.5-5.5-5.5-14.3 0-19.8l154-154c5.5-5.5 14.3-5.5 19.8 0s5.5 14.3 0 19.8l-154 154c-5.5 5.5-14.3 5.5-19.8 0zM88 424h48v36.3l-64.5 11.3-31.1-31.1L51.7 376H88v48z"/></svg></span>Quesstion<span class="details-icon"><svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></span>
    </div>
    <div class="details-content">
        <div class="admonition-content"><p>é‚£ä¹ˆï¼Œæ ¸å¿ƒé—®é¢˜å°±æ˜¯â€”â€”â€”â€”å¦‚ä½•å®šä¹‰ã€Œå•è¯çš„é‡è¦æ€§ã€è¿™ä¸ªæ¦‚å¿µï¼Ÿ</p>]]></description>
</item><item>
    <title>è¯è¢‹æ¨¡å‹</title>
    <link>https://martinlwx.github.io/zh-cn/an-introduction-of-bag-of-word-model/</link>
    <pubDate>Fri, 11 Aug 2023 18:55:09 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/zh-cn/an-introduction-of-bag-of-word-model/</guid>
    <description><![CDATA[<h2 id="ä»€ä¹ˆæ˜¯è¯è¢‹æ¨¡å‹" class="headerLink">
    <a href="#%e4%bb%80%e4%b9%88%e6%98%af%e8%af%8d%e8%a2%8b%e6%a8%a1%e5%9e%8b" class="header-mark"></a>ä»€ä¹ˆæ˜¯è¯è¢‹æ¨¡å‹</h2><p>åœ¨ NLP ä¸­ï¼Œæˆ‘ä»¬éœ€è¦å°†æ–‡æ¡£ï¼ˆdocumentï¼‰è¡¨ç¤ºä¸ºå‘é‡ï¼Œè¿™æ˜¯å› ä¸ºæœºå™¨å­¦ä¹ åªèƒ½å¤Ÿå¤„ç†æ•°å­—ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘ä»¬è¦æ‰¾åˆ°ä¸‹é¢è¿™ä¹ˆä¸€ä¸ª<em>ç¥å¥‡</em>çš„å‡½æ•°ï¼š</p>
<p>$$
f(\text{document}) = vector
$$</p>
<p>ä»Šå¤©è¦è®¨è®ºçš„æ˜¯è¯è¢‹æ¨¡å‹ï¼ˆbag-of-word, BoWï¼‰ï¼Œè¯è¢‹æ¨¡å‹å¯ä»¥è®©æˆ‘ä»¬æŠŠè¾“å…¥çš„æ–‡æ¡£è½¬å˜æˆä¸€ä¸ªå‘é‡è¡¨ç¤º</p>]]></description>
</item></channel>
</rss>
