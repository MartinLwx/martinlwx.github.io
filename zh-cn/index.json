[{"categories":["Algorithm"],"content":"Kosaraju 算法的解释","date":"2025-04-26","objectID":"/zh-cn/kosaraju-algorithm-explained/","series":null,"tags":["Algorithm"],"title":"Kosaraju 算法：求解有向图的强连通分量","uri":"/zh-cn/kosaraju-algorithm-explained/"},{"categories":["Algorithm"],"content":" Intro在做算法题练习的时候遇到了一道有趣的题目 - 1682. Flight Routes Check。要解决这一道题需要高效确定一个有向图上有多少强连通分量。在看了一下题解之后，我发现 Kosaruju 算法可以用于解决这个问题，它可以在线性时间内找到有向图的所有强连通分量。这里说的线性时间是 $$ O(V+E) $$ 其中 $V$ 为图的节点个数，$E$ 为图的边的个数 说是有趣是因为这个算法的实现很简单，但是要形成关于这个算法的直觉我发现确实需要费点功夫。在我看来，在学习算法的过程中，弄懂 Why 比知道 How 来说更有价值，因此有了这篇博客，与你分享关于我的一点看法 ","date":"2025-04-26","objectID":"/zh-cn/kosaraju-algorithm-explained/:1:0","series":null,"tags":["Algorithm"],"title":"Kosaraju 算法：求解有向图的强连通分量","uri":"/zh-cn/kosaraju-algorithm-explained/#intro"},{"categories":["Algorithm"],"content":" Kosaraju 算法规定记号如下 $G$ 表示原始有向图 $G’$ 表示它的反向图。一个图的反向图就是保持节点不变，将所有的边调转方向得到的图 算法流程 将 $G$ 的所有的边调转方向，得到 $G'$ 正向 DFS：遍历 $G$ 上的所有节点跑 DFS，并将遍历到的节点按照结束访问的顺序（后序）放入一个栈里面 反向 DFS：根据上一步的栈，不断弹出栈顶的节点，在 $G’$ 上跑 DFS，相当于上一轮最后结束访问的会最先被访问到。每一轮 DFS 发现的点都在同一个强连通分量上 Tip 正向 DFS 和反向 DFS 的区别在于操作的对象不同，前者是原始图 $G$，后者是反向图 $G’$。这里用不同的名字加以区分 ","date":"2025-04-26","objectID":"/zh-cn/kosaraju-algorithm-explained/:2:0","series":null,"tags":["Algorithm"],"title":"Kosaraju 算法：求解有向图的强连通分量","uri":"/zh-cn/kosaraju-algorithm-explained/#kosaraju-算法"},{"categories":["Algorithm"],"content":" 关于 Kosaraju 算法的直觉flowchart subgraph G SCC1(SCC1) --\u003e SCC2(SCC2) --\u003e n(...) --\u003e SCC3(SCC3 ) end flowchart subgraph G' CCS3(SCC3) --\u003e m(...) --\u003e CCS2(SCC2) --\u003e CCS1(SCC1) end 将有向图上的每个强连通分量压缩成一个点，那么这个有向图就变成了一个 DAG。上面我用 mermaid 画了一个图示，其中 SCC 是强连通分量（Strongly Connected Component) 的缩写 Tip 在 DAG 上，Source 的意思是没有入边的节点，Sink 的意思是没有出边的节点 正向 DFS 的时候，最后结束访问的肯定是 $G$ 构成的 DAG 上的 Source（对应 $G$ 的 $SCC1$) 反向 DFS 的时候会从 $G’$ 构成的 DAG 的 Sink（对应 $G$ 构成的 DAG 的 Source $SCC1$（对应 ）出发开始遍历。但注意，现在不同的 强连通分量 之间的边也反过来了，所以此时 DFS 没法跑出强连通分量。以上图为例，在 $G’$ 上从 $SCC1$ 开始做反向 DFS 的时候，肯定没法跑出 $SCC1$，其他的同理 正是因为这个性质，保证了在反向 DFS 的时候，每次结束一轮 DFS 都能找到一个强连通分量 当然能够这么做还依赖于下面这么一个事实：如果将一个 强连通分量 里所有节点的边反向翻过来，它依然是一个 强连通分量 ","date":"2025-04-26","objectID":"/zh-cn/kosaraju-algorithm-explained/:3:0","series":null,"tags":["Algorithm"],"title":"Kosaraju 算法：求解有向图的强连通分量","uri":"/zh-cn/kosaraju-algorithm-explained/#关于-kosaraju-算法的直觉"},{"categories":["Algorithm"],"content":" 例子下面是 1682. Flight Routes Check 的题解 c++ #include \u003calgorithm\u003e #include \u003ciostream\u003e #include \u003cvector\u003e using std::cin; using std::cout; using std::fill; using std::vector; void dfs(int cur, const vector\u003cvector\u003cint\u003e\u003e \u0026graph, vector\u003cbool\u003e \u0026visited, vector\u003cint\u003e \u0026stack, bool recorded) { if (visited[cur]) { return; } visited[cur] = true; for (const auto \u0026out : graph[cur]) { dfs(out, graph, visited, stack, recorded); } if (recorded) { // finishing time stack.push_back(cur); } } int main() { // IO int N{}, M{}; cin \u003e\u003e N \u003e\u003e M; vector\u003cvector\u003cint\u003e\u003e G(N + 1); vector\u003cvector\u003cint\u003e\u003e GT(N + 1); for (auto i{0}; i \u003c M; i++) { int x{}, y{}; cin \u003e\u003e x \u003e\u003e y; G[x].push_back(y); GT[y].push_back(x); } // DFS on original graph (G) vector\u003cbool\u003e visited(N + 1, false); vector\u003cint\u003e stack; for (auto i{1}; i \u003c= N; i++) { if (!visited[i]) { // Set recorded to true to put nodes to a stack by finishing time dfs(i, G, visited, stack, true); } } // Reset visited fill(visited.begin(), visited.end(), false); // DFS on transpose graph (GT) vector\u003cint\u003e ans; while (!stack.empty()) { const auto node{stack.back()}; if (!visited[node]) { ans.push_back(node); dfs(node, GT, visited, stack, false); } stack.pop_back(); } if (ans.size() \u003e 1) { cout \u003c\u003c \"NO\\n\" \u003c\u003c ans[1] \u003c\u003c \" \" \u003c\u003c ans[0] \u003c\u003c \"\\n\"; } else { cout \u003c\u003c \"YES\\n\"; } } ","date":"2025-04-26","objectID":"/zh-cn/kosaraju-algorithm-explained/:4:0","series":null,"tags":["Algorithm"],"title":"Kosaraju 算法：求解有向图的强连通分量","uri":"/zh-cn/kosaraju-algorithm-explained/#例子"},{"categories":["Algorithm"],"content":" Refs","date":"2025-04-26","objectID":"/zh-cn/kosaraju-algorithm-explained/:5:0","series":null,"tags":["Algorithm"],"title":"Kosaraju 算法：求解有向图的强连通分量","uri":"/zh-cn/kosaraju-algorithm-explained/#refs"},{"categories":["ML-DL"],"content":"对 torch.einsum API 的介绍","date":"2025-04-14","objectID":"/zh-cn/the-magic-torch-einsum-api/","series":null,"tags":["PyTorch","Deep-Learning","Machine-Learning"],"title":"神奇的 torch.einsum API","uri":"/zh-cn/the-magic-torch-einsum-api/"},{"categories":["ML-DL"],"content":" Motivations在 PyTorch 里面存在着很多跟矩阵乘法、矩阵向量乘法等操作相关的 API，这对记忆来说是一种负担。并且，在使用这些 API 的过程中经常需要对矩阵进行 reshape 等操作，确保维度信息对得上 有没有一个神奇的 API 可以覆盖所有可能的情况呢？答案是有的，那就是 torch.einsum ","date":"2025-04-14","objectID":"/zh-cn/the-magic-torch-einsum-api/:1:0","series":null,"tags":["PyTorch","Deep-Learning","Machine-Learning"],"title":"神奇的 torch.einsum API","uri":"/zh-cn/the-magic-torch-einsum-api/#motivations"},{"categories":["ML-DL"],"content":" torch.einsum 是什么？torch.einsum 的用法是 python torch.einsum(\u003ceinstein_notations\u003e, input1, input2, ...) 其中 input1, input2, ... 是所有参与运算的 tensor， \u003ceinstein_notations\u003e 指的是爱因斯坦求和约定，是 1 个字符串，遵循如下的格式 text \"\u003cdimensions_of_input_1\u003e,\u003cdimensions_of_input_2\u003e-\u003e\u003cdimensions_of_output\u003e\" 可以将上面的式子拆成两个部分 在 -\u003e 左侧是 \u003cdimensions_of_intput_*\u003e，即每个输入的维度信息 在 -\u003e 右侧是 \u003cdimensions_of_output\u003e，即预期输出的维度信息 这里说的维度信息是用英文字母表示的字符串，比如 $\\mathbf M\\in\\mathcal R^{i\\times j}$ 就写成 ij 写爱因斯坦求和约定的时候记住如下几点 不同输入的维度信息如果用到了相同的字母（比如 $\\mathbf M_{ik}\\mathbf N_{kj}$ 里面的 $k$），那么对应的维度上会先按元素相乘然后求和，并且这些字母不会在输出的维度信息里面出现 如果输入的维度信息用到了某个字母但是这些字母没有在输出的维度信息上出现，那么这些字母上会做求和 同一个项（输入或者输出）用到的字母不能有重复 ","date":"2025-04-14","objectID":"/zh-cn/the-magic-torch-einsum-api/:2:0","series":null,"tags":["PyTorch","Deep-Learning","Machine-Learning"],"title":"神奇的 torch.einsum API","uri":"/zh-cn/the-magic-torch-einsum-api/#torcheinsum-是什么"},{"categories":["ML-DL"],"content":" Various Cases Info 通过例子学习是最快上手 torch.einsum 的方法 以矩阵乘法为例，假设输入是 $\\mathbf M\\in\\mathcal R^{i\\times j}$ 和 $\\mathbf N\\in\\mathcal R^{j\\times k}$，那么矩阵乘法可以写为 python torch.einsum(\"ik,kj-\u003eij\", M, N) 如果想要对矩阵 $\\mathbf M$ 进行行求和，可以用 python torch.einsum(\"ij-\u003ei\", M) 同理，列求和是 python torch.einsum(\"ij-\u003ei\", M) 也可以不用求和的功能，比如只是想要转置一下矩阵 $\\mathbf M$ python torch.einsum(\"ij-\u003eji\", M) element-wise 相乘也是支持的 python torch.einsum(\"ij,ij-\u003eij\", M, M) 在深度学习中，经常会遇到的是 batch matrix-matrix product。现在假设矩阵 $\\mathbf M$ 的维度变成了 $b\\times i\\times j$，矩阵 $\\mathbf N$ 的维度变成了 $b\\times j\\times k$，不难写出如下的代码 python torch.einsum(\"bij,bjk-\u003ebik\", M, N) Tip 在书写每个项（输入或者输出）维度信息的时候，都可以用 ... 表示不关心的维度，但每个项最多只能用一次。，根据这个技巧，batch-matrix-matrix product 的代码也可以写为 python torch.einsum(\"...ij,...jk-\u003e...ik\", M, N) 现在假设有向量 $\\mathbf v\\in\\mathcal R^{d}$，想要计算它的 内积 可以这么写 python torch.einsum(\"i,i-\u003e\", v, v) ","date":"2025-04-14","objectID":"/zh-cn/the-magic-torch-einsum-api/:3:0","series":null,"tags":["PyTorch","Deep-Learning","Machine-Learning"],"title":"神奇的 torch.einsum API","uri":"/zh-cn/the-magic-torch-einsum-api/#various-cases"},{"categories":["ML-DL"],"content":" 总结就我个人而言，我很喜欢 torch.einsum 这个 API，因为写爱因斯坦求和记号约定的时候其实是在做声明式编程，就像你写 SQL 一样。此刻的你只会关心输入、输出是什么，而不关心具体要用什么操作完成，即关心的是 what，不关心的是 how :) ","date":"2025-04-14","objectID":"/zh-cn/the-magic-torch-einsum-api/:4:0","series":null,"tags":["PyTorch","Deep-Learning","Machine-Learning"],"title":"神奇的 torch.einsum API","uri":"/zh-cn/the-magic-torch-einsum-api/#总结"},{"categories":["Programming-Languages"],"content":"介绍了 multiprocessing.Pool 和 concurrent.futures.Future API 用来做数据并行","date":"2025-03-30","objectID":"/zh-cn/data-parallel-with-two-different-api/","series":null,"tags":["Python","Performance-Engineering"],"title":"Python 的 2 个进程池相关 API","uri":"/zh-cn/data-parallel-with-two-different-api/"},{"categories":["Programming-Languages"],"content":" Intro作为一名算法工程师，在我的工作中经常都会写各种 Python 脚本来处理大量数据，做数据清洗、信息提取等。通常情况下，这些数据的处理并不涉及竞争条件（Race Condition），而是简单的数据并行（Data Parallel），属于 CPU 密集型任务。通常情况下，这样的任务可以被抽象为 map(fn, data) 的模式 Python 因为存在 GIL 锁，这种情况下，采用多线程并不能提高处理的效率，而是应该采用多进程。另外，一般情况下写代码的时候都是直接创建进程池然后，今天本文要讲的就是 2 种进程池的 API：multiprocessing.Pool 和 concurrent.futures.ProcessPoolExecutor，并进行一些简单的对比 在开始之前，先定义一个处理函数 task 以及导入必要的库，并假设它是一个计算密集的函数。这里用 time.sleep 随机暂停 1 ~ 3 秒假装它很耗时 python import time import random import multiprocessing as mp from concurrent import futures def task(x: int, y: int) -\u003e int: # Let's assume it's a heavy task time.sleep(random.randint(1, 5)) return x + y 并假设我们要处理的输入是 (1, 1), (2, 2), (3, 3), (4, 4)，这可以用 xs 和 ys 构造出来 python xs = range(1, 5) ys = range(1, 5) ","date":"2025-03-30","objectID":"/zh-cn/data-parallel-with-two-different-api/:1:0","series":null,"tags":["Python","Performance-Engineering"],"title":"Python 的 2 个进程池相关 API","uri":"/zh-cn/data-parallel-with-two-different-api/#intro"},{"categories":["Programming-Languages"],"content":" multiprocessing.Poolmultiprocessing 库提供了进程池的实现 Pool，通过 processes 参数可以设置进程池的大小。multiprocessing.Pool 对象有很多的方法，比如 map, imap, apply 等。在本文的场景下，最适合的函数是 starmap 方法 python def mp_starmap(): with mp.Pool(processes=4) as pool: for result in pool.starmap(task, zip(xs, ys)): print(f\"{result=}\") if __name__ == \"__main__\": mp_starmap() Tip 如果 task 的入参只有 1 个，那么就用 pool.map 方法 ","date":"2025-03-30","objectID":"/zh-cn/data-parallel-with-two-different-api/:2:0","series":null,"tags":["Python","Performance-Engineering"],"title":"Python 的 2 个进程池相关 API","uri":"/zh-cn/data-parallel-with-two-different-api/#multiprocessingpool"},{"categories":["Programming-Languages"],"content":" concurrent.futures.ProcessPoolExecutor从 Python 3.2 起，多了一个 concurrent.futures 包，里面也提供了 1 个进程池的实现，叫做 ProcessPoolExecutor1 python def exetutor_map(): with futures.ProcessPoolExecutor(max_workers=4) as exetutor: for result in exetutor.map(task, xs, ys): print(f\"{result=}\") if __name__ == \"__main__\": exetutor_map() 可以看到，代码几乎和 multiprocessing.Pool 的实现差不多，只是在名字和参数上换了一下。一个比较明显的区别是，executor.map 方法传入多个参数的时候更加自然，不需要再自己 zip 一下 Tip executor.map(fn, *iterables) 的原理是用 future 对象包裹 fn(*iterables)，它会返回一个关于 future 对象的生成器，当遍历这个生成器获取返回结果的时候，会调用每个 future 对象的 .result() 方法阻塞等待直到结果返回 如果你不想要用 executor.map，也可以自己进行异步任务的提交和结果获取，需要用到 executor.submit 方法和 futures.as_completed 方法 executor.submit(fn, *args, **kwargs)，提交 fn(*args, **kwargs) 任务，它会将其变成一个 future 对象 futures.as_completed(futures)，参数是可迭代的 future 对象列表，它会返回一个迭代器，当底层的 future 对象执行完成之后会一一返回。注意它返回的是一个个 future 对象，所以还需要自己用 .result() 获取每个 future 对象包裹的可调用对象返回的值 整体代码如下 python def exetutor_submit_completed(): with futures.ProcessPoolExecutor() as exetutor: todo = [exetutor.submit(task, x, y) for x, y in zip(xs, ys)] for future in futures.as_completed(todo): print(f\"result={future.result()}\") if __name__ == \"__main__\": exetutor_submit_completed() 手动 submit 有个不足是 as_completed 返回的 future 对象的顺序跟 submit 提交任务的顺序不匹配。这种情况下，经常会用一个字典来记住入参和 futures 对象之间的映射关系，如下所示 python def exetutor_submit_completed_enhanced(): result = {} with futures.ProcessPoolExecutor() as exetutor: todo = {exetutor.submit(task, x, y): (x, y) for x, y in zip(xs, ys)} for future in futures.as_completed(todo): input_args = todo[future] result[input_args] = future.result() print(f\"result={future.result()}\") if __name__ == \"__main__\": exetutor_submit_completed_enhanced() ","date":"2025-03-30","objectID":"/zh-cn/data-parallel-with-two-different-api/:3:0","series":null,"tags":["Python","Performance-Engineering"],"title":"Python 的 2 个进程池相关 API","uri":"/zh-cn/data-parallel-with-two-different-api/#concurrentfuturesprocesspoolexecutor"},{"categories":["Programming-Languages"],"content":" 用哪一个？就我个人观点，更推荐使用 concurrent.futures.ProcessPoolExecutor，主要是出于下面几个原因 第一，executor.map 跟自带的 map 一样，都是 lazy 的，两者返回的都是 Python Generator。但 pool.map 是 eager 的，要用 lazy 的得换成 pool.imap 第二，当 task 函数有多个入参的时候（正如本文的例子），executor.map(task, args1, args2) 比 pool.starmap(task, zip(args1, args2)) 语法上要优美一些。而且这两者其实是不对等的，一个是 lazy 的，一个是 eager 的，对等的 API 应该是 pool.istarmap，但这个 API 并不存在。但可以通过 pool.imap 进行模拟，只是需要额外定义一个 helper 函数 python def task_helper(seq): return task(*seq) def mp_imap(): with mp.Pool() as pool: for result in pool.imap(task_helper, zip(xs, ys)): print(f\"{result=}\") if __name__ == \"__main__\": mp_imap() 第三，可能也是最重要的一点。在使用 multiprocessing.Pool 的时候，如果其中一个进程被 kill 了，multiprocessing.Pool 会一直卡住不动。但如果是 concurrent.futures.ProcessPoolExecutor，会立刻报一个异常，并显示如下的错误信息 text concurrent.futures.process.BrokenProcessPool: A process in the process pool was\\ terminated abruptly while the future was running or pending. ","date":"2025-03-30","objectID":"/zh-cn/data-parallel-with-two-different-api/:4:0","series":null,"tags":["Python","Performance-Engineering"],"title":"Python 的 2 个进程池相关 API","uri":"/zh-cn/data-parallel-with-two-different-api/#用哪一个"},{"categories":["Programming-Languages"],"content":" 总结用 concurrent.futures.ProcessPoolExecutor 实现进程池 ","date":"2025-03-30","objectID":"/zh-cn/data-parallel-with-two-different-api/:5:0","series":null,"tags":["Python","Performance-Engineering"],"title":"Python 的 2 个进程池相关 API","uri":"/zh-cn/data-parallel-with-two-different-api/#总结"},{"categories":["Programming-Languages"],"content":" Refs PEP3148.futures - execute computations asynchronously ↩︎ ","date":"2025-03-30","objectID":"/zh-cn/data-parallel-with-two-different-api/:6:0","series":null,"tags":["Python","Performance-Engineering"],"title":"Python 的 2 个进程池相关 API","uri":"/zh-cn/data-parallel-with-two-different-api/#refs"},{"categories":["Program-Analysis"],"content":"介绍用来构造调用图的 Class Hierarchy Analysis 算法","date":"2025-03-19","objectID":"/zh-cn/call-graph-generation-using-class-hierarchy-analysis/","series":null,"tags":["Program-Analysis","Compiler","Internal"],"title":"Class Hierarchy Analysis 算法: 快速生成调用图","uri":"/zh-cn/call-graph-generation-using-class-hierarchy-analysis/"},{"categories":["Program-Analysis"],"content":" 调用图生成的核心问题对于 OOP 语言来说，搭建调用图的核心问题是有多态的场景下如何确定到底是哪一个方法被调用了，下面是 Java 的一些可能的函数调用 1 Static Call Special Call Virtual Call Instruction invokestatic invokespecial invokeinterface, invokevirtual Receiver Objects ❌ ✅ ✅ Target Methods Static Method Constructor, Private Instance Method, Superclass Instance Method Other Instance Method Count of Possible Target Methods 1 1 $\\ge 1$ (polymorphism) Determinancy Compile-time Compile-time Run-time 其中 Virtual Call 因为包含了多态，方法调用存在多个可能的目标方法 ","date":"2025-03-19","objectID":"/zh-cn/call-graph-generation-using-class-hierarchy-analysis/:1:0","series":null,"tags":["Program-Analysis","Compiler","Internal"],"title":"Class Hierarchy Analysis 算法: 快速生成调用图","uri":"/zh-cn/call-graph-generation-using-class-hierarchy-analysis/#调用图生成的核心问题"},{"categories":["Program-Analysis"],"content":" 方法调用与方法签名以 Java 语言为例，可能存在如下的方法调用 java A a = ... a.foo() 上面的方法调用是 a.foo()，调用者是 a，a 的声明类型是 A 对于方法，我们最关心的是它的方法签名，即方法的唯一 ID，它包含如下的要素 2 Class Type: 调用者的声明类型 \" 子签名 \" Method Name: 方法的名字，在这个例子中就是 foo Return Type: 方法的返回类型 Parameter Types: 方法每个入参的类型 这里的“子签名”不包含 Class Type，后面在 CHA 算法里面会看到它的用处 为了方便，这里为方法签名引入记号 2： java \u003cClass Type\u003e: \u003cReturn Type\u003e \u003cMethod Name\u003e(\u003cParameter Types\u003e) 那么上面的 a.foo() 的记号就是 A: foo() ","date":"2025-03-19","objectID":"/zh-cn/call-graph-generation-using-class-hierarchy-analysis/:2:0","series":null,"tags":["Program-Analysis","Compiler","Internal"],"title":"Class Hierarchy Analysis 算法: 快速生成调用图","uri":"/zh-cn/call-graph-generation-using-class-hierarchy-analysis/#方法调用与方法签名"},{"categories":["Program-Analysis"],"content":" Class Hierarchy Analysis 算法的 Motivations类层次结构分析（Class Hierarchy Analysis，CHA）算法的核心思想是根据方法调用里面的调用者（Receive Variable）的声明类型（Declarative Type）推导到底调用了哪个（些）方法，后面会展开来说是什么意思 顾名思义，CHA 是基于类层次结构的分析，那么使用 CHA 的前提是类的层次结构是已知的，另外 CHA 假设：调用者可能指向它的声明类型，也可能是声明类型的子类 Tip 有时候，调用者的声明类型可能是一个接口，那么此时 CHA 假设调用者可能指向所有实现了这个接口的类 ","date":"2025-03-19","objectID":"/zh-cn/call-graph-generation-using-class-hierarchy-analysis/:3:0","series":null,"tags":["Program-Analysis","Compiler","Internal"],"title":"Class Hierarchy Analysis 算法: 快速生成调用图","uri":"/zh-cn/call-graph-generation-using-class-hierarchy-analysis/#class-hierarchy-analysis-算法的-motivations"},{"categories":["Program-Analysis"],"content":" CHA 算法CHA 算法只要记住 2 个函数即可，$\\texttt{Dispatch}$ 和 $\\texttt{Resolve}$ ","date":"2025-03-19","objectID":"/zh-cn/call-graph-generation-using-class-hierarchy-analysis/:4:0","series":null,"tags":["Program-Analysis","Compiler","Internal"],"title":"Class Hierarchy Analysis 算法: 快速生成调用图","uri":"/zh-cn/call-graph-generation-using-class-hierarchy-analysis/#cha-算法"},{"categories":["Program-Analysis"],"content":" Dispatch 函数输入 当前考虑的类 $c$ 方法签名 $m$ 输出：实际上被调用的方法 算法：对于 $\\texttt{Dispatch}(c,m)$ 如果类 $c$ 里面有非抽象方法 符合方法签名 $m$（这里不需要考虑方法签名 $m$ 的 Class Type，这也是前面为啥单独把“子类型“单独列出来），那么就找到了实际上被调用的方法，直接返回该方法 否则，调用 $\\texttt{Dispatch}(c’,m)$，这里的 $c’$ 是 $c$ 的父类 总结：$\\texttt{Dispatch}$ 很好理解，其实它和我们自己肉眼确定 OOP 语言的某个方法调用实际上被调用的方法是一致的 ","date":"2025-03-19","objectID":"/zh-cn/call-graph-generation-using-class-hierarchy-analysis/:4:1","series":null,"tags":["Program-Analysis","Compiler","Internal"],"title":"Class Hierarchy Analysis 算法: 快速生成调用图","uri":"/zh-cn/call-graph-generation-using-class-hierarchy-analysis/#dispatch-函数"},{"categories":["Program-Analysis"],"content":" Resolve 函数 Tip 简单来说，call site 就是方法调用所在的语句 输入：call site 输出：所有这个 call site 可能调用的方法集合 算法： 初始化集合 $T$ 为空 定义 $m$ 为 call site 的方法签名 分情况 如果 $m$ 是静态方法调用，直接返回 ${ m }$ 如果 $m$ 是普通实例方法调用（非 Virtual Call），拿出 $m$ 的声明类型 $c^m$ ，那么 $T= {\\texttt{Dispatch}(c^m, m)}$ 如果 $m$ 是 Virtual Call，那么取出 call site 调用者的声明类型（记为 $c$），对于 $c$ 以及的每一个子类 $c’$，调用 $\\texttt{Dispatch}(c’, m)$ 并把结果加到 $T$ 里面。 总结：CHA 算法对待 Virtual Call 的方法很粗暴也很直接，直接枚举所有可能的情况，它认为实际的调用者可能是声明类型的实例，也可能是声明类型的子类（直接或间接）的实例 ","date":"2025-03-19","objectID":"/zh-cn/call-graph-generation-using-class-hierarchy-analysis/:4:2","series":null,"tags":["Program-Analysis","Compiler","Internal"],"title":"Class Hierarchy Analysis 算法: 快速生成调用图","uri":"/zh-cn/call-graph-generation-using-class-hierarchy-analysis/#resolve-函数"},{"categories":["Program-Analysis"],"content":" 用 CHA 算法生成调用图输入：Entry Method，Java 的话就是 main 方法 输出：调用图 算法： 初始化 $\\texttt{WorkList} = {Entry\\ Method}$，存储着要处理的方法 $\\texttt{CG} = \\emptyset$，表示调用图，可以用边的集合表示调用图 $\\texttt{RM} = \\emptyset$，表示可达的方法，同时也起到了哈希表的作用，只要方法进入到 $\\texttt{RM}$ 那就表示处理过了 只要 $\\texttt{WorkList}$ 非空 取出 1 个方法，记为 $m$ 如果 $m$ 不在 $\\texttt{RM}$ 里面，也就是还没有访问过 把 $m$ 加到 $\\texttt{RM}$ 里面 对于方法 $m$ 的每一个 call site $cs$ $T=\\texttt{Resolve}(cs)$ 对于集合 $T$ 里面的每一个方法 $m'$ 把调用边 $cs\\rightarrow m’$ 添加到 $\\texttt{CG}$ 里面 把方法 $m’$ 添加到 $\\texttt{WorkList}$ 里面 返回 $\\texttt{CG}$ ","date":"2025-03-19","objectID":"/zh-cn/call-graph-generation-using-class-hierarchy-analysis/:5:0","series":null,"tags":["Program-Analysis","Compiler","Internal"],"title":"Class Hierarchy Analysis 算法: 快速生成调用图","uri":"/zh-cn/call-graph-generation-using-class-hierarchy-analysis/#用-cha-算法生成调用图"},{"categories":["Program-Analysis"],"content":" CHA Example. ArkAnalyzer最近因为工作需要在看 ArkAnalyzer 的源码 3，里面刚好有 CHA 算法的例子，下面来看看到底是如何实现的，源码仓挂在了 Gitee 上，链接在 这里 Tip 下面的代码经过省略，只显示跟 CHA 算法有关的部分 ","date":"2025-03-19","objectID":"/zh-cn/call-graph-generation-using-class-hierarchy-analysis/:6:0","series":null,"tags":["Program-Analysis","Compiler","Internal"],"title":"Class Hierarchy Analysis 算法: 快速生成调用图","uri":"/zh-cn/call-graph-generation-using-class-hierarchy-analysis/#cha-example-arkanalyzer"},{"categories":["Program-Analysis"],"content":" 方法签名先看方法签名的类 MethodSignature ts export class MethodSignature { private declaringClassSignature: ClassSignature; private methodSubSignature: MethodSubSignature; ... } 它的 2 个成员分别是 ClassSignature 和 MethodSubSignature ts export class ClassSignature { private declaringFileSignature: FileSignature; private className: string; ... } export class MethodSubSignature { private methodName: string; private parameters: MethodParameter[]; private returnType: Type; private staticFlag: boolean; } ClassSignature + MethodSubSignature 的 methodName, parameters, returnType 刚好就是我们前面提到的方法签名的构成 ","date":"2025-03-19","objectID":"/zh-cn/call-graph-generation-using-class-hierarchy-analysis/:6:1","series":null,"tags":["Program-Analysis","Compiler","Internal"],"title":"Class Hierarchy Analysis 算法: 快速生成调用图","uri":"/zh-cn/call-graph-generation-using-class-hierarchy-analysis/#方法签名"},{"categories":["Program-Analysis"],"content":" 调用图生成的入口函数入口函数是 makeCallGraphCHA 函数，入参是一堆 Entry Points，用方法签名表示 ts public makeCallGraphCHA(entryPoints: MethodSignature[]): CallGraph { let callGraph = new CallGraph(this); let callGraphBuilder = new CallGraphBuilder(callGraph, this); callGraphBuilder.buildClassHierarchyCallGraph(entryPoints); return callGraph; } public buildClassHierarchyCallGraph(entries: Method[], displayGeneratedMethod: boolean = false): void { ... let classHierarchyAnalysis: ClassHierarchyAnalysis = new ClassHierarchyAnalysis(this.scene, this.cg); classHierarchyAnalysis.start(displayGeneratedMethod); } ","date":"2025-03-19","objectID":"/zh-cn/call-graph-generation-using-class-hierarchy-analysis/:6:2","series":null,"tags":["Program-Analysis","Compiler","Internal"],"title":"Class Hierarchy Analysis 算法: 快速生成调用图","uri":"/zh-cn/call-graph-generation-using-class-hierarchy-analysis/#调用图生成的入口函数"},{"categories":["Program-Analysis"],"content":" CHA 实现可以看到 classHierarchyAnalysis.start 启动了 CHA 算法，下面是这个方法的内容 ts protected init(): void { this.processedMethod = new Set(); this.cg.getEntries().forEach((entryFunc) =\u003e { this.workList.push(entryFunc); }) } public start(displayGeneratedMethod: boolean): void { this.init(); while (this.workList.length !== 0) { const method = this.workList.shift() as FuncID; const cgNode = this.cg.getNode(method) as CallGraphNode; if (this.processedMethod.has(method) || cgNode.isSdkMethod()) { continue; } ... this.processMethod(method).forEach((cs: CallSite) =\u003e { let me = this.cg.getArkMethodByFuncID(cs.calleeFuncID); this.addCallGraphEdge(method, me, cs, displayGeneratedMethod); if (!this.processedMethod.has(cs.calleeFuncID)) { this.workList.push(cs.calleeFuncID); this.processedMethod.add(cs.callerFuncID); } }) } } 可以看到，算法流程基本上和前面描述的 CHA 算法逻辑差不多，关键几个点解释如下 this.processedMethod 看名字也知道，表示处理过的方法，避免重复处理同一个方法 this.processMethod(method) 调用的 processMethod 方法后面会讲 ","date":"2025-03-19","objectID":"/zh-cn/call-graph-generation-using-class-hierarchy-analysis/:6:3","series":null,"tags":["Program-Analysis","Compiler","Internal"],"title":"Class Hierarchy Analysis 算法: 快速生成调用图","uri":"/zh-cn/call-graph-generation-using-class-hierarchy-analysis/#cha-实现"},{"categories":["Program-Analysis"],"content":" Dispatch + Resolve在 ArkAnalyzer 里面，$\\texttt{Dispatch}$ 函数和 $\\texttt{Resolve}$ 函数都放在了 resolvecall 里面，resolveCall 则是通过 processMethod 唤起 ts protected processMethod(methodID: FuncID): CallSite[] { ... cfg.getStmts().forEach((stmt) =\u003e { if (stmt.containsInvokeExpr()) { this.resolveCall(cgNode.getID(), stmt).forEach(stmt =\u003e calleeMethods.push(stmt)); } }) return calleeMethods; } resolveCall 的代码为 ts public resolveCall(callerMethod: NodeID, invokeStmt: Stmt): CallSite[] { let invokeExpr = invokeStmt.getInvokeExpr(); let resolveResult: CallSite[] = []; if (!invokeExpr) { return []; } // process anonymous method call this.getParamAnonymousMethod(invokeExpr).forEach(method =\u003e { resolveResult.push( new CallSite( invokeStmt, undefined, this.cg.getCallGraphNodeByMethod(method).getID(), callerMethod, ) ); }); // 返回方法 let calleeMethod = this.resolveInvokeExpr(invokeExpr); if (!calleeMethod) { return resolveResult; } if (invokeExpr instanceof ArkStaticInvokeExpr) { // NOTE: Case 1. Static Method Call resolveResult.push( new CallSite( invokeStmt, undefined, this.cg.getCallGraphNodeByMethod(calleeMethod!.getSignature()).getID(), callerMethod! ) ); } else { let declareClass = calleeMethod.getDeclaringArkClass(); // NOTE: Case 2. Virtual Call this.getClassHierarchy(declareClass).forEach((arkClass: ArkClass) =\u003e { if (arkClass.isAbstract()) { return; } let possibleCalleeMethod = arkClass.getMethodWithName(calleeMethod!.getName()); if (possibleCalleeMethod \u0026\u0026 possibleCalleeMethod.isGenerated() \u0026\u0026 arkClass.getSignature().toString() !== declareClass.getSignature().toString()) { // remove the generated method in extended classes return; } if (possibleCalleeMethod \u0026\u0026 !possibleCalleeMethod.isAbstract()) { resolveResult.push( new CallSite( invokeStmt, undefined, this.cg.getCallGraphNodeByMethod(possibleCalleeMethod.getSignature()).getID(), callerMethod ) ); } }); } return resolveResult; } 和前面介绍的 $\\texttt{Dispatch}, \\texttt{Resolve}$ 相比，ArkAnalyzer 似乎直接将非静态方法调用都当成 Virtual Call 处理 ","date":"2025-03-19","objectID":"/zh-cn/call-graph-generation-using-class-hierarchy-analysis/:6:4","series":null,"tags":["Program-Analysis","Compiler","Internal"],"title":"Class Hierarchy Analysis 算法: 快速生成调用图","uri":"/zh-cn/call-graph-generation-using-class-hierarchy-analysis/#dispatch--resolve"},{"categories":["Program-Analysis"],"content":" 总结以上就是 CHA 算法的全部内容，它的优点是简单，计算很快，但缺点是不够精确，可能存在误报。比如，假设 A 和 B 这两个类里面都有 foo 方法，对于下面这样一段 Java 代码 java A a = new B(); a.foo(); CHA 算法会认为 A 和 B 的 foo 方法都是目标方法，因为它没有考虑到 new B() 这一部分。这些可以通过指针分析进一步精确化，这一块就放在未来的文章中再讨论了 :0 ","date":"2025-03-19","objectID":"/zh-cn/call-graph-generation-using-class-hierarchy-analysis/:7:0","series":null,"tags":["Program-Analysis","Compiler","Internal"],"title":"Class Hierarchy Analysis 算法: 快速生成调用图","uri":"/zh-cn/call-graph-generation-using-class-hierarchy-analysis/#总结"},{"categories":["Program-Analysis"],"content":" Ref 南京大学.软件分析2020.07.Interprocedural Analysis Page 20 ↩︎ 南京大学.软件分析2020.07.Interprocedural Analysis Page 23 ↩︎ ↩︎ ArkAnalyzer: The Static Analysis Framework for OpenHarmony ↩︎ ","date":"2025-03-19","objectID":"/zh-cn/call-graph-generation-using-class-hierarchy-analysis/:8:0","series":null,"tags":["Program-Analysis","Compiler","Internal"],"title":"Class Hierarchy Analysis 算法: 快速生成调用图","uri":"/zh-cn/call-graph-generation-using-class-hierarchy-analysis/#ref"},{"categories":["Algorithm"],"content":"介绍前缀和数组这种数据结构","date":"2025-03-15","objectID":"/zh-cn/ds-prefixsum-array/","series":null,"tags":["Data-Structure"],"title":"前缀和数组: 快速计算数组区间和","uri":"/zh-cn/ds-prefixsum-array/"},{"categories":["Algorithm"],"content":" Motivations有这么一类问题——给定一个数组 $arr$ 和 $Q$ 个查询，每一个查询的格式是 $query(l, r)$，意思是计算区间和 $arr[l] + arr[l + 1] + … + arr[r]$ 如果采用暴力求解，那么查询区间和的时间复杂度是 $O(N)$，处理 $Q$ 个查询就需要 $O(NQ)$，有没有什么数据结构或者是算法可以优化这个时间复杂度呢？ 前缀和数组就可以做到，这就是今天要讲的主题 ","date":"2025-03-15","objectID":"/zh-cn/ds-prefixsum-array/:1:0","series":null,"tags":["Data-Structure"],"title":"前缀和数组: 快速计算数组区间和","uri":"/zh-cn/ds-prefixsum-array/#motivations"},{"categories":["Algorithm"],"content":" 前缀和数组定义先看前缀和数组，定义如下 $$ \\texttt{prefix}[k]=\\sum_{i=0}^{k-1}arr[i] $$ 换言之，$\\texttt{prefix}[k]$ 是数组 $arr$ 前 $k$ 个数字的和，这也是为什么它叫做前缀和数组 计算出前缀和数组 $\\texttt{prefix}$ 只需要 $O(N)$ 的时间复杂度，按顺序遍历 $arr$ 数组，利用如下的公式 $$ \\texttt{prefix}[k+1] = \\texttt{prefix}[k] + arr[k] $$ 根据前缀和数组的定义，区间和的计算可以利用如下的式子 $$ query[l, r]=\\texttt{prefix}[r+1]-\\texttt{prefix}[l] $$ 可以看到，现在处理一个区间查询的时间复杂度变成了 $O(1)$，处理 $Q$ 个查询的时间复杂度是 $$ O(N + Q)\\ll O(NQ) $$ ","date":"2025-03-15","objectID":"/zh-cn/ds-prefixsum-array/:2:0","series":null,"tags":["Data-Structure"],"title":"前缀和数组: 快速计算数组区间和","uri":"/zh-cn/ds-prefixsum-array/#前缀和数组定义"},{"categories":["Algorithm"],"content":" 前缀和数组实现 Tip 定义前缀和数组的时候记住：前缀和数组的长度 = 原数组长度 + 1 按照定义写如下 python prefix_sum = [0 for _ in range(len(arr) + 1)] for i in range(len(arr)): prefix_sum[i + 1] = prefix_sum[i] + arr[i] 当然我更经常使用的是如下的写法 :) python from itertools import accumulate prefix_sum = list(accumulate(a, initial=0)) ","date":"2025-03-15","objectID":"/zh-cn/ds-prefixsum-array/:3:0","series":null,"tags":["Data-Structure"],"title":"前缀和数组: 快速计算数组区间和","uri":"/zh-cn/ds-prefixsum-array/#前缀和数组实现"},{"categories":["Algorithm"],"content":" Lazy Update前面我们的数组是 $arr$ 是静态的，即读取进来之后就不会再更改了。但有时候做题会发现，题目要求我们支持这么一种更新操作 $update(arr, l, r, x)$——对区间 $[l, r]$ 的数字批量加上一个数字或者减去一个数字。一道典型的题目是是 SPOJ.HAYBALE-Haybale stacking 还是先来分析一下暴力算法的时间复杂度。假设有 $K$ 个这样的更新操作，处理单个 $update(arr, a, b, x)$ 操作的时间复杂度是 $O(N)$，那么 $K$ 个更新操作就是 $O(NK)$，显然时间复杂度太高了，在算法题里面经常都会 TLE 为了节省性能开销，不难想到不应该真的去更新，而是应该惰性更新（Lazy Update），那么要怎么做呢？答案就在下面这个公式上 $$ \\texttt{prefix}[i+1] = \\texttt{prefix}[i] + arr[i] $$ 前缀和数组会不断累加原数组的值，这里存在一个“累加”的效果，试想一下，如果我们让 $arr[l] + x$ 会怎么样？可想而知，从 $l$ 这个位置开始的前缀和数组都会 $+x$，到这里答案已经呼之欲出了，我们再让 $arr[r + 1] - x$，从 $r + 1$ 这个位置开始的前缀和数组都会 $-x$。等价的效果就是 $[l, r]$ 这个区间里面的元素都 $+x$ 而不影响其他位置的值。Python 代码大致如下 python def update(arr, l, r, x): arr[l] += x arr[r + 1] -= x 这样更新的操作就是 $O(1)$ 了， $K$ 个更新操作只需要 $O(K)$，最后再用 $O(N)$ 计算前缀和数组，总的时间复杂度为 $O(N + K)$ $$ O(N + K)\\ll O(NK) $$ Example 如果你仍然无法上面的文字描述，那么可以尝试推导如下这个例子。假设有下面这样一个数组，我们要将区间 [2, 4] 都加上 1 Index 0 1 2 3 4 5 6 arr 1 2 3 4 5 6 Calculate the Prefix Sum 0 1 3 6 10 15 21 Add 1 to [2, 4] with the Lazy Update trick 1 2 4 (+1) 4 5 5 (-1) Calculate the Prefix Sum 0 1 3 7 11 16 21 从前缀和数组可以看到，prefix[3] ~ prefix[5] 从 6, 10, 15 变成了 7, 11, 16，而 prefix[0], prefix[1], prefix[2], prefix[6] 保持值不变 ","date":"2025-03-15","objectID":"/zh-cn/ds-prefixsum-array/:4:0","series":null,"tags":["Data-Structure"],"title":"前缀和数组: 快速计算数组区间和","uri":"/zh-cn/ds-prefixsum-array/#lazy-update"},{"categories":["ML-DL"],"content":"An explanation of the weight tying techniques in transformer","date":"2025-03-11","objectID":"/zh-cn/an-explanation-of-weight-tying/","series":null,"tags":["NLP","LLM","Deep-Learning","Paper"],"title":"语言模型中的 Weight Tying 技术","uri":"/zh-cn/an-explanation-of-weight-tying/"},{"categories":["ML-DL"],"content":" 引言 Quote In our model, we share the same weight matrix between the two embedding layers and the pre-softmax linear transformation - Attention is All You Need, Section 3.4. Embeddings and Softmax1 在 Attention is All You Need1 这一篇论文的 3.4. Embeddings and Softmax 章节里面有上面这一句话，它是什么意思呢？ 意思是：作者将 token embedding 层的权重和最后做 Softmax 前的线性变换层的权重共享了，这也叫做 Weight Tying 技术，出自于 Using the Output Embedding to Improve Language Models 这一篇论文 2。在本篇文章中，我会简单介绍下原理和实现。 ","date":"2025-03-11","objectID":"/zh-cn/an-explanation-of-weight-tying/:1:0","series":null,"tags":["NLP","LLM","Deep-Learning","Paper"],"title":"语言模型中的 Weight Tying 技术","uri":"/zh-cn/an-explanation-of-weight-tying/#引言"},{"categories":["ML-DL"],"content":" Weight Tying 是什么flowchart LR wte(input embedding) lm_head(output embedding) wte --\u003e ... --\u003e lm_head 在语言模型里面，通常存在两个权重矩阵 input embedding (用记号 $\\mathbf U$ 表示）：将输入的 token 变为 token embedding，在 PyTorch 代码中对应 nn.Embedding output embedding（用记号 $\\mathbf V$ 表示）：将 token embedding 变为 Vocab 上关于 token 的概率分布，在 PyTorch代码中对应 nn.Linear 作者 argue 说，训练的时候对 $\\mathbf U$ 和 $\\mathbf V$ 的期望是类似的1 对 $\\mathbf U$ 来说，希望语义相似的 token 有相似的 token embedding 对 $\\mathbf V$ 来说，希望 如果不同的 token 语义相似，那么他们在 token 的概率分布中有相近的概率分数 除此之外，$\\mathbf U$ 和 $\\mathbf V$ 的大小还是一样的。既然如此，这两者可以合并进行权重共享吗？ 答案是可以，具体的实验细节可以参考原论文 2，这里不展开 ","date":"2025-03-11","objectID":"/zh-cn/an-explanation-of-weight-tying/:2:0","series":null,"tags":["NLP","LLM","Deep-Learning","Paper"],"title":"语言模型中的 Weight Tying 技术","uri":"/zh-cn/an-explanation-of-weight-tying/#weight-tying-是什么"},{"categories":["ML-DL"],"content":" Weight Tying 的实现在 PyTorch 代码里面，$\\mathbf U$ 用 nn.Embedding 实现；$\\mathbf V$ 用 nn.Linear 实现，代码如下 python in_features, hidden_dim = 3, 4 U = nn.Embedding(in_features, hidden_dim) V = nn.Linear(hidden_dim, in_features, bias=False) Weight Tying 的 PyTorch 实现很简单，只需要将两者的 weight 指向同一个地方即可 python U.weight = V.weight ","date":"2025-03-11","objectID":"/zh-cn/an-explanation-of-weight-tying/:3:0","series":null,"tags":["NLP","LLM","Deep-Learning","Paper"],"title":"语言模型中的 Weight Tying 技术","uri":"/zh-cn/an-explanation-of-weight-tying/#weight-tying-的实现"},{"categories":["ML-DL"],"content":" 总结在语言模型里面，对 input embedding $\\mathbf U$ 和 output embedding $\\mathbf V$ 进行权重共享的好处是显而易见的：需要训练的参数减半，模型的表现还差不多，甚至输出的困惑度还更低了 2。在代码实现上也算容易 ","date":"2025-03-11","objectID":"/zh-cn/an-explanation-of-weight-tying/:4:0","series":null,"tags":["NLP","LLM","Deep-Learning","Paper"],"title":"语言模型中的 Weight Tying 技术","uri":"/zh-cn/an-explanation-of-weight-tying/#总结"},{"categories":["ML-DL"],"content":" 参考 Vaswani, Ashish, et al. “Attention is all you need.” Advances in neural information processing systems 30 (2017). ↩︎ ↩︎ ↩︎ Press, Ofir, and Lior Wolf. “Using the output embedding to improve language models.” arXiv preprint arXiv:1608.05859(2016). ↩︎ ↩︎ ↩︎ ","date":"2025-03-11","objectID":"/zh-cn/an-explanation-of-weight-tying/:5:0","series":null,"tags":["NLP","LLM","Deep-Learning","Paper"],"title":"语言模型中的 Weight Tying 技术","uri":"/zh-cn/an-explanation-of-weight-tying/#参考"},{"categories":["ML-DL"],"content":"介绍了 Transformer 的多头注意力","date":"2025-03-04","objectID":"/zh-cn/an-explanation-of-multi-head-attention/","series":null,"tags":["Deep-Learning","LLM"],"title":"多头注意力是什么","uri":"/zh-cn/an-explanation-of-multi-head-attention/"},{"categories":["ML-DL"],"content":" 什么是多头注意力在上一篇文章里面我们已经讲完了 Self Attention|自注意力，这里我们在自注意力的基础上多增加一点东西：加上多头注意力（Multi-Head Attention，MHA）。这个其实才是本来 Transformer 的自注意力的完全版本1。因为大部分内容在前文已经讲完，本篇不会太长～ 之前我们提到有下面这三个矩阵 $$ \\mathbf Q,\\mathbf K,\\mathbf V\\in\\mathcal{R}^{n\\times d} $$ 假设有 $n_h$ 个头，多头注意力的意思就是将每个长度为 $d$ 的 Query/Key/Value 向量切分为 $n_h$ 个，所以每一个头的向量长度变成了 $d_h=d/n_h$，那么上面 3 个矩阵就变成了 $$ \\mathbf Q,\\mathbf K,\\mathbf V\\in\\mathcal{R}^{n_h\\times n\\times d_h} $$ 注意在维度里面，$n_h$ 放在第一个位置 为啥要这样子做呢？可以从矩阵乘法的角度入手。在不采用多头注意力之前 $$ \\begin{split} \\mathbf Q\\in\\mathcal{R}^{n\\times d}\\\\ \\mathbf K^T\\in\\mathcal{R}^{d\\times n}\\\\ \\mathbf Q\\mathbf K^T\\in\\mathcal R^{n\\times n} \\end{split} $$ 我们得到了一个注意力分数矩阵 在采用多头注意力之后，维度变成了如下的样子 $$ \\begin{split} \\mathbf Q\\in\\mathcal{R}^{n_h\\times n\\times d_h}\\\\ \\mathbf K^T\\in\\mathcal{R}^{n_h\\times d_h\\times n}\\\\ \\mathbf Q\\mathbf K^T\\in\\mathcal R^{n_h\\times n\\times n} \\end{split} $$ 我们得到了 $n_h$ 个注意力分数矩阵。同样的，我还是用 Exclidraw 画了一张图来示意（假设 $n_h=4$），相同颜色之间进行运算，4 种颜色所以得到了 4 套注意力分数矩阵 为了公式的简洁，忽略用 $1/\\sqrt d_h$ 做 Scaling，那么多头注意力最后的输出是 $$ \\texttt{softmax}(\\mathbf Q\\mathbf K^T)\\mathbf V\\in\\mathcal R^{n_h\\times n\\times d_h} $$ 最后做一下 reshape，将 $\\mathcal R^{n_h\\times n\\times d_h}$ 变回 $\\mathcal{R}^{n\\times d}$ 即可 ","date":"2025-03-04","objectID":"/zh-cn/an-explanation-of-multi-head-attention/:1:0","series":null,"tags":["Deep-Learning","LLM"],"title":"多头注意力是什么","uri":"/zh-cn/an-explanation-of-multi-head-attention/#什么是多头注意力"},{"categories":["ML-DL"],"content":" 实现多头注意力基于之前自注意力的代码，进行如下的操作就可以得到多头注意力 实现单向注意力矩阵的 bias 需要的目标维度是 (1, 1, block_size, block_size) q, k, v 都需要 reshape 一下 最后做 attn @ v 需要调用 contiguous 然后再做 Reshape 完整代码在这里 python class MultiHeadAttn(nn.Module): def __init__(self, n_embd: int, block_size: int, n_heads: int): super().__init__() self.attn = nn.Linear(n_embd, 3 * n_embd) self.n_embd = n_embd self.n_heads = n_heads assert self.n_embd % self.n_heads == 0 self.register_buffer( \"bias\", torch.tril(torch.ones(block_size, block_size)).view( 1, 1, block_size, block_size, ), ) def forward(self, x): B, T, C = x.size() # (batch_size, seq_len, n_embd) qkv = self.attn(x) # qkv: (batch_size, seq_len, 3 * n_embd) q, k, v = qkv.split(self.n_embd, dim=2) # split in n_embd dimension q = q.view(B, T, self.n_heads, C // self.n_heads).transpose( 1, 2 ) # q: (batch_size, n_heads, seq_len, n_embd) k = k.view(B, T, self.n_heads, C // self.n_heads).transpose( 1, 2 ) # k: (batch_size, n_heads, seq_len, n_embd) v = v.view(B, T, self.n_heads, C // self.n_heads).transpose( 1, 2 ) # v: (batch_size, n_heads, seq_len, n_embd) attn = (q @ k.transpose(-2, -1)) * ( 1.0 / math.sqrt(k.size(-1)) ) # attn: (batch_size, n_heads, seq_len, seq_len) attn = attn.masked_fill(self.bias[:, :, :T, :T] == 0, -float(\"inf\")) attn = F.softmax(attn, dim=-1) out = (attn @ v).transpose(1, 2).contiguous().view(B, T, C) return out ","date":"2025-03-04","objectID":"/zh-cn/an-explanation-of-multi-head-attention/:2:0","series":null,"tags":["Deep-Learning","LLM"],"title":"多头注意力是什么","uri":"/zh-cn/an-explanation-of-multi-head-attention/#实现多头注意力"},{"categories":["ML-DL"],"content":" 总结总结来说，多头注意力的奥妙就在维度上。通过多头注意力，虽然 Query/Key/Value 向量都变短了（$d\\rightarrow d_h$），但是我们得到了更多的注意力分数矩阵（$1\\rightarrow n_h$）。如果说每一个注意力分数矩阵都捕捉了一种模式的话，那么多头注意力就是捕捉了多种模式，那效果自然就更好了 :) ","date":"2025-03-04","objectID":"/zh-cn/an-explanation-of-multi-head-attention/:3:0","series":null,"tags":["Deep-Learning","LLM"],"title":"多头注意力是什么","uri":"/zh-cn/an-explanation-of-multi-head-attention/#总结"},{"categories":["ML-DL"],"content":" Ref Vaswani, Ashish, et al. “Attention is all you need.” Advances in neural information processing systems 30 (2017). ↩︎ ","date":"2025-03-04","objectID":"/zh-cn/an-explanation-of-multi-head-attention/:4:0","series":null,"tags":["Deep-Learning","LLM"],"title":"多头注意力是什么","uri":"/zh-cn/an-explanation-of-multi-head-attention/#ref"},{"categories":["ML-DL"],"content":"介绍了 Transformer 的自注意力的最基础版本","date":"2025-03-02","objectID":"/zh-cn/an-explanation-of-self-attention/","series":null,"tags":["Deep-Learning","LLM"],"title":"如何理解 Transformer 的自注意力公式","uri":"/zh-cn/an-explanation-of-self-attention/"},{"categories":["ML-DL"],"content":" Info 进一步阅读: 多头注意力 MHA ","date":"2025-03-02","objectID":"/zh-cn/an-explanation-of-self-attention/:0:0","series":null,"tags":["Deep-Learning","LLM"],"title":"如何理解 Transformer 的自注意力公式","uri":"/zh-cn/an-explanation-of-self-attention/#"},{"categories":["ML-DL"],"content":" 引言大模型基于 Transformer 架构搭建而成，而自注意力机制是 Transformer 的核心。要理解大模型就要从理解自注意力开始。在本篇文章里，我将拆解自注意力公式来帮助你理解，最后还会手撕自注意力的 PyTorch 代码 :0 Info 记号规定：粗体大写表示矩阵，粗体小写表示向量，普通小写表示标量 本文提到的自注意力确切来说是单向的自注意力 ","date":"2025-03-02","objectID":"/zh-cn/an-explanation-of-self-attention/:1:0","series":null,"tags":["Deep-Learning","LLM"],"title":"如何理解 Transformer 的自注意力公式","uri":"/zh-cn/an-explanation-of-self-attention/#引言"},{"categories":["ML-DL"],"content":" 自注意力的理解 Note 原论文1用的是 $d_k$ 而不是 $d$，$d_k$ 表示 Key 向量的长度。这里为了方便，认为 Query、Key、Value 向量是等长的，都为 $d$ 在原论文里面，自注意力的公式是1 $$ \\texttt{Self-Attention}(\\mathbf Q, \\mathbf K, \\mathbf V)=\\texttt{softmax}(\\frac{\\mathbf Q\\mathbf K^T}{\\sqrt d})\\mathbf V $$ 上面是公式描述，如果看不懂也没关系，后面会逐步拆解。简单来说，自注意力的原理是：对于每个 token $i$，通过计算得到它的 Query ($\\mathbf q_i$)、Key ($\\mathbf k_i$)、Value ($\\mathbf v_i)$ 向量，然后这个 token $i$ 会拿着它自己的 $\\mathbf q_i$ 和其他所有的 （包括 token $i$ 自己）token 的 $\\mathbf k_j$ 向量计算注意力分数 $a_{ij}$，每个 $(\\texttt{token } i,\\texttt{token } j)$ 的 pair 都可以得到注意力分数 $a_{ij}$，每个注意力分数 $a_{ij}$ 都会和对应的 $\\mathbf v_j$ 相乘，这样子做加权和之后就得到了 token $i$ 的新的向量表示 这么说可能有点绕，因此下面来拆解一下上面的公式，这个公式里面涉及到这么几个变量 $\\mathbf Q,\\mathbf K,\\mathbf V,d_k$，他们的意思分别是 $\\mathbf Q$ 表示所有 token 的 Query 向量构成的矩阵 $\\mathbf K$ 表示所有 token 的 Key 向量构成的矩阵 $\\mathbf V$ 表示所有 token 的 Value 向量构成的矩阵 $d$ 表示 Query/Key/Value 向量的长度 首先需要知道怎么从输入得到 $\\mathbf Q,\\mathbf K,\\mathbf V$。用 $\\mathbf x_{1:n}$ 表示输入的 $n$ 个 token 的向量表示，通过 $\\mathbf W^Q, \\mathbf W^K, \\mathbf W^V$ 三个矩阵的权重变换（其实就是 矩阵乘法）就得到 $\\mathbf Q,\\mathbf K, \\mathbf V$ $$ \\mathbf Q,\\mathbf K,\\mathbf V\\in\\mathcal{R}^{n\\times d} $$ 我用 Exclidraw 画了一张图，来帮助你进行理解这 3 个矩阵 先看自注意力公式的核心部分 $$ \\mathbf Q\\mathbf K^T\\in\\mathcal R^{n\\times n} $$ $\\mathbf Q\\mathbf K^T$ 得到的是一个 $n\\times n$ 的矩阵（这里 $n$ 是输入的长度），其中位置 $(i, j)$ 表示 $\\mathbf q_i^T\\mathbf k_j$ 这个向量内积，这就是 token $i$ 和 token $j$ 的注意力分数。所以 $\\mathbf Q\\mathbf K^T$ 就是一个 token-to-token 的注意力分数矩阵。以 $\\mathbf q_0$ 为例，它和所有 token 的 $k_j$ 向量的注意力分数的计算可以用下图进行描述 接下来是在注意力矩阵上加 $\\texttt{softmax}$ 做归一化，确保注意力分数矩阵的每一行的注意力分数的和为 1 $$ \\texttt{softmax}(\\mathbf Q\\mathbf K^T)\\in\\mathcal R^{n\\times n} $$ 最后，将归一化后的注意力分数矩阵乘以 $\\mathbf V$ $$ \\texttt{softmax}(\\mathbf Q\\mathbf K^T)\\mathbf V\\in\\mathcal R^{n\\times d} $$ 这就是前面所说的加权和，比如我们考虑 token $0$，它和所有 token $j$ 的注意力分数是 $$ [\\mathbf q_0^T\\mathbf k_0, \\mathbf q_0^T\\mathbf k_1, \\mathbf q_0^T\\mathbf k_2, …, \\mathbf q_0^T\\mathbf k_j]=[a_{00}, a_{01}, …,a_{0j}] $$ 做加权和会得到 $$ \\sum_j(\\mathbf q_0^T\\mathbf k_j)\\mathbf v_j=\\sum_j a_{0j}\\mathbf v_j $$ 如下图所示 这就是 token $0$ 更新后的向量表示，其他的 token 同理 现在只剩下最后一个问题，为什么要除以一个 $\\sqrt{d}$？其实在原论文里就有答案 1：作者说在计算注意力的时候 $\\mathbf q_i^T\\mathbf k$ 的向量内积可能会很大，这样会导致被 $\\texttt{softmax}$ 之后落在“饱和区”，梯度会比较小，就不利于用 Gradient-descent|梯度下降 算法优化。所以用 $1/\\sqrt d$ 做一下 Scaling 这里的 $\\sqrt d$ 其实是 L2 范数，比如向量 $[1, 1]$ 长度为 2，L2 范数 就是 $\\sqrt 2$，那么长度为 $d$ 的向量的 L2 范数 就是 $\\sqrt d$ 了 ","date":"2025-03-02","objectID":"/zh-cn/an-explanation-of-self-attention/:2:0","series":null,"tags":["Deep-Learning","LLM"],"title":"如何理解 Transformer 的自注意力公式","uri":"/zh-cn/an-explanation-of-self-attention/#自注意力的理解"},{"categories":["ML-DL"],"content":" 自注意力实现上面讲述了自注意力的原理，下面就来手撕一下自注意力算法的代码，注意实现的时候会做一些优化，比如 $\\mathbf W^Q, \\mathbf W^K, \\mathbf W^V$ 没有必要用 3 个 nn.Linear，直接用 1 个 nn.Linear 然后做 split 就行 实现单向注意力只需要在计算出 $\\mathbf Q\\mathbf K^T$ 之后，将不需要做注意力运算（上三角部分）的位置赋值为 -float('inf')，那么在 $\\texttt{softmax}$ 之后这些位置的注意力自然就是 0 了 总结上面的说明，可以得到下面的代码（我添加了注释） python import math import torch import torch.nn as nn import torch.nn.functional as F class NaiveAttention(nn.Module): def __init__(self, n_embd: int, block_size: int): super().__init__() self.attn = nn.Linear(n_embd, 3 * n_embd) self.n_embd = n_embd self.register_buffer( \"bias\", torch.tril(torch.ones(block_size, block_size)).view( 1, block_size, block_size, ), ) def forward(self, x): B, T, C = x.size() # (batch_size, seq_len, n_embd) qkv = self.attn(x) # qkv: (batch_size, seq_len, 3 * n_embd) q, k, v = qkv.split(self.n_embd, dim=2) # split in n_embd dimension attn = (q @ k.transpose(1, 2)) * ( 1.0 / math.sqrt(k.size(-1)) ) # attn: (batch_size, seq_len, seq_len) attn = attn.masked_fill(self.bias[:, :T, :T] == 0, -float(\"inf\")) attn = F.softmax(attn, dim=-1) # print(f\"{attn=}\") out = attn @ v # (batch_size, seq_len, n_embd) return out 然后可以随便构造一个输入 python module = NaiveAttention(n_embd=4, block_size=5) sample_input = torch.randn(1, 5, 4) 查看一下注意力分数矩阵（即 attn 变量）和最后的输出（即 out 变量） python # attn matrix: [[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000], [0.3017, 0.6983, 0.0000, 0.0000, 0.0000], [0.3125, 0.2572, 0.4303, 0.0000, 0.0000], [0.2190, 0.3706, 0.2354, 0.1750, 0.0000], [0.1901, 0.2321, 0.1831, 0.1889, 0.2058]]] # output: [[[0.2348, 0.0224, 0.5836, 0.1414], [0.1057, 0.2104, 0.6170, 0.5556], [0.4593, 0.0303, 0.7982, 0.0422], [0.2862, 0.1033, 0.6313, 0.2689], [0.3003, 0.1009, 0.6536, 0.2153]]] ","date":"2025-03-02","objectID":"/zh-cn/an-explanation-of-self-attention/:3:0","series":null,"tags":["Deep-Learning","LLM"],"title":"如何理解 Transformer 的自注意力公式","uri":"/zh-cn/an-explanation-of-self-attention/#自注意力实现"},{"categories":["ML-DL"],"content":" 总结以上就是本文的所有内容，本文的目的是让你对 Transformer 的自注意力机制有一个基本的了解。当然这并不是现如今大模型用的自注意力版本。在此之上，还有多头注意力（MHA）、多头潜在注意力（MLA）等，这些打算放到后续的文章讲解 : ) ","date":"2025-03-02","objectID":"/zh-cn/an-explanation-of-self-attention/:4:0","series":null,"tags":["Deep-Learning","LLM"],"title":"如何理解 Transformer 的自注意力公式","uri":"/zh-cn/an-explanation-of-self-attention/#总结"},{"categories":["ML-DL"],"content":" Ref Vaswani, Ashish, et al. “Attention is all you need.” Advances in neural information processing systems 30 (2017). ↩︎ ↩︎ ↩︎ ","date":"2025-03-02","objectID":"/zh-cn/an-explanation-of-self-attention/:5:0","series":null,"tags":["Deep-Learning","LLM"],"title":"如何理解 Transformer 的自注意力公式","uri":"/zh-cn/an-explanation-of-self-attention/#ref"},{"categories":["Program-Analysis","compiler"],"content":"介绍了 Basic Block 和 Control Flow Graph，以及两者之间的关联","date":"2025-02-20","objectID":"/zh-cn/from-basic-block-to-control-flow-graph/","series":null,"tags":["Program-Analysis"],"title":"从 Basic Block 到 Control Flow Graph","uri":"/zh-cn/from-basic-block-to-control-flow-graph/"},{"categories":["Program-Analysis","compiler"],"content":" Info 注意：三地址码是 Basic Block（BB）的基础，而 Basic Block 是 Control Flow Graph（CFG） 的基础，因此在阅读本文之前，你最好了解一下三地址码，可以参考我写好的上一篇博客 ","date":"2025-02-20","objectID":"/zh-cn/from-basic-block-to-control-flow-graph/:0:0","series":null,"tags":["Program-Analysis"],"title":"从 Basic Block 到 Control Flow Graph","uri":"/zh-cn/from-basic-block-to-control-flow-graph/#"},{"categories":["Program-Analysis","compiler"],"content":" Basic Block (BB)","date":"2025-02-20","objectID":"/zh-cn/from-basic-block-to-control-flow-graph/:1:0","series":null,"tags":["Program-Analysis"],"title":"从 Basic Block 到 Control Flow Graph","uri":"/zh-cn/from-basic-block-to-control-flow-graph/#basic-block-bb"},{"categories":["Program-Analysis","compiler"],"content":" BB 是什么flowchart subgraph tac [Three-Address Code] subgraph bb1 [Basic Block 1] direction TB instruction1 instruction2 end subgraph bb2 [Basic Block 2] direction TB instruction3 instruction4 instruction5 end end 得到一段程序的三地址码表示之后，就可以将它转化为 Basic Block (BB) 列表，每个 Basic Block 都包含最长且连续的三地址码指令，如上所示。并且每个 Basic Block 满足如下的条件 只有一个入口，为 BB 的第一条三地址码指令 只有一个出口，为 BB 的最后一条三地址码指令 ","date":"2025-02-20","objectID":"/zh-cn/from-basic-block-to-control-flow-graph/:1:1","series":null,"tags":["Program-Analysis"],"title":"从 Basic Block 到 Control Flow Graph","uri":"/zh-cn/from-basic-block-to-control-flow-graph/#bb-是什么"},{"categories":["Program-Analysis","compiler"],"content":" 如何得到 BB输入：程序的所有三地址码指令 输出：Basic Block 列表 算法： 确定 Leader，这里 Leader 的意思是每一个 BB 的第一条指令 输入的第一条指令是 Leader 任何跳转指令（条件跳转/无条件跳转）的目标指令是 Leader 任何跳转指令（条件跳转/无条件跳转）的下一条指令是 Leader 根据 Leader 对输入进行分块，就得到了 BB 列表 可选：本来三地址码跳转指令的跳转目标都是指令，一般会将其改为 BB 的序号。能这么替换的原因是：BB 只有 1 个入口和 1 个出口 ","date":"2025-02-20","objectID":"/zh-cn/from-basic-block-to-control-flow-graph/:1:2","series":null,"tags":["Program-Analysis"],"title":"从 Basic Block 到 Control Flow Graph","uri":"/zh-cn/from-basic-block-to-control-flow-graph/#如何得到-bb"},{"categories":["Program-Analysis","compiler"],"content":" 以 LLVM IR 为例仍然沿用上一篇博客里面的例子，假设要分析的是下面这一段 C/C++ 代码（main.cpp） cpp int main() { int sum = 0; for (int i = 0; i \u003c 10; i++) { sum += i; } return 0; } 用 clang 导出 LLVM IR，命令如下 sh $ clang -S -emit-llvm main.cpp 这里我从导出的 LLVM IR 代码里面提取出所有的指令，并给每一条指令分配了格式为 （i) 的序号 llvm (1) %1 = alloca i32 (2) %2 = alloca i32 (3) %3 = alloca i32 (4) store i32 0, ptr %1 (5) store i32 0, ptr %2 (6) store i32 0, ptr %3 (7) br label (8) (8) %5 = load i32, ptr %3 (9) %6 = icmp slt i32 %5, 10 (10) br i1 %6, label (11), label (20) (11) %8 = load i32, ptr %3 (12) %9 = load i32, ptr %2 (13) %10 = add nsw i32 %9, %8 (14) store i32 %10, ptr %2 (15) br label (16) (16) %12 = load i32, ptr %3 (17) %13 = add nsw i32 %12, 1 (18) store i32 %13, ptr %3 (19) br label (8) (20) ret i32 0 根据前面的算法，这里要先找到 Leader 第一条指令是 Leader，即 (1) 任何跳转指令的目标是 Leader，即 (8), (11), (20), (16) 任何跳转指令的下一条指令是 Leader，即 (8), (11), (16), (20) 去重一下就得到了 (1), (8), (11), (16), (20)，那么上面的代码就可以划分为如下的 BB llvm (1) %1 = alloca i32 (2) %2 = alloca i32 (3) %3 = alloca i32 (4) store i32 0, ptr %1 (5) store i32 0, ptr %2 (6) store i32 0, ptr %3 (7) br label (8) (8) %5 = load i32, ptr %3 (9) %6 = icmp slt i32 %5, 10 (10) br i1 %6, label (11), label (20) (11) %8 = load i32, ptr %3 (12) %9 = load i32, ptr %2 (13) %10 = add nsw i32 %9, %8 (14) store i32 %10, ptr %2 (15) br label (16) (16) %12 = load i32, ptr %3 (17) %13 = add nsw i32 %12, 1 (18) store i32 %13, ptr %3 (19) br label (8) (20) ret i32 0 那么这样对不对呢？，从 clang 导出的原始 LLVM IR 可以看出，这是正确的 :) llvm define noundef i32 @main() #0 { 0: ; this line is added by me to make it more explicit %1 = alloca i32 %2 = alloca i32 ; %2 is sum %3 = alloca i32 ; %3 is i store i32 0, ptr %1 store i32 0, ptr %2 ; sum = 0 store i32 0, ptr %3 ; i = 0 br label %4 ; jump to %4 4: ; preds = %11, %0 %5 = load i32, ptr %3 ; load i %6 = icmp slt i32 %5, 10 ; %6 = check if i \u003c 10 br i1 %6, label %7, label %14 ; conditional jump based on if %6 is true 7: ; preds = %4 %8 = load i32, ptr %3 ; i %9 = load i32, ptr %2 ; sum %10 = add nsw i32 %9, %8 ; temp = sum + i store i32 %10, ptr %2 ; sum = temp br label %11 ; jump to %11 11: ; preds = %7 %12 = load i32, ptr %3 ; i %13 = add nsw i32 %12, 1 ; temp = i++ store i32 %13, ptr %3 ; i = temp br label %4 ; jump to %4 14: ; preds = %4 ret i32 0 ; return 0 } Tip 在 LLVM IR 里面，跳转指令的跳转目标 label 也可以是自动生成的数字（例子中的 %0, %4, %7, %11, %14），这个和我们前面提到的 (1), (8), (11), (16), (20) 是对应的 ","date":"2025-02-20","objectID":"/zh-cn/from-basic-block-to-control-flow-graph/:1:3","series":null,"tags":["Program-Analysis"],"title":"从 Basic Block 到 Control Flow Graph","uri":"/zh-cn/from-basic-block-to-control-flow-graph/#以-llvm-ir-为例"},{"categories":["Program-Analysis","compiler"],"content":" Control Flow Graph (CFG)","date":"2025-02-20","objectID":"/zh-cn/from-basic-block-to-control-flow-graph/:2:0","series":null,"tags":["Program-Analysis"],"title":"从 Basic Block 到 Control Flow Graph","uri":"/zh-cn/from-basic-block-to-control-flow-graph/#control-flow-graph-cfg"},{"categories":["Program-Analysis","compiler"],"content":" CFG 是什么CFG 是一种图结构的 IR，是很多静态程序分析的基础，它的构成是 节点：一般是 BB。但有时候则是三地址码的一条指令1 边：箭头的方向表示控制的转移，或者说代码可能沿着这条边继续执行 如果用图来表示，那么就是 flowchart TB subgraph CFG [Control Flow Graph] bb1(Basic Block 1) bb2(Basic Block 2) bb3(Basic Block 3) bb4(Basic Block 4) bb1 --\u003e bb2 \u0026 bb3 bb2 \u0026 bb3 --\u003e bb4 end ","date":"2025-02-20","objectID":"/zh-cn/from-basic-block-to-control-flow-graph/:2:1","series":null,"tags":["Program-Analysis"],"title":"从 Basic Block 到 Control Flow Graph","uri":"/zh-cn/from-basic-block-to-control-flow-graph/#cfg-是什么"},{"categories":["Program-Analysis","compiler"],"content":" 如何得到 CFG输入：BB 列表，用 $B_i$ 表示第 $i$ 个 BB。注意 BB 代表的三地址码指令连起来跟本来程序的三地址码指令连起来有一样的顺序 输出：CFG 算法： 如果 $B_i$ 经由跳转指令（条件跳转/无条件跳转）到 $B_j$，则创建 $B_i\\rightarrow B_j$ 这条边 如果 $B_j$ 本来就在 $B_i$ 后面而且 $B_i$ 的最后一条指令不是无条件跳转指令，那么也会创建 $B_i\\rightarrow B_j$ 这条边 ","date":"2025-02-20","objectID":"/zh-cn/from-basic-block-to-control-flow-graph/:2:2","series":null,"tags":["Program-Analysis"],"title":"从 Basic Block 到 Control Flow Graph","uri":"/zh-cn/from-basic-block-to-control-flow-graph/#如何得到-cfg"},{"categories":["Program-Analysis","compiler"],"content":" 以 LLVM IR 为例 llvm 0: ; this line is added by me to make it more explicit %1 = alloca i32 %2 = alloca i32 ; %2 is sum %3 = alloca i32 ; %3 is i store i32 0, ptr %1 store i32 0, ptr %2 ; sum = 0 store i32 0, ptr %3 ; i = 0 br label %4 ; jump to %4 4: ; preds = %11, %0 %5 = load i32, ptr %3 ; load i %6 = icmp slt i32 %5, 10 ; %6 = check if i \u003c 10 br i1 %6, label %7, label %14 ; conditional jump based on if %6 is true 7: ; preds = %4 %8 = load i32, ptr %3 ; i %9 = load i32, ptr %2 ; sum %10 = add nsw i32 %9, %8 ; temp = sum + i store i32 %10, ptr %2 ; sum = temp br label %11 ; jump to %11 11: ; preds = %7 %12 = load i32, ptr %3 ; i %13 = add nsw i32 %12, 1 ; temp = i++ store i32 %13, ptr %3 ; i = temp br label %4 ; jump to %4 14: ; preds = %4 ret i32 0 ; return 0 继续沿用前面的 LLVM IR 的例子，在前面的例子中，我们已经得到了所有的 BB 列表，接下来要解决的就是如何加边然后构造 CFG。按照算法流程： 检查所有的跳转指令 %0 跳转到 %4，因此有 %0 -\u003e %4 %4 可能跳转到 %7, %14，因此有 %4 -\u003e %7 和 %4 -\u003e %14 %7 跳转到 %11，因此有 %7 -\u003e %11 %11 跳转到 %4，因此有 %11 -\u003e %4 检查条件跳转指令 %4 的最后一条是条件跳转指令，%7 跟在 %4 后面，因此有 %4 -\u003e %7 如何检验上面推导的关系对不对呢？其实在上面的 LLVM IR 里面已经给出了答案 llvm 0: ; this line is added by me to make it more explicit ... ; omit 4: ; preds = %11, %0 ... ; omit 7: ; preds = %4 ... ; omit 11: ; preds = %7 ... ; omit 14: ; preds = %4 ... ; omit 在代码的注释里面，它说 %4 的前驱（predecessor）是 %11 和 %0，这和我们的推导是一致的，剩下的也都符合 最后，我们可以用 clang 和 opt 导出 CFG 感受一下 sh $ clang -Xclang -disable-O0-optnone -S -emit-llvm main.cpp -o main.ll $ opt -passes='dot-cfg' main.ll $ dot -Tpdf .main.dot -o result.pdf ","date":"2025-02-20","objectID":"/zh-cn/from-basic-block-to-control-flow-graph/:2:3","series":null,"tags":["Program-Analysis"],"title":"从 Basic Block 到 Control Flow Graph","uri":"/zh-cn/from-basic-block-to-control-flow-graph/#以-llvm-ir-为例-1"},{"categories":["Program-Analysis","compiler"],"content":" 总结以上就是本文的全部内容，通过同一个例子，从三地址码到 Basic Block，再到 CFG，这一条线算是串起来了。而有了 CFG 之后，后面要做数据流分析等程序分析就比较容易了~ ","date":"2025-02-20","objectID":"/zh-cn/from-basic-block-to-control-flow-graph/:3:0","series":null,"tags":["Program-Analysis"],"title":"从 Basic Block 到 Control Flow Graph","uri":"/zh-cn/from-basic-block-to-control-flow-graph/#总结"},{"categories":["Program-Analysis","compiler"],"content":" Ref 南京大学.软件分析2020.02.Intermediate Representation ↩︎ ","date":"2025-02-20","objectID":"/zh-cn/from-basic-block-to-control-flow-graph/:4:0","series":null,"tags":["Program-Analysis"],"title":"从 Basic Block 到 Control Flow Graph","uri":"/zh-cn/from-basic-block-to-control-flow-graph/#ref"},{"categories":["Program-Analysis"],"content":"介绍程序的中间表示的一种：三地址码","date":"2025-02-18","objectID":"/zh-cn/three-address-code/","series":null,"tags":["Program-Analysis","Compiler"],"title":"三地址码(3AC/TAC)是什么","uri":"/zh-cn/three-address-code/"},{"categories":["Program-Analysis"],"content":" 信息 进一步阅读 从 Basic Block 到 Control Flow graph ","date":"2025-02-18","objectID":"/zh-cn/three-address-code/:0:0","series":null,"tags":["Program-Analysis","Compiler"],"title":"三地址码(3AC/TAC)是什么","uri":"/zh-cn/three-address-code/#"},{"categories":["Program-Analysis"],"content":" 什么是三地址码三地址码（Three-Address Code，也简记为 3AC/TAC）是一种程序的中间表示（Intermediate Representation，IR），通常用在编译器、程序分析当中。顾名思义，三地址码的每一条指令最多只有三个“地址”，这里的“地址”包括变量、常量。常见的形式包括下面几种 1 c // assignment with binary operator(bop) x = y bop z // assignment with binary operator(uop) x = uop y // copy x = y // unconditional jump goto label // conditional jump 1 if x goto L // conditional jump 2 // rop = relation operator // e.g. \u003e, \u003c, \u003e=, … if x rop y goto L // procedure call call p // return return val ","date":"2025-02-18","objectID":"/zh-cn/three-address-code/:1:0","series":null,"tags":["Program-Analysis","Compiler"],"title":"三地址码(3AC/TAC)是什么","uri":"/zh-cn/three-address-code/#什么是三地址码"},{"categories":["Program-Analysis"],"content":" 三地址码实现（四元组）根据三地址码的特点，可以用一个四元组存储三地址码的指令：(destination, operator, operand1, operand2)，那么代码就可以表示为一个四元组数组，或者是四元组链表2 四元组链表的好处是不用提前计算要开辟多大的空间存储三地址码。如果是四元组数组的话，一开始数组开辟过大会导致内存浪费，开辟得太小又会引入额外的性能开销 2 ","date":"2025-02-18","objectID":"/zh-cn/three-address-code/:2:0","series":null,"tags":["Program-Analysis","Compiler"],"title":"三地址码(3AC/TAC)是什么","uri":"/zh-cn/three-address-code/#三地址码实现四元组"},{"categories":["Program-Analysis"],"content":" Practical Example. LLVM IR前面本文提到的三地址码的常见形式是抽象的表示，具体实现的时候写法上会有所差异。以 LLVM IR 为例，它就是典型的三地址码，比如对于下面这一段 C/C++ 程序（main.cpp） c++ int main() { int sum = 0; for (int i = 0; i \u003c 10; i++) { sum += i; } return 0; } 用 clang 导出 LLVM IR，命令如下 sh $ clang -S -emit-llvm main.cpp 在同目录下可以看到 main.ll 文件。我删去了部分代码并加上了注释来帮助你理解，内容如下 llvm define noundef i32 @main() #0 { %1 = alloca i32 %2 = alloca i32 ; %2 is sum %3 = alloca i32 ; %3 is i store i32 0, ptr %1 store i32 0, ptr %2 ; sum = 0 store i32 0, ptr %3 ; i = 0 br label %4 ; jump to %4 4: ; preds = %11, %0 %5 = load i32, ptr %3 ; load i %6 = icmp slt i32 %5, 10 ; %6 = check if i \u003c 10 br i1 %6, label %7, label %14 ; conditional jump based on if %6 is true 7: ; preds = %4 %8 = load i32, ptr %3 ; i %9 = load i32, ptr %2 ; sum %10 = add nsw i32 %9, %8 ; temp = sum + i store i32 %10, ptr %2 ; sum = temp br label %11 ; jump to %11 11: ; preds = %7 %12 = load i32, ptr %3 ; i %13 = add nsw i32 %12, 1 ; temp = i++ store i32 %13, ptr %3 ; i = temp br label %4 ; jump to %4 14: ; preds = %4 ret i32 0 ; return 0 } ","date":"2025-02-18","objectID":"/zh-cn/three-address-code/:3:0","series":null,"tags":["Program-Analysis","Compiler"],"title":"三地址码(3AC/TAC)是什么","uri":"/zh-cn/three-address-code/#practical-example-llvm-ir"},{"categories":["Program-Analysis"],"content":" 总结三地址码很好理解，作为程序 IR 的一种，它是很多程序分析工具的基础 1（比如我最近正在看的 ArkAnalyzer3）。三地址码和 AST 相比，它的优势是：更加紧凑，并且带有控制流的信息（你能够通过阅读代码知道程序的运行逻辑），而且通常是编程语言无关的。这个给后续的程序分析和处理带来了很大的方便 ","date":"2025-02-18","objectID":"/zh-cn/three-address-code/:4:0","series":null,"tags":["Program-Analysis","Compiler"],"title":"三地址码(3AC/TAC)是什么","uri":"/zh-cn/three-address-code/#总结"},{"categories":["Program-Analysis"],"content":" Refs 南京大学.软件分析2020.02.Intermediate Representation ↩︎ ↩︎ Engineering a Compiler 5.3.3 Representing Linear Codes ↩︎ ↩︎ Chen, Haonan, et al. “ArkAnalyzer: The Static Analysis Framework for OpenHarmony.” arXiv preprint arXiv:2501.05798 (2025). ↩︎ ","date":"2025-02-18","objectID":"/zh-cn/three-address-code/:5:0","series":null,"tags":["Program-Analysis","Compiler"],"title":"三地址码(3AC/TAC)是什么","uri":"/zh-cn/three-address-code/#refs"},{"categories":["ML-DL"],"content":" Motivation当前的 RAG 技术无法回答关于语料库的全局性问题，比如“这个数据集的主题是什么”。这一类问题不是可以通过检索增强技术解决的，因为答案一般不在某一段文本里面，正确答案需要理解整个语料库并给出抽象的总结，作者称这类问题为 query-focused summarization (QFS) 问题1。普通的 RAG 技术无法很好处理这个问题。 将整个语料库的文本放在上下文窗口里面又不大现实，就算能放得下，面对超长输入，LLM 经常会忘掉中间的信息 本文提出的 GraphRAG1 就是要解决这些问题 ","date":"2025-02-11","objectID":"/zh-cn/the-flow-of-graphrag/:1:0","series":null,"tags":["Paper","LLM"],"title":"GraphRAG 工作流","uri":"/zh-cn/the-flow-of-graphrag/#motivation"},{"categories":["ML-DL"],"content":" GraphRAG Tip 要理解 GraphRAG 最好要有知识图谱的背景，比如对社区、社区检测算法要有一定的了解。另外要对图这种数据结构有比较清楚的了解 ","date":"2025-02-11","objectID":"/zh-cn/the-flow-of-graphrag/:2:0","series":null,"tags":["Paper","LLM"],"title":"GraphRAG 工作流","uri":"/zh-cn/the-flow-of-graphrag/#graphrag"},{"categories":["ML-DL"],"content":" Document -\u003e TextChunkflowchart LR Document --\u003e TextChunk1 \u0026 TextChunk2 \u0026 ... 将文档划分为多个 Text Chunk（彼此之间可以有重叠） ","date":"2025-02-11","objectID":"/zh-cn/the-flow-of-graphrag/:2:1","series":null,"tags":["Paper","LLM"],"title":"GraphRAG 工作流","uri":"/zh-cn/the-flow-of-graphrag/#document---textchunk"},{"categories":["ML-DL"],"content":" TextChunk -\u003e Entity \u0026 Relationship \u0026 Claimflowchart LR TextChunk --\u003e Entity \u0026 Relationship \u0026 Claim 每一个 Text Chunk 会被 LLM 用来提取知识图谱里的 实体，包括 名字、类型、描述 关系，包括 起点、描述、终点 断言（Claim） Tip 同一个实体在不同的 LLM 回复中：可以采用投票法，看得票最多的 类型 是什么 同一个实体可能会有多个描述，这些描述的长度加起来可能超过 LLM 的上下文长度窗口：可以用 LLM 对这些描述生成摘要。同个关系的多个描述也同理 提取的原理就是写 Prompt 给大模型，这里的 Prompt 会用 Few-shot learning 和 In-Context learning 的技术作增强，可以想象，这里的 Prompt 很关键 除了精心编写 Prompt 以外，作者1还提出可以多次执行提取的步骤，这是为了鼓励 LLM 发现上一轮遗漏的实体。怎么鼓励呢？可以尝试告诉 LLM 说上一轮遗漏掉了非常多的实体 Tip 注意，Text Chunk 设置得越大，LLM 调用的次数就越少，速度越快。但作者1发现提取的实体量、关系的数量会变少，因此这里需要做好权衡，可以参考论文里的 Figure 2 ","date":"2025-02-11","objectID":"/zh-cn/the-flow-of-graphrag/:2:2","series":null,"tags":["Paper","LLM"],"title":"GraphRAG 工作流","uri":"/zh-cn/the-flow-of-graphrag/#textchunk---entity--relationship--claim"},{"categories":["ML-DL"],"content":" Graph Communities Detectionflowchart LR Document(Document in the form of entity, relationships, and claims) subgraph community_tree root(Community1) root2(Community2) root3(Community3) root --\u003e root2 \u0026 root3 root --\u003e dots(...) root2 --\u003e dots1(...) root3 --\u003e dots2(...) dots --\u003e dots3(...) end Document --\u003e community_tree 在上一个阶段后，其实我们已经为每个文档搭建了一个知识图谱，接下来就可以在这个知识图谱上用 Leiden 社区检测算法，该算法会返回知识图谱里面的社区（Graph Communities），注意这些社区是树状的（下称社区树），结构是有层次的 ","date":"2025-02-11","objectID":"/zh-cn/the-flow-of-graphrag/:2:3","series":null,"tags":["Paper","LLM"],"title":"GraphRAG 工作流","uri":"/zh-cn/the-flow-of-graphrag/#graph-communities-detection"},{"categories":["ML-DL"],"content":" Graph Communities -\u003e Community Summariesflowchart LR Community --\u003e CommuniySummary 这一步需要用 LLM 得到每个社区的总结，针对不同类型的社区有不同的策略 叶子社区 将所有的关系按照 起点 和 终点 的度数和降序排列，🤔 也许是度数和越高越重要 按顺序处理，对于每条关系，依次添加如下的文本到上下文窗口里直到上下文窗口放不下 起点 对应的 描述 终点 对应的 描述 任何跟这条关系有关联的断言 这条关系的 描述 非叶子社区，即下面都是子社区 假装子社区不存在：按照上面的方法处理，但前提是不超过 LLM 的上下文窗口长度 否则，对子社区进行排序，按照它包含的实体、关系的描述文本的总长度降序排列（🤔 文本越多信息越丰富越要保留）。然后依次将社区总结（短）替换为叶子社区那样拼接的描述（长），目的显然是要保留更细粒度的信息（社区 -\u003e 社区包含的实体、关系） Tip 所以，社区总结的处理方式是在社区树上用 Bottom-Up 的方式得到的 ","date":"2025-02-11","objectID":"/zh-cn/the-flow-of-graphrag/:2:4","series":null,"tags":["Paper","LLM"],"title":"GraphRAG 工作流","uri":"/zh-cn/the-flow-of-graphrag/#graph-communities---community-summaries"},{"categories":["ML-DL"],"content":" Community Summaries -\u003e Community Answers -\u003e Global Answerflowchart LR a(Random shuffled community summaries) a --\u003e Chunk1 \u0026 Chunk2 \u0026 annoy(...) Chunk1 --\u003e p(Intermediate Answer1) Chunk2 --\u003e q(Intermediate Answer2) annoy --\u003e r(...) window(Context Window) p \u0026 q \u0026 r --\u003e window window --\u003e ans(Global Answer) 现在，每一个社区都有自己的社区总结，可以用这些社区总结来回答用户的问题，具体步骤如下 将所有的社区总结打乱，然后划分为一个个 Chunk。这种方式确保了相关的信息分布在不同的 Chunk Map 阶段：用每一个 Chunk 让 LLM 生成临时回复，并让 LLM 给出临时回复的得分（0～100），得分衡量了这个生成的临时回复对用户问题的帮助程度 Reduce 阶段：将临时回复按照得分降序排列然后一一拼接起来，直到上下文窗口长度放不下，然后再让 LLM 生成最终回复 ","date":"2025-02-11","objectID":"/zh-cn/the-flow-of-graphrag/:2:5","series":null,"tags":["Paper","LLM"],"title":"GraphRAG 工作流","uri":"/zh-cn/the-flow-of-graphrag/#community-summaries---community-answers---global-answer"},{"categories":["ML-DL"],"content":" 总结上面就是 GraphRAG 的全部内容，整体流程还算是蛮清晰的，官方也提供了实现，但折腾了一会发现只支持 OpenAI 的 LLM，并且很难做定制化。在一番搜索之后，我找到了 nano-graphrag，阅读了源码并用一段文本试用了一下，生成的知识图谱还挺对的 :) Edge, Darren, et al. “From local to global: A graph rag approach to query-focused summarization.” arXiv preprint arXiv:2404.16130 (2024). ↩︎ ↩︎ ↩︎ ↩︎ ","date":"2025-02-11","objectID":"/zh-cn/the-flow-of-graphrag/:3:0","series":null,"tags":["Paper","LLM"],"title":"GraphRAG 工作流","uri":"/zh-cn/the-flow-of-graphrag/#总结"},{"categories":["ML-DL"],"content":"MoE 论文的阅读笔记","date":"2025-02-02","objectID":"/zh-cn/reading-notes-mixture-of-experts/","series":null,"tags":["Paper","Deep-Learning"],"title":"论文阅读: Outrageously Large Neural Networks-The Sparsely-Gated Mixture-of-Experts Layer","uri":"/zh-cn/reading-notes-mixture-of-experts/"},{"categories":["ML-DL"],"content":" Motivations模型能力跟模型参数量有关系，模型参数量越多，数据越多，效果就越好。但训练成本也成倍上升。为了解决这个问题，大家提出了很多种条件计算（Conditional Computations）的方案，顾名思义，某些条件满足的情况下才会计算，这样就可以不增加训练成本的同时增加模型参数量，提升模型效果 作者提出了 Sparsely-Gated Mixture-of-Experts Layer (MoE) 架构，如下所示1 ","date":"2025-02-02","objectID":"/zh-cn/reading-notes-mixture-of-experts/:1:0","series":null,"tags":["Paper","Deep-Learning"],"title":"论文阅读: Outrageously Large Neural Networks-The Sparsely-Gated Mixture-of-Experts Layer","uri":"/zh-cn/reading-notes-mixture-of-experts/#motivations"},{"categories":["ML-DL"],"content":" MoE 架构MoE 层包含 $n$ 个专家（Expert） $E_1, E_2, …, E_n$，以及一个门控网络 $G$，门控网络 $G$ 的输出是一个长度为 $n$ 的向量 用 $x$ 表示输入，$G(x)$ 表示门控网络的输出，$E_i(x)$ 表示专家 $E_i$ 的输出，那么 MoE 的输出 $y$ 可以表示为 $$ y=\\sum_{i=1}^nG(x)_iE_i(x) $$ 注意这里的 $G(x)_i$ 的下角标 $i$ 表示 $G(x)$ 的第 $i$ 个位置。所以上面的式子告诉我们 MoE 的输出就是对 $n$ 个专家的输出的加权和 可想而知，如果 $G(x)_i =0$，那么对应的 $E_i(x)$ 就没有必要计算，训练成本就这么降低了。如果 $G(x)$ 的很多位置都 $=0$，即门控网络 $G$ 的输出是稀疏的，那么训练成本可以减少非常多 Tip 上面是单层 MoE 架构，不难想象可以创建分层 MoE ","date":"2025-02-02","objectID":"/zh-cn/reading-notes-mixture-of-experts/:2:0","series":null,"tags":["Paper","Deep-Learning"],"title":"论文阅读: Outrageously Large Neural Networks-The Sparsely-Gated Mixture-of-Experts Layer","uri":"/zh-cn/reading-notes-mixture-of-experts/#moe-架构"},{"categories":["ML-DL"],"content":" Expert所谓的专家就是神经网络，论文里面用的是简单的 FFN 层 ","date":"2025-02-02","objectID":"/zh-cn/reading-notes-mixture-of-experts/:2:1","series":null,"tags":["Paper","Deep-Learning"],"title":"论文阅读: Outrageously Large Neural Networks-The Sparsely-Gated Mixture-of-Experts Layer","uri":"/zh-cn/reading-notes-mixture-of-experts/#expert"},{"categories":["ML-DL"],"content":" Gating Network Tip 前面提到，为了能够尽可能降低训练成本，门控网络 $G$ 的输出应该是稀疏的 一个简单的 idea 是将输入 $x$ 乘以一个权重矩阵 $W_g$，然后用 $\\texttt{Softmax}$ 函数（注意 $\\texttt{Softmax}$ 的输出和为 1） $$ \\texttt{Softmax}(x\\cdot W_g) $$ 注意，它不是稀疏的。所以作者用了如下的手段让它是稀疏的 得到 $x\\cdot W_g$ 之后叠加一个可以调节的高斯噪声 保留其中值最大的 TopK 个，剩下的设置为 $-\\infty$（注意 $-\\infty$ 在经过 $\\texttt{Softmax}$ 就得到了 0） 最后再用 $\\texttt{softmax}$ 这里解释一下什么叫做可以调节的高斯噪声，作者将 Softplus 函数乘以高斯噪声，同时控制 Softplus 的输入为 $x\\cdot W_{noise}$，这里的权重矩阵 $W_{noise}$ 也起到了调节的作用。这样每一个不同的 MoE 层的噪声可以单独控制 将上面的文字表述翻译为公式就是 $$ \\begin{split} G(x)\u0026=\\texttt{Softmax}(KeepTopK(H(x), k)) \\\\\\ H(x)_i\u0026=(x\\cdot W_g)_i + \\texttt{StandardNormal}()\\cdot\\texttt{Softplus}\\big((x\\cdot W_{noise})_i\\big) \\\\\\ KeepTopK(v,k)_i\u0026= \\begin{cases} v_i \u0026 \\texttt{if }v_i\\texttt{ is in the top }k\\texttt{ elements of } v\\\\\\ -\\infty \u0026 \\texttt{otherwise} \\end{cases} \\end{split} $$ ","date":"2025-02-02","objectID":"/zh-cn/reading-notes-mixture-of-experts/:2:2","series":null,"tags":["Paper","Deep-Learning"],"title":"论文阅读: Outrageously Large Neural Networks-The Sparsely-Gated Mixture-of-Experts Layer","uri":"/zh-cn/reading-notes-mixture-of-experts/#gating-network"},{"categories":["ML-DL"],"content":" MoE 优化","date":"2025-02-02","objectID":"/zh-cn/reading-notes-mixture-of-experts/:3:0","series":null,"tags":["Paper","Deep-Learning"],"title":"论文阅读: Outrageously Large Neural Networks-The Sparsely-Gated Mixture-of-Experts Layer","uri":"/zh-cn/reading-notes-mixture-of-experts/#moe-优化"},{"categories":["ML-DL"],"content":" Batch sizeBatch Size 开大一点效率才会高，采用 MoE 架构之后，假设 Batch Size 是 $b$，每一次都会从 $n$ 个专家中选择 $k$ 个激活，那么对于每一个专家来说，等价的 Batch Size 是 $$ \\frac{kb}{n} $$ 可想而知，大 Batch Size 就应该调大 $b$，但要是显存放不下呢？针对这个问题，作者提出了如下的建议——采用数据并行，但每个专家只有 1 份，在多个设备上共享，其他层（包括门控网络）都是每个设备 1 份。注意，每个专家都只会收到跟自己有关的样本来进行计算和更新，假设有 $d$ 个设备，每个设备处理 $b$ 个样本，那么这样优化之后每个专家等价的 Batch Size 是 $$ \\frac{kbd}{n} $$ 这意味着，可以通过增加设备来调大 Batch Size ","date":"2025-02-02","objectID":"/zh-cn/reading-notes-mixture-of-experts/:3:1","series":null,"tags":["Paper","Deep-Learning"],"title":"论文阅读: Outrageously Large Neural Networks-The Sparsely-Gated Mixture-of-Experts Layer","uri":"/zh-cn/reading-notes-mixture-of-experts/#batch-size"},{"categories":["ML-DL"],"content":" 充分利用所有专家作者在实验中发现，MoE 架构的门控网络 $G$ 几乎总是会选择少数几个专家，而且随着训练的进行这个情况会不断恶化，因为被更新的专家越有概率被选中 为了缓和这个问题，作者增加了一个约束——定义专家的重要性 $Importance$。现在假设有 1 个 Batch 的数据（用 $X$ 表示）进来，对于专家 $E_i$，它的重要性 = $\\sum_{x\\in X} G(x)_i$，因此所有专家的重要性 $Importance(X)$ 可以表示为 $$ Importance(X)=\\sum_{x\\in X}G(x) $$ 注意 $Importance(X)$ 是一个长度为 $n$ 的向量，每个位置是对应专家的重要性得分。根据 $Importance(X)$ 可以定义一个额外的损失 $$ L_{importance}(X)=w_{importance}\\cdot\\texttt{CV}(Importance(X))^2 $$ 这个损失会被加到总的损失里。其中 $w_{importance}$ 是超参数，$\\texttt{CV}$ 表示变异系数（Coefficient of Variation），衡量了离散程度。不同专家彼此的得分越不相同，离散程度越大，损失则越大。因此，增加这个损失函数鼓励不同专家有一样的重要性 ","date":"2025-02-02","objectID":"/zh-cn/reading-notes-mixture-of-experts/:3:2","series":null,"tags":["Paper","Deep-Learning"],"title":"论文阅读: Outrageously Large Neural Networks-The Sparsely-Gated Mixture-of-Experts Layer","uri":"/zh-cn/reading-notes-mixture-of-experts/#充分利用所有专家"},{"categories":["ML-DL"],"content":" 实验结果 上面的图1说明了下面几个结论 不管是单层 MoE 还是多层 MoE，都比 Baseline 好 多层 MoE 效果比单层 MoE 稍微好些 相同训练成本下（纵轴），采用 MoE 架构的模型表现更好 ","date":"2025-02-02","objectID":"/zh-cn/reading-notes-mixture-of-experts/:4:0","series":null,"tags":["Paper","Deep-Learning"],"title":"论文阅读: Outrageously Large Neural Networks-The Sparsely-Gated Mixture-of-Experts Layer","uri":"/zh-cn/reading-notes-mixture-of-experts/#实验结果"},{"categories":["ML-DL"],"content":" 总结可以看到，MoE 架构允许我们在增加模型参数量的同时，训练成本不会成比例上升。并且在模型推理的时候，每次只有 K 个专家在处理，因此推理也更快了。不过，整个模型还是要都加载到显存里面，不能只加载几个专家🤔 ","date":"2025-02-02","objectID":"/zh-cn/reading-notes-mixture-of-experts/:5:0","series":null,"tags":["Paper","Deep-Learning"],"title":"论文阅读: Outrageously Large Neural Networks-The Sparsely-Gated Mixture-of-Experts Layer","uri":"/zh-cn/reading-notes-mixture-of-experts/#总结"},{"categories":["ML-DL"],"content":" Refs Shazeer, Noam, et al. “Outrageously large neural networks: The sparsely-gated mixture-of-experts layer.” arXiv preprint arXiv:1701.06538 (2017). ↩︎ ↩︎ ","date":"2025-02-02","objectID":"/zh-cn/reading-notes-mixture-of-experts/:6:0","series":null,"tags":["Paper","Deep-Learning"],"title":"论文阅读: Outrageously Large Neural Networks-The Sparsely-Gated Mixture-of-Experts Layer","uri":"/zh-cn/reading-notes-mixture-of-experts/#refs"},{"categories":["Programming-Languages"],"content":"对 Python 装饰器的介绍，从基本原理到常见装饰器","date":"2025-01-20","objectID":"/zh-cn/understanding-python-decorator/","series":null,"tags":["Python"],"title":"什么是 Python 装饰器","uri":"/zh-cn/understanding-python-decorator/"},{"categories":["Programming-Languages"],"content":" 引言如果你能够认识到函数是一等公民（First-class）的话，那么你理解 Python 装饰器应该没有什么困难。函数是一等公民（First-class）就意味着：函数也是值，和其他基本类型（int, str, float, etc）等一样，都可以作为函数的入参和返回值 如果一个函数的入参是某函数，或者返回值是某函数，这样的函数也叫做高阶函数，装饰器就是这样子的 在我看来，装饰器的好处是不需要修改原有的函数的情况下修改函数的功能，这也合理，毕竟它叫做装饰器 ","date":"2025-01-20","objectID":"/zh-cn/understanding-python-decorator/:1:0","series":null,"tags":["Python"],"title":"什么是 Python 装饰器","uri":"/zh-cn/understanding-python-decorator/#引言"},{"categories":["Programming-Languages"],"content":" 装饰器其实只是语法糖在详细了解 Python 装饰器之前，我想告诉你的是：Python 装饰器其实是语法糖，比如下面这段代码 python @some_decorator def foobar(): ... 其实等价于下面这段代码 python def foobar(): ... foobar = some_decorator(foobar) 如果有多个装饰器，也是一样的道理，越靠近被装饰的函数的装饰器越早起作用 python @foo @bar def hello(): ... # ------------------ def hello(): ... hello = foo(bar(hello)) ","date":"2025-01-20","objectID":"/zh-cn/understanding-python-decorator/:2:0","series":null,"tags":["Python"],"title":"什么是 Python 装饰器","uri":"/zh-cn/understanding-python-decorator/#装饰器其实只是语法糖"},{"categories":["Programming-Languages"],"content":" 再谈装饰器前面提到，装饰器不过就是输入为函数，输出也为函数的高阶函数，拆解一下 输入为函数：函数是装饰器的入参 输出为函数：装饰器返回的是函数 注意，一个函数可能有参数也可能没有参数，可能有 positional argument 还可能有 keyword argument。因此，为了能够表示各种可能性，可以用 *args, **kwargs表示。因此，经过整理，我们就能够推导出装饰器该怎么写了 python def some_decorator(func): def inner(*args, **kwargs): # do something before the function call func(*args, **kwargs) # do something after the function call return inner 让我们考虑一个更复杂的情况，如果装饰器本身有参数呢？我们可以语法糖的角度反推一下 python @some_decorator(k1=v1, k2=v2) def foobar(): ... 等价于 python def foobar(): ... some_decorator(k1=v1, k2=v2)(foobar) 在前面的装饰器模板中，some_decorator 的入参是被装饰的函数 func，即 some_decorator(func)，但现在变成了 some_decorator(k1=v1, k2=v2)，所以我们知道：some_decorator(k1=v1, k2=v2)应该返回一个函数。那就是多嵌套一个函数，如下所示 python def some_decorator(k1, k2): def wrapper(func): def inner(*args, **kwargs): # do something before the function call func(*args, **kwargs) # do something after the function call return inner return wrapper ","date":"2025-01-20","objectID":"/zh-cn/understanding-python-decorator/:3:0","series":null,"tags":["Python"],"title":"什么是 Python 装饰器","uri":"/zh-cn/understanding-python-decorator/#再谈装饰器"},{"categories":["Programming-Languages"],"content":" 常用装饰器","date":"2025-01-20","objectID":"/zh-cn/understanding-python-decorator/:4:0","series":null,"tags":["Python"],"title":"什么是 Python 装饰器","uri":"/zh-cn/understanding-python-decorator/#常用装饰器"},{"categories":["Programming-Languages"],"content":" @property面向对象编程里面会对属性（或称成员字段）进行封装，外界只能通过 getter/setter 进行访问。@property 正如它的名字一样，可以方便地访问/删除/修改属性，就好像这个属性不是私有属性，并且可以直接访问一样。比如 python class Name: def __init__(self, x: str | None = None): self.__first_name = x @property def first_name(self): return self.__first_name @first_name.setter def first_name(self, value: str): self.__first_name = value @first_name.deleter def first_name(self, value: str): del self.__first_name me = Name() print(me.first_name) # without parenthesis me.first_name = \"Martin\" print(me.first_name) ","date":"2025-01-20","objectID":"/zh-cn/understanding-python-decorator/:4:1","series":null,"tags":["Python"],"title":"什么是 Python 装饰器","uri":"/zh-cn/understanding-python-decorator/#property"},{"categories":["Programming-Languages"],"content":" @functools.wraps普通的装饰器存在一个缺陷，被装饰函数的名字会被修改，以前面的 some_decorator 这个装饰器为例 python @some_decorator def hello(): print(\"hello\") print(hello.__name__) # inner 可以看到，被装饰的函数 hello 的名字变成了 inner（some_decorator 里面的函数），这在 Debug 的时候不大友好，因此，可以用 @functools.wraps python import functools def some_decorator(func): @functools.wraps(func) # \u003c------------ def inner(*args, **kwargs): # do something before the function call print(\"Before\") func(*args, **kwargs) print(\"After\") # do something after the function call return inner @some_decorator def hello(): print(\"hello\") print(hello.__name__) # hello 可以看到，函数 hello 的名字被保留了 ","date":"2025-01-20","objectID":"/zh-cn/understanding-python-decorator/:4:2","series":null,"tags":["Python"],"title":"什么是 Python 装饰器","uri":"/zh-cn/understanding-python-decorator/#functoolswraps"},{"categories":["Programming-Languages"],"content":" @cache在写算法题的时候，如果我们想要缓存一个函数的计算结果，就可以用 @cache。可以理解为它帮我们维护了一个字典，字典的 Key 是函数入参，字典的 Value 是函数的返回值 python from functools import cache @cache def fib(n: int) -\u003e int: if n == 0: return 0 elif n == 1 or n == 2: return 1 else: return fib(n - 1) + fib(n - 2) ","date":"2025-01-20","objectID":"/zh-cn/understanding-python-decorator/:4:3","series":null,"tags":["Python"],"title":"什么是 Python 装饰器","uri":"/zh-cn/understanding-python-decorator/#cache"},{"categories":["Programming-Languages"],"content":" @timeit这个装饰器也很常用，写起来也很简单，这是用来测量函数耗时的 python import time import functools def timeit(func): @functools.wraps(func) def inner(*args, **kwargs): start = time.time() func(*args, **kwargs) end = time.time() print(f\"Execute {func.__name__} in {end - start:.2f} seconds\") return inner @timeit def foobar(): ans = 0 for i in range(10000000): ans += i return ans foobar() ","date":"2025-01-20","objectID":"/zh-cn/understanding-python-decorator/:4:4","series":null,"tags":["Python"],"title":"什么是 Python 装饰器","uri":"/zh-cn/understanding-python-decorator/#timeit"},{"categories":["Programming-Languages"],"content":" 总结到这里本文就结束了，其实 Python 装饰器还可以用来装饰一个类，但在本文里面没有提及，因为我面向对象编程用得并不多。不过我相信，理解了 Python 装饰器如何装饰一个函数，那么你也能够理解 Python 装饰器是如何装饰一个类的 ","date":"2025-01-20","objectID":"/zh-cn/understanding-python-decorator/:5:0","series":null,"tags":["Python"],"title":"什么是 Python 装饰器","uri":"/zh-cn/understanding-python-decorator/#总结"},{"categories":["NLP"],"content":"kNN-LM 的论文阅读笔记","date":"2024-12-23","objectID":"/zh-cn/what-is-knn-lm/","series":null,"tags":["Paper","NLP","Deep-Learning","LLM"],"title":"论文阅读: Generalization through Memorization: Nearest Neighbor Language Models","uri":"/zh-cn/what-is-knn-lm/"},{"categories":["NLP"],"content":" Motivation语言模型解决 2 种问题 用一个特征向量表示句子前缀 使用该特征向量预测下一个 token 本文提出的 $k\\texttt{NN-LM}$ 基于这么一个假设：学习特征向量表示比预测下一个 token，因此本文的方法主要基于该假设进行设计 ","date":"2024-12-23","objectID":"/zh-cn/what-is-knn-lm/:1:0","series":null,"tags":["Paper","NLP","Deep-Learning","LLM"],"title":"论文阅读: Generalization through Memorization: Nearest Neighbor Language Models","uri":"/zh-cn/what-is-knn-lm/#motivation"},{"categories":["NLP"],"content":" kNN-LM下面这张图概括了 $k\\texttt{NN-LM}$ 的思想1 ","date":"2024-12-23","objectID":"/zh-cn/what-is-knn-lm/:2:0","series":null,"tags":["Paper","NLP","Deep-Learning","LLM"],"title":"论文阅读: Generalization through Memorization: Nearest Neighbor Language Models","uri":"/zh-cn/what-is-knn-lm/#knn-lm"},{"categories":["NLP"],"content":" 数据准备使用 $k\\texttt{NN-LM}$ 需要先对语料库的文本进行处理，分成下面几个步骤，下面我会结合一个详细的例子来进行说明，比如语料库里面有这么一个句子 text Today is a good [day] 这句子可以被分为 2 个部分 Today is a good day 是上下文 $c_i$（Context），把这个上下文扔给 LLM，就可以得到一个向量表示 $f(c_i)$ day 是下一个 token $w_i$（Target） 这样就得到了一个 $(f(c_i),w_i)$ 的 pair，可以存储在 KV 数据库里面，在论文里叫做 Datastore ","date":"2024-12-23","objectID":"/zh-cn/what-is-knn-lm/:2:1","series":null,"tags":["Paper","NLP","Deep-Learning","LLM"],"title":"论文阅读: Generalization through Memorization: Nearest Neighbor Language Models","uri":"/zh-cn/what-is-knn-lm/#数据准备"},{"categories":["NLP"],"content":" 推理阶段 Info KNN 算法我之前写过一篇博客介绍，在这里 那么在模型推理的时候如何使用这个 KV 数据库呢？假设用 $x$ 表示 LLM 的输入，那么步骤如下 用 LLM 生成它的向量表示 $f(x)$ 用 $f(x)$ 作为 Query，在 KV 数据库里面用 KNN 算法找到最近的 $k$ 个邻居（用 $\\mathcal N$ 表示）。换句话说，找和 LLM 输入 $x$ 最相似 $k$ 个上下文，注意每一个上下文都有下一个 token 假设邻居 $i$ 到 $f(x)$ 的距离是 $d_i$，$k$ 个邻居的距离就得到了一个距离向量数组 $[d_1, d_2,…,d_k]$，将距离取负然后做 Softmax 就得到了概率分布，这是关于距离的概率分布，但也可以转化为关于每个邻居背后的 token $w_i$ 的概率 $[p_1,p_2, p_3,…,p_k]$。注意这里可能不同邻居的下一个 token 是一样的，那么对应的概率要相加（可以看前面的图，有 2 个 Hawaii） 此时再把 Vocab $\\mathcal V$ 的其他 token 的概率设置为 0，就得到了在 Vocab $\\mathcal V$ 上的概率分布 $p_\\texttt{kNN}(y|x)$，一个长度为 $|\\mathcal V|$ 的向量 而 LLM 也会为输入 $x$ 输出下一个 token 的概率分布 $p_\\texttt{LM}(y|x)$ 引入一个超参数 $\\lambda$ 综合这两个概率分布 $$ p(y|x)=\\lambda p_\\texttt{kNN}(y|x)+(1-\\lambda)p_\\texttt{LM}(y|x) $$ 用这下一个 token 的概率分布预测下一个 token 即可 ","date":"2024-12-23","objectID":"/zh-cn/what-is-knn-lm/:2:2","series":null,"tags":["Paper","NLP","Deep-Learning","LLM"],"title":"论文阅读: Generalization through Memorization: Nearest Neighbor Language Models","uri":"/zh-cn/what-is-knn-lm/#推理阶段"},{"categories":["NLP"],"content":" 实验用 FAISS 快速检索 KV 数据库中的邻居 距离的计算则采用欧几里得距离而不是向量内积，因为作者发现这个效果更好 根据实验结果，有如下几个发现（知识库指的就是 KV 数据库） 发现 索引 将 LLM 的训练数据作为知识库能降低 LLM 输出的困惑度 Table 1 在小数据集上微调 LLM，并外挂一个大知识库，比直接在这个大知识库上做训练效果更好 Table 3 最好的上下文表示是：LLM 的最后一个 transformer 层其中的 FFN 层的输入 Figure 3 检索的邻居越多，效果越好 Figure 4 如果知识库是同个领域的，那么就把 $\\lambda$ 设置得小一点，反之就设置得大一点 Figure 5 ","date":"2024-12-23","objectID":"/zh-cn/what-is-knn-lm/:3:0","series":null,"tags":["Paper","NLP","Deep-Learning","LLM"],"title":"论文阅读: Generalization through Memorization: Nearest Neighbor Language Models","uri":"/zh-cn/what-is-knn-lm/#实验"},{"categories":["NLP"],"content":" kNN-LLM 的优缺点分析在了解了 $k\\texttt{NN-LM}$ 的原理之后，我们可以尝试理解一下它的优缺点 优点是 1 能够捕捉到文本中一些罕见模式，对 out-of-domain 的文本生成效果也比较好，这体现在 $k\\texttt{NN}$ 和 $\\texttt{LM}$ 的协同 $k\\texttt{NN}$ 可以捕捉到：上下文相似，下一个 token 一样，但 token 的含义不同 $\\texttt{LM}$ 可以捕捉到：上下文不同，下一个 token 一样 不足点是 1 空间开销大，因为给定语料库我们是为每个 token 构造 KV pair，所以 KV 数据库的大小跟跟 token 数量挂钩。所以在 Scalability 上 $k-\\texttt{NN-LM}$ 存在比较大的问题 在模型输入和检索结果之间没有注意力的计算，这会降低模型的表现 ","date":"2024-12-23","objectID":"/zh-cn/what-is-knn-lm/:4:0","series":null,"tags":["Paper","NLP","Deep-Learning","LLM"],"title":"论文阅读: Generalization through Memorization: Nearest Neighbor Language Models","uri":"/zh-cn/what-is-knn-lm/#knn-llm-的优缺点分析"},{"categories":["NLP"],"content":" 参考 ACL tutorial 2023. Section 3: Retrieval-based LMs: Architecture ↩︎ ↩︎ ↩︎ ","date":"2024-12-23","objectID":"/zh-cn/what-is-knn-lm/:5:0","series":null,"tags":["Paper","NLP","Deep-Learning","LLM"],"title":"论文阅读: Generalization through Memorization: Nearest Neighbor Language Models","uri":"/zh-cn/what-is-knn-lm/#参考"},{"categories":["ML-DL"],"content":"介绍 KNN 算法的原理","date":"2024-12-15","objectID":"/zh-cn/what-is-k-nearest-neighbor-algorithms/","series":null,"tags":["Machine-Learning"],"title":"KNN 算法是什么","uri":"/zh-cn/what-is-k-nearest-neighbor-algorithms/"},{"categories":["ML-DL"],"content":" 什么是 KNN Tip 显然，从定义来看，KNN 算法并不需要训练 KNN 允许我们根据一堆已知类别的样本判断一个新的样本 $\\mathbf x$ 的类别，判断的原理是综合考虑距离它最近的 $K$ 个样本的类别 那么可想而知，有这么几个核心的问题值得研究 $K$ 应该是多少？ 如何度量“距离”？ 如何综合最近的 $K$ 个样本的类别的结果？ ","date":"2024-12-15","objectID":"/zh-cn/what-is-k-nearest-neighbor-algorithms/:1:0","series":null,"tags":["Machine-Learning"],"title":"KNN 算法是什么","uri":"/zh-cn/what-is-k-nearest-neighbor-algorithms/#什么是-knn"},{"categories":["ML-DL"],"content":" 关于 K 的选取$K$ 越大，参考的样本就越多，理论上会越准确，但实际上考虑太多的样本会把距离不近的样本也包括进来 $K$ 太小的话，又会导致 KNN 的预测的方差比较大 所以，$K$ 不能太大也不能太小，那么在实际上操作的时候：可以让 $K$ 从小到大变化，观察验证集上的表现。用 $K$ 作为横轴，验证集上的表现作为纵轴画出曲线，这个曲线的拐点就是最佳的 $K$，这就是所谓的“肘部法则” 也可以考虑用交叉验证法选择最佳的 $K$ Tip 值得一提的是，$K$ 最好是奇数，这样比较不会出现 $K$ 个邻居里面每一个类别的数量都相等，导致 KNN 无法给出预测 ","date":"2024-12-15","objectID":"/zh-cn/what-is-k-nearest-neighbor-algorithms/:2:0","series":null,"tags":["Machine-Learning"],"title":"KNN 算法是什么","uri":"/zh-cn/what-is-k-nearest-neighbor-algorithms/#关于-k-的选取"},{"categories":["ML-DL"],"content":" 关于距离假设每一个样本都用长度为 $d$ 的向量表示，那么样本之间的距离计算可以考虑用欧几里得距离 $$ \\texttt{distance}(\\mathbf x,\\mathbf y)=\\sqrt{\\sum_{i=1}^d(x_i-y_i)^2} $$ ","date":"2024-12-15","objectID":"/zh-cn/what-is-k-nearest-neighbor-algorithms/:3:0","series":null,"tags":["Machine-Learning"],"title":"KNN 算法是什么","uri":"/zh-cn/what-is-k-nearest-neighbor-algorithms/#关于距离"},{"categories":["ML-DL"],"content":" 如何综合 K 个最近邻居的结果在找到新样本的 $K$ 个最近的邻居之后，让这 $K$ 个邻居进行投票，投票数最多的类别就是新样本的类别 ","date":"2024-12-15","objectID":"/zh-cn/what-is-k-nearest-neighbor-algorithms/:4:0","series":null,"tags":["Machine-Learning"],"title":"KNN 算法是什么","uri":"/zh-cn/what-is-k-nearest-neighbor-algorithms/#如何综合-k-个最近邻居的结果"},{"categories":["ML-DL"],"content":" 算法实现Scikit-Learn 库提供了 API 用于创建 KNN 分类器，在开始之前，我们先生成一个数据集用于演示 python import numpy as np np.random.seed(40) from sklearn.datasets import make_classification from sklearn.model_selection import train_test_split X, y = make_classification( n_samples=100, n_features=2, n_informative=2, n_redundant=0, n_clusters_per_class=1, random_state=40, ) X_train, X_temp, y_train, y_temp = train_test_split( X, y, test_size=0.2, random_state=40 ) X_valid, X_test, y_valid, y_test = train_test_split( X_temp, y_temp, test_size=0.5, random_state=40 ) 为了对数据集有更好的了解，这里可以画一个散点图。结果如下所示 接下来创建一个 KNN 分类器，在训练集 X_train 上“训练”一个 KNN 模型 python from sklearn.neighbors import KNeighborsClassifier neigh = KNeighborsClassifier(n_neighbors=5) neigh.fit(X_train, y_train) Warning 这里其实没有训练！ 现在假设有一个新的样本 [0, 0]，就可以用这个模型判断它的类别 python test_point = [0, 0] neigh.predict([test_point]) # array([1]) 同样的，可以画出散点图看一下，其中的黑色 $\\times$ 表示邻居，红色的 $\\times$ 是用于测试的样本 [0, 0] 根据结果来看，4 个邻居是类别 1，1 个邻居是类别 0，所以 [0, 0] 的类别是 1 ","date":"2024-12-15","objectID":"/zh-cn/what-is-k-nearest-neighbor-algorithms/:5:0","series":null,"tags":["Machine-Learning"],"title":"KNN 算法是什么","uri":"/zh-cn/what-is-k-nearest-neighbor-algorithms/#算法实现"},{"categories":["ML-DL"],"content":" FAQ","date":"2024-12-15","objectID":"/zh-cn/what-is-k-nearest-neighbor-algorithms/:6:0","series":null,"tags":["Machine-Learning"],"title":"KNN 算法是什么","uri":"/zh-cn/what-is-k-nearest-neighbor-algorithms/#faq"},{"categories":["ML-DL"],"content":" 不平衡数据集可以用 KNN 吗不推荐，因为样本不平衡会导致用 KNN 算法得到的分类几乎总是样本多的类别 ","date":"2024-12-15","objectID":"/zh-cn/what-is-k-nearest-neighbor-algorithms/:6:1","series":null,"tags":["Machine-Learning"],"title":"KNN 算法是什么","uri":"/zh-cn/what-is-k-nearest-neighbor-algorithms/#不平衡数据集可以用-knn-吗"},{"categories":["ML-DL"],"content":" K 的大小和模型复杂度的关系一个有趣的问题是：$K$ 越大 KNN 越复杂？还是 $K$ 越小？答案：$K$ 越小模型越复杂，也因此更容易“过拟合” 这句话可以反过来理解，$K$ 最大的情况下等于所有样本的个数 $N$，此时只要是新样本，会总是被判断为 $N$ 个样本中最多的类别，这样的模型显然太简单了 ","date":"2024-12-15","objectID":"/zh-cn/what-is-k-nearest-neighbor-algorithms/:6:2","series":null,"tags":["Machine-Learning"],"title":"KNN 算法是什么","uri":"/zh-cn/what-is-k-nearest-neighbor-algorithms/#k-的大小和模型复杂度的关系"},{"categories":["ML-DL"],"content":" KNN 应该做 Normalize 吗？显然是的，不然计算距离的时候，数值比较大的特征对距离的影响更大 ","date":"2024-12-15","objectID":"/zh-cn/what-is-k-nearest-neighbor-algorithms/:6:3","series":null,"tags":["Machine-Learning"],"title":"KNN 算法是什么","uri":"/zh-cn/what-is-k-nearest-neighbor-algorithms/#knn-应该做-normalize-吗"},{"categories":["ML-DL"],"content":" KNN 可以用于回归问题吗？可以，比如取 $K$ 个邻居的平均值，但一般 KNN 还是用来做分类问题 ","date":"2024-12-15","objectID":"/zh-cn/what-is-k-nearest-neighbor-algorithms/:6:4","series":null,"tags":["Machine-Learning"],"title":"KNN 算法是什么","uri":"/zh-cn/what-is-k-nearest-neighbor-algorithms/#knn-可以用于回归问题吗"},{"categories":["ML-DL"],"content":" KNN 可以如何改进？朴素的 KNN 采用投票法，即每一个邻居节点的贡献度是一样的，一个改进方向是：修改每一个邻居节点的贡献度，比如越近的邻居贡献度越大。一个常用的权重是 $1/d$，这里的 $d$ 是到邻居到新样本的距离 ","date":"2024-12-15","objectID":"/zh-cn/what-is-k-nearest-neighbor-algorithms/:6:5","series":null,"tags":["Machine-Learning"],"title":"KNN 算法是什么","uri":"/zh-cn/what-is-k-nearest-neighbor-algorithms/#knn-可以如何改进"},{"categories":["Programming-Languages"],"content":"对 OCaml 中的 Phantom Type 是什么进行了介绍","date":"2024-12-08","objectID":"/zh-cn/what-is-phantom-type-in-ocaml/","series":null,"tags":["OCaml"],"title":"OCaml 中的 Phantom Type 是什么","uri":"/zh-cn/what-is-phantom-type-in-ocaml/"},{"categories":["Programming-Languages"],"content":" 语法 Info = 左侧是类型（Type），右侧是值（Value） 只需要在定义 Variant Type 的时候，在 = 左侧加上 'a 等泛型变量，但是在 = 不要放，像下面这样 ocaml type 'a t = some_type 这里的精髓在于：= 右侧并没有使用到 'a，因此 'a 其实我们想放什么都可以 这里的 'a 就是 Phantom Type，它出现在类型（= 左侧）当中，但是在创建值的时候并不会用到，所以说是 Phantom (幽灵👻) 既然没有用到，那么干脆就不要写 'a，而是直接用 _，这是比较 idiomatic 的写法 ocaml type _ t = some_type 接下来我们看看如何使用 Phantom Types ","date":"2024-12-08","objectID":"/zh-cn/what-is-phantom-type-in-ocaml/:1:0","series":null,"tags":["OCaml"],"title":"OCaml 中的 Phantom Type 是什么","uri":"/zh-cn/what-is-phantom-type-in-ocaml/#语法"},{"categories":["Programming-Languages"],"content":" 使用场合 Info 在我看来，Phantom type 最大的用处是给类型加上“状态”，因此可以进行更细粒度的类型区分 我这里就借用 Haskell MOOC 里面的例子：货币计算 1。显然，不管是什么货币类型，都可以用一个浮点数表示（在 OCaml 里面对应 float 类型）。让我们用 Phantom Type 定义如下的货币类型 ocaml utop # type _ currency = Currency of float;; 然后定义 2 个 Phantom Type：美元和人民币 ocaml utop # type dollar;; utop # type yuan;; 现在来写一个货币相加的函数，假设我们只想要让美元相加，那么我们可以这么写 ocaml utop # let dollar_add (Currency x : dollar currency) (Currency y : dollar currency) : dollar currency = Currency (x +. y);; val dollar_add : dollar currency -\u003e dollar currency -\u003e dollar currency = \u003cfun\u003e 从函数签名可以看到，这个函数只会让美元相加，我们可以尝试验证一下 ocaml utop # let three_dollar : dollar currency = Currency 3.0;; utop # let four_dollar : dollar currency = Currency 4.0;; utop # let four_dollar : dollar currency = Currency 4.0;; val four_dollar : dollar currency = Currency 4. 可以看到，美元求和没有问题，可以试一下用这个函数对人民币求和 ocaml utop # let yuan_sum = dollar_add three_yuan four_yuan;; Error: This expression has type yuan currency but an expression was expected of type dollar currency Type yuan is not compatible with type dollar 在编译期间，编译器帮我们捕捉到了这个错误😺 但如果我们想要一个通用的函数可以处理任何货币类型呢？我们可以选择加上 'a currency 这种类型声明，比如下面这个 scale 函数 ocaml utop # let scale (Currency x : 'a currency) factor : 'a currency = Currency (x *. factor);; val scale : 'a currency -\u003e float -\u003e 'a currency = \u003cfun\u003e 也可以选择省略掉类型声明 ocaml utop # let scale (Currency x) factor = Currency (x *. factor);; val scale : 'a currency -\u003e float -\u003e 'b currency = \u003cfun\u003e 不一样的是函数返回类型变成了 'b currency，这是因为 OCaml 总是会推断更 General 的情况。如果这不是你的预期行为，还是得自己加上类型声明 ","date":"2024-12-08","objectID":"/zh-cn/what-is-phantom-type-in-ocaml/:2:0","series":null,"tags":["OCaml"],"title":"OCaml 中的 Phantom Type 是什么","uri":"/zh-cn/what-is-phantom-type-in-ocaml/#使用场合"},{"categories":["Programming-Languages"],"content":" 总结和不使用 Phantom Type 相比，使用 Phantom Type 的好处是什么？在我看来有如下几点 扩展性：每当我们要添加一个新的 case 的时候，只需要多写一个 Phantom Type（type ...）即可，扩展性比较好 类型安全：通过给函数加上类型声明，就可以控制函数的行为，实现更细粒度的控制。OCaml 编译器会帮我们追踪“状态”，在编译期间就能够捕捉类型错误 因为函数要加上类型声明，使用 Phantom Type 之后代码似乎更加啰嗦了。但实际上，写 OCaml 代码的时候可以选择将类型声明放在单独的 .mli 文件里面，在对应的 .ml 文件里面写实现，这样代码看上去仍然是比较简洁的。本文受限于篇幅并没有采取这种方式。可以在 Jane Street 的 这篇博客 里面看到这种用法 ","date":"2024-12-08","objectID":"/zh-cn/what-is-phantom-type-in-ocaml/:3:0","series":null,"tags":["OCaml"],"title":"OCaml 中的 Phantom Type 是什么","uri":"/zh-cn/what-is-phantom-type-in-ocaml/#总结"},{"categories":["Programming-Languages"],"content":" 参考 https://haskell.mooc.fi/part2#phantom-types ↩︎ ","date":"2024-12-08","objectID":"/zh-cn/what-is-phantom-type-in-ocaml/:4:0","series":null,"tags":["OCaml"],"title":"OCaml 中的 Phantom Type 是什么","uri":"/zh-cn/what-is-phantom-type-in-ocaml/#参考"},{"categories":["NLP"],"content":"In-Context Retrieval-Augmented Language Models 的论文阅读笔记","date":"2024-12-04","objectID":"/zh-cn/in-context-ralm-paper-reading/","series":null,"tags":["Paper","NLP","Deep-Learning","LLM"],"title":"论文阅读: In-Context Retrieval-Augmented Language Models","uri":"/zh-cn/in-context-ralm-paper-reading/"},{"categories":["NLP"],"content":" The ideaIn-Context RALM1 是用于 Autoregressive LM 上的 RAG 技术。RAG 说白了就是在模型推理的时候有个 Retriever 检索相关的文档，检索到的文档会和本来的输入拼接在一起 在 In-Context Learning 里面，会把一些例子放在用户输入的前面，再给 LLM。因此不难想象 In-Context RALM 也类似：In-Context RALM 就是将检索到的最相关的文档直接拼在模型输入的前面，优势是不需要再训练 LLM，我用 mermaid 画了一个图，如下所示 flowchart subgraph Input direction TB document query end query --\u003e Retriever(Retriever) --\u003e document document ---|Concat| query Input --\u003e LLM --\u003e Output 那么带有 RAG 的 LLM 做文本生成的公式表示是 $$ P_\\theta(x_1,x_2,…,x_L)=\\prod_{i=1}^L P_\\theta\\big(x_i|[R_{\\mathcal C}(x_{\u003ci});x_{\u003ci}]\\big) $$ 其中 $R_{\\mathcal C}(x_{\u003ci})$ 表示用输入 ${x_1,x_2,…,x_{i-1}}$ 让 Retriever 检索到的文档，$x_{\u003ci}$ 对应 ${x_1,x_2,…,x_{i-1}}$ $[;]$ 表示 Concat 操作，$[x;y]$ 就是将 $x$ 和 $y$ 拼接起来 上面一段话已经概括了 In-Context RALM 的设计（就是这么简单！）。但其实还是有几个细节值得深究，作者着重研究了下面几个 应该用什么 Retriever？ Retriever 检索的频率应该如何设置？ Retriever 的输入是什么？即它是根据什么做检索的？ 如果使用更多 Retriever 检索到的文档而不止是最相关的，效果会更好吗？ 下面我们一一来看上面问题的研究结论 :) ","date":"2024-12-04","objectID":"/zh-cn/in-context-ralm-paper-reading/:1:0","series":null,"tags":["Paper","NLP","Deep-Learning","LLM"],"title":"论文阅读: In-Context Retrieval-Augmented Language Models","uri":"/zh-cn/in-context-ralm-paper-reading/#the-idea"},{"categories":["NLP"],"content":" Retriever Choice作者研究了 2 种 Retriever Sparse Retriever BM25 Dense Retriever 冻结参数的 BERT-base Contriever Spider ","date":"2024-12-04","objectID":"/zh-cn/in-context-ralm-paper-reading/:1:1","series":null,"tags":["Paper","NLP","Deep-Learning","LLM"],"title":"论文阅读: In-Context Retrieval-Augmented Language Models","uri":"/zh-cn/in-context-ralm-paper-reading/#retriever-choice"},{"categories":["NLP"],"content":" Retrieval Stride Info REALM 我之前也发过一篇论文阅读笔记，感兴趣的可以查看该链接 Retrieval Stride 要解决的是“Retriever 检索的频率应该如何设置”这个问题，像 REALM 一样在一开始的时候做检索（而且只做一次）当然可以，但作者提出：应该固定步长就做一次检索，这里的步长（用 $s$ 表示）用 token 数量来度量 作者发现，$s$ 越小，模型生成的文本越好，但开销也会越大，这里存在 trade-off。每隔 $s$ 个 token 的情况做一次检索的情况下，带有 RAG 的 LLM 的文本生成可以用公式表示为 $$ P_\\theta(x_1,x_2,…,x_L)=\\prod_{j=0}^{n_s-1}\\prod_{i=1}^{s} P_\\theta\\big(x_{s\\cdot j +i}|[R_{\\mathcal C}(x_{\\le s\\cdot j});x_{\u003c(s\\cdot j + i)}]\\big) $$ 这里说的开销包括两个部分 Retriever 检索的开销 检索到的文档需要重新让 LLM 计算 Embedding ","date":"2024-12-04","objectID":"/zh-cn/in-context-ralm-paper-reading/:1:2","series":null,"tags":["Paper","NLP","Deep-Learning","LLM"],"title":"论文阅读: In-Context Retrieval-Augmented Language Models","uri":"/zh-cn/in-context-ralm-paper-reading/#retrieval-stride"},{"categories":["NLP"],"content":" Retrieval Query Length那么 Retriever 的输入应该是什么呢？一个朴素的想法是，将用户的输入和和截止目前为止 LLM 生成的 token（这两者可以用 $x_{\\le x_{s\\cdot j}}$ 表示） 一起作为 Retriever 的输入，但作者认为最后几个 token 对 LLM 的生成更重要 因此作者想到，每隔 $s$ 个 token 要让 Retriever 去检索的时候只需要给最后 $l$ 个 token 就可以，并不需要给当前所有的 token（即 $x_{\\le s\\cdot j}$）。用公式表示就是 $$ P_\\theta(x_1,x_2,…,x_L)=\\prod_{j=0}^{n_s-1}\\prod_{i=1}^{s} P_\\theta\\big(x_{s\\cdot j +i}|[R_{\\mathcal C}(x_{s\\cdot j-l+1:{s\\cdot j}});x_{\u003c(s\\cdot j + i)}]\\big) $$ 其中 $s\\cdot j-l+1:{s\\cdot j}$ 表示 $[s\\cdot j-l+1,{s\\cdot j}]$，也就是当前位置的前 $l$ 个 token Faq $l$ 应该等于 $s$ 吗？作者发现 $s=l$ 的话，效果会不好 ","date":"2024-12-04","objectID":"/zh-cn/in-context-ralm-paper-reading/:1:3","series":null,"tags":["Paper","NLP","Deep-Learning","LLM"],"title":"论文阅读: In-Context Retrieval-Augmented Language Models","uri":"/zh-cn/in-context-ralm-paper-reading/#retrieval-query-length"},{"categories":["NLP"],"content":" RerankingRetriever 会对语料库中的文档都计算相关性，一般只使用最相关的文档，但直接根据相关性计算出来的就一定最好吗？是否可以考虑返回 Top-k 个然后重新做排序操作？ 作者研究了 2 种排序方法 第一种，直接用 LLM 判断，假设要对 k 个文档排序，那么对于每一个文档 $d_i$：取 $x_{s\\cdot j}$ 的最后 $s’$ 个 token 作为预测目标，并从 LLM 输入中去掉这 $s’$ 个 token。文档 $d_i$ 会被添加到 LLM 输入的前面，然后再让 LLM 预测。最好的文档就是会让这 $s’$ 个 token 出现频率最高的 $$ \\texttt{argmax}\\ p(x_{s\\cdot j-s’+1:s\\cdot j}|[d_i;x_{\\le s\\cdot j-s’})) $$ Tip 第一种方法里面用于排序的 LLM 并没有要求要和负责生成文本的 LLM 一样。因此出于性能的考虑，负责排序的 LLM 完全可以用更小的模型 第二种，直接训练一个 reranker，作者称其为 Predictive Reranking Reranker 输入 $x_{\\le s\\cdot j}$ $d_i$ Reranker 返回：一个标量，表示 $d_i$ 和 $x_{\\le s\\cdot j}$ 的相关性 那么每个文档 $d_i$ 都会有个相关性的得分，经过 $\\texttt{softmax}$ 之后 k 个文档的得分就形成了一个概率分布，概率最大的文档就是相关性最强的 Tip 那么训练集的样本的 label 从哪里来呢？ 让 LLM 模型用 $x_{\\le s\\cdot j}$ 生成 $s$ 个 token（用 $y$ 表示），注意这里的 $s$ 是步长 让 Retriever 用最后 $l$ 个 token 检索到 k 个文档 让 LLM 根据 $[d_i; x_{\\le s\\cdot j}]$ 预测 $y$，计算概率，就得到了 label ","date":"2024-12-04","objectID":"/zh-cn/in-context-ralm-paper-reading/:1:4","series":null,"tags":["Paper","NLP","Deep-Learning","LLM"],"title":"论文阅读: In-Context Retrieval-Augmented Language Models","uri":"/zh-cn/in-context-ralm-paper-reading/#reranking"},{"categories":["NLP"],"content":" 总结我将本文的研究结论汇总成一张表格，如下所示 Conclusion Reference Predictive Reranking 的效果会更好一些 Figure 1 BM25 虽然只考虑了语法信息，但是作为 Retriever 比基于神经网络的效果还要好（推荐设置 $l=32, s=4$） Figure 3 不管 LLM 的模型大小，用了 In-Context RALM 的 RAG 技术之后，LLM 生成的文本的困惑度都下降了 Figure 4 检索的频率越高（即 $s$ 越小），效果越好（极限情况下每个 token 生成的时候都检索一次） Figure 5 给 Retriever 的输入只需要 LLM 输入的最后 $l$ 个 token 效果就很好了 Figure 6 对 Retriever 返回的文档进行重新排序是有帮助的，提升效果明显 Figure 7 只需要使用 Retriever 返回的最相关的文档就可以了，更多文档的提升并不明显 Figure 8 ","date":"2024-12-04","objectID":"/zh-cn/in-context-ralm-paper-reading/:2:0","series":null,"tags":["Paper","NLP","Deep-Learning","LLM"],"title":"论文阅读: In-Context Retrieval-Augmented Language Models","uri":"/zh-cn/in-context-ralm-paper-reading/#总结"},{"categories":["NLP"],"content":" 参考 Ram, Ori, et al. “In-context retrieval-augmented language models.” Transactions of the Association for Computational Linguistics 11 (2023): 1316-1331. src ↩︎ ","date":"2024-12-04","objectID":"/zh-cn/in-context-ralm-paper-reading/:3:0","series":null,"tags":["Paper","NLP","Deep-Learning","LLM"],"title":"论文阅读: In-Context Retrieval-Augmented Language Models","uri":"/zh-cn/in-context-ralm-paper-reading/#参考"},{"categories":["NLP"],"content":"关于 Google 的 REALM 论文的介绍","date":"2024-11-30","objectID":"/zh-cn/rag-realm-paper-reading/","series":null,"tags":["Paper","NLP","Deep-Learning"],"title":"论文阅读: REALM: Retrieval-Augmented Language Model Pre-Training","uri":"/zh-cn/rag-realm-paper-reading/"},{"categories":["NLP"],"content":" 引言最近打算系统性学习 RAG 技术，开始看起了相关文献，目前的思路是按照 ACL 2023 Tutorial 的 Roadmap 过一遍。本篇是对早期的 RAG 技术的 REALM 的介绍 Info 本文采用的模型是 Masked LM 的 BERT，还不是 LLM。因此本文后续的部分内容需要你对 BERT 有一定的了解，包括 BERT 的预训练过程、BERT 微调等 ","date":"2024-11-30","objectID":"/zh-cn/rag-realm-paper-reading/:1:0","series":null,"tags":["Paper","NLP","Deep-Learning"],"title":"论文阅读: REALM: Retrieval-Augmented Language Model Pre-Training","uri":"/zh-cn/rag-realm-paper-reading/#引言"},{"categories":["NLP"],"content":" The ideaMotivation 是这样子的：知识以参数的形式存储在模型里面，注意这是 implicit 的。本文提出可以在模型推理的时候，新增一个 Retriever，负责检索到跟输入相关的文本，来辅助模型推理 Info 如果你对 BERT 很熟悉，应该还记得输入的限制最大为 512 个 token。因此这里的文本其实指的是 Text Chunk，论文里提到将文档都切成了一个个 Chunk 架构长下面这样 1 Info 注意几点 这里的语言模型采用的是 BERT，所以可以看到 [CLS], [MASK], [SEP] 这些特殊的 token Retriever 取回的 Text Chunk 和本来的 Query 用 [SEP] 拼接起来了 也就是现在多了一个 Retriever，那么就要处理几个问题 如何训练 Retriever？ Retriever 要检查的语料库（图中的 $\\mathcal Z$）特别大，如何高效做检索？ Retriever 找到相关的 Text Chunk 之后要如何使用？ 对于第一个问题，作者想到了 Unsupervised-Learning，用 Perplexity 作为“信号”，如果加上了 Retriever 检索到的 Text Chunk 之后会使得模型生成的 Text Chunk 的 Perplexity 提高，那么说明检索到的 Text Chunk 不好，反之则说明检索到了相关的 Text Chunk 对于第二个问题，每一个文档会被切分成一个个 Text Chunk，每一个 Text Chunk 都可以提前生成 Embedding，那么在得到 Query 的 Embedding 之后，只需要和每一个 Text Chunk 做向量内积，就可以计算相关性了 ","date":"2024-11-30","objectID":"/zh-cn/rag-realm-paper-reading/:2:0","series":null,"tags":["Paper","NLP","Deep-Learning"],"title":"论文阅读: REALM: Retrieval-Augmented Language Model Pre-Training","uri":"/zh-cn/rag-realm-paper-reading/#the-idea"},{"categories":["NLP"],"content":" 模型架构记输入为 $x$，输出为 $y$，检索到的 Text Chunk 是 $z$，REALM 要做的事情就是给定输入预测输出，也就是 $$ p(y|x) $$ REALM 将其分为 2 步 retrieve：从语料库 $\\mathcal Z$ 里面检索 Text Chunk $z$，这可以建模为一个概率分布 $p(z|x)$ predict：那么预测就是做条件生成，即 $p(y|z,x)$ 根据前面的定义，我们需要解决的是 2 个公式的求解：$p(z|x),p(y|z,x)$，分别交给 Retriever 和 Encoder 负责，整体遵循 retrieve-then-predict 的思路 ","date":"2024-11-30","objectID":"/zh-cn/rag-realm-paper-reading/:3:0","series":null,"tags":["Paper","NLP","Deep-Learning"],"title":"论文阅读: REALM: Retrieval-Augmented Language Model Pre-Training","uri":"/zh-cn/rag-realm-paper-reading/#模型架构"},{"categories":["NLP"],"content":" Retriever先看 Retriever，负责处理 $p(z|x)$，即做 Text Chunk 的检索。公式计算方式为 $$ \\begin{aligned} p(z|x)\u0026=\\frac{exp\\ f(x,z)}{\\sum_{z’}exp\\ f(x,z’)} \\\\ f(x,z)\u0026=\\texttt{Embed}_{input}(x)^T\\texttt{Embed}_{doc}(z) \\end{aligned} $$ 翻译成中文就是，得到输入的 Embedding $\\texttt{Embed}_{input}(x)$，并计算语料库 $\\mathcal Z$ 的每个 Text Chunk 的 Embedding，用输入的 Embedding 和每个Text Chunk 的 Embedding 分别做向量内积，$\\texttt{softmax}$ 之后就可以得到概率分布，也就知道每一个 Text Chunk 跟输入的相关性 用 BERT 提取输入的 Embedding 的过程比较好理解，输出的 [CLS] 的 Embedding 一般被看成是输入的整体表示，作者还将其乘以一个权重矩阵做投影降维。核心问题是 Retriever 的输入是什么？ 作者定义了如下的输入模板 $$ \\begin{aligned} \\texttt{join}_\\texttt{BERT}(x)\u0026=\\texttt{[CLS]}x\\texttt{[SEP]} \\\\ \\texttt{join}_\\texttt{BERT}(x_1,x_2)\u0026=\\texttt{[CLS]}x_1\\texttt{[SEP]}x_2\\texttt{[SEP]} \\end{aligned} $$ 对于 Query 来说，就是 $\\texttt{join}_\\texttt{BERT}(query)$ 对于 Text Chunk 来说，就是 $\\texttt{join}_\\texttt{BERT}(z_{title}, z_{body})$。这里有点意思，title 和 body 分开，再用 [SEP] 拼接起来 ","date":"2024-11-30","objectID":"/zh-cn/rag-realm-paper-reading/:3:1","series":null,"tags":["Paper","NLP","Deep-Learning"],"title":"论文阅读: REALM: Retrieval-Augmented Language Model Pre-Training","uri":"/zh-cn/rag-realm-paper-reading/#retriever"},{"categories":["NLP"],"content":" EncoderEncoder 负责处理 $p(y|z,x)$，作者区分了预训练和微调 2 个场景，这里不对其进行展开。因为现在显然是 LLM 的时代了，我们看一下输入就好 $$ \\texttt{join}_{\\texttt{BERT}}(x, z_{\\texttt{body}}) $$ ","date":"2024-11-30","objectID":"/zh-cn/rag-realm-paper-reading/:3:2","series":null,"tags":["Paper","NLP","Deep-Learning"],"title":"论文阅读: REALM: Retrieval-Augmented Language Model Pre-Training","uri":"/zh-cn/rag-realm-paper-reading/#encoder"},{"categories":["NLP"],"content":" 模型训练我们要优化的是 $p(y|x)$ 这个概率分布，希望给定输入 $x$ 的情况下，可以找到最相关的 $y$ 现在多了一个 Text Chunk 检索的步骤，根据边缘概率有 $$ p(y|x)=\\sum_{z\\in\\mathcal Z}p(y|z,x)p(z|x) $$ 这里面有几个挑战 $\\sum_{z\\in\\mathcal Z}$ 说明我们需要对语料库里的每个 Text Chunk $z$ 都计算一下最后求和，Text Chunk 数量太多了怎么办？作者认为，取 Top-k 个，这是因为理想的情况下，很多 Text Chunk 都是无关的，所以 $p(z|x)\\approx 0$ Text Chunk 的 Embedding 可以提前计算，但问题是：随着 $\\texttt{Embed}_{doc}$ 模型更新之后，原有的 Embedding 就不适用了，理想的情况下应该每次模型更新完成之后都更新一下 Text Chunk 的 Embedding，但这样会影响训练。针对不同的场合，作者提出了不同的方法 预训练：训练几百个 Step 之后再更新 $\\texttt{Embed}_{doc}$ 的参数，然后刷新每个 Text Chunk 的索引，论文里说是 500 个 Step 微调：如果只是微调，那么不会更新 $\\texttt{Embed}_{doc}$ 的参数 ","date":"2024-11-30","objectID":"/zh-cn/rag-realm-paper-reading/:4:0","series":null,"tags":["Paper","NLP","Deep-Learning"],"title":"论文阅读: REALM: Retrieval-Augmented Language Model Pre-Training","uri":"/zh-cn/rag-realm-paper-reading/#模型训练"},{"categories":["NLP"],"content":" 总结2020 年提出的 REALM 是 BERT 模型下的 RAG 技术，虽然现在 BERT 已经不那么流行了，但 REALM 的 RAG 设计还是有值得借鉴的地方 在一开始就检索相关的 Text Chunk，而且只检索一次 当语料库太大的时候，选取 Top-k 个最相关的 Text Chunk 就可以了 Guu, Kelvin, et al. “Retrieval augmented language model pre-training.” International conference on machine learning. PMLR, 2020. src ↩︎ ","date":"2024-11-30","objectID":"/zh-cn/rag-realm-paper-reading/:5:0","series":null,"tags":["Paper","NLP","Deep-Learning"],"title":"论文阅读: REALM: Retrieval-Augmented Language Model Pre-Training","uri":"/zh-cn/rag-realm-paper-reading/#总结"},{"categories":["Programming-Languages"],"content":"对 OCaml 的 Polymorphic variant 类型的介绍，包括含义、使用场合等","date":"2024-11-24","objectID":"/zh-cn/use-polymorphic-variant-type-in-ocaml/","series":null,"tags":["OCaml"],"title":"使用 OCaml 中的 Polymorphic Variant 类型","uri":"/zh-cn/use-polymorphic-variant-type-in-ocaml/"},{"categories":["Programming-Languages"],"content":" 引言我已经学习并使用了 OCaml 有段时间了，但是一直搞不清楚 Polymorphic variant 有什么用。最近在看 Yojson 的时候又看到了这种用法，一番搜索之后发现并没有看到关于 Polymorphic variant 的比较好的文章（官方介绍 在我看来有点难懂），只看到一些相关的回答12。经过仔细学习之后，我决定写一篇文章，希望能对你有所帮助 :) 信息 我不是一个 OCaml 专家，所以本文可能也不是一篇比较好的文章 ","date":"2024-11-24","objectID":"/zh-cn/use-polymorphic-variant-type-in-ocaml/:1:0","series":null,"tags":["OCaml"],"title":"使用 OCaml 中的 Polymorphic Variant 类型","uri":"/zh-cn/use-polymorphic-variant-type-in-ocaml/#引言"},{"categories":["Programming-Languages"],"content":" 语法所有 variant 用方括号 [] 括起来，每一个 constructor 用 backtick （ ` ）标识，比如 ocaml type either = [ | `A of int | `B ] 在定义值的时候，也要加上 backtick ocaml utop # let v = `A 1;; val v : [\u003e `A of int/2 ] = `A 1 ","date":"2024-11-24","objectID":"/zh-cn/use-polymorphic-variant-type-in-ocaml/:2:0","series":null,"tags":["OCaml"],"title":"使用 OCaml 中的 Polymorphic Variant 类型","uri":"/zh-cn/use-polymorphic-variant-type-in-ocaml/#语法"},{"categories":["Programming-Languages"],"content":" 下界与上界 Tip int/2 的意思可以看 StackOverflow 上的一个 回答 前面我们定义 v 的可以看到，类型并不是 either，而是 [\u003e ...]，这是什么意思？根据 polymorphic variant 的 syntax，我们知道 [ ... ] 是 polymorphic variant type，那 \u003e 呢？ 它跟数学中的 \u003e 有类似的语义，表示除了我们指定的 constructor 以外还可以有更多的 constructor，比如 ocaml [`A of int | `B] [`A of int | `B | `C] ... 因此，polymorphic variant 也叫做 open variant 同理有 [\u003c ...]，这个类型约束的意思是：该类型最多有这些 constructor，可以更少但不能多。比如 ocaml [\u003c `A of int | `B] 那么可以有如下 3 种情况 ocaml [`A of int] [`B] [`A of int | `B] 所以，polymorphic variant 还是很灵活的，它的类型定义存在下面 3 种 [ ... ] 表示只有这些可能的 variant [\u003e ... ] 表示有这些可能的 variant，但接受更多的 variant [\u003c ... ] 表示有这些可能的 variant，但不接受再增加 variant ","date":"2024-11-24","objectID":"/zh-cn/use-polymorphic-variant-type-in-ocaml/:3:0","series":null,"tags":["OCaml"],"title":"使用 OCaml 中的 Polymorphic Variant 类型","uri":"/zh-cn/use-polymorphic-variant-type-in-ocaml/#下界与上界"},{"categories":["Programming-Languages"],"content":" Pattern Matching如果函数入参是一个 polymorphic variant，我们可以尝试写一下 Pattern Matching 的函数，比如 ocaml utop # let foo = function | `A -\u003e \"A\" | `B -\u003e \"B\" ;; val foo : [\u003c `A | `B ] -\u003e string/2 = \u003cfun\u003e 可以看到，OCaml 推断的入参类型是 [\u003c ...]，这是合理的，因为 如果我们提供了其他的 constructor，这个函数是无法处理的，比如 ocaml utop # foo `C;; Error: This expression has type [\u003e `C ] but an expression was expected of type [\u003c `A | `B ] The second variant type does not allow tag(s) `C 现在我们对 foo 函数稍作修改，将 B 的分支改成 C，得到 bar 函数 ocaml utop # let bar = function | `A -\u003e \"A\" | `C -\u003e \"C\" val bar : [\u003c `A | `C ] -\u003e string/2 = \u003cfun\u003e 然后我们可以尝试将 foo 函数和 bar 函数放在同一个列表里面，那么这个函数列表应该有什么类型？我们可以尝试自己做一下类型推断，已知 foo 函数可以处理 A 或者是 B bar 函数可以处理 A 或者是 C 一个列表要求里面所有的 item 的类型是一样的 警告 你可能看到我在写 Inline Code 的时候省略了 backtick，这是因为会和 Markdown 的 Inline Code 语法冲突 那么函数列表的类型就应该是 ([\u003c A] -\u003e string) list，可以用 utop 可以检查一下是否如此 ocaml utop # let funcs = [ foo; bar ];; val funcs : ([\u003c `A ] -\u003e string/2) list/2 = [\u003cfun\u003e; \u003cfun\u003e] 信息 通过前面的例子，我们发现，OCaml 可以根据 [\u003e ...] 和 [\u003c ...] 的使用情况自动进行类型推断，找到符合的类型 另外，在做 Pattern Matching 的时候，可以用 #some_variant 的语法表示整个 polymorphic variant，比如 ocaml type my_type = [ `A | `B ] let process_a_b_c = function | #my_type -\u003e \"A or B\" | `C -\u003e \"C\" ","date":"2024-11-24","objectID":"/zh-cn/use-polymorphic-variant-type-in-ocaml/:4:0","series":null,"tags":["OCaml"],"title":"使用 OCaml 中的 Polymorphic Variant 类型","uri":"/zh-cn/use-polymorphic-variant-type-in-ocaml/#pattern-matching"},{"categories":["Programming-Languages"],"content":" 使用场景 Info 更多的使用场景可以参考论文 Programming with Polymorphic Variants ","date":"2024-11-24","objectID":"/zh-cn/use-polymorphic-variant-type-in-ocaml/:5:0","series":null,"tags":["OCaml"],"title":"使用 OCaml 中的 Polymorphic Variant 类型","uri":"/zh-cn/use-polymorphic-variant-type-in-ocaml/#使用场景"},{"categories":["Programming-Languages"],"content":" 不定义直接使用这是最直观的应用，有时候只是在某一个地方用到了 Variant Type，用 type name = ... 定义一下会显得有点多余，这种时候直接用 Polymorphic Variant Type 下面的例子可以用来对比一下 ocaml type animals = | Dog | Cat let make_sound = function | Dog -\u003e \"It's a dog\" | Cat -\u003e \"It's a cat\" 上面，我定义了一个 make_sound 函数用来模拟动物的叫声。如果使用 Polymorphic Variant 可以这么写，就不用多定义一个类型了 ocaml let make_sound = function | `Dog -\u003e \"It's a dog\" | `Cat -\u003e \"It's a cat\" (* val make_sound : [\u003c `Cat | `Dog ] -\u003e string = \u003cfun\u003e *) ","date":"2024-11-24","objectID":"/zh-cn/use-polymorphic-variant-type-in-ocaml/:5:1","series":null,"tags":["OCaml"],"title":"使用 OCaml 中的 Polymorphic Variant 类型","uri":"/zh-cn/use-polymorphic-variant-type-in-ocaml/#不定义直接使用"},{"categories":["Programming-Languages"],"content":" 共享数据类型在使用某个库的时候，你可能需要用到它的定义的数据类型，这个时候你可以将这个库列为你的依赖，比如 ocaml (* ./mycolor.ml *) type rgb = Red | Green | Blue (* ./main.ml *) let process_color = function | Mycolor.Red -\u003e \"Red\" (* the Main module depends on Mycolor *) | Mycolor.Green -\u003e \"Green\" | Mycolor.Blue -\u003e \"Blue\" 但如果数据类型是用 Polymorphic Variant 定义的，那么就可以消去这个依赖 ocaml (* ./mycolor.ml *) type rgb = [ `Red | `Green | `Blue ] (* ./main.ml *) let process_color = function | `Red -\u003e \"Red\" (* the dependence is gone *) | `Green -\u003e \"Green\" | `Blue -\u003e \"Blue\" 技巧 通常这个时候，库的设计者会在文档里面告诉你，比如 Yojson 的 JSON 类型 就是用 polymorphic variant 定义的 ","date":"2024-11-24","objectID":"/zh-cn/use-polymorphic-variant-type-in-ocaml/:5:2","series":null,"tags":["OCaml"],"title":"使用 OCaml 中的 Polymorphic Variant 类型","uri":"/zh-cn/use-polymorphic-variant-type-in-ocaml/#共享数据类型"},{"categories":["Programming-Languages"],"content":" SubtypePolymorphic variant 特别适合不同的 Variant type 有共同的部分这种情况，在写处理这些类型的函数的时候很方便 举例来说，common 是 foo 和 bar 的子类型，因为 foo 和 bar 都包含 A 和 B 这两个 constructor ocaml type common = A | B type foo = | Common of common (* it's kind of redundant *) | C | D type bar = | Common of common | E | F 现在假设有一个 show 函数，需要处理上面 3 种类型，那么你不得不写 3 个函数，如下所示 ocaml let show = function | A -\u003e \"A\" | B -\u003e \"B\" let show_foo arg = match (arg : foo) with | Common v -\u003e show v | C -\u003e \"C\" | D -\u003e \"D\" let show_bar arg = match (arg : bar) with | Common v -\u003e show v | E -\u003e \"E\" | F -\u003e \"F\" 除此之外，我们还需要加上 : foo 和 : bar 来区分不同的类型。而如果使用 Polymorphic variant，上面的代码就可以简化为 ocaml let show = function | `A -\u003e \"A\" | `B -\u003e \"B\" | `C -\u003e \"C\" | `D -\u003e \"D\" | `E -\u003e \"E\" | `F -\u003e \"F\" ","date":"2024-11-24","objectID":"/zh-cn/use-polymorphic-variant-type-in-ocaml/:5:3","series":null,"tags":["OCaml"],"title":"使用 OCaml 中的 Polymorphic Variant 类型","uri":"/zh-cn/use-polymorphic-variant-type-in-ocaml/#subtype"},{"categories":["Programming-Languages"],"content":" 缺点尽管 polymorphic variant 用起来似乎更加灵活和方便，但这是有代价的 3 Complexity：Polymorphic Variants 的 typing rule 更加复杂，特别是报错信息更不友好了 Error-finding：用 Polymorphic Variants 会导致你不大容易找到 Bug Efficiency：性能会稍微差一些 ","date":"2024-11-24","objectID":"/zh-cn/use-polymorphic-variant-type-in-ocaml/:6:0","series":null,"tags":["OCaml"],"title":"使用 OCaml 中的 Polymorphic Variant 类型","uri":"/zh-cn/use-polymorphic-variant-type-in-ocaml/#缺点"},{"categories":["Programming-Languages"],"content":" 参考 Variants or Polymorphic variants ↩︎ Is there any kind of guideline about when to use polymorphic variants? ↩︎ Real World OCaml. When to Use Polymorphic Variants ↩︎ ","date":"2024-11-24","objectID":"/zh-cn/use-polymorphic-variant-type-in-ocaml/:7:0","series":null,"tags":["OCaml"],"title":"使用 OCaml 中的 Polymorphic Variant 类型","uri":"/zh-cn/use-polymorphic-variant-type-in-ocaml/#参考"},{"categories":["Programming-Languages"],"content":"关于 Applicative Functor 的介绍，比如有了 Functor 为什么还要 Applicative Functor","date":"2024-10-20","objectID":"/zh-cn/why-applicative-functor/","series":null,"tags":["Haskell","Functional-Programming"],"title":"为什么需要 Applicative Functor","uri":"/zh-cn/why-applicative-functor/"},{"categories":["Programming-Languages"],"content":" 信息 阅读本文之前，我假设你对 Functor 有很好的理解 ","date":"2024-10-20","objectID":"/zh-cn/why-applicative-functor/:0:0","series":null,"tags":["Haskell","Functional-Programming"],"title":"为什么需要 Applicative Functor","uri":"/zh-cn/why-applicative-functor/#"},{"categories":["Programming-Languages"],"content":" 为啥需要 Applicative Functor在学习 Applicative Functor 之前，首先是一个关键的问题，为什么有了 Functor 我们还需要 Applicative Functor？ Functor 的 fmap :: a -\u003e b -\u003e f a -\u003e f b 不难理解，这里的 map 函数 a -\u003e b 只有 1 个入参 a，那如果我们想要 map 包含多个入参的函数呢？比如 (+) :: a -\u003e a -\u003e a 需要 2 个参数，那用 fmap 会得到什么？看下面的代码 haskell ghci\u003e let a = fmap (+) [1,2,3] ghci\u003e :t a a :: Num a =\u003e [a -\u003e a] 可以看到，List Functor 里面的每一个值都变成了一个函数 a -\u003e a，也不难理解，Haskell Function 都是 Currying Functions，所以列表里面的元素相当于都成为了 (+) 左侧的入参，可以将其想象为 haskell [\\x -\u003e 1 + x, \\x -\u003e 2 + x, \\x -\u003e 3 + x] -- or, more simpler [(1+), (2+), (3+)] 那么我们应该可以这么写代码（让 1 成为 (+) 右侧的入参） haskell ghci\u003e fmap ($ 1) a [2,3,4] -- 2 = 1 + 1 -- 3 = 2 + 1 -- 4 = 3 + 1 注意 所以结论是：如果 fmap f x 的 map 函数 f 包含 2 个入参，那么 Functor x 里面的值会变成一个函数 理解了上面你也就不难理解我们可以很轻松用 fmap 得到 Just (1+) haskell ghci\u003e let justF = fmap (+) $ Just 1 ghci\u003e :t justF justF :: Num a =\u003e Maybe (a -\u003e a) 现在设想，我们有一个值 Just 2 haskell ghci\u003e :t Just 2 Just 2 :: Num a =\u003e Maybe a 那么，我们能否以某种方式结合 Just (1+) 和 Just 2 得到 Just (1+2) = Just 3 呢？毕竟，这是一件很自然的事情 你会发现无法用 fmap 做到这一点，因为 fmap 能用来 map 的函数的类型是 a -\u003e b ，是一个普通的一元函数，但现在函数在 Functor 里面（Maybe (a -\u003e a) 而不是 a -\u003e a）。那么，如果存在这么一个操作符 magicOperator，我们可以尝试推导它的类型签名，不难推出，应该是下面这样 信息 一元函数（Unary Function），意思是只有 1 个入参的函数 haskell magicOperator :: Maybe (a -\u003e b) -\u003e Maybe a -\u003e Maybe b 技巧 虽然无法直接用 fmap，但是我们可以通过 Pattern Matching 将 Just 里面的函数提取出来再用 fmap haskell apply Nothing _ = Nothing apply (Just f) Nothing = Nothing apply (Just f) (Just v) = fmap f (Just v) 但其他的 Functor 类型不一定支持你用 Pattern Matching 做提取 :( 如果将 Maybe 替换为一个抽象的 type constructor f，那么我们就可以得到 haskell magicOperator :: f (a -\u003e b) -\u003e f a -\u003e f b 恭喜你，你刚刚自己推导出了 Applicative Functor 的 \u003c*\u003e 操作符 前面我们只考虑 map 函数入参为 1 个的场景，现在来考虑 n 个入参 的场景，用函数 g 表示 map 函数，它的类型签名是 haskell g :: t1 -\u003e t2 -\u003e t3 -\u003e ... -\u003e tn -\u003e t 假设我们有一堆的 Functor xi，每一个 xi 的类型都是 f ti，因为 Haskell Function 的函数都是 Currying Functions，可以先从 fmap g x1 开始推导 haskell -- Note that -- 1. fmap :: (a -\u003e b) -\u003e f a -\u003e f b -- 2. g :: t1 -\u003e t2 -\u003e t3 -\u003e ... -\u003e tn -\u003e t -- 3. x1 :: f t1 fmap g x1 :: f (t2 -\u003e t3 -\u003e ... -\u003e tn -\u003e t) 接下来可以尝试推导 fmap g x1 x2，但很快会发现，类型对不上 haskell fmap g x1 :: f (t2 -\u003e t3 -\u003e ... -\u003e tn -\u003e t) x2 :: f t2 显然，这里应该用 Applicative Functor 的 \u003c*\u003e，正确的形式应该是 haskell fmap g x1 \u003c*\u003e x2 \u003c*\u003e x3 \u003c*\u003e x4 \u003c*\u003e ... \u003c*\u003e xn -- or, more simpler g \u003c$\u003e x1 \u003c*\u003e x2 \u003c*\u003e x3 \u003c*\u003e x4 \u003c*\u003e ... \u003c*\u003e xn 注意 所以结论是：我们需要 Applicative Functor 的 \u003c*\u003e，因为有的 Functor 里面是函数，有的 Functor 里面是值。\u003c*\u003e 可以将一个 Functor 里面的函数 apply 在另外一个 Functor 的值上，所以 \u003c*\u003e 起到了Function Application 的作用 ","date":"2024-10-20","objectID":"/zh-cn/why-applicative-functor/:1:0","series":null,"tags":["Haskell","Functional-Programming"],"title":"为什么需要 Applicative Functor","uri":"/zh-cn/why-applicative-functor/#为啥需要-applicative-functor"},{"categories":["Programming-Languages"],"content":" 什么是 Applicative Functor 警告 除了满足下面的定义之外，Applicative Functor 还应该满足 Haskell Applicative Laws 现在知道 Applicative Functor 的 \u003c*\u003e 是用来做 Function Application 的了，来看一下 Applicative 的定义 haskell class (Functor f) =\u003e Applicative f where pure :: a -\u003e f a (\u003c*\u003e) :: f (a -\u003e b) -\u003e f a -\u003e f b 先看 pure 函数，看函数签名就很好理解，a -\u003e f a，只是把一个普通的值 a 放到了 Applicative Functor 里面，最直观的应用就是将一个函数放到 Applicative Functor 里面。在前面的例子中，我们有 haskell fmap g x1 \u003c*\u003e x2 \u003c*\u003e x3 \u003c*\u003e x4 \u003c*\u003e ... \u003c*\u003e xn -- or, more simpler g \u003c$\u003e x1 \u003c*\u003e x2 \u003c*\u003e x3 \u003c*\u003e x4 \u003c*\u003e ... \u003c*\u003e xn 如果用 pure 的话，也可以这么写 haskell pure g \u003c*\u003e x1 \u003c*\u003e x2 \u003c*\u003e x3 \u003c*\u003e x4 \u003c*\u003e ... \u003c*\u003e xn \u003c*\u003e 在前面我们自己推导过，含义已经清晰了，这里不再赘述 让我们来看 Applicative Functor 的一个例子，Maybe 类型其实就是一个 Applicative Functor haskell instance Applicative Maybe where pure = Just (Just f) \u003c*\u003e (Just x) = Just (f x) _ \u003c*\u003e _ = Nothing ","date":"2024-10-20","objectID":"/zh-cn/why-applicative-functor/:2:0","series":null,"tags":["Haskell","Functional-Programming"],"title":"为什么需要 Applicative Functor","uri":"/zh-cn/why-applicative-functor/#什么是-applicative-functor"},{"categories":["Programming-Languages"],"content":" $, \u003c$\u003e, \u003c*\u003e现在让我们来对比一下 3 个都表达了 Function Application 的操作符 haskell ($) :: (a -\u003e b) -\u003e a -\u003e b (\u003c$\u003e) :: Functor f =\u003e (a -\u003e b) -\u003e f a -\u003e f b (\u003c*\u003e) :: Applicative f =\u003e f (a -\u003e b) -\u003e f a -\u003e f b 其中 ($) 是普通的函数调用，将一个普通的一元函数应用在一个普通的值上，但通常我们不会写 f $ x 而是直接写 f x \u003c$\u003e 是 fmap 的中缀形式，将一个普通的一元函数应用在一个 Functor 上 \u003c*\u003e 是 Applicative Functor 的操作符，将一个普通的一元函数 lift 到 Applicative Functor 里，然后应用在一个 Functor 上 ","date":"2024-10-20","objectID":"/zh-cn/why-applicative-functor/:3:0","series":null,"tags":["Haskell","Functional-Programming"],"title":"为什么需要 Applicative Functor","uri":"/zh-cn/why-applicative-functor/#--"},{"categories":["Programming-Languages"],"content":" 总结本文谈到了为什么有了 Functor，我们还需要 Applicative Functor。在我看来，Applicative Functor 最大的用处是我们可以方便地将任何一个普通函数 lift 到 Functor 里面，然后用 \u003c*\u003e 做 Function Application ","date":"2024-10-20","objectID":"/zh-cn/why-applicative-functor/:4:0","series":null,"tags":["Haskell","Functional-Programming"],"title":"为什么需要 Applicative Functor","uri":"/zh-cn/why-applicative-functor/#总结"},{"categories":["Vim-Neovim","Git"],"content":"介绍了如何在 Neovim 里面使用 vim-fugitive，对常见的 git 工作流都进行了介绍","date":"2024-10-11","objectID":"/zh-cn/my-workflow-of-using-vim-fugitive-in-neovim/","series":null,"tags":["Git","Vim","Neovim"],"title":"在 Neovim 里面使用 vim-fugitive 的工作流","uri":"/zh-cn/my-workflow-of-using-vim-fugitive-in-neovim/"},{"categories":["Vim-Neovim","Git"],"content":" 引言最近在使用 Git + Neovim 的时候，发现我的工作流还是有一些不那么顺畅的地方。我习惯性退出 Neovim，然后在命令行写 Git 相关的命令，并且在提交代码变更前我习惯用 delta 查看 diff 信息。为了减少要打的字符，我还开启了 Oh My Zsh 的 git 插件，这样我就可以用一堆缩写了，比如 ga = git add、gcmsg = git commit -m 不顺畅主要的原因是我发现我经常在 Neovim 和命令行之间切换，就像这样 flowchart i(编辑代码) ---\u003e|退出 Neovim| j(用 git diff 看下 diff 信息) ---\u003e k(发现有点小问题，需要修改) k ---\u003e|打开 Neovim| i 就在这时我想起了躺在我插件列表的 vim-fugitive，我记得它在 GitHub 主页 说过 it’s “so awesome, it should be illegal”，当时没有深究。于是今天我经过一番钻研之后，下面是我总结的一些使用 vim-fugitive 的工作流 ","date":"2024-10-11","objectID":"/zh-cn/my-workflow-of-using-vim-fugitive-in-neovim/:1:0","series":null,"tags":["Git","Vim","Neovim"],"title":"在 Neovim 里面使用 vim-fugitive 的工作流","uri":"/zh-cn/my-workflow-of-using-vim-fugitive-in-neovim/#引言"},{"categories":["Vim-Neovim","Git"],"content":" Workflows","date":"2024-10-11","objectID":"/zh-cn/my-workflow-of-using-vim-fugitive-in-neovim/:2:0","series":null,"tags":["Git","Vim","Neovim"],"title":"在 Neovim 里面使用 vim-fugitive 的工作流","uri":"/zh-cn/my-workflow-of-using-vim-fugitive-in-neovim/#workflows"},{"categories":["Vim-Neovim","Git"],"content":" Preliminary大多数命令行的的 Git 命令，你都可以替换为 :Git ...，比如 git blame 就是 :Git blame，其中 :Git 可以缩写为 :G ","date":"2024-10-11","objectID":"/zh-cn/my-workflow-of-using-vim-fugitive-in-neovim/:2:1","series":null,"tags":["Git","Vim","Neovim"],"title":"在 Neovim 里面使用 vim-fugitive 的工作流","uri":"/zh-cn/my-workflow-of-using-vim-fugitive-in-neovim/#preliminary"},{"categories":["Vim-Neovim","Git"],"content":" Git status用 vim-fugitive 查看当前仓库的状态非常简单，直接用 text :G 输出类似下面这样 text Head: main Merge: origin/main Help: g? Untracked (1) ? foo.py Staged (1) A bar.py Unpushed to origin/main (1) 7c08152 add .gitignore 其中 Untracked 表示新文件，还没有用 git 管理 Staged 表示添加到 staging area 的文件 Unpushed to origin/main 表示本地的 Commit 每个文件前面有一个文件状态码，不同的状态码的含义并不同 '' unmodified M modified T file type changed A added D deleted R renamed c copied U updated but unmerged ? untracked ! ignored ","date":"2024-10-11","objectID":"/zh-cn/my-workflow-of-using-vim-fugitive-in-neovim/:2:2","series":null,"tags":["Git","Vim","Neovim"],"title":"在 Neovim 里面使用 vim-fugitive 的工作流","uri":"/zh-cn/my-workflow-of-using-vim-fugitive-in-neovim/#git-status"},{"categories":["Vim-Neovim","Git"],"content":" Git add \u0026 git commit还是用前面的例子，如果我们想要把 foo.py 添加到 staging area 里面，就将光标停在 foo.py 上，然后按下 s text Head: main Merge: origin/main Help: g? Untracked (1) ? foo.py Staged (1) A bar.py Unpushed to origin/main (1) 7c08152 add .gitignore 你应该可以看到变成了下面这样 text Head: main Merge: origin/main Help: g? Staged (2) A bar.py A foo.py Unpushed to origin/main (1) 7c08152 add .gitignore 要撤销 staging 也很容易，按 u 就行，这个跟 Vim 的操作是一致的，很好记 最后，修改完文件之后，移动光标到文件上，按 cc，就会执行 git commit，可以看到弹出了一个 buffer 让我们填写 commit message，保存退出 commit 就添加成功了。除此之外，还有下面这些常用的命令 ca，ca = git commit --amend，将修改合并到 last commit 并且重新填写 commit message， ce，ca = git commit --amend --no-edit，将修改合并到 last commit 并且保持 commit message 不变 cw，用来修改 last commit message 将光标停留在 untracked file 上，然后按下 I，就可以看到文件的状态变成了 A。本质是帮我们执行了 git add --intent-to-add。git add --intent-to-add 的好处是本来 untracked file 也可以看 diff 了1，普通的 git add 做不到这点，前者对应 git status 的 Changes not staged for commit，后者对应 Changes to be committed，可以用 git status 验证一下 ","date":"2024-10-11","objectID":"/zh-cn/my-workflow-of-using-vim-fugitive-in-neovim/:2:3","series":null,"tags":["Git","Vim","Neovim"],"title":"在 Neovim 里面使用 vim-fugitive 的工作流","uri":"/zh-cn/my-workflow-of-using-vim-fugitive-in-neovim/#git-add--git-commit"},{"categories":["Vim-Neovim","Git"],"content":" See Git diff另外一个常用的功能是，查看文件的 diff 信息看我们具体修改了什么，比如下面的 text Head: main Merge: origin/main Help: g? Staged (2) A bar.py A foo.py Unpushed to origin/main (1) 7c08152 add .gitignore 如果该文件的代码变更并不多，那么直接将光标停在文件上按下 = 就可以看到 diff 信息了 技巧 再次按下 = 就可以将 diff 信息关闭 text Head: main Merge: origin/main Help: g? Staged (2) A bar.py A foo.py @@ -0,0 +1,2 @@ +def main(): + print(\"Please enter a integer\") Unpushed to origin/main (1) 7c08152 add .gitignore 但如果该文件的代码变更很大，那么可能 side-by-side 的 diff 信息展示更合理，此时只需要将光标停在文件上按下 dv 就可以， 技巧 如果用 dv 看 diff 信息，那么除了看之外，你还可以进行修改 ","date":"2024-10-11","objectID":"/zh-cn/my-workflow-of-using-vim-fugitive-in-neovim/:2:4","series":null,"tags":["Git","Vim","Neovim"],"title":"在 Neovim 里面使用 vim-fugitive 的工作流","uri":"/zh-cn/my-workflow-of-using-vim-fugitive-in-neovim/#see-git-diff"},{"categories":["Vim-Neovim","Git"],"content":" Git log直接用下面的命令就可以看到所有的 Commit 的信息 text :G log 可以看到新打开的 buffer 里展示了如下的信息 text commit 23ffed83d3ac5b3b7de37ecb29b55e5cf35b5f65 Author: MartinLwx \u003c*****************\u003e Date: Thu Oct 10 22:07:02 2024 +0800 add bar.py commit 7c081527a2dbadafbaf7907c5b547afc9e725ac9 Author: MartinLwx \u003c*****************\u003e Date: Thu Oct 10 22:05:54 2024 +0800 add .gitignore 将光标停留在 commit 上 按下 o 键 就可以在新的 buffer 看到这个 commit 的详细信息 技巧 用 ]] 和 [[ 可以快速在不同的 commit 之间移动 ","date":"2024-10-11","objectID":"/zh-cn/my-workflow-of-using-vim-fugitive-in-neovim/:2:5","series":null,"tags":["Git","Vim","Neovim"],"title":"在 Neovim 里面使用 vim-fugitive 的工作流","uri":"/zh-cn/my-workflow-of-using-vim-fugitive-in-neovim/#git-log"},{"categories":["Vim-Neovim","Git"],"content":" Git blame这里单独挑 git blame 出来是因为 vim-fugitive 的 git blame 展示非常直观，左边清楚展示了是什么 commit 引入的变更，以及是哪个作者引入的。对应的命令是 :G blame text 23ffed83 1 (MartinLwx 2024-10-10 22:07:02 +0800 1) def main(): 23ffed83 2 (MartinLwx 2024-10-10 22:07:02 +0800 2) print(\"Please enter a integer\") 更厉害的是，这个 :G blame 的输出是可以交互的，比如你想要展示 commit 更详细的信息，只需要将光标停留在 commit 上，然后按下 o ","date":"2024-10-11","objectID":"/zh-cn/my-workflow-of-using-vim-fugitive-in-neovim/:2:6","series":null,"tags":["Git","Vim","Neovim"],"title":"在 Neovim 里面使用 vim-fugitive 的工作流","uri":"/zh-cn/my-workflow-of-using-vim-fugitive-in-neovim/#git-blame"},{"categories":["Vim-Neovim","Git"],"content":" Split code change into multiple commits很多时候，你修改了代码完成了多个功能的开发或者是 Bug 修复，但是你中途忘记一边改一边提交 commit 了，那么要如何拆分不同的代码变更分别提交 commit？（毕竟一个 commit 解决一个问题是好的实践） 先来看 foo.py 文件，假设它本来是这样子的 python def main(): print(\"Please enter a integer\") 然后我们做了如下的代码变更，并且假设每个分支代表一个特性的添加或者是功能的修复 python def main(): i = input(\"Please enter a integer\") if i == 0: print(\"i == 0\") elif i == 1: print(\"i == 1\") else: print(\"i not in [0, 1]\") 将光标停留在文件上，按 = 就可以看到 diff 信息 text Head: main Push: origin/main Help: g? Unstaged (1) M foo.py @@ -1,2 +1,8 @@ def main(): i = input(\"Please enter a integer\") + if i == 0: + print(\"i == 0\") + elif i == 1: + print(\"i == 1\") + else: + print(\"i not in [0, 1]\") Unpushed to * (3) d2d951f add foo.py 23ffed8 add bar.py 7c08152 add .gitignore 接下来用 V 选中如下 2 行 text + if i == 0: + print(\"i == 0\") 然后按下 s 单独 stage 部分代码变更，此时下方就会出现一个 Staged 的文件 text Head: main Push: origin/main Help: g? Unstaged (1) M foo.py @@ -2,3 +2,7 @@ def main(): i = input(\"Please enter a integer\") if i == 0: print(\"i == 0\") + elif i == 1: + print(\"i == 1\") + else: + print(\"i not in [0, 1]\") Staged (1) M foo.py Unpushed to * (3) d2d951f add foo.py 23ffed8 add bar.py 7c08152 add .gitignore 用 cc 提交 commit 即可 text Head: main Push: origin/main Help: g? Unstaged (1) M foo.py @@ -2,3 +2,7 @@ def main(): i = input(\"Please enter a integer\") if i == 0: print(\"i == 0\") + elif i == 1: + print(\"i == 1\") + else: + print(\"i not in [0, 1]\") Unpushed to * (4) c46474f add i == 0 d2d951f add foo.py 23ffed8 add bar.py 7c08152 add .gitignore 可以看到我们新添加了一个 commit c46474f add i == 0，这个步骤可以多次执行 技巧 ]c 和 [c 可以在不同的 diff 信息之间快速移动 如法炮制，就完成了代码变更的拆分 ","date":"2024-10-11","objectID":"/zh-cn/my-workflow-of-using-vim-fugitive-in-neovim/:2:7","series":null,"tags":["Git","Vim","Neovim"],"title":"在 Neovim 里面使用 vim-fugitive 的工作流","uri":"/zh-cn/my-workflow-of-using-vim-fugitive-in-neovim/#split-code-change-into-multiple-commits"},{"categories":["Vim-Neovim","Git"],"content":" Git rebase -igit rebase -i 是我另外一个常用的功能，这里我们可以尝试将刚才拆分的 3 个 commit 合并 text 68081e9 add else branch f9dfc93 add i == 1 c46474f add i == 0 先用 :G log 展开 commit history text commit 68081e928ad8dbbafc8e20ebefaeb7f3dad968bf Author: MartinLwx \u003c****************\u003e Date: Thu Oct 10 23:10:14 2024 +0800 add else branch commit f9dfc93d9846a3cec6220b0f91b8e4a84dcb9367 Author: MartinLwx \u003c****************\u003e Date: Thu Oct 10 22:57:04 2024 +0800 add i == 1 commit c46474f9cf8c34071fa95f797e94ffc75b1ee3e2 Author: MartinLwx \u003c****************\u003e Date: Thu Oct 10 22:55:03 2024 +0800 add i == 0 然后将光标停留在 add i == 0 这一个对应的 commit 上，按下 ri（Hint：ri = rebase -i），然后进行如下修改 text r c46474f add i == 0 s f9dfc93 add i == 1 s 68081e9 add else branch 合并之后 text Head: main Push: origin/main Help: g? Unpushed to * (4) c814dce merge 3 commits d2d951f add foo.py 23ffed8 add bar.py 7c08152 add .gitignore ","date":"2024-10-11","objectID":"/zh-cn/my-workflow-of-using-vim-fugitive-in-neovim/:2:8","series":null,"tags":["Git","Vim","Neovim"],"title":"在 Neovim 里面使用 vim-fugitive 的工作流","uri":"/zh-cn/my-workflow-of-using-vim-fugitive-in-neovim/#git-rebase--i"},{"categories":["Vim-Neovim","Git"],"content":" Resolve merge conflicts最后看一下，分支合并的时候要如何使用 vim-fugitive，假设在另外一个叫作 feature 的分支上，foo.py 代码长这样子 text def main(): i = input(\"Please enter a integer\") if i == 0: i = i + 1 else: i = i + 2 我们在 main 分支下用 text :G merge feature 此时用 :G 看到的会是这样子 text Head: main Push: origin/main Help: g? Unstaged (1) U foo.py Staged (1) U foo.py Unpushed to * (6) 21055dc add else branch f9dfc93 add i == 1 c46474f add i == 0 d2d951f add foo.py 23ffed8 add bar.py 7c08152 add .gitignore 其中我们需要关注的是 Unstaged 里面的文件，需要修改这些文件解决合并冲突。为了解决方便冲突，光标在文件上停留然后按下 dv，就可以看到打开了 3 个 buffer 左边的是发起合并的分支的代码，也就是 main 分支 中间的是冲突的代码 右边的是被合并的分支的代码，也就是 feature 分支 只需要在中间的 buffer 修改好代码冲突，用 :Gwrite 就完成了文件的保存以及将其添加到 staging area 里 但有时候，你可能只是想要采用某一个分支的代码，那么在中间修改冲突比较繁琐而且没啥意义，这个时候直接移动到左边的 buffer 或者右边的 buffer（取决于你想要哪一个分支的代码），然后用 :Gwrite! 进行文件保存以及将其添加到 staging area 里 无论是上面哪一种情况，最后都需要用 cc 提交一下 commit，分支就合并好了 text Head: main Push: origin/main Help: g? Unpushed to * (8) d23d66e Merge branch 'feature' 6ad1330 nonsense update 21055dc add else branch f9dfc93 add i == 1 c46474f add i == 0 d2d951f add foo.py 23ffed8 add bar.py 7c08152 add .gitignore ","date":"2024-10-11","objectID":"/zh-cn/my-workflow-of-using-vim-fugitive-in-neovim/:2:9","series":null,"tags":["Git","Vim","Neovim"],"title":"在 Neovim 里面使用 vim-fugitive 的工作流","uri":"/zh-cn/my-workflow-of-using-vim-fugitive-in-neovim/#resolve-merge-conflicts"},{"categories":["Vim-Neovim","Git"],"content":" 总结以上就是我发现的 vim-fugitive 的工作流，并且使用了有一会。对于我而言，我发现确实之前的不顺畅感消失了，我感觉在 Neovim 里面用 Git 更加高效了，因为我不再需要频繁地在 Neovim、Terminal 之间进行上下文切换。而频繁的上下文切换可是会降低生产力的2 https://stackoverflow.com/questions/24329051/what-does-git-add-intent-to-add-or-n-do-and-when-should-it-be-used ↩︎ https://www.software.com/devops-guides/context-switching ↩︎ ","date":"2024-10-11","objectID":"/zh-cn/my-workflow-of-using-vim-fugitive-in-neovim/:3:0","series":null,"tags":["Git","Vim","Neovim"],"title":"在 Neovim 里面使用 vim-fugitive 的工作流","uri":"/zh-cn/my-workflow-of-using-vim-fugitive-in-neovim/#总结"},{"categories":["Program-Analysis"],"content":"介绍了 Tree-sitter 的基本工作原理，详细介绍了 Query 的使用","date":"2024-09-07","objectID":"/zh-cn/tree-sitter-and-its-query/","series":null,"tags":["Compiler","Program-Analysis"],"title":"Tree-sitter 以及它的 Query 功能","uri":"/zh-cn/tree-sitter-and-its-query/"},{"categories":["Program-Analysis"],"content":" Info 更新： 2025-04-26: 修复了失效的 Playground 链接；新增 Playground in Neovim 章节 ","date":"2024-09-07","objectID":"/zh-cn/tree-sitter-and-its-query/:0:0","series":null,"tags":["Compiler","Program-Analysis"],"title":"Tree-sitter 以及它的 Query 功能","uri":"/zh-cn/tree-sitter-and-its-query/#"},{"categories":["Program-Analysis"],"content":" 引言Tree-sitter 是一个 Parse Generator，也就是用来生成 Parser 的。除此之外，它还提供了一些额外的功能，比如今天要聊到的 Tree-sitter Query ，Query 提供了一套基于 S 表达式的 DSL（Domain Specific Language），可以查询 AST，获得你想要的信息，在正式学习如何使用 Query 前，我们先讲一些相关的背景知识，好让这个文章尽量是 Self-contained 的 ","date":"2024-09-07","objectID":"/zh-cn/tree-sitter-and-its-query/:1:0","series":null,"tags":["Compiler","Program-Analysis"],"title":"Tree-sitter 以及它的 Query 功能","uri":"/zh-cn/tree-sitter-and-its-query/#引言"},{"categories":["Program-Analysis"],"content":" S 表达式 信息 如果你曾经写过 Lisp 或者是其他 Lisp 方言（比如 Scheme、Racket 等），你对 S 表达式应该很熟悉 S 表达式的定义是递归式的，定义如下 S 表达式为 x，这里的 x 是 Atom，Atom 就是不可再分解的意思 S 表达式不为空，而是 (S1 S2 ... Sn) 的形式，其中从 S1 到 Sn 都是 S 表达式 S 表达式是递归式定义的，树也是递归式定义的，因此 S 表达式可以用来表示树，以一个简单的 AST 为例 python + / \\ 1 - / \\ 2 3 上面的 AST 就是一个简单的 1 + (2 - 3)，而它的 S 表达式是 lisp (+ 1 (- 2 3)) 这种情况下，每个 () 里面，第一个是父节点，其他的则是这个父节点的孩子节点 ","date":"2024-09-07","objectID":"/zh-cn/tree-sitter-and-its-query/:2:0","series":null,"tags":["Compiler","Program-Analysis"],"title":"Tree-sitter 以及它的 Query 功能","uri":"/zh-cn/tree-sitter-and-its-query/#s-表达式"},{"categories":["Program-Analysis"],"content":" AST in Tree-sitterTree-sitter 支持生成很多编程语言的 Parser，每一个支持的编程语言都有一个对应的 tree-sitter-* GitHub 仓库，比如 Python 的就是 tree-sitter-python 每一个 tree-sitter-* 仓库里面都会有一个 grammar.js 文件，这个文件定义了对应编程语言的 AST 结构，以 tree-sitter-python 为例，Python 里面的 for 循环语句的语法是这样子的 js for_statement: $ =\u003e seq( optional('async'), 'for', field('left', $._left_hand_side), 'in', field('right', $._expressions), ':', field('body', $._suite), field('alternative', optional($.else_clause)), ), 如果对编译器有一定了解，我们不难就不难看出 Python 的 For 循环语句大概是这样子的 python [async] for \u003cleft\u003e in \u003cright\u003e: \u003cbody\u003e [\u003celse_clause\u003e] 技巧 [] 表示可选项，\u003c\u003e 表示还有另外的 Non-terminal，可以进一步展开 知道 Tree-sitter 的 AST 是如何定义出来之后，我们当然要知道如何用 Tree-sitter 生成的 Parser 去生成代码的 AST 我们可以使用命令行，首先用 homebrew 安装并进行配置 sh $ brew install tree-sitter $ tree-sitter init-config 然后，克隆你要分析的编程语言的 tree-sitter-* 仓库并生成 Parser，后面要以 Python 代码为例子，因此这里就用 tree-sitter-python 作为例子 sh $ git clone git@github.com:tree-sitter/tree-sitter-python.git $ tree-sitter generate # generate a parser in src/parser.c 技巧 如果想要在任意目录都可以用 tree-sitter 解析，那么就 调用 tree-sitter init-config 确定你使用的操作系统的 tree-sitter 配置文件位置 打开配置文件查看 parse-directories 字段看都有哪一些文件夹 将 tree-sitter-* 仓库放到对应文件夹下（任意挑一个）即可 现在在同个目录下，你就可以生成 Python 代码的 AST 了，让我们先写一段简单的 Python 代码 python def sum(x: int, y: int) -\u003e int: return x + y sum(1, 2) 通过如下的命令就可以得到 S 表达式的 AST 了 sh $ tree-sitter parse foo.py lisp (module [0, 0] - [5, 0] (function_definition [0, 0] - [1, 16] name: (identifier [0, 4] - [0, 7]) parameters: (parameters [0, 7] - [0, 23] (typed_parameter [0, 8] - [0, 14] (identifier [0, 8] - [0, 9]) type: (type [0, 11] - [0, 14] (identifier [0, 11] - [0, 14]))) (typed_parameter [0, 16] - [0, 22] (identifier [0, 16] - [0, 17]) type: (type [0, 19] - [0, 22] (identifier [0, 19] - [0, 22])))) return_type: (type [0, 27] - [0, 30] (identifier [0, 27] - [0, 30])) body: (block [1, 4] - [1, 16] (return_statement [1, 4] - [1, 16] (binary_operator [1, 11] - [1, 16] left: (identifier [1, 11] - [1, 12]) right: (identifier [1, 15] - [1, 16]))))) (expression_statement [4, 0] - [4, 9] (call [4, 0] - [4, 9] function: (identifier [4, 0] - [4, 3]) arguments: (argument_list [4, 3] - [4, 9] (integer [4, 4] - [4, 5]) (integer [4, 7] - [4, 8]))))) 其中 [x1, y1] - [x2, y2] 这个的意思是，这个 AST 节点对应的源码在源文件的 x1 行到 x2 行，y1 到 y2 列，索引从 0 开始，左闭右开 ","date":"2024-09-07","objectID":"/zh-cn/tree-sitter-and-its-query/:3:0","series":null,"tags":["Compiler","Program-Analysis"],"title":"Tree-sitter 以及它的 Query 功能","uri":"/zh-cn/tree-sitter-and-its-query/#ast-in-tree-sitter"},{"categories":["Program-Analysis"],"content":" Basic Query Syntax那么如何在 AST 中找到自己感兴趣的节点呢？这就是 Query 要做的事情了 Query 就是一个 S 表达式，比如我们想要找到 Python 代码里面的函数定义，它对应的 S 表达式如下 lisp (function_definition) 同时，Tree-sitter 还允许我们 返回被匹配到的内容，保存在一个变量里面，只需要在 @variable_name 放在 AST 节点对应的 S 表达式的后面，比如 lisp (function_definition) @func 技巧 现在，被匹配到的 Python 函数的源代码都会被保存在 func 这个变量里面 技巧 在 Tree-sitter 的语法文件里面，AST 节点分为 2 种，一种是带名字的（Named AST Nodes），一种是匿名的（Anonymous AST Nodes）。对于 Named AST Node，它在 AST 里面的形式是：field_name: S-expression 另外，Tree-sitter 还支持指定 AST 节点必须有某些类型的孩子节点，只需要加上 field: 这种前缀。比如我们要找有返回类型声明的 Python 函数 lisp (function_definition return_type: (type)) @has_return_type_func 也支持指定 AST 节点不能有某些类型的孩子节点，只需要在 field 的前面用 ! 即可。比如下面的例子要找的是没有返回类型声明的 Python 函数 lisp (function_definition !return_type) @no_return_type_func 那么对于 Anonymous AST 节点呢？直接指定要匹配的结果即可，不需要用 ()。还是用前面的代码作为例子，我们想要找二元操作，而且执行的是 + 法，就可以这么写 lisp (binary_operator operator: \"+\") @add_op 技巧 匿名 AST 节点不会在导出的 AST 里面，那要如何写 Query 呢？查看对应编程语言的 grammar.js 文件，比如我这里就参考了 这几行 ","date":"2024-09-07","objectID":"/zh-cn/tree-sitter-and-its-query/:4:0","series":null,"tags":["Compiler","Program-Analysis"],"title":"Tree-sitter 以及它的 Query 功能","uri":"/zh-cn/tree-sitter-and-its-query/#basic-query-syntax"},{"categories":["Program-Analysis"],"content":" Advanced Query SyntaxQuery 还支持更多的语法，像正则表达式里面的 *, ?, +, [abc] 都支持的，考虑这么一个场景，我们有如下的 3 个 Python 列表 python arr1 = [] arr2 = [1] arr3 = [1, 2] 我们想要提取每个这样的列表里面的数字，但可能有 0 个，也可能有任意个，这恰恰是正则表达式里面的 * 的用法，因此我们可以写出如下的 Query lisp ((integer) (\",\" (integer))*)@int_list 另外 Query 还支持 . 这种标记，根据出现的位置不同含义也不同，前面提到，对于一个 (S1 S2 ... Sn) 这样的 S 表达式，S1 是父节点，S2 ... Sn 都是它的子节点 如果 . 出现在 S1 后面，那么 S2 必须是父节点 S1 的第一个孩子。现在假设我们要从 arr1, arr2, arr3 中提取第一个元素（若有），那么我们可以这么写 lisp (list . (integer) @first_int) 如果 . 出现在 Sn 的后面，那么 Sn 必须是父节点 S1 的最后一个孩子，同理，我们可以提取 arr1, arr2, arr3 的最后一个元素 lisp (list (integer) @last_int .) 现在情况更加复杂，Python 列表是动态的，可能包含各种数据类型的元素，比如 python arr1 = [] arr2 = [None] arr3 = [1, 2, \"90\"] 这个时候我们就不能用 (integer) 去匹配了，我们需要一种特殊的表达式，表示可以匹配任意 AST 节点类型，在 Python 里面，_ 可以起到这样的功能。Tree-sitter 的 Query 也是，所以我们可以写 lisp (list (_) @last_int .) 技巧 (_) 可以匹配 Named AST Node，_ 可以匹配 Named AST Node 或者 Anonymous AST Node ","date":"2024-09-07","objectID":"/zh-cn/tree-sitter-and-its-query/:5:0","series":null,"tags":["Compiler","Program-Analysis"],"title":"Tree-sitter 以及它的 Query 功能","uri":"/zh-cn/tree-sitter-and-its-query/#advanced-query-syntax"},{"categories":["Program-Analysis"],"content":" More Advanced Query Syntax只是用 @variable_name 获取被匹配的内容似乎没有多大用处，要是可以基于被匹配的内容做进一步的筛选就好了，Tree-sitter Query 也是支持的，这叫做 predicate 每一个 predicate 也是一个 S 表达式，形如 (S1 S2 S3) S1 的位置可以是 #eq?, #not-eq?, #any-eq?, #any-not-eq?, #match?, #not-match?, #any-match?, #any-not-match?, #any-of?, #not-any-of? 中的任意一个，看名字就知道意思了 S2 的位置必须是 @variable_name S3 的位置可以是 @variable_name，或者是字符串（使用 *eq? 时）、正则表达式（使用 *match? 时）、候选列表（使用 *-of? 时，直接列出来即可，不需要用 () 括起来） 信息 Lisp 或者是其他的 Lisp 方言里面就有一个 eq? 函数 现在，我们尝试用 predicate 进行筛选：提取列表里面的最后一个元素，而且当且仅当它是字符串 \"90\" 的时候，不难用下面的 Query 表达式进行验证 lisp (list (string) @last_str (#eq? @last_str \"90\") .) ","date":"2024-09-07","objectID":"/zh-cn/tree-sitter-and-its-query/:6:0","series":null,"tags":["Compiler","Program-Analysis"],"title":"Tree-sitter 以及它的 Query 功能","uri":"/zh-cn/tree-sitter-and-its-query/#more-advanced-query-syntax"},{"categories":["Program-Analysis"],"content":" Bindings前面都是用命令行工具或者直接在官网的 Playground 上进行验证，那能否将这些功能融入其他编程语言的代码里面呢？当然可以，具体处置的编程语言可以看 官网 以 Python 的 binding 为例，我们需要先安装 sh $ pip install tree-sitter $ pip install tree-sitter-python 然后就可以开始编写代码了，先生成 Parser 然后解析代码得到 AST python import tree_sitter_python as tspython from tree_sitter import Language, Parser PY_LANGUAGE = Language(tspython.language()) code = \"\"\"def sum(x: int, y: int) -\u003e int: return x + y sum(1, 2) \"\"\" parser = Parser(PY_LANGUAGE) tree = parser.parse(bytes(code, encoding=\"utf8\")) 现在 tree 就是解析得到的 AST，我们可以查看根节点的类型以及对应的源码的起始位置 python parser = Parser(PY_LANGUAGE) tree = parser.parse(bytes(code, encoding=\"utf8\")) root_node = tree.root_node print(root_node.type) # module print(root_node.start_point) # Point(row=0, column=0) print(root_node.end_point) # Point(row=5, column=0) 可以看到，结果和之前命令行的输出是一致的 lisp (module [0, 0] - [5, 0] ... ;; omit 这里我们可以写一个 Query，提取函数里面带类型提示的入参，并打印参数名、参数类型 python query = PY_LANGUAGE.query( \"\"\"(typed_parameter (identifier)@name type: (type (identifier)@val))\"\"\" ) captures = query.captures(root_node) for arg_name, arg_type in zip(captures[\"name\"], captures[\"val\"]): print(f\"{str(arg_name.text)}: {str(arg_type.text)}\") ","date":"2024-09-07","objectID":"/zh-cn/tree-sitter-and-its-query/:7:0","series":null,"tags":["Compiler","Program-Analysis"],"title":"Tree-sitter 以及它的 Query 功能","uri":"/zh-cn/tree-sitter-and-its-query/#bindings"},{"categories":["Program-Analysis"],"content":" Playground in Neovim如果你跟我一样也使用 Neovim 并且安装了 nvim-treesitter 的话，它其实自带了一个 Playground 只需要用 :EditQuery 就可以启动可交互的 Playground，如下图所示 可以看到，被匹配的源代码会有阴影包裹 :) ","date":"2024-09-07","objectID":"/zh-cn/tree-sitter-and-its-query/:8:0","series":null,"tags":["Compiler","Program-Analysis"],"title":"Tree-sitter 以及它的 Query 功能","uri":"/zh-cn/tree-sitter-and-its-query/#playground-in-neovim"},{"categories":["Program-Analysis"],"content":" 总结Tree-sitter 是一个强大又轻量的 Parser Generator，在做程序分析的时候我经常都会用它生成的 Parser 加上 Query 功能在 AST 里面提取信息，这些信息可以用于做进一步的分析。和 ANTLR 以及其他的 Parser Generator 相比，我感觉还是 Tree-sitter 更好用一些。这可能是因为我学过 Scheme、Racket 这种 Lisp 形式的编程语言，用 S 表达式写 Query 让我感觉很亲切 :) ","date":"2024-09-07","objectID":"/zh-cn/tree-sitter-and-its-query/:9:0","series":null,"tags":["Compiler","Program-Analysis"],"title":"Tree-sitter 以及它的 Query 功能","uri":"/zh-cn/tree-sitter-and-its-query/#总结"},{"categories":["Programming-Languages"],"content":"对 Python 3.7 引入的 dataclass 的一个简明教程，覆盖语法、语义等","date":"2024-08-17","objectID":"/zh-cn/learn-to-use-dataclass-in-python/","series":null,"tags":["Python"],"title":"@dataclass 简明教程（Python3.7）","uri":"/zh-cn/learn-to-use-dataclass-in-python/"},{"categories":["Programming-Languages"],"content":" 引言Python 的 tuple 很好用，它可以让我们快速地将不同类型的值封装在一起，作为一个整体进行管理，自带的排序规则也十分直观，简单易用。但实际用下来我发现，一旦 tuple 的字段比较多，我就被迫要自己写一下注释注明一下不同位置的字段的具体含义是啥，比如 python t = (3, 4, 3.5) # (x, y, value) 后面我就可以跳到这个定义的地方通过看注释来弄清楚每个字段的含义。但这确实带来了诸多不便，代码一旦变长就不大好定位该行语句 于是想说可以写一个类，这样我就可以「用名字而不是位置」去引用某个字段，但是写一个类要自己重写 __init__、__repr__ 等，这里面很多代码都是冗余的。今天要讲的 dataclass 就是要解决这个问题，不用写很多冗余的代码，就可以起到一样的效果，即实现一个 Named Tuple 技巧 学习任何一个语言的特性只需要弄清楚几个问题 语法是什么？ 语义是什么？ 有哪些适合的场景？ ","date":"2024-08-17","objectID":"/zh-cn/learn-to-use-dataclass-in-python/:1:0","series":null,"tags":["Python"],"title":"@dataclass 简明教程（Python3.7）","uri":"/zh-cn/learn-to-use-dataclass-in-python/#引言"},{"categories":["Programming-Languages"],"content":" 语法 python from dataclasses import dataclass @dataclass class Point: x: int y: int value: float = 0.0 上面是定义了一个 Point 的例子，它包含 3 个字段，坐标 (x, y) 和该坐标对应的值 value（默认值是 0）。从例子中可以看出 dataclass 是一个 Python 装饰器，用来装饰一个类 对于类的实例变量，必须加上类型提示，并且允许设置默认值 ","date":"2024-08-17","objectID":"/zh-cn/learn-to-use-dataclass-in-python/:2:0","series":null,"tags":["Python"],"title":"@dataclass 简明教程（Python3.7）","uri":"/zh-cn/learn-to-use-dataclass-in-python/#语法"},{"categories":["Programming-Languages"],"content":" 语义那么这样的一个类有啥功能呢？ python ... # omitted foo = Point(3, 4, 3.5) # __init__ bar = Point(3, 4, 3.5) # __init__ print(foo) # __repr__ print(foo.x) # named reference print(foo == bar) # __eq__ 可以看到，@dataclass 自动帮我们实现了 __init__, __repr__, __eq__，并且我们可以用名字去引用某个字段的值 从原理上来看，加上类型提示的字段会被存储在类的 __annotations__ 属性里面（按照声明的顺序） python print(Point.__annotations__) # {'x': \u003cclass 'int'\u003e, 'y': \u003cclass 'int'\u003e, 'value': \u003cclass 'float'\u003e} 所以总结来说，语义是这样的： 根据声明的字段自动生成 __init__, __repr__, __eq__ 方法，如果类本身已经有了这些方法，则优先用类自己定义的 带有类型提示的字段会成为上述生成的方法的参数，参数的顺序就是字段声明的顺序 以 __init__ 为例，上面的类其实会生成下面的 __init__ 方法 python class Point: ... def __init__(self, x: int, y: int, value: float = 0.0): self.x = x self.y = y self.value = value ","date":"2024-08-17","objectID":"/zh-cn/learn-to-use-dataclass-in-python/:3:0","series":null,"tags":["Python"],"title":"@dataclass 简明教程（Python3.7）","uri":"/zh-cn/learn-to-use-dataclass-in-python/#语义"},{"categories":["Programming-Languages"],"content":" 高级用法上面的使用已经足以覆盖大多数使用场景，但 dataclass 其实提供了更多，它允许我们控制装饰类的过程甚至是每个字段的行为，这是不同粒度的控制，一个是针对整体，一个是针对字段 @dataclass 本身是一个装饰器，装饰器就是函数，我们可以通过控制函数的参数来控制装饰类的过程，我把几个比较重要的配置项罗列在下面，同时我给出了这些配置项的默认值 python @dataclass( init=true, # generate __init__ method repr=true, # generate __repr__ method # default format: \u003cclassname\u003e(field1=..., field2=..., ...) eq=true, # compare dataclasses like tuples order=false, # generate __lt/lt/gt/ge__ methods frozen=false, # if true, assigning to fields will generate an exception ) 以 order 为例，比如我们希望刚才的 Point 类是可以比较的：先按照坐标 (x, y) 然后按照 value 比较，我们可以这么写代码 python from dataclasses import dataclass @dataclass(order=True) class Point: x: int y: int value: float foo = Point(3, 4, 3.5) # __init__ bar = Point(3, 4, 4.5) # __init__ print(foo \u003c bar) # __eq__ datclass 的 field 是用来控制每个字段的行为的，同样有很多可以定制的选项，完整的可以参考 这里，我下面只讲一下最重要的几个 defalt, default_factory，这两个是用来给字段设置默认值的，前置直接设置默认值，后者则可以指定了一个不带有参数的构造函数（比如 list, set 等都是可以的），根据自己的需要选择其中一个即可 repr，是否要将这个字段放到 __repr__ 里面 仍然用前面的 Point 作为例子，我们想要把 value 变成 values，也就是每个字段可以有一堆的值，那么我们可以这么写 python from dataclasses import dataclass, field @dataclass class Point: x: int y: int value: list[float] = field(default_factory=list) foo = Point(3, 4, [3.5, 4.5, 5.5]) # __init__ print(foo.__annotations__) 最后再谈一下涉及到继承的场景，被 @dataclass 装饰的类也是类，也能用于继承，那么当一个 data class 继承另外一个 data class 会发生什么呢？特别是有相同名字的字段的场景，比如 python from dataclasses import dataclass @dataclass class A: x: int = 1 y: int = 2 z: int = 5 @dataclass class B(A): x: int = 3 y: int = 4 foo = B() print(foo) # B(x=3, y=4, z=5) 继承的原理是这样的 1 检查被装饰类的所有父类（按照 MRO 的逆序），也就是从 Object 开始一路沿着子类收集 fields 最后加上被装饰类自己的 fields，这样就完成了fields 的合并。注意这里可能出现同名的 field 这种情况，后面的会覆盖前面的 ","date":"2024-08-17","objectID":"/zh-cn/learn-to-use-dataclass-in-python/:4:0","series":null,"tags":["Python"],"title":"@dataclass 简明教程（Python3.7）","uri":"/zh-cn/learn-to-use-dataclass-in-python/#高级用法"},{"categories":["Programming-Languages"],"content":" FAQ","date":"2024-08-17","objectID":"/zh-cn/learn-to-use-dataclass-in-python/:5:0","series":null,"tags":["Python"],"title":"@dataclass 简明教程（Python3.7）","uri":"/zh-cn/learn-to-use-dataclass-in-python/#faq"},{"categories":["Programming-Languages"],"content":" dataclass 如何区分类变量和实例变量？用类型提示区分类变量和实例变量，类变量的类型是 typing.ClassVar python from typing import ClassVar from dataclasses import dataclass, field @dataclass class Point: x: int y: int value: list[float] = field(default_factory=list) a_class_variable: ClassVar[int] = 3 a_point = Point(3, 4) print(Point.a_class_variable) ","date":"2024-08-17","objectID":"/zh-cn/learn-to-use-dataclass-in-python/:5:1","series":null,"tags":["Python"],"title":"@dataclass 简明教程（Python3.7）","uri":"/zh-cn/learn-to-use-dataclass-in-python/#dataclass-如何区分类变量和实例变量"},{"categories":["Programming-Languages"],"content":" vs namedtuple参考自 1 @dataclass collections.namedtuple 字段值一样但不同类型是否看作相等（Point3D(2017, 6, 2) == Date(2017, 6, 2)) ❌ ✅ 为字段设置默认值 ✅ ❌ 控制每个字段的行为（__init__, __repr__, etc） ✅ ❌ 通过继承的方式结合多个字段 ✅ ❌ ","date":"2024-08-17","objectID":"/zh-cn/learn-to-use-dataclass-in-python/:5:2","series":null,"tags":["Python"],"title":"@dataclass 简明教程（Python3.7）","uri":"/zh-cn/learn-to-use-dataclass-in-python/#vs-namedtuple"},{"categories":["Programming-Languages"],"content":" 总结Python 的 @dataclass 让我们可以用 declarative 的形式描述一个类，我们只需要描述每个字段的类型、默认值等，他就会帮我们自动生成有用的一些函数，可以理解为 data class = mutable namedtuple with default value 👍 ","date":"2024-08-17","objectID":"/zh-cn/learn-to-use-dataclass-in-python/:6:0","series":null,"tags":["Python"],"title":"@dataclass 简明教程（Python3.7）","uri":"/zh-cn/learn-to-use-dataclass-in-python/#总结"},{"categories":["Programming-Languages"],"content":" 参考 PEP 557 – Data Classes ↩︎ ↩︎ ","date":"2024-08-17","objectID":"/zh-cn/learn-to-use-dataclass-in-python/:7:0","series":null,"tags":["Python"],"title":"@dataclass 简明教程（Python3.7）","uri":"/zh-cn/learn-to-use-dataclass-in-python/#参考"},{"categories":["Software-Engineering"],"content":"利用 GitHub Actions 自动化 Hugo 博客的部署","date":"2024-07-29","objectID":"/zh-cn/use-github-actions-to-automate-hugo-build/","series":null,"tags":["DevOps","CI/CD","GitHub"],"title":"使用 GitHub Actions 自动化 Hugo 博客部署","uri":"/zh-cn/use-github-actions-to-automate-hugo-build/"},{"categories":["Software-Engineering"],"content":" 前言最近在学习 GitHub Actions，GitHub Actions 是 GitHub 提供的一个特性，可以用来自动化执行一些步骤。在软件开发中，最常见的需要自动化的场景可能就是构建了。对于编译型的编程语言（比如 C/C++）编写的软件，通常需要编写对应的构建的脚本，软件构建的过程涉及到：环境准备、依赖下载、启动构建等。不过，利用 GitHub Actions 来自动化软件构建过程并不是本文的主题。在我思考我可以将 GitHub Actions 用于何处的时候，我想到了：利用 GitHub Actions 来自动化 Hugo 博客的部署。因为 Hugo 博客的部署也涉及到不少一系列固定的步骤 :) ","date":"2024-07-29","objectID":"/zh-cn/use-github-actions-to-automate-hugo-build/:1:0","series":null,"tags":["DevOps","CI/CD","GitHub"],"title":"使用 GitHub Actions 自动化 Hugo 博客部署","uri":"/zh-cn/use-github-actions-to-automate-hugo-build/#前言"},{"categories":["Software-Engineering"],"content":" 背景我的 Hugo 博客包含了 2 个仓库 public 仓库 - martinlwx.github.io，存放了生成的 Hugo 静态网站 private 仓库，该仓库存放了 Hugo 的配置文件，以及博客文章的原始 Markdown 文件。private 仓库下存在一个 ./public 目录，是一个 git submodule，指向了前面提到的 public 仓库 大概长下面这个样子 flowchart LR private(\"Private repo\") --\u003e|git push| public(\"Public repo: martinlwx.github.io\") Warning 如果你没有使用 Algolia 的话，你就没有必要上传 index.json 文件 部署 Hugo 博客的流程是这样子的：先写好文章，然后用 Hugo 生成静态博客，然后将生成的 index.json 文件用 atomic-algolia 上传到 Algolia，所以我之前编写了如下的 shell 脚本（取名为 deploy.sh） sh #!/bin/bash echo \"Deploying hugo website...\" # delete all the files in public folder rm -rf public/* # build the website hugo -t DoIt # upload index.json node push_algolia_json.js # deploy the website msg=\"rebuild site on $(date)\" echo \"$msg\" cd public || exit git add . git commit -m \"$msg\" git push # backup private repo cd .. || exit git add . git commit -m \"backup hugo on $(date)\" git push echo \"Git push successfully!\" 那么，我就可以用如下的命令完成 Hugo 博客的部署 sh $ bash deploy.sh ","date":"2024-07-29","objectID":"/zh-cn/use-github-actions-to-automate-hugo-build/:2:0","series":null,"tags":["DevOps","CI/CD","GitHub"],"title":"使用 GitHub Actions 自动化 Hugo 博客部署","uri":"/zh-cn/use-github-actions-to-automate-hugo-build/#背景"},{"categories":["Software-Engineering"],"content":" GitHub Actions 中的概念在 GitHub Actions 里面，涉及到许多概念，包括 Workflow、Event、Job、Action、Step Workflow 里面可以包含一到多个 Job，每个 Job 里面则包含了多个 Step，每个 Step 可以运行 Shell 命令、Shell 脚本或者是执行 action，这里的 action 可以看成是别人写好的脚本，通常是一些复杂而重复的操作。通过复用别人的 action 我们就极大程度减轻了编写 Workflow 的工作量 Workflow 通常被我们设置好的 Event 触发，Event 包括跟 git 有关的事件，比如 git push、收到 PR 请求等。触发之后 workflow 就会开始运行了。用图表示就是 timeline Event: push : pull request : ... Job1 : Step 1. Run action : Step 2. Run action : Step 3. Run action : Step 4. Run action : ... Job2: Step 1. Run action : Step 2. Run action : Step 3. Run action : Step 4. Run action : ... 我们可以用一个 YAML 文件来描述 Workflow，这个 YAML 文件会放到 git 仓库里面和源代码一起管理，详细的语法可以在官网找到 ","date":"2024-07-29","objectID":"/zh-cn/use-github-actions-to-automate-hugo-build/:3:0","series":null,"tags":["DevOps","CI/CD","GitHub"],"title":"使用 GitHub Actions 自动化 Hugo 博客部署","uri":"/zh-cn/use-github-actions-to-automate-hugo-build/#github-actions-中的概念"},{"categories":["Software-Engineering"],"content":" 编写 YAML 文件 Info 下面假定你已经对 GitHub Actions 的基本语法有一定的了解，这不是本文的重点 :) 接下来，我们要尝试将前面提到的 Shell 脚本变成 GitHub Actions 对应的 YAML 文件（取名为 build_and_deploy.yaml 文件） yaml name: hugo-deploy on: push: branches: - master jobs: build-and-deploy: runs-on: ubuntu-latest steps: - name: Check out this repo uses: actions/checkout@v4 with: submodules: 'recursive' fetch-depth: 0 - name: Install Hugo CLI uses: peaceiris/actions-hugo@v3 with: hugo-version: 'latest' extended: true - name: Install node.js uses: actions/setup-node@v4 with: node-version: 'latest' - name: Install atomic-algolia run: npm install atomic-algolia - name: Build the website with the DoIt theme run: hugo -t DoIt - name: Upload index.json for search run: node push_algolia_json.js - name: Deploy uses: peaceiris/actions-gh-pages@v4 with: deploy_key: ${{ secrets.HUGO_PRIVATE_KEY }} external_repository: Martinlwx/martinlwx.github.io publish_branch: main publish_dir: ./public 其中 actions/checkout 是一个别人写好的 action，可以用来将 git 仓库下载到本地，我的 private 仓库涉及到 2 个 git submodule DoIt，我的博客主题 public 仓库 这里需要把他们都 clone 到本地，所以设置 submodules: true，fetch-depth: 0 则会在 clone 的时候将所有的 commit 都 clone 下来 接下来我们要安装 Hugo，虽然官网上给出了 详细的步骤，但是我觉得较为繁琐，于是我找到了 actions-hugo，该 action 可以自动帮我们下载并安装好 Hugo，hugo-version: 'latest' 则是让它每次都用最新版本的 Hugo。因为 DoIt 使用了 admonition 等特性，所以还需要设置 extended: true，也就是使用 extended 版本的 Hugo Warning 如果你没有使用 Algolia 的话，你就没有必要安装 node.js，也没有必要安装 atomic-algolia，也没有必要进行 index.json 文件的上传 安装 node.js 也是同样的道理，已经有别人写好的了，这里不再赘述 在安装完 node.js 之后，用 npm 安装 atomic-algolia，这样后面就可以上传 index.json 文件了 在上传 index.json 文件之前，我们需要先用 Hugo 生成静态博客，这样才能保证 index.json 文件是最新的。跟在本地生成 Hugo 静态博客一样，用 hugo -t DoIt 指定主题并生成即可 生成 index.json 文件之后就可以用 node push_algolia_json.js 上传了，push_algolia_json.js 文件怎么写可以看 atomic-algolia 文档 最后，就涉及到 Hugo 博客的部署了，actions-hugo 的同一个作者还写了另外一个 action actions-gh-pages 可以用来快速部署。这里情况稍微复杂一些，前面提到，我有 1 个 public 仓库和 1 个 private 仓库，这里要做的事情其实是要从 private 仓库部署到 public 仓库。根据 actions-gh-pages 的 README.md 文档，需要设置 external_repository，将其指向我的 public 仓库的路径，格式也很好懂。另外因为部署要跨 git 仓操作，所以需要设置 deploy_key，这意味着我们需要生成 ssh-key 并分别添加到不同的 git 仓库里，这是相对比较麻烦的一步 flowchart LR private(\"` Private repo (use the *private* ssh-key as a *secret*) `\") --\u003e|peaceiris/actions-gh-pages@v4| public(\"` Public repo (use the *public* ssh-key as a *deploy key*) `\") 首先，用自己的电脑生成配对的 ssh-key sh # replace with your email here. $ ssh-keygen -t ed25519 -C martinlwx@163.com -f \"hugo\" 在当前目录，你就可以看到 hugo 和 hugo.pub 这两个文件了，接下来 点开 public 仓库的 Settings -\u003e Deploy keys -\u003e Add deploey key，将 hugo.pub 的内容添加进去，这里 Title 取什么名字无关紧要，要紧的是设置 Allow Write Access 点开 private 仓库的 Settings -\u003e Secrets and variables -\u003e Actions -\u003e Manage repository secret，将 hugo 的内容添加进去，Title 可以取作 HUGO_PRIVATE_KEY，就可以在 deploy_key 字段里面引用 ${{ secrets.HUGO_PRIVATE_KEY }} 剩下没有解释的几个配置项 publish_branch: main，看名字也很好懂，这里指的是部署的时候要部署到哪个分支，我的 public 仓库 只有 main 分支，所以就这么设置了 publish_dir: ./public，这里指的是你的 private 仓库生成 Hugo 静态博客的时候输出到什么文件夹，我的就是输出到 ./public 文件夹 上面的步骤都完成之后，在 private 仓库的根目录新建 .github/workflows 目录，并将如上的 YAML 保存在里面，git add \u0026 git push 一下就好了。之后点开仓库的 Actions 就可以看到该 workflow 了，如下所示 ","date":"2024-07-29","objectID":"/zh-cn/use-github-actions-to-automate-hugo-build/:4:0","series":null,"tags":["DevOps","CI/CD","GitHub"],"title":"使用 GitHub Actions 自动化 Hugo 博客部署","uri":"/zh-cn/use-github-actions-to-automate-hugo-build/#编写-yaml-文件"},{"categories":["Software-Engineering"],"content":" 总结在搭建完流水线之后，我发现我的工作量似乎变多了，本来 bash deploy.sh 就能搞定的事情，现在需要自己 git add 和 git commit（不过这也是因为之前的 commit message 是调用命令生成的）。但不管怎么说，还是从中学习到了 GitHub Actions 的使用，自动化部署 Hugo 博客是一次有意思的 CI/CD 实践。希望本文能给屏幕前的你带来帮助 :) ","date":"2024-07-29","objectID":"/zh-cn/use-github-actions-to-automate-hugo-build/:5:0","series":null,"tags":["DevOps","CI/CD","GitHub"],"title":"使用 GitHub Actions 自动化 Hugo 博客部署","uri":"/zh-cn/use-github-actions-to-automate-hugo-build/#总结"},{"categories":["Programming-Languages"],"content":"对尾调用以及尾调用优化的简单介绍，并通过 OCaml 的代码研究了是否开启尾调用优化的性能开销","date":"2024-03-22","objectID":"/zh-cn/tail-call-and-tail-call-optimization/","series":null,"tags":["OCaml","Programming-Languages","Performance-Engineering"],"title":"尾调用与尾调用优化","uri":"/zh-cn/tail-call-and-tail-call-optimization/"},{"categories":["Programming-Languages"],"content":" 尾调用 \u0026 尾递归假设函数 A 调用了函数 B，我们称函数 A 为 Caller，函数 B 为 Callee。 尾调用（Tail-call）指的是：Caller 最后只需要返回 Callee 这个函数调用的计算结果，其他运算都执行完成了1 如果 Callee 就是 Caller 自己，即出现了尾调用 + 递归调用的情况，那么这个函数就符合尾递归（Tail-recursive）的特点，暂且称其为尾递归函数 ","date":"2024-03-22","objectID":"/zh-cn/tail-call-and-tail-call-optimization/:1:0","series":null,"tags":["OCaml","Programming-Languages","Performance-Engineering"],"title":"尾调用与尾调用优化","uri":"/zh-cn/tail-call-and-tail-call-optimization/#尾调用--尾递归"},{"categories":["Programming-Languages"],"content":" 尾调用优化（TCO）根据函数调用的原理，本来函数 A 调用函数 B 的时候，我们需要为函数 B 创建一个 stack frame，然后压入到函数调用栈中，后续需要根据 stack frame 里面的函数返回地址进行返回。但如果这是一个尾调用，我们何必多此一举呢？反正函数 A 已经执行了它所有的计算过程，只需要等待尾调用的函数 B 的返回结果并将其返回即可 尾调用优化（Tail-call Optimization，TCO）的思想就是这样的：如果是尾调用，就不创建新的 stack frame，而是复用 Caller 的 stack frame 就好了 2 那么，尾调用优化的好处是什么呢？显然，尾递归函数的时间开销和空间开销大大降低了，我们可以放心地随意用尾递归而不会用担心栈溢出的问题，只要对应的编程语言支持尾调用优化并开启即可 ","date":"2024-03-22","objectID":"/zh-cn/tail-call-and-tail-call-optimization/:1:1","series":null,"tags":["OCaml","Programming-Languages","Performance-Engineering"],"title":"尾调用与尾调用优化","uri":"/zh-cn/tail-call-and-tail-call-optimization/#尾调用优化tco"},{"categories":["Programming-Languages"],"content":" 将普通递归函数改写为尾递归函数 信息 下面采用 OCaml 编写代码，因为它支持尾调用优化~ 如果你会其他函数式编程语言看懂它应该也没问题 :) 但并不是所有的递归函数都是尾递归函数，因此，我们还需要知道如何将任意一个递归函数改写为尾递归函数，一个比较流行的方式是 Accumulator 模式 具体步骤如下 3 创建一个辅助函数 helper，一般而言它会有 2 个参数 当前正在处理的数据 当前已经“累计的值” 辅助函数 helper 的 base case 变为：返回最后“累计的值” 原本递归函数的 base case 变为：调用辅助函数 helper 用经典的求解阶乘程序为例，首先用 dune 创建一个项目 sh $ dune init project tco 然后在 ./tco/bin/main.ml 里面写下求阶乘的递归函数 ocaml let rec factorial n = match n with 0 | 1 -\u003e 1 | n -\u003e n * factorial (n - 1) 显然，它不是一个尾递归函数，这是因为：我们计算完 factorial (n - 1) 的时候，还需要把它乘以 n 才能返回，所以，它并不符合最后只需要返回函数调用的结果这个要求 现在我们将这个函数改写为尾递归函数 ocaml let factorial_tco n = let rec helper cur acc = match cur with | 0 | 1 -\u003e acc (* 返回“计算出来的值” *) | cur -\u003e (helper [@tailcall]) (cur - 1) (acc * cur) in helper n 1 (* 调用辅助函数 *) 技巧 在 OCaml 里面，可以在调用函数的时候用 [@tailcall] 标注确保是尾调用，否则编译的时候会弹出警告，用法就是 (fun_call[@tailcall]) 为了测试 2 个不同的实现的性能差异，我们可以用 core_bench 工具。首先，先安装必要的库 sh $ opam install core_bench 接下来修改配置文件，将 ./tco/bin/dune 修改为 lisp (executable (public_name tco) (name main) (libraries tco core core_bench core_unix.command_unix)) 然后增加关于性能测试的代码，最后 ./tco/bin/main.ml 文件长下面这样 ocaml open Core open Core_bench let rec factorial n = match n with | 0 | 1 -\u003e 1 | n -\u003e n * factorial (n - 1) let factorial_tco n = let rec helper cur acc = match cur with | 0 | 1 -\u003e acc | cur -\u003e (helper [@tailcall]) (cur - 1) (acc * cur) in helper n 1 (* Benchmark *) let bench () = Bench.make_command [ Bench.Test.create ~name:\"factorial\" (fun () -\u003e factorial 10000); Bench.Test.create ~name:\"factorial_tco\" (fun () -\u003e factorial_tco 10000); ] |\u003e Command_unix.run let _ = bench () 接下来构建项目并执行即可 sh $ dune build $ dune exec tco 在我的 MacBook M3 Air 上的输出结果如下所示 text Estimated testing time 20s (2 benchmarks x 10s). Change using '-quota'. ┌───────────────┬──────────┬────────────┐ │ Name │ Time/Run │ Percentage │ ├───────────────┼──────────┼────────────┤ │ factorial │ 40.42us │ 100.00% │ │ factorial_tco │ 10.06us │ 24.90% │ └───────────────┴──────────┴────────────┘ 可以看到，开启尾调用优化的递归函数的时间开销是原来的 1/4 而已🚀 警告 因为测试机器的不同，你的输出结果跟我的会有所差别，但是是否开启尾调用优化的性能差异应该还是很明显的。另外，尾调用优化的效果还跟递归函数的调用深度有关系，如果将 10000 改成 10 就可以看到性能差距不是那么明显了 ","date":"2024-03-22","objectID":"/zh-cn/tail-call-and-tail-call-optimization/:2:0","series":null,"tags":["OCaml","Programming-Languages","Performance-Engineering"],"title":"尾调用与尾调用优化","uri":"/zh-cn/tail-call-and-tail-call-optimization/#将普通递归函数改写为尾递归函数"},{"categories":["Programming-Languages"],"content":" 总结以上就是关于「尾调用」\u0026「尾调用优化」的全部内容，说白了，尾调用优化就是将计算的结果暂时存储在函数的参数里面，从而避免了不断创建 stack frame 的开销。性能上是提升了但是代码也不那么优美了。所以，建议还是正常写递归函数，当出现性能瓶颈的时候再改写为尾递归函数~ ","date":"2024-03-22","objectID":"/zh-cn/tail-call-and-tail-call-optimization/:3:0","series":null,"tags":["OCaml","Programming-Languages","Performance-Engineering"],"title":"尾调用与尾调用优化","uri":"/zh-cn/tail-call-and-tail-call-optimization/#总结"},{"categories":["Programming-Languages"],"content":" 参考 Tail Recursion | Coursera ↩︎ Accumulators for Tail Recursion | Coursera ↩︎ Perspective on Tail Recursion | Coursera ↩︎ ","date":"2024-03-22","objectID":"/zh-cn/tail-call-and-tail-call-optimization/:4:0","series":null,"tags":["OCaml","Programming-Languages","Performance-Engineering"],"title":"尾调用与尾调用优化","uri":"/zh-cn/tail-call-and-tail-call-optimization/#参考"},{"categories":["Vim-Neovim"],"content":"Learn to use text-object in vim/neovim","date":"2024-03-03","objectID":"/zh-cn/learn-to-use-text-objects-in-vim/","series":null,"tags":["Vim","Neovim"],"title":"学习使用 Vim\u0026Neovim 的 text-object","uri":"/zh-cn/learn-to-use-text-objects-in-vim/"},{"categories":["Vim-Neovim"],"content":" 引言你可能不知道什么是 text-object，但我相信你可能已经在使用了只是你自己没有意识到。比如，在写代码的时候，我们经常想要修改函数调用的入参。比如我们在下面这段代码中，想要修改成 bar(3, 2, 1)，而你的光标停留在 () 里面 python def foo(): ... res = bar(1, 2, 3) # ^ # The position of your cursor(on `,`) ... 你会如何修改呢？如果你用 Vim/Neovim 已经很熟练了，你多半会不假思索地敲下 ci) 或者 ci(，然后就可以快速敲下新的入参了。这里的 i( 或者 i) 就是所谓的 text-object 了 警告 不好的做法：用 F( 找到左括号，然后用 x 一个字符一个字符删除 ","date":"2024-03-03","objectID":"/zh-cn/learn-to-use-text-objects-in-vim/:1:0","series":null,"tags":["Vim","Neovim"],"title":"学习使用 Vim\u0026Neovim 的 text-object","uri":"/zh-cn/learn-to-use-text-objects-in-vim/#引言"},{"categories":["Vim-Neovim"],"content":" 自带的 text-object 技巧 用 :h text-objects 查看更多帮助信息 简单来说，text-object 是文本对象，对应一块区域的文本，而且这一块文本包含结构在里面，所以它们可以当成一个 text-object 来处理，给很多操作带来方便 Vim/Neovim 自带的 text-object 包含两种情况，由两个字母组成： 第一个字母要么是 i 要么是 a 简单来说，i 指的是 text-object 本身，而 a 则还包含了下一个/上一个空格或者是成对字符 记忆：i = (i)nside，a = (a)round 第二个字母有两种情况 成对字符中的一个 成对字符：{}, (), [], '', \"\", \u003ctag\u003e\u003c/tag\u003e，其中 \u003ctag\u003e\u003c/tag\u003e 用 t 代指，比如删除 \u003ctag\u003efoobar\u003c/tag\u003e 里面的 foobar 你只需要将光标放在 tag 里面并按下 dit e.g. a{ = (around) {，选中 {} 内的所有东西（包括 {}） (w)ord, (s)entences, (p)aragraphs 每一种都可以和 i 或者 a 搭配使用，所以会有 iw, aw, is, as, ip, ap 这几种 ","date":"2024-03-03","objectID":"/zh-cn/learn-to-use-text-objects-in-vim/:2:0","series":null,"tags":["Vim","Neovim"],"title":"学习使用 Vim\u0026Neovim 的 text-object","uri":"/zh-cn/learn-to-use-text-objects-in-vim/#自带的-text-object"},{"categories":["Vim-Neovim"],"content":" 扩展 text-object前面我们提到，text-object 对应的文本包含一定的结构，那么什么文本天然有结构信息呢？那就是代码，代码是高度结构化的文本，受到对应语法的严格限制 在写代码的时候，我们常常想要直接删掉整个函数体重写。如果函数体是用 {} 括起来的，那么通常我们可以利用 ci{ 完成这个任务，只是需要注意光标所在的位置，要确保函数体的 {} 是最靠近光标所在位置的，这有点恼人 示例 Rust 代码的函数体就是用 {} 括起来的，所以删掉函数体我们可以考虑将光标停在 if 的 i 上，然后用 ci{ 就好了 rust fn fib(n: i32) -\u003e i32 { // The position of your cursor(on `i`) // v if n == 1 || n == 2 { 1 } else { fib(n - 1) + fib(n-2) } } 但如果函数体并不是用 {} 括起来的呢？比如 Python 代码，此时 ci{ 就不能用了 python def fib(n: int): if n == 1 or n == 2: return 1 return fib(n - 1) + fib(n - 2) 考虑到代码是高度结构化的，是否存在某个特殊的 text-object 让我们可以选中函数体并整个删除呢？这正是 nvim-treesitter-textobjects 要做的事情，它是基于 nvim-treesitter 的 Lua 插件。它通过对代码的 AST 的分析，帮我们定义了函数体、循环体等 text object，也叫做 syntax aware text object，因为它跟编程语言的语法有关系 技巧 查看对应的 commit 了解文件变更，以及我是如何组织配置文件的 你的文件组织方式可能跟我不同，但我想下面的内容理解起来没有什么困难 :) 如果你也用的是 lazy.nvim 的话，只需要在插件列表里面追加 lua require(\"lazy\").setup({ ... { \"nvim-treesitter/nvim-treesitter-textobjects\", dependencies = \"nvim-treesitter/nvim-treesitter\", config = function() require(\"config.nvim-treesitter-textobjects\") end, }, ... }) 在 config 目录下新增 nvim-treesitter-textobjects.lua 文件添加如下的配置（大部分代码被我省略了，完整文件在这里） lua local is_ok, configs = pcall(require, \"nvim-treesitter.configs\") if not is_ok then return end configs.setup({ textobjects = { select = { ... keymaps = { -- outer: outer part -- inner: inner part [\"af\"] = \"@function.outer\", [\"if\"] = \"@function.inner\", [\"ac\"] = \"@class.outer\", [\"ic\"] = \"@class.inner\", [\"al\"] = \"@loop.outer\", [\"il\"] = \"@loop.inner\", }, include_surrounding_whitespace = true, }, }, ... }) 根据我的个人需要，我设置了 6 种 text-object，分别是 af, if, ac, ic, al, il，分别用于处理函数、类和循环，在官方仓库的 README 里你可以看到更多支持的 syntax aware text-object 接下来我们就可以用 dif 方便地在函数体里的任意位置删掉整个函数体了（只要确保你的光标在函数体内），还是方便很多的！ ","date":"2024-03-03","objectID":"/zh-cn/learn-to-use-text-objects-in-vim/:3:0","series":null,"tags":["Vim","Neovim"],"title":"学习使用 Vim\u0026Neovim 的 text-object","uri":"/zh-cn/learn-to-use-text-objects-in-vim/#扩展-text-object"},{"categories":["Vim-Neovim"],"content":" 总结text-object 将文本组织成对象，我们可以方便地对齐进行操作。在 nvim-treesitter-textobjects 的加持下，编程语言的各种结构也可以被当成是 text-object，使用下来非常方便🍺 ","date":"2024-03-03","objectID":"/zh-cn/learn-to-use-text-objects-in-vim/:4:0","series":null,"tags":["Vim","Neovim"],"title":"学习使用 Vim\u0026Neovim 的 text-object","uri":"/zh-cn/learn-to-use-text-objects-in-vim/#总结"},{"categories":["Vim-Neovim"],"content":"从零开始用 Neovim 配置 OCaml 的开发环境，包括 LSP、Formatter 等","date":"2024-01-23","objectID":"/zh-cn/neovim-setup-for-ocaml/","series":null,"tags":["Vim","Neovim","OCaml"],"title":"OCaml 的 Neovim 配置方案","uri":"/zh-cn/neovim-setup-for-ocaml/"},{"categories":["Vim-Neovim"],"content":" Info 更新说明: 2025-03-22: 将 null-ls/none-ls 插件更换为 conform.nvim 插件，因为配置更简单 :) ","date":"2024-01-23","objectID":"/zh-cn/neovim-setup-for-ocaml/:0:0","series":null,"tags":["Vim","Neovim","OCaml"],"title":"OCaml 的 Neovim 配置方案","uri":"/zh-cn/neovim-setup-for-ocaml/#"},{"categories":["Vim-Neovim"],"content":" 前言在上一篇博客中，我详细介绍了如何从零开始配置 Neovim，让它更接近 IDE。但我没有讲到的是： 有的 LSP 本身不支持代码格式化，要如何配置 Neovim 让它可以用第三方的代码格式化工具？ 新增一门编程语言支持的时候，要怎么修改配置文件？ 最近在学习函数式编程需要在我的 Mac 上配置 OCaml，正好以它为例，回答以上两个问题 Info 本文假定你已经阅读过我之前的文章，因此对于一些细节问题，我就不再赘述 ","date":"2024-01-23","objectID":"/zh-cn/neovim-setup-for-ocaml/:1:0","series":null,"tags":["Vim","Neovim","OCaml"],"title":"OCaml 的 Neovim 配置方案","uri":"/zh-cn/neovim-setup-for-ocaml/#前言"},{"categories":["Vim-Neovim"],"content":" 安装 OCaml Info 其他系统的安装方法可以看这里 在 Mac 上安装 OCaml 用 Homebrew 比较方便 sh $ brew install opam 按照 Homebrew 的输出，我们还需要进行额外的配置，需要修改 ~/.zshrc（如果你用的是 Zsh）或者是 ~/.bashrc（如果你用的是 Bash） sh $ opam init # 按照提示按下 y 确认即可 接下来让我们上一步的配置生效 sh $ source ~/.zshrc # $ source ~/.bashrc # if you use bash 最后，我们可以通过如下的命令检查是否安装成功 sh $ opam switch 输出应该跟下面的差不多 text # switch compiler description -\u003e 5.0.0 ocaml-base-compiler.5.0.0 5.0.0 default ocaml.4.14.0 default Tip 接下来需要安装一些包，因为网络原因访问可能会比较慢。加速可以通过换源实现，这里用的是上海交通大学的源，配置命令为 sh $ opam repo \\ set-url default \\ https://mirrors.sjtug.sjtu.edu.cn/git/opam-repository.git \\ --all --set-default 等待该命令执行完就完成了换源 类似 Python 有 REPL，如 IPython。在 OCaml 里也有类似的工具，叫做 utop sh $ opam install utop 接下来尝试使用 utop 看是否安装成功 sh $ utop 如果一切正常，你应该可以看到如下的输出 text ─────────────────────────────────────────────────────────┬─────────────────────────────────────────────────────────────┬────────────────────────────────────────────────────────── │ Welcome to utop version 2.13.1 (using OCaml version 5.0.0)! │ └─────────────────────────────────────────────────────────────┘ Type #utop_help for help about using utop. ─( 10:33:26 )─\u003c command 0 \u003e────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────{ counter: 0 }─ utop # ┌──────────────┬──────────────┬───────────────┬─────┬───────────┬────┬───┬──────────┬─────┬───────────┬──────┬────────────┬───────┬───────────┬──────────────┬──────────┬────────┐ │Afl_instrument│Alias_analysis│Allocated_const│Annot│Applicative│Arch│Arg│Arg_helper│Array│ArrayLabels│Asmgen│Asmlibrarian│Asmlink│Asmpackager│Assert_failure│Ast_helper│Ast_inva│ └──────────────┴──────────────┴───────────────┴─────┴───────────┴────┴───┴──────────┴─────┴───────────┴──────┴────────────┴───────┴───────────┴──────────────┴──────────┴────────┘ ","date":"2024-01-23","objectID":"/zh-cn/neovim-setup-for-ocaml/:2:0","series":null,"tags":["Vim","Neovim","OCaml"],"title":"OCaml 的 Neovim 配置方案","uri":"/zh-cn/neovim-setup-for-ocaml/#安装-ocaml"},{"categories":["Vim-Neovim"],"content":" 配置 OCaml LSP Tip 如果你跟着我上一篇的教程进行配置，那么你的目录结构应该长下面这样 text . ├── init.lua └── lua ├── colorscheme.lua ├── keymaps.lua ├── lsp.lua ├── options.lua └── plugins.lua 之前的文章里面我们配置 LSP 的时候借助了 mason.nvim。要增加新的编程语言的 LSP 同样可以用这个工具，步骤如下 打开 Neovim，输入 :Mason，在 (2) LSP 里面找到 ocaml-lsp，将光标放在该行然后按下 i 就可以安装了，稍候片刻☕️ 打开 LSP 配置文件（我放在了 lsp.lua 文件里面），添加如下的内容 lua ... -- rest of the configurations lspconfig.ocamllsp.setup({ on_attach = on_attach, }) Warning 你可能有自己的配置文件而没有跟着我的上一篇 文章操作，所以在你的配置文件里面加上这一段代码并不保证能够 work。你可以选择浏览完整文件 来理解这段代码的作用，和尝试迁移配置到你的配置文件中 修改完 lsp.lua 文件之后，重启 Neovim 之后就生效了 Warning 和 rust-analyzer 类似，ocaml-lsp 的 LSP 也只支持在项目里启用，无法在单文件下生效 接下来，可以用 dune 新建项目，尝试写一下 OCaml 的代码，检查 LSP 是否正常工作 ","date":"2024-01-23","objectID":"/zh-cn/neovim-setup-for-ocaml/:3:0","series":null,"tags":["Vim","Neovim","OCaml"],"title":"OCaml 的 Neovim 配置方案","uri":"/zh-cn/neovim-setup-for-ocaml/#配置-ocaml-lsp"},{"categories":["Vim-Neovim"],"content":" 配置 OCaml Formatterocaml-lsp 本身并不支持 OCaml 代码的格式化，在完成如上的配置之后，如果你尝试格式化，会发现 Neovim 报错： text [LSP] Format request failed, no matching language servers. 因此，接下来要讲解的就是如何配置 OCaml 的代码格式化功能。 之前你可能已经注意到，在 Neovim 里面输入 :Mason 的时候可以看到，它不仅支持安装 LSP，还可以安装 Linter、Formatter 等。其中 Formatter 就是用于代码的格式化。OCaml 的 Formmater 是 ocamlformat，首先我们在 Mason 的窗口 (5) Formatter 里找到它，将光标停留在该选项，然后按下 i 安装。等待片刻之后就可以看到安装成功了☕️ ocamlformat 本身只是一个 CLI 工具，没法方便地集成到 Neovim 里面。这里我们可以用 conform.nvim 插件，该插件会对接 ocamlformat 等各种 Formatter 打开 plugins.lua 新增如下 Lua 代码，保存并重启后 lazy.nvim 就会自动安装新插件，稍候片刻☕️ lua ... -- rest of the configurations, omit for simplicity require(\"lazy\").setup({ { \"stevearc/conform.nvim\", opts = { formatters_by_ft = { ocaml = { \"ocamlformat\" }, }, formatters = { ocamlformat = { prepend_args = { \"--if-then-else\", \"vertical\", \"--break-cases\", \"fit-or-vertical\", \"--type-decl\", \"sparse\", }, }, }, }, } ... -- rest of the configurations, omit for simplicity }) 上面的配置看起来可能有点复杂，但其实意思很直白 formatters_by_ft 用来指定对应编程语言的 Formatter，这里是 ocaml 如果想要进一步定制化 Formatter 的功能，可以在 formatters 进行进一步定制 Tip FAQs： 如何确定编程语言用什么 Formatter？用 :help conform-formatters 就可以看到所有 conform.nvim 支持的 Formatter，在 :Mason 的 (5) Formatter 里面找到并安装 如何往 conform.nvim 里添加 Formatter？在 formatters_by_ft 里面新增 Entry，格式可以参考上面 ocaml 的设置 如何确定 Formatter 都有什么具体的配置项来定制化？查看各个工具的官方文档 最后，我们还需要修改 lsp.lua 文件，原本跟代码格式化有关的行长这个样子 lua ... -- rest of the configurations, omit for simplicity vim.keymap.set(\"n\", \"\u003cspace\u003ef\", function() vim.lsp.buf.format({ async = true }) end, bufopts) ... -- rest of the configurations, omit for simplicity 现在因为我们使用 conform.nvim，相当于所有的格式化都交给它来做，因此用的是 conform.nvim 的 format 函数 lua ... -- rest of the configurations, omit for simplicity vim.keymap.set(\"n\", \"\u003cspace\u003ef\", function() require(\"conform\").format({ async = true, lsp_fallback = true }) end, bufopts) ... -- rest of the configurations, omit for simplicity 这里 lsp_fallback 的意思是如果没有对应的 Formatter 就尝试用 LSP 自带的 Formatter（若有） 完成文件编辑之后，重启 Neovim 就生效了 ","date":"2024-01-23","objectID":"/zh-cn/neovim-setup-for-ocaml/:4:0","series":null,"tags":["Vim","Neovim","OCaml"],"title":"OCaml 的 Neovim 配置方案","uri":"/zh-cn/neovim-setup-for-ocaml/#配置-ocaml-formatter"},{"categories":["Vim-Neovim"],"content":" 总结现在对前文的内容进行总结，如果你跟我一样也使用 mason.nvim, mason-lspconfig, conform.nvim 这些插件。那么在添加一门新的编程语言的时候，你可以这样配置： 首先在你的机器上配置好该编程语言的开发环境，查询官方文档即可 打开 Neovim，输入 :Mason 安装对应的 LSP，先检查官方文档看有没有自带 Formatter，如果没有就用 :Mason 安装对应的 Formatter 打开 lsp.lua 文件配置 LSP 如果是自己单独下载的 Formatter，还需要在 conform.nvim 的配置项里面进行设置 对于本文没有说清楚的地方，你可以查看我的 dotfiles 配置 来了解更多的信息~~ ","date":"2024-01-23","objectID":"/zh-cn/neovim-setup-for-ocaml/:5:0","series":null,"tags":["Vim","Neovim","OCaml"],"title":"OCaml 的 Neovim 配置方案","uri":"/zh-cn/neovim-setup-for-ocaml/#总结"},{"categories":["ML-DL"],"content":"介绍了 LLM 推理加速的方法之一 - KV Cache","date":"2023-10-12","objectID":"/zh-cn/llm-inference-optimization-kv-cache/","series":null,"tags":["NLP","Deep-Learning","LLM"],"title":"LLM 推理加速 - KV Cache","uri":"/zh-cn/llm-inference-optimization-kv-cache/"},{"categories":["ML-DL"],"content":" 背景LLM 用于推理的时候就是不断基于前面的所有 token 生成下一个 token 假设现在已经生成了 $t$ 个 token，用 $x_{1:t}$ 表示。在下一轮，LLM 会生成 $x_{1:t+1}$，注意他们的前 $t$ 个 token 是一样的 $$ x_{1:t+1}=\\text{LLM}(x_{1:t}) $$ 再下一步也是相似的 $$ x_{1:t+2}=\\text{LLM}(x_{1:t+1}) $$ 概括来说，每一轮用上一轮的输出当成新的输入让 LLM 预测，一般这个过程会持续到输出达到提前设定的最大长度或者是 LLM 自己生成了特殊的结束 token ","date":"2023-10-12","objectID":"/zh-cn/llm-inference-optimization-kv-cache/:1:0","series":null,"tags":["NLP","Deep-Learning","LLM"],"title":"LLM 推理加速 - KV Cache","uri":"/zh-cn/llm-inference-optimization-kv-cache/#背景"},{"categories":["ML-DL"],"content":" KV Cache 原理 信息 LLM 的推理过程很好理解，但是这个简单的实现存在一个问题——存在不少的重复计算导致计算效率不是很高🧐 只需要看 LLM 的连续两次前向传播推理计算就很好理解为什么说存在重复计算了 比如考虑下面这一步 $$ x_{1:t+1}=\\text{LLM}(x_{1:t}) $$ LLM 的输入是 $x_{1:t}$，先只看最后一个 token $x_t$，它的 query 向量会和前面的每个 token 以及自己产生的 key 向量计算内积 $$ \\mathbf q_{t}^T\\mathbf k_{1},\\mathbf q_{t}^T\\mathbf k_{2},…,\\mathbf q_{t}^T\\mathbf k_{t} $$ 然后看下一步 $$ x_{1:t+2}=\\text{LLM}(x_{1:t+1}) $$ LLM 的输入是 $x_{1:t+1}$，看最后一个 token $x_{t+1}$，它的 query 向量也会和前面的每个 token 以及自己产生的 key 向量计算内积 $$ \\mathbf q_{t+1}^T\\mathbf k_{1},\\mathbf q_{t+1}^T\\mathbf k_{2},…,\\mathbf q_{t+1}^T\\mathbf k_{t+1} $$ 此时考虑 $x_{t+1}$ 的前一个 token $x_t$，它也要经历类似的步骤 $$ \\mathbf q_{t}^T\\mathbf k_{1},\\mathbf q_{t}^T\\mathbf k_{2},…,\\mathbf q_{t}^T\\mathbf k_{t} $$ 可以看到，这个计算完全和上一轮的计算重复了，对于在 $x_t$ 之前的 token 也是这个道理。我们需要重新计算得到 $x_{1:t}$ 的所有 key 向量和 value 向量，而这些向量的值其实是不会变的🧐 Tip 那么我们只需要把之前 token 的 key 向量和 value 向量都缓存起来，那么就没有必要重复计算了，这就是 KV Cache 的核心思想 在运用了 KV Cache 之后，除了第一轮以外的每一轮，我们都只需要关注输入的最后一个 token，用这个 token 计算得到它的 query, key, value 向量，然后拿着这三个新向量和之前所有缓存的 key/value 向量计算自注意力 我画了一个示意图来帮助理解开启 KV Cache 之后发生了什么，考虑 LLM 从无到有开始生成 4 个 token，其中蓝色的部分表示 KV Cache 里面缓存的值；红色则表示没有被缓存 ","date":"2023-10-12","objectID":"/zh-cn/llm-inference-optimization-kv-cache/:2:0","series":null,"tags":["NLP","Deep-Learning","LLM"],"title":"LLM 推理加速 - KV Cache","uri":"/zh-cn/llm-inference-optimization-kv-cache/#kv-cache-原理"},{"categories":["ML-DL"],"content":" KV Cache 的效率分析KV Cache 加速推理的原理是：在自注意力层，本来每次要做矩阵乘法 $\\mathbf Q\\mathbf K^T$，现在因为 KV Cache 的存在，我们不需要整个 $\\mathbf Q$ 和 $\\mathbf K^T$ 做矩阵乘法，只需要每次输入的最后一个 token 的 query 向量 $\\mathbf q$ 和 $\\mathbf K$ 做向量 - 矩阵乘法，之后更新 KV Cache 缓存即可 采用了 KV Cache 的话 LLM 的推理过程可以看成 2 个阶段 第一次迭代的时候，此时 KV Cache 为空，所有的输入的 token 都需要为其计算 key, value, query 向量，其中 key 和 value 会被缓存起来 后续的每一次迭代，只需要为新的 token 计算 key、value、query，并更新 KV Cache KV Cache 加速推理的代价是显存占用会变高，所以它是空间换时间的办法，关于开不开 KV Cache 的显存占用峰值的对比可以看 这里。我在这里放一个总结： 用 KV Cache - 2 * hidden_size * num_layers * decoder_length 2：因为要存储 key 和 value 向量 hidden_size：key 和 value 向量的长度 num_layers：每一层都要缓存 key、value 向量 decoder_length：序列长度 不用 KV Cache - 2 * hidden_size * 1 * decoder_length 注意 可以看到，开启 KV Cache 之后，显存占用的峰值是原来的 num_layers 倍。这里用“峰值”这个词是因为，KV Cache 开启之后显存是不断累积增加的；关闭的话每次都会重新计算。所以用“峰值”会更为准确一些 ","date":"2023-10-12","objectID":"/zh-cn/llm-inference-optimization-kv-cache/:3:0","series":null,"tags":["NLP","Deep-Learning","LLM"],"title":"LLM 推理加速 - KV Cache","uri":"/zh-cn/llm-inference-optimization-kv-cache/#kv-cache-的效率分析"},{"categories":["ML-DL"],"content":" KV Cache APIHuggingface 的 model.generate API 有一个参数为 use_cache，可以用来控制是否开启 KV Cache，这个选项是默认打开的1 ","date":"2023-10-12","objectID":"/zh-cn/llm-inference-optimization-kv-cache/:4:0","series":null,"tags":["NLP","Deep-Learning","LLM"],"title":"LLM 推理加速 - KV Cache","uri":"/zh-cn/llm-inference-optimization-kv-cache/#kv-cache-api"},{"categories":["ML-DL"],"content":" 参考 GenerationConfig ↩︎ ","date":"2023-10-12","objectID":"/zh-cn/llm-inference-optimization-kv-cache/:5:0","series":null,"tags":["NLP","Deep-Learning","LLM"],"title":"LLM 推理加速 - KV Cache","uri":"/zh-cn/llm-inference-optimization-kv-cache/#参考"},{"categories":["ML-DL"],"content":"介绍了 LoRA 微调的原理，以及相关的源代码分析","date":"2023-09-14","objectID":"/zh-cn/lora-finetuning/","series":null,"tags":["Paper","Internal","Deep-Learning"],"title":"LoRA 微调","uri":"/zh-cn/lora-finetuning/"},{"categories":["ML-DL"],"content":" 什么是 LoRA 自从 LLM 时代到来之后，如何微调 LLM 成为了一个难题，因为 LLM 的模型实在是太大了，很难做全量微调更新所有参数。可选的路线有：冻结整个模型做 Prompt tuning 或者 In-context Learning；冻结整个模型但是会插入可训练的模块。今天要介绍的 LoRA(Low-Rank Adaptation) 就对应了后者的技术路线，这是微软团队的工作1 LoRA 的思想其实挺简单，我们知道，在深度学习里面，模型的参数是通过梯度下降进行更新的，考虑一个矩阵 $\\mathbf W_0\\in\\mathcal{R}^{d\\times d}$（这里的下标 0 表示它是初始值），可以用 $\\Delta \\mathbf W$ 表示它最后训练完成的时候相对于一开始的初始值的变化量，那么训练完成之后这个矩阵的参数会是 $$\\mathbf W_0+\\Delta \\mathbf W$$ LoRA 微调要解决的问题是 - 能不能在冻结 $\\mathbf W_0$ 的情况下，求解出 $\\Delta \\mathbf W$？而且求解的开销要尽可能低？这是可以的，因为研究人员发现训练完成后的 LLM 的模型权重的 Intrinsic rank 比较低，于是作者假设 $\\Delta\\mathbf W$ 也是如此，那么我们就可以对 $\\Delta \\mathbf W$ 做低秩分解，最后实验表明这个假设是正确的，LoRA 微调效果挺好1，低秩分解指的是 $$\\Delta \\mathbf W=\\mathbf B\\mathbf A$$ 其中 $\\mathbf B\\in\\mathcal{R}^{d\\times r}$，$\\mathbf A\\in\\mathcal{R}^{r\\times d}$，$\\mathbf B$ 采用零值初始化，$\\mathbf A$ 则是采用高斯函数初始化，这样在一开始训练的时候 $\\mathbf B\\mathbf A=0$，LoRA 模块对本来的模型不造成影响 如果输入是 $\\mathbf x$，那么 LoRA 的计算方式就是 $$\\mathbf W_0\\mathbf x+\\frac{\\alpha}{r}\\Delta \\mathbf W\\mathbf x=\\mathbf W_0\\mathbf x+\\frac{\\alpha}{r}\\mathbf B\\mathbf A\\mathbf x$$ 这里的 $\\alpha$ 就是放缩因子，$r$ 则是降维矩阵降维后的大小，整体作为一个缩放因子，在后面的源码分析会有所体现 LoRA 微调训练的时候只需要通过梯度下降更新 $\\mathbf B$ 和 $\\mathbf A$，而推理的时候，可以直接把 $\\mathbf W_0$ 和 $\\mathbf B\\mathbf A$ 合并起来，就像 LoRA 模块不存在一样。这是 LoRA 一个显著优势：它并不会带来推理延迟👍 另外可以计算一下使用 LoRA 之后，可学习的参数量的变化 $$ (\\mathbf W_0+\\frac{\\alpha}{r}\\Delta\\mathbf W)\\mathbf x=\\mathbf W_0\\mathbf x+\\frac{\\alpha}{r}\\Delta \\mathbf W\\mathbf x=\\mathbf W_0\\mathbf x+\\frac{\\alpha}{r}\\mathbf B\\mathbf A\\mathbf x $$ 这里的 $r\\ll d$，因此可以减少很多需要训练的模型参数，所以 LoRA 是参数高效的微调方法👍 还剩下两个问题 —— LoRA 要加在 Transformer 的哪一个部分？最佳的 r 是多少？ 在论文的 7.1 里面，作者对比之后发现同时加在 $\\mathbf W_q$ 和 $\\mathbf W_v$ 上的效果是最好的1 在论文的 7.2 里面，作者发现一味增大 r 并没有带来太多的提升，4 ~ 8 效果就不错了，这验证了 LLM 的模型权重的 Intrinsic rank 确实比较低1 ","date":"2023-09-14","objectID":"/zh-cn/lora-finetuning/:1:0","series":null,"tags":["Paper","Internal","Deep-Learning"],"title":"LoRA 微调","uri":"/zh-cn/lora-finetuning/#什么是-lora"},{"categories":["ML-DL"],"content":" 如何使用 LoRA？Huggingface 的 peft 就支持 LoRA 微调，在 Github 仓库的 README.md 文件就给了一个例子，只需要用 LoraConfig 对参数进行配置，然后用 get_peft_model 就完成了对模型的改造，就可以用于后续训练了 python from transformers import AutoModelForCausalLM from peft import get_peft_config, get_peft_model, LoraConfig, TaskType model_name_or_path = \"facebook/opt-350m\" peft_config = LoraConfig( task_type=TaskType.CAUSAL_LM, r=8, lora_alpha=32, lora_dropout=0.1, ) model = AutoModelForCausalLM.from_pretrained(model_name_or_path) model = get_peft_model(model, peft_config) model.print_trainable_parameters() # output: trainable params: 786,432 # || all params: 331,982,848 # || trainable%: 0.2368893467652883 训练完成之后需要保存模型，调用 model.save_pretrained(output_dir) 即可，其中 output_dir 就是要保存的路径，观察目录结构可以发现，只保存 LoRA 模块的权重而不需要保存整个模型。目录结构长下面这样 sh output_dir ├── README.md ├── adapter_config.json └── adapter_model.bin 后续要加载模型也很简单 python from peft import AutoPeftModelForCausalLM peft_model_name_or_path = \"./output_dir\" model = AutoPeftModelForCausalLM.from_pretrained(peft_model_name_or_path) ","date":"2023-09-14","objectID":"/zh-cn/lora-finetuning/:2:0","series":null,"tags":["Paper","Internal","Deep-Learning"],"title":"LoRA 微调","uri":"/zh-cn/lora-finetuning/#如何使用-lora"},{"categories":["ML-DL"],"content":" LoRA 源码阅读 下面的代码我去掉了一些无关的代码，比如错误处理、过于冗长的类型提示等。参考的源代码是 peft 0.5.0 版本 LoRA 微调的核心是 LoraModel 类 python class LoraModel(BaseTuner): def __init__(self, model, config, adapter_name) -\u003e None: super().__init__(model, config, adapter_name) ... LoraModel 继承自 BaseTuner 并且调用了 BaseTuner 的构造函数，所以我们应该去查看父类构造函数做了什么，定位到父类 BaseTuner python class BaseTuner(nn.Module, ABC): def __init__(self, model, peft_config, adapter_name) -\u003e None: super().__init__() self.model = model self.inject_adapter(self.model, adapter_name) self.model.peft_config = self.peft_config 核心应该是这个 inject_adapter 方法 python class BaseTuner(nn.Module, ABC): def inject_adapter(self, model: nn.Module, adapter_name: str): peft_config = self.peft_config[adapter_name] is_target_modules_in_base_model = False key_list = [key for key, _ in model.named_modules()] peft_config = self._prepare_adapter_config(peft_config, model_config) for key in key_list: if not self._check_target_module_exists(peft_config, key): continue is_target_modules_in_base_model = True parent, target, target_name = _get_submodules(model, key) optionnal_kwargs = { \"loaded_in_8bit\": getattr(model, \"is_loaded_in_8bit\", False), \"loaded_in_4bit\": getattr(model, \"is_loaded_in_4bit\", False), \"current_key\": key, } self._create_and_replace( peft_config, adapter_name, target, target_name, parent, **optionnal_kwargs, ) # 显而易见，就是标记一下只有 adapter 是可以训练的 self._mark_only_adapters_as_trainable() # 如果是推理阶段，那么就所有的参数都冻结 if self.peft_config[adapter_name].inference_mode: for n, p in self.model.named_parameters(): if adapter_name in n: p.requires_grad = False 可以看到 inject_adapters 做的事情无非就是遍历每个 Module 看哪些是要修改的，重点是这个 _create_and_replace 方法，于是接下来就定位到了 LoraModel 的 _create_and_replace 方法 python class LoraModel(BaseTuner): def _create_and_replace( self, lora_config, adapter_name, target, target_name, parent, **optionnal_kwargs, ): bias = hasattr(target, \"bias\") and target.bias is not None kwargs = { \"r\": lora_config.r, \"lora_alpha\": lora_config.lora_alpha, \"lora_dropout\": lora_config.lora_dropout, \"fan_in_fan_out\": lora_config.fan_in_fan_out, \"init_lora_weights\": lora_config.init_lora_weights, } kwargs[\"loaded_in_8bit\"] = optionnal_kwargs.pop(\"loaded_in_8bit\", False) kwargs[\"loaded_in_4bit\"] = optionnal_kwargs.pop(\"loaded_in_4bit\", False) kwargs[\"bias\"] = bias if isinstance(target, LoraLayer) and isinstance(target, torch.nn.Conv2d): ... else: new_module = self._create_new_module( lora_config, adapter_name, target, **kwargs ) self._replace_module(parent, target_name, new_module, target) 这里看到了 LoraLayer，猜测应该是改变之后的 Linear 层，但我们关心的是 LoRA 如何在 nn.Linear 层上面做改动，因此应该看 _create_new_module 方法 python class LoraModel(BaseTuner): def _create_new_module(lora_config, adapter_name, target, **kwargs): if loaded_in_8bit and isinstance(target, bnb.nn.Linear8bitLt): ... else: if isinstance(target, torch.nn.Linear): # 拷贝本来的权重矩阵的 in_features 和 out_features 属性 in_features, out_features = target.in_features, target.out_features elif isinstance(target, Conv1D): ... else: ... new_module = Linear( adapter_name, in_features, out_features, bias=bias, **kwargs ) return new_module 通过拷贝本来的 nn.Linear 的 in_features 和 out_features 属性，LoRA 创建了一个 Linear 类，在同个文件中可以找到这个类的定义 python class Linear(nn.Linear, LoraLayer): def __init__( self, adapter_name: str, in_features: int, out_features: int, r: int = 0, lora_alpha: int = 1, lora_dropout: float = 0.0, fan_in_fan_out: bool = False, is_target_conv_1d_layer: bool = False, **kwargs, ): init_lora_weights = kwargs.pop(\"init_lora_weights\", True) nn.Linear.__init__(self, in_features, out_features, **kwargs) LoraLayer.__init__(self, in_features=in_features, out_features=out_features) # Freezing the pre-trained weight matrix self.weight.requires_grad = False nn.Linear.reset_parameters(self) self.update_layer(adapter_name, r, lora_alpha, lora_dropout, init_lora_weights) self.active_adapter = adapter_name Linear 类采用了 Mixin 的设计模式，分别调用了 nn.Linear 和 LoraLayer 的构造函数，注意这里的 self.weight 是模型本来的 nn.Linear 层的权重，可以看到被冻结了，而 LoRA 引入的权重矩阵则是用 update_layer 方法设置，搜索该方法将","date":"2023-09-14","objectID":"/zh-cn/lora-finetuning/:3:0","series":null,"tags":["Paper","Internal","Deep-Learning"],"title":"LoRA 微调","uri":"/zh-cn/lora-finetuning/#lora-源码阅读"},{"categories":["ML-DL"],"content":" 参考 LoRA: Low-Rank Adaptation of Large Language Models ↩︎ ↩︎ ↩︎ ↩︎ ","date":"2023-09-14","objectID":"/zh-cn/lora-finetuning/:4:0","series":null,"tags":["Paper","Internal","Deep-Learning"],"title":"LoRA 微调","uri":"/zh-cn/lora-finetuning/#参考"},{"categories":["Algorithm"],"content":"介绍了下一个排列问题的算法以及 Python 实现","date":"2023-09-06","objectID":"/zh-cn/the-next-lexicographical-permutation-problem/","series":null,"tags":["Algorithm"],"title":"下一个排列问题","uri":"/zh-cn/the-next-lexicographical-permutation-problem/"},{"categories":["Algorithm"],"content":" 引言有时候我们会想要生成一个序列的「下一个排列」或者是「上一个排列」，你会怎么做呢？如果你对 C++ 很熟悉的话，不难想到可以用 next_permutation1 和 prev_permutation2。但是 Python 并没有提供类似的 API。因此今天要探讨的就是如何用 Python 实现这 2 个 API，又因为「上一个排列」和「下一个排列」的方法其实大同小异，因此让我们聚焦其中的「下一个排列」问题 ","date":"2023-09-06","objectID":"/zh-cn/the-next-lexicographical-permutation-problem/:1:0","series":null,"tags":["Algorithm"],"title":"下一个排列问题","uri":"/zh-cn/the-next-lexicographical-permutation-problem/#引言"},{"categories":["Algorithm"],"content":" 算法流程也许会让你感到意外的是，「下一个排列」问题在 14 世纪的时候就有人想出解决办法来了3，假设现在给定一个序列 a，下面是具体的算法步骤 找到最大的索引 k 使得 a[k] \u003c a[k + 1]，如果不存在这样的索引的话，那么说明当前的序列已经是最后一个排列了 找到最大的索引 l，l \u003e k 而且 a[k] \u003c a[l] 交换 a[k], a[l] 的值 翻转从 a[k + 1] 开始的部分 这样你就得到了「下一个排列」，但为什么这个算法是正确的？接下来我们逐步拆解一下这些步骤背后的原理 ","date":"2023-09-06","objectID":"/zh-cn/the-next-lexicographical-permutation-problem/:2:0","series":null,"tags":["Algorithm"],"title":"下一个排列问题","uri":"/zh-cn/the-next-lexicographical-permutation-problem/#算法流程"},{"categories":["Algorithm"],"content":" 算法的理解试问一个问题，在不知道这个算法之前，你会如何解决「下一个排列」问题？如果你对回溯算法很熟悉的话，应该不难想到我们可以干脆从第一个排列开始暴力枚举，逐个对比就容易定位到当前序列的下一个排列了。当然这个算法的复杂度太高，达到了 $O(N!)$。因此我们可以尝试优化一下，这就带来了第一个问题 Q1 - 用回溯算法生成当前序列的「下一个排列」的时候有什么特点？ 我们可以按顺序打出 [1, 2, 3, 4] 的所有排列并尝试找一下规律 Python [[1, 2, 3, 4], [1, 2, 4, 3], [1, 3, 2, 4], [1, 3, 4, 2], [1, 4, 2, 3], [1, 4, 3, 2], [2, 1, 3, 4], ... # omit [4, 3, 2, 1]] 就看其中一个例子好了，[1, 4, 3, 2] 为什么下一个排列是 [2, 1, 3, 4]？你能否发现什么规律？更确切地说，为什么第一位从 1 变成了 2？[1, 4, 3, 2] 这个序列有什么特点？可以看到末尾的 4, 3, 2 是最长非递增后缀的，那么这个规律适用任何情况吗？不妨再看另外一个例子，[1, 2, 4, 3] -\u003e [1, 3, 2, 4]，你会发现，同样的，我们仍然可以找到一个最长非递增后缀 [4, 3]，同时第二位的 2 变成了 3，把这些并排放在一起可能会更直观些： Python [1, 4, 3, 2] ^ # non-increasing suffix [2, 1, 3, 4] ^ # change this [1, 2, 4, 3] ^ # non-increasing suffix [1, 3, 2, 4] ^ # change this 所以结论似乎是——找到序列末尾的最长非递增后缀的开始位置 j，要生成下一个序列的话需要调大 j - 1 的位置的值。这恰恰是前面算法流程的第一步做的事情。如果从上面的观察导出这个结论无法说服你，那么可以从回溯的代码角度入手，什么时候会修改 j - 1 的值？答案是当我们已经枚举完 a[j:] 部分的所有排列的时候，那么这个时候 a[j:] 有什么特点？特点是，从 a[j:] 会是非递增的，因为我们回溯的时候是按照字典序从小到大枚举 Python indices: 0, 1, 2, ..., j - 1, j, ..., n - 1 # a[j - 1] \u003c a[j] A1 - 在生成下一个排列的时候，我们总是会调大末尾的最长非递增后缀的左边一个位置的元素 为了后续讨论方便，我们称前面找到的最长非递增后缀左边的位置为 pivot（也就是前面的 j - 1）。那么现在就引出了第二个问题 Q2 - a[pivot] 的值要怎么改变？ 因为要求解的是下一个排列，因此我们希望 a[pivot] 要增加，而且不要增加太多，应该增加“一点点”就好，那么什么是这个“一点点”？仍然从回溯的角度理解，我们会按照字典序从小到大枚举，因此 a[pivot] 应该要变成比它更大的下一个元素，那么这个下一个更大的元素去哪里找？答案是在 a[pivot + 1:] 里面找，换言之，我们要去 a[pivot + 1:] 里面找比 a[pivot] 大而且尽量小的元素 别忘了 a[pivot + 1:] 的特点：它是非递增的，因此我们可以从右到左检查 a[pivot + 1:] 这个部分的元素的值，找到第一个比 a[pivot] 大的，这又解释了前面算法的第二个步骤 A2 - 从右到左在 a[pivot + 1:] 里面找第一个值比 a[pivot] 大的索引（这个索引我们记作 r） 前面提到的算法还有最后两个步骤没有解释，这两个其实是互相关联的 Q3 - 为什么要交换 a[pivot] 和 a[r]，以及为什么随后要翻转 a[pivot + 1:]？ 理论上来说，我们修改了 a[pivot] 的值之后，a[pivot + 1:] 这个部分也需要修改，那么问题是如何修改？从回溯的角度来看，a[pivot + 1:] 应该从最小字典序开始枚举，这意味着 a[pivot + 1:] 应该是非递减的。有趣的是，交换 a[pivot] 和 a[r] 之后，a[pivot + 1:] 这个后缀仍然是非递增的，那么我们要把它变成非递减的只需要翻转一下这个部分就行，这就解释了前面算法的第三步和第四步 A3 - 交换 a[pivot] 和 a[r] 之后 a[pivot + 1:] 仍然是非递增，翻转操作把这个后缀变成了非递减 ","date":"2023-09-06","objectID":"/zh-cn/the-next-lexicographical-permutation-problem/:3:0","series":null,"tags":["Algorithm"],"title":"下一个排列问题","uri":"/zh-cn/the-next-lexicographical-permutation-problem/#算法的理解"},{"categories":["Algorithm"],"content":" 代码Leetcode 有一道题目可以练习，推荐先按照自己的理解动手实现下再参考下面的代码 :) Python class Solution: def nextPermutation(self, nums: List[int]) -\u003e None: # Step 1. Find the rightmost i s.t. a[i] \u003e a[i - 1] # and set pivot to i - 1 pivot = -1 for i in reversed(range(len(nums))): if i - 1 \u003e= 0 and nums[i] \u003e nums[i - 1]: pivot = i - 1 break if pivot == -1: nums.reverse() return # Step 2. Find the rightmost value s.t. a[i] \u003e a[pivot] for i in reversed(range(len(nums))): if nums[i] \u003e nums[pivot]: nums[i], nums[pivot] = nums[pivot], nums[i] break # Step 3. Reverse the (pivot, len(nums)) part left, right = pivot + 1, len(nums) - 1 while left \u003c right: nums[left], nums[right] = nums[right], nums[left] left += 1 right -= 1 return None ","date":"2023-09-06","objectID":"/zh-cn/the-next-lexicographical-permutation-problem/:4:0","series":null,"tags":["Algorithm"],"title":"下一个排列问题","uri":"/zh-cn/the-next-lexicographical-permutation-problem/#代码"},{"categories":["Algorithm"],"content":" 总结从回溯的角度来理解「下一个排列」问题的算法就很自然了（起码对我来说），希望你也能有所收获 :) ","date":"2023-09-06","objectID":"/zh-cn/the-next-lexicographical-permutation-problem/:5:0","series":null,"tags":["Algorithm"],"title":"下一个排列问题","uri":"/zh-cn/the-next-lexicographical-permutation-problem/#总结"},{"categories":["Algorithm"],"content":" 参考 std::next_permutation ↩︎ std::prev_permutation ↩︎ Permutation-Wiki ↩︎ ","date":"2023-09-06","objectID":"/zh-cn/the-next-lexicographical-permutation-problem/:6:0","series":null,"tags":["Algorithm"],"title":"下一个排列问题","uri":"/zh-cn/the-next-lexicographical-permutation-problem/#参考"},{"categories":["NLP"],"content":"介绍了 BPE 算法用来分词的原理","date":"2023-08-24","objectID":"/zh-cn/the-bpe-tokenizer/","series":null,"tags":["NLP","LLM"],"title":"BPE 分词解密 - 实现方法与示例讲解","uri":"/zh-cn/the-bpe-tokenizer/"},{"categories":["NLP"],"content":" BPE 简介在 NLP 里面，一个核心的问题是，如何对文本进行分词？从分类的角度上面来说，可以分为： Char level Word level Subword level 先看 Char level 分词，顾名思义，就是把文本拆分成一个个字符单独表示，比如 highest -\u003e h, i, g, h, e, s, t，一个显然的好处是，Vocab 不会太大，Vocab 的大小为字符集的大小，也不会遇到 Out-of-vocabulary(OOV) 的问题，但是字符本身并没有传达太多的语义，而且分词之后会有太多的 token，光是一个 highest 就可以得到 7 个 token，难以想象很长的文本分出来会有多少个😨 再看 Word level 分词，Word level 分词一般通过空格或者标点符号来把文本分成一个个单词，这样分词之后的 token 数量就不会太多，比如 Today is a good day -\u003e Today, is, a, good, day。但 Word level 分词也有问题，比如英文中的 high, higher, highest 这三个单词显然语义相似，因为另外两个只是比较级，但是 Word level 分词会把他们看成 3 个单独的单词 🤔️ 那么是否存在一种折中的办法，使得我们大概率不会遇到 OOV 的问题；分词得到的 token 数量又不能太多；而且分词能够考虑到复合词、时态变化、单复数呢？这就是 Subword level 做的事情，仍然是刚才的例子，根据英语的词根原理的话，我们可以把 higher 划分为 high, er，highest 划分为 high, est，所以 Subword level 分词就是把一个单词用多个子词表示，今天要介绍的 BPE 就属于 Subword level 的一种 BPE 的全称是 Byte Pair Encoding，这里有个细节值得思考，什么是 Byte pair？ASCII 编码的话任何字符都是 1 byte，但如果是 utf-8 编码呢？一个字符不一定是 1 byte，它可以是 3 bytes 也可以是 4 bytes，🤔️ 那如果 BPE 用在 utf-8 的文本里面，byte pair 又是什么东西？所以我感觉这里是有点歧义性的，因此更恰当的理解方式也许是，byte pair 其实是 char pair，这里的 char 是 utf-8 的 char ","date":"2023-08-24","objectID":"/zh-cn/the-bpe-tokenizer/:1:0","series":null,"tags":["NLP","LLM"],"title":"BPE 分词解密 - 实现方法与示例讲解","uri":"/zh-cn/the-bpe-tokenizer/#bpe-简介"},{"categories":["NLP"],"content":" BPE 训练流程接下来正式介绍 BPE 分词算法的训练流程，假设我们手头有一堆文档 $D={d_1,d_2,…}$ 把每个文档 $d$ 变成单词列表，比如你可以简单用空格分词 统计每个单词 $w$ 在所有文档 $D$ 中的出现频率，并计算初始字符集 alphabet 作为一开始的 Vocab（包括后面的 \u003c/w\u003e），字符集的意思就是所有文档 $D$ 中不同的字符集合 先将每个单词划分为一个个 utf-8 char，称为一个划分，比如 highest -\u003e h, i, g, h, e, s, t 然后，在每个单词的划分最后面加上 \u003c/w\u003e，那么现在 highest -\u003e h, i, g, h, e, s, t, \u003c/w\u003e 重复下面步骤直到满足两个条件中的任意一个：1）Vocab 达到上限。2）达到最大迭代次数 找到最经常一起出现的 pair，并记录这个合并规则，放在 merge table 里面，同时把合并之后的结果放到 Vocab 里面 更新所有单词的划分，假设我们发现 (h, i) 最经常一起出现，那么 hi 就会被添加到 Vocab 里面，同时修改划分方式为：highest -\u003e hi, g, h, e, s, t, \u003c/w\u003e 你可能会有下面 3 个疑惑： 为什么要统计词频？因为统计词频会让找最经常出现的 pair 这件事变得简单 为什么要加 \u003c/w\u003e？因为我们希望能够还原输入，因此需要做个标记表示这是单词之间的边界 如果多个 pair 的词频一样怎么处理？这个不同实现可能不一样，但在我看来应该关系不大 💡 从算法流程可以看到，BPE 分词算法合并最经常一起出现的 pair 的时候，并不会跨越单词 ","date":"2023-08-24","objectID":"/zh-cn/the-bpe-tokenizer/:1:1","series":null,"tags":["NLP","LLM"],"title":"BPE 分词解密 - 实现方法与示例讲解","uri":"/zh-cn/the-bpe-tokenizer/#bpe-训练流程"},{"categories":["NLP"],"content":" BPE 应用流程在 BPE 完成训练之后，我们会得到一个 merge table，也会得到一个 Vocab，假设现在要处理文本 s 和训练的时候采用一样的方法，先把 s 拆分成单词列表，每个单词拆分为一个个 utf-8 char，记得每个单词的划分最后要加上 \u003c/w\u003e 遍历 merge table，并检查每个合并规则是否可以用来更新每个单词的划分，可以的话就合并更新 💡 这里有个细节：之前我们是找最经常一起出现的 pair 并记录这个合并规则。所以按序遍历 merge table 就已经隐含了「优先合并最经常出现的 pair」这件事了，注意体会~ ","date":"2023-08-24","objectID":"/zh-cn/the-bpe-tokenizer/:1:2","series":null,"tags":["NLP","LLM"],"title":"BPE 分词解密 - 实现方法与示例讲解","uri":"/zh-cn/the-bpe-tokenizer/#bpe-应用流程"},{"categories":["NLP"],"content":" BPE 例子停留在算法不提供例子的话，经常还是会云里雾里，所以现在来结合一个例子看 BPE 是如何工作的 比如语料库是 python corpus = [\"highest\", \"higher\", \"lower\", \"lowest\", \"cooler\", \"coolest\"] 这里跳过统计词频，因为每一个都是 1。先把每个单词变成一个个 utf-8 字符然后加上 \u003c/w\u003e python { \"highest\": [\"h\", \"i\", \"g\", \"h\", \"e\", \"s\", \"t\", \"\u003c/w\u003e\"], \"higher\": [\"h\", \"i\", \"g\", \"h\", \"e\", \"r\", \"\u003c/w\u003e\"], \"lower\": [\"l\", \"o\", \"w\", \"e\", \"r\", \"\u003c/w\u003e\"], \"lowest\": [\"l\", \"o\", \"w\", \"e\", \"s\", \"t\", \"\u003c/w\u003e\"], \"cooler\": [\"c\", \"o\", \"o\", \"l\", \"e\", \"r\", \"\u003c/w\u003e\"], \"collest\": [\"c\", \"o\", \"o\", \"l\", \"e\", \"s\", \"t\", \"\u003c/w\u003e\"], } 可以看到 (e, s) 总共出现了 3 次，是最多次的，将 es 添加到 Vocab 里面，然后重新划分。注意这里 (e, r) 其实也有一样的出现频率，所以选 (e, r) 合并也是可以的 python { \"highest\": [\"h\", \"i\", \"g\", \"h\", \"es\", \"t\", \"\u003c/w\u003e\"], \"higher\": [\"h\", \"i\", \"g\", \"h\", \"e\", \"r\", \"\u003c/w\u003e\"], \"lower\": [\"l\", \"o\", \"w\", \"e\", \"r\", \"\u003c/w\u003e\"], \"lowest\": [\"l\", \"o\", \"w\", \"es\", \"t\", \"\u003c/w\u003e\"], \"cooler\": [\"c\", \"o\", \"o\", \"l\", \"e\", \"r\", \"\u003c/w\u003e\"], \"collest\": [\"c\", \"o\", \"o\", \"l\", \"es\", \"t\", \"\u003c/w\u003e\"], } 接下来发现最多的是 (es, t)，更新划分 python { \"highest\": [\"h\", \"i\", \"g\", \"h\", \"est\", \"\u003c/w\u003e\"], \"higher\": [\"h\", \"i\", \"g\", \"h\", \"e\", \"r\", \"\u003c/w\u003e\"], \"lower\": [\"l\", \"o\", \"w\", \"e\", \"r\", \"\u003c/w\u003e\"], \"lowest\": [\"l\", \"o\", \"w\", \"est\", \"\u003c/w\u003e\"], \"cooler\": [\"c\", \"o\", \"o\", \"l\", \"e\", \"r\", \"\u003c/w\u003e\"], \"collest\": [\"c\", \"o\", \"o\", \"l\", \"est\", \"\u003c/w\u003e\"], } 接下来发现最多的是 (est, \u003c/w\u003e)，更新划分 python { \"highest\": [\"h\", \"i\", \"g\", \"h\", \"est\u003c/w\u003e\"], \"higher\": [\"h\", \"i\", \"g\", \"h\", \"e\", \"r\", \"\u003c/w\u003e\"], \"lower\": [\"l\", \"o\", \"w\", \"e\", \"r\", \"\u003c/w\u003e\"], \"lowest\": [\"l\", \"o\", \"w\", \"est\u003c/w\u003e\"], \"cooler\": [\"c\", \"o\", \"o\", \"l\", \"e\", \"r\", \"\u003c/w\u003e\"], \"collest\": [\"c\", \"o\", \"o\", \"l\", \"est\u003c/w\u003e\"], } 接下来发现最多的是 (e, r)，更新划分 python { \"highest\": [\"h\", \"i\", \"g\", \"h\", \"est\u003c/w\u003e\"], \"higher\": [\"h\", \"i\", \"g\", \"h\", \"er\", \"\u003c/w\u003e\"], \"lower\": [\"l\", \"o\", \"w\", \"er\", \"\u003c/w\u003e\"], \"lowest\": [\"l\", \"o\", \"w\", \"est\u003c/w\u003e\"], \"cooler\": [\"c\", \"o\", \"o\", \"l\", \"er\", \"\u003c/w\u003e\"], \"collest\": [\"c\", \"o\", \"o\", \"l\", \"est\u003c/w\u003e\"], } 接下来发现最多的是 (er, \u003c/w\u003e)，更新划分 python { \"highest\": [\"h\", \"i\", \"g\", \"h\", \"est\u003c/w\u003e\"], \"higher\": [\"h\", \"i\", \"g\", \"h\", \"er\u003c/w\u003e\"], \"lower\": [\"l\", \"o\", \"w\", \"er\u003c/w\u003e\"], \"lowest\": [\"l\", \"o\", \"w\", \"est\u003c/w\u003e\"], \"cooler\": [\"c\", \"o\", \"o\", \"l\", \"er\u003c/w\u003e\"], \"collest\": [\"c\", \"o\", \"o\", \"l\", \"est\u003c/w\u003e\"], } 后面还可以继续迭代更新，这里就不展开了，相信上面的例子已经够清楚了。而且到这一步，我们已经得到了 er, est 这两个有意义的后缀 :) ","date":"2023-08-24","objectID":"/zh-cn/the-bpe-tokenizer/:1:3","series":null,"tags":["NLP","LLM"],"title":"BPE 分词解密 - 实现方法与示例讲解","uri":"/zh-cn/the-bpe-tokenizer/#bpe-例子"},{"categories":["NLP"],"content":" BPE 的 Huggingface 实现Huggingface 提供的 API 还挺简单的，可以注意到 CharBPETokenizer 的 Char，也证明了前面我说的——BPE 是按照 char pair 来的 python from tokenizers import CharBPETokenizer # Instantiate tokenizer tokenizer = CharBPETokenizer() tokenizer.train_from_iterator( corpus, vocab_size=17, min_frequency=2, ) ","date":"2023-08-24","objectID":"/zh-cn/the-bpe-tokenizer/:1:4","series":null,"tags":["NLP","LLM"],"title":"BPE 分词解密 - 实现方法与示例讲解","uri":"/zh-cn/the-bpe-tokenizer/#bpe-的-huggingface-实现"},{"categories":["NLP"],"content":" 手动实现 BPE最好理解一个算法的办法永远都是尝试自己实现一个。我这里按照前面描述的算法流程实现了一个 BPE 类，如果初始化的时候设置 debug=True 就可以看到整个 BPE 是如何更新的 首先来看构造函数和用来训练的 train 方法 python from collections import defaultdict, Counter from pprint import pprint class BPE: def __init__( self, corpus: list[str], vocab_size: int, max_iter: int | None = None, debug: bool = False, ): self.corpus = corpus self.vocab_size = vocab_size self.vocab = [] self.word_freq = Counter() self.splits = {} # e.g. highest: [high, est\u003c/w\u003e] self.merges = {} # e.g. [high, est\u003c/w\u003e]: highest self.max_iter = max_iter self.debug = debug def train(self): \"\"\"Train a BPE Tokenizer\"\"\" # count the word frequency for document in self.corpus: # split each document in corpus by whitespace words = document.split() self.word_freq += Counter(words) # initialize the self.splits for word in self.word_freq: self.splits[word] = list(word) + [\"\u003c/w\u003e\"] if self.debug: print(f\"Init splits: {self.splits}\") alphabet = set() for word in self.word_freq: alphabet |= set(list(word)) alphabet.add(\"\u003c/w\u003e\") self.vocab = list(alphabet) self.vocab.sort() cnt = 0 while len(self.vocab) \u003c self.vocab_size: if self.max_iter and cnt \u003e= self.max_iter: break # find the most frequent pair pair_freq = self.get_pairs_freq() if len(pair_freq) == 0: print(\"No pair available\") break pair = max(pair_freq, key=pair_freq.get) self.update_splits(pair[0], pair[1]) if self.debug: print(f\"Updated splits: {self.splits}\") self.merges[pair] = pair[0] + pair[1] self.vocab.append(pair[0] + pair[1]) if self.debug: print( f\"Most frequent pair({max(pair_freq.values())} times) \" f\"is : {pair[0]}, {pair[1]}. Vocab size: {len(self.vocab)}\" ) cnt += 1 流程还是挺清晰的，核心的几个函数实现如下 python ... def update_splits(self, lhs: str, rhs: str): \"\"\"If we see lhs and rhs appear consecutively, we merge them\"\"\" for word, word_split in self.splits.items(): new_split = [] cursor = 0 while cursor \u003c len(word_split): if ( word_split[cursor] == lhs and cursor + 1 \u003c len(word_split) and word_split[cursor + 1] == rhs ): new_split.append(lhs + rhs) cursor += 2 else: new_split.append(word_split[cursor]) cursor += 1 self.splits[word] = new_split # if word_split != new_split: # print(f\"old: {word_split}\") # print(f\"new: {new_split}\") def get_pairs_freq(self) -\u003e dict: \"\"\"Compute the pair frequency\"\"\" pairs_freq = defaultdict(int) for word, freq in self.word_freq.items(): split = self.splits[word] for i in range(len(split)): if i + 1 \u003c len(split): pairs_freq[(split[i], split[i + 1])] += freq return pairs_freq 最后我们就可以写一个 tokenize 函数 python ... def tokenize(self, s: str) -\u003e list[str]: splits = [list(t) + [\"\u003c/w\u003e\"] for t in s.split()] for lhs, rhs in self.merges: for idx, split in enumerate(splits): new_split = [] cursor = 0 while cursor \u003c len(split): if ( cursor + 1 \u003c len(split) and split[cursor] == lhs and split[cursor + 1] == rhs ): new_split.append(lhs + rhs) cursor += 2 else: new_split.append(split[cursor]) cursor += 1 assert \"\".join(new_split) == \"\".join(split) splits[idx] = new_split return sum(splits, []) 尝试用自己写的 BPE 对刚才的 corpus 进行分词 python bpe = BPE(corpus, vocab_size=17, debug=False) bpe.train() bpe.tokenize(\" \". join(corpus)) 输出是： python ['h', 'i', 'g', 'h', 'est\u003c/w\u003e', 'h', 'i', 'g', 'h', 'er\u003c/w\u003e', 'l', 'o', 'w', 'er\u003c/w\u003e', 'l', 'o', 'w', 'est\u003c/w\u003e', 'c', 'o', 'o', 'l', 'er\u003c/w\u003e', 'c', 'o', 'o', 'l', 'est\u003c/w\u003e'] 🤔️ 说明代码写对了，而且多亏了 \u003c/w\u003e，我们可以很清楚看到单词之间的边界，也可以还原出本来的输入 ","date":"2023-08-24","objectID":"/zh-cn/the-bpe-tokenizer/:1:5","series":null,"tags":["NLP","LLM"],"title":"BPE 分词解密 - 实现方法与示例讲解","uri":"/zh-cn/the-bpe-tokenizer/#手动实现-bpe"},{"categories":["NLP"],"content":" 总结BPE 算法简单而且很好用，但是当深入到实现的时候，你发现会有不少细节问题，但正是因为接触到这些细节才使得对 BPE 的理解更加深刻🍺 这里可以讨论一下 BPE 的局限性，那就是你会发现把文档变成一个个单词我们这里用的是空格划分，但是像中文的话，空格并不是单词之间的边界，这就不大好办了 ","date":"2023-08-24","objectID":"/zh-cn/the-bpe-tokenizer/:1:6","series":null,"tags":["NLP","LLM"],"title":"BPE 分词解密 - 实现方法与示例讲解","uri":"/zh-cn/the-bpe-tokenizer/#总结"},{"categories":["NLP"],"content":"介绍了 NLP 中的 TF-IDF 模型","date":"2023-08-16","objectID":"/zh-cn/an-introduction-of-tf-idf-model/","series":null,"tags":["NLP","Machine-Learning","Internal"],"title":"TF-IDF 模型","uri":"/zh-cn/an-introduction-of-tf-idf-model/"},{"categories":["NLP"],"content":" 什么是 TF-IDF 模型在之前的 文章 中谈到了词袋模型，也讲到了它的许多不足，在今天的这篇文章中，我们要尝试解决词袋模型的缺点之一：每个词的重要性是一样的 Quesstion 那么，核心问题就是————如何定义「单词的重要性」这个概念？ 一个想法是：一个单词在一个文档里面出现得越频繁，则这个单词对于这个文档来说越重要。比如一篇讨论狗的文章，大概率文章里面会出现很多「狗」，即词频高的单词反映了文档的主题 但如果这个词在语料库的所有文档中都出现得很频繁呢？比如「的」，在每个文档中，它的词频应该都不低，那能说这个单词更重要吗？显然是不行的，「的」更多是服务于语法结构而没包含太多的语义信息。于是我们有了另外一个线索：如果一个单词在每个文档中的词频都很高，那么这个单词的重要性应该就没那么重要 因此一个合理的解决方案应该考虑单词在「单个文档」的词频，但也应该考虑它在「多个文档」的词频，TF-IDF 就兼顾了这两点 Note 概括来说，TF-IDF 的“直觉”理解就是：相似的文档用的词 也许 是差不多的，而不同的词的重要性应该是不一样的 ","date":"2023-08-16","objectID":"/zh-cn/an-introduction-of-tf-idf-model/:1:0","series":null,"tags":["NLP","Machine-Learning","Internal"],"title":"TF-IDF 模型","uri":"/zh-cn/an-introduction-of-tf-idf-model/#什么是-tf-idf-模型"},{"categories":["NLP"],"content":" TF-IDF 模型细节TF-IDF 由 2 个部分组成：词频（Term frequency，TF） + 逆文档频率（Inverse document frequency，IDF），先说 TF 再说 IDF ","date":"2023-08-16","objectID":"/zh-cn/an-introduction-of-tf-idf-model/:2:0","series":null,"tags":["NLP","Machine-Learning","Internal"],"title":"TF-IDF 模型","uri":"/zh-cn/an-introduction-of-tf-idf-model/#tf-idf-模型细节"},{"categories":["NLP"],"content":" TF所谓 TF，可以看成是关于文档 $d$ 和单词 $w$ 的函数 $\\text{TF}(w, d)$，计算公式如下： $$ \\text{TF}(w, d)=\\frac{\\text{frequency of}\\ w\\ \\text{in}\\ d}{\\text{word counts of } d} $$ 也就是统计文档 $d$ 的单词 $w$ 的词频，然后除以对应文档 $d$ 的总的单词数量即可 Bug 在 Scikit-Learn 框架中，TF 的计算不大一样，它并没有除以文档的总的单词数量。其实除以文档的总的单词数量是为了让一个文档 $d$ 的所有单词的 $\\text{TF}(w, d)$ 加起来为一，起到一个归一化的作用 Scikit-Learn 是在 TF-IDF 计算完成之后才做归一化的。后面我们会用一个例子证明这点 ","date":"2023-08-16","objectID":"/zh-cn/an-introduction-of-tf-idf-model/:2:1","series":null,"tags":["NLP","Machine-Learning","Internal"],"title":"TF-IDF 模型","uri":"/zh-cn/an-introduction-of-tf-idf-model/#tf"},{"categories":["NLP"],"content":" IDF在写下 IDF 的具体公式之前，别忘了我们的目的：降低每个文档都出现的常见词的重要性。所以 IDF 是一个关于单词 $w$ 和语料库 $corpus$ 的函数 $$ \\text{IDF}(w, corpus)=log\\ \\frac{\\text{document count of }corpus}{1+\\text{count of document which contains }w} $$ 注意分母位置的 1 避免了除 0 的情况 Note $corpus$ 一般是固定下来不变的，可以看成一个常量而不是自变量，那么就可以把 IDF 看成是只跟单词 $w$ 有关系 Warning 注意一个问题，这里的 $log$ 是 $log_2$ 还是 $log_{10}$ 还是 $ln$ ？不同的框架的实现可能会有差异，Scikit-Learn 用的是自然对数 $ln$ Bug 在 Scikit-Learn 框架中，IDF 的计算跟上面的公式并不一样，默认情况下 Scikit-Learn 的 IDF 是这样的 1 $$ \\text{IDF}(w, corpus)=log\\ \\frac{1 + \\text{document count of }corpus}{1+\\text{count of document which contains }w} + 1 $$ 🤔️ 我个人理解的话就是，Scikit-Learn 做的改动使得 $\\text{IDF}(w)$ 不可能小于 1，而本来的公式如果一个单词 $w$ 在每个文档都出现了的话，$\\text{IDF}(w)$ 算出来会是负的，因此 Scikit-Learn 的改动感觉更实用了，不同单词的 IDF 比较起来就很直观 ","date":"2023-08-16","objectID":"/zh-cn/an-introduction-of-tf-idf-model/:2:2","series":null,"tags":["NLP","Machine-Learning","Internal"],"title":"TF-IDF 模型","uri":"/zh-cn/an-introduction-of-tf-idf-model/#idf"},{"categories":["NLP"],"content":" TF-IDF把 TF 和 IDF 相乘，就得到了最后的 TF-IDF 表达式： $$ \\text{TF-IDF}(w, d, corpus)=\\text{TF}(w, d) * \\text{IDF}(w, corpus) $$ ","date":"2023-08-16","objectID":"/zh-cn/an-introduction-of-tf-idf-model/:2:3","series":null,"tags":["NLP","Machine-Learning","Internal"],"title":"TF-IDF 模型","uri":"/zh-cn/an-introduction-of-tf-idf-model/#tf-idf"},{"categories":["NLP"],"content":" Scikit-Learn 的 TF-IDF虽然 TF-IDF 实现起来很简单，但是实际用的时候，你多半还是不会自己实现 TF-IDF，而是直接用成熟的 Scikit-Learn 提供的 API。这里我们来研究一下 Scikit-Learn 怎么计算 TF-IDF。我们继续沿用 Scikit-Learn 的官方例子 python toy_corpus = [ 'This is the first document.', 'This is the second second document.', 'And the third one.', 'Is this the first document?', ] tokenized_toy_corpus = [ ['this', 'is', 'the', 'first', 'document'], ['this', 'is', 'the', 'second', 'second', 'document'], ['and', 'the', 'third', 'one'], ['is', 'this', 'the', 'first', 'document'] ] 让我们先来看看 Scikit-Learn 里面如何计算 TF-IDF python from sklearn.feature_extraction.text import TfidfVectorizer # set norm=None for comparison vectorizer = TfidfVectorizer(norm=None) X = vectorizer.fit_transform(toy_corpus) 通过 X.toarray() 就可以拿到 TF-IDF 矩阵，如下所示（注意我关闭了归一化，所以一个文档内的不同单词的 TF-IDF 值加起来不为 1） and document first is one second the third this document1 0.0 1.22314 1.51082 1.22314 0.0 0.0 1.0 0.0 1.22314 document2 0.0 1.22314 0.0 1.22314 0.0 3.83258 1.0 0.0 1.22314 document3 1.91629 0.0 0.0 0.0 1.91629 0.0 1.0 1.91629 0.0 document4 0.0 1.22314 1.51082 1.22314 0.0 0.0 1.0 0.0 1.22314 下面则是之前词袋模型的输出 and document first is one second the third this document1 0 1 1 1 0 0 1 0 1 document2 0 1 0 1 0 2 1 0 1 document3 1 0 0 0 1 0 1 1 0 document4 0 1 1 1 0 0 1 0 1 🤔️ 对比一下两者你会发现，现在 document1 文档里面 document，first 这两个单词的重要性不一样了：document 的 TF-IDF 是 1.22314，而 first 的 TF-IDF 是 1.51082，因为语料库中包含他们的文档数量并不相同。而词袋模型认识不到这点，认为两者都是 1 通过 vectorizer 的 idf_ 属性我们就能够拿到 Scikit-Learn 计算出来的每个单词的 IDF python print(vectorizer.idf_) # [1.91629073 1.22314355 1.51082562 1.22314355 1.91629073 # 1.91629073 1. 1.91629073 1.22314355] 🤔️ 此时你要是把这个 IDF 向量乘以词袋模型输出的矩阵（注意向量会被广播），你就得到了 Scikit-Learn 算出来的 TF-IDF 矩阵，这验证了前面我们说的： Scikit-Learn 直接用词袋模型的输出当成 TF Scikit-Learn 的 IDF 计算跟标准的不一样 ","date":"2023-08-16","objectID":"/zh-cn/an-introduction-of-tf-idf-model/:3:0","series":null,"tags":["NLP","Machine-Learning","Internal"],"title":"TF-IDF 模型","uri":"/zh-cn/an-introduction-of-tf-idf-model/#scikit-learn-的-tf-idf"},{"categories":["NLP"],"content":" 手动实现 TF-IDF手动实现也并不复杂，下面假设语料库或者是文档都是分词好的，采用和 Scikit-Learn 一样的 TF-IDF 计算方式 Warning 注意下面的代码未经优化，只是为了演示 python import math def TF(word: str, tokenized_document: list[str]) -\u003e float: return tokenized_document.count(word) def IDF(word: str, tokenized_corpus: list[list[str]]) -\u003e float: doc_count_contains_word = 0 for doc in tokenized_corpus: if word in doc: doc_count_contains_word += 1 return math.log((1 + len(tokenized_corpus)) / (1 + doc_count_contains_word)) + 1 def TF_IDF( word: str, tokenized_document: list[str], tokenized_corpus: list[list[str]], ) -\u003e float: return TF(word, tokenized_document) * IDF(word, tokenized_corpus) ","date":"2023-08-16","objectID":"/zh-cn/an-introduction-of-tf-idf-model/:4:0","series":null,"tags":["NLP","Machine-Learning","Internal"],"title":"TF-IDF 模型","uri":"/zh-cn/an-introduction-of-tf-idf-model/#手动实现-tf-idf"},{"categories":["NLP"],"content":" 总结在这篇文章中，我们研究了 TF-IDF 如何对词袋模型做出了改进：额外考虑一个单词在所有文档中的词频来调整它的重要性。通过分析官方的例子，我们也验证了确实单词的重要性现在是不一样的了，这是对词袋模型一个不错的改进 从实现的角度来说，TF-IDF 的计算只需要遍历语料库一次即可，在遍历的过程中额外维护几个变量：每个单词出现在了多少个文档里面；处理的文档数量等，Gensim 的 Dictionary 类就是这么设计的，感兴趣的话可以看下源代码 ","date":"2023-08-16","objectID":"/zh-cn/an-introduction-of-tf-idf-model/:5:0","series":null,"tags":["NLP","Machine-Learning","Internal"],"title":"TF-IDF 模型","uri":"/zh-cn/an-introduction-of-tf-idf-model/#总结"},{"categories":["NLP"],"content":" 参考 TF-IDF term weighting ↩︎ ","date":"2023-08-16","objectID":"/zh-cn/an-introduction-of-tf-idf-model/:6:0","series":null,"tags":["NLP","Machine-Learning","Internal"],"title":"TF-IDF 模型","uri":"/zh-cn/an-introduction-of-tf-idf-model/#参考"},{"categories":["NLP"],"content":"词袋模型简介","date":"2023-08-11","objectID":"/zh-cn/an-introduction-of-bag-of-word-model/","series":null,"tags":["NLP","Machine-Learning","AI4SE"],"title":"词袋模型","uri":"/zh-cn/an-introduction-of-bag-of-word-model/"},{"categories":["NLP"],"content":" 什么是词袋模型在 NLP 中，我们需要将文档（document）表示为向量，这是因为机器学习只能够处理数字。也就是说，我们要找到下面这么一个神奇的函数： $$ f(\\text{document}) = vector $$ 今天要讨论的是词袋模型（bag-of-word, BoW），词袋模型可以让我们把输入的文档转变成一个向量表示 💡 尽管词袋模型在 2023 年已经过时了，我仍然鼓励你学习词袋模型，并且思考下面几个重要问题： Motivation 是什么？ 优缺点是什么？ 如何把它变得更好？ ","date":"2023-08-11","objectID":"/zh-cn/an-introduction-of-bag-of-word-model/:1:0","series":null,"tags":["NLP","Machine-Learning","AI4SE"],"title":"词袋模型","uri":"/zh-cn/an-introduction-of-bag-of-word-model/#什么是词袋模型"},{"categories":["NLP"],"content":" 词袋模型的 motivation 和直观理解在了解词袋模型细节之前，我想先给你一个词袋模型可能是有用的直觉 —— 相似的文档用的词也许是差不多的 你可能持反对意见，并且可以给出许多反例。我承认，这也是为什么我们需要更加强大的模型 :) ","date":"2023-08-11","objectID":"/zh-cn/an-introduction-of-bag-of-word-model/:1:1","series":null,"tags":["NLP","Machine-Learning","AI4SE"],"title":"词袋模型","uri":"/zh-cn/an-introduction-of-bag-of-word-model/#词袋模型的-motivation-和直观理解"},{"categories":["NLP"],"content":" 词袋模型细节构造一个词袋模型只需要做两件事情 创建词汇表（Vocab），每个单词都在词汇表里面有一个独特的 ID（一般从 0 开始）。注意词袋模型输出的向量的长度等于词汇表的大小 遍历语料库中的每个文档，把这个文档新出现的单词添加到词汇表里面 在构造好词袋模型之后，就可以把任何文档都转变成向量表示了。方法也很简单，只要统计文档中每个单词出现的次数。值得一提的是，对于文档中不在词汇表里面的单词，一般直接就忽略不计 让我们来结合一个简单例子理解1 python toy_corpus = [ 'This is the first document.', 'This is the second second document.', 'And the third one.', 'Is this the first document?', ] 删除标点符号，然后用空格分词，同时把所有的单词变成小写，预处理之后，我们就可以得到 python tokenized_toy_corpus = [ ['this', 'is', 'the', 'first', 'document'], ['this', 'is', 'the', 'second', 'second', 'document'], ['and', 'the', 'third', 'one'], ['is', 'this', 'the', 'first', 'document'] ] 为了简单，我们这里考虑把所有文档的所有单词都包括在词汇表里面 python flatten_list_as_set = set(sum(tokenized_toy_corpus, start=[])) print(f\"the toy vocab size: {len(flatten_list_as_set)}\") the toy vocab size: 9 💡 一个用 sum 函数摊平 list 的小技巧 :D 然后，让我们给词汇表里面的每个单词一个独特的 ID python toy_token2id = {} for token in sorted(flatten_list_as_set): toy_token2id[token] = len(toy_token2id) print(toy_token2id) { 'and': 0, 'document': 1, 'first': 2, 'is': 3, 'one': 4, 'second': 5, 'the': 6, 'third': 7, 'this': 8 } 可以看到，词汇表的大小是 9，那么我们也就知道，每个文档可以用一个长度为 9 的向量表示 让我们手动计算一下每个文档的词袋模型向量来检查我们是否理解正确 python BoW_matrix = [] for document in tokenized_toy_corpus: temp = [0] * 9 for token in document: temp[toy_token2id[token]] += 1 BoW_matrix.append(temp) print(BoW_matrix) [ [0, 1, 1, 1, 0, 0, 1, 0, 1], [0, 1, 0, 1, 0, 2, 1, 0, 1], [1, 0, 0, 0, 1, 0, 1, 1, 0], [0, 1, 1, 1, 0, 0, 1, 0, 1] ] 直接看数字的话不是很直观，可以多增加一行一列，就能把单词和词频对应上了。如果你检查答案1的话，你会发现和我们算出来的一模一样 and document first is one second the third this document1 0 1 1 1 0 0 1 0 1 document2 0 1 0 1 0 2 1 0 1 document3 1 0 0 0 1 0 1 1 0 document4 0 1 1 1 0 0 1 0 1 如何解读这个表格？ 每一行就是对应文档的词袋模型输出的向量表示，以 document2 为例，它包含了下面这些单词 document * 1 is * 1 second * 2 the * 1 this * 1 之前提到，分词之后的 document2 是 ['this', 'is', 'the', 'second', 'second', 'document']，显然和这个向量表示是对应的 现在你就知道如何解读这个了矩阵了 :D 🧐 你也许注意到了，这个矩阵中有很多 0。BoW 的矩阵确实是这样的，是一个稀疏矩阵，这也是它的缺点之一 python from sklearn.metrics.pairwise import cosine_similarity 我们可以用向量内积计算 2 个向量之间的相似度 之前的 tokenized_toy_corpus 如下 python tokenized_toy_corpus = [ ['this', 'is', 'the', 'first', 'document'], ['this', 'is', 'the', 'second', 'second', 'document'], ['and', 'the', 'third', 'one'], ['is', 'this', 'the', 'first', 'document'] ] 现在，假设查询（query）是最后一个文档 —— ['is', 'this', 'the', 'first', 'document']，前 3 个文档中哪一个跟它最像？ 我们可以一眼看出答案是第一个，那么机器能否也发现这点？ python print( cosine_similarity([BoW_matrix[3]], [BoW_matrix[0]]), cosine_similarity([BoW_matrix[3]], [BoW_matrix[1]]), cosine_similarity([BoW_matrix[3]], [BoW_matrix[2]]), ) [[1.]] [[0.63245553]] [[0.2236068]] 🤔️ 机器也看出来了 ","date":"2023-08-11","objectID":"/zh-cn/an-introduction-of-bag-of-word-model/:1:2","series":null,"tags":["NLP","Machine-Learning","AI4SE"],"title":"词袋模型","uri":"/zh-cn/an-introduction-of-bag-of-word-model/#词袋模型细节"},{"categories":["NLP"],"content":" 更复杂的真实数据集前面的例子太简单了，下面我会用一个更复杂的真实数据集 —— CodeSearchNet。它包含了许多编程语言的函数，这里我挑 Python 来展示 当然你也可以选择你感兴趣的编程语言 :) python from datasets import load_dataset from gensim import corpora def process_data(partition: str) -\u003e list[str]: \"\"\" Get data from the datasets library from huggingface. Only keep the `whole_func_string` column Arg --- `partition`: train/validation/test Return ----- return a list of python functions \"\"\" raw_datasets = load_dataset(\"code_search_net\", \"python\") return raw_datasets[partition][\"whole_func_string\"] 取决于你的网络这可能得花上一点时间，压缩文件大小是 941MB python # use the test dataset to speed up the process corpus = process_data(\"test\") 来看一下数据中的一个例子 python print(corpus[0]) def get_vid_from_url(url): \"\"\"Extracts video ID from URL. \"\"\" return match1(url, r'youtu\\.be/([^?/]+)') or \\ match1(url, r'youtube\\.com/embed/([^/?]+)') or \\ match1(url, r'youtube\\.com/v/([^/?]+)') or \\ match1(url, r'youtube\\.com/watch/([^/?]+)') or \\ parse_query_param(url, 'v') or \\ parse_query_param(parse_query_param(url, 'u'), 'v') 在前面的英文分词中，我们删除了标点符号，用空格分词。代码的分词则比较不一样，编程语言有自己对应的语法（上下文无关文法），那么就可以用词法分析器拿到一个个 token。我这里用 Python 自带的 tokenize 简单实现了一下 下面的函数如果看不懂也没关系，可以直接跳过。用词法分析器分词只是为了得到更精确的分词结果 :) python import ast from io import BytesIO import tokenize def get_token_stream(code: str) -\u003e list[str]: \"\"\" Tokenize the source code and return a token stream Note that the following token type will be removed: - COMMENT - NEWLINE - NL - INDENT - DEDENT - ENCODING - STRING \"\"\" # see https://docs.python.org/3/library/token.html useless_token_type = { tokenize.COMMENT, tokenize.NEWLINE, tokenize.NL, # non-terminating newline tokenize.INDENT, tokenize.DEDENT, tokenize.ENCODING, tokenize.STRING, } parse_tree = ast.parse(code) origin_tokens = tokenize.tokenize(BytesIO(code.encode(\"utf-8\")).readline) token_as_strlist = [ token.string for token in origin_tokens if token.type not in useless_token_type ] return token_as_strlist 注意两件事情： 我删除了所有的字符串，包括文档、f-string、普通字符串和注释等 我没有把变量名或者函数名根据 camelCase 或者 snake_case 这两种命名惯例进一步分词 首先，先用 get_token_stream 把数据中的 Python 代码都分词一下。注意数据中包含了 Python2 和 Python3，这里直接丢弃了 Python2 的代码 python from tqdm.auto import tqdm py2_cnt, py3_cnt = 0, 0 new_corpus = [] codes = [] for code in tqdm(corpus): try: codes.append(get_token_stream(code)) new_corpus.append(code) py3_cnt += 1 except SyntaxError: py2_cnt += 1 print(f\"Python2: {py2_cnt}, Python3: {py3_cnt}\") corpus = new_corpus 让我们验证一下 get_token_stream 是否分词分对了 python print(codes[0]) [ 'def', 'get_vid_from_url', '(', 'url', ')', ':', 'return', 'match1', '(', 'url', ',', ')', 'or', 'match1', '(', 'url', ',', ')', 'or', 'match1', '(', 'url', ',', ')', 'or', 'match1', '(', 'url', ',', ')', 'or', 'parse_query_param', '(', 'url', ',', ')', 'or', 'parse_query_param', '(', 'parse_query_param', '(', 'url', ',', ')', ',', ')', '' ] 现在，可以利用 Gensim 提供的 API 来创建词汇表 python from gensim import corpora dictionary = corpora.Dictionary(codes) print(dictionary) Dictionary\u003c77242 unique tokens: ['', '(', ')', ',', ':']...\u003e 可以看到，词汇表太大了，让我们看看能否优化一下 一般来说，我们不会关心只出现一次的 token，因此，我们可以把他们删除掉 python once_ids = [ token_id for token_id, doc_freq in dictionary.dfs.items() if doc_freq == 1 ] dictionary.filter_tokens(once_ids) dictionary.compactify() print(dictionary) Dictionary\u003c31933 unique tokens: ['', '(', ')', ',', ':']...\u003e 现在只剩下 31933 tokens 了，这已经好多了，我猜测 token 这么多的原因是有很多变量/函数名都不一样 🧐 Dictionary 提供了 most_common 方法可以找到词频最多的 token，让我们看下能否发现一些有意思的事情 python dictionary.most_common(25) [ ('.', 202834), ('(', 199868), (')', 199868), (',', 162853), ('=', 142808), (':', 110829), ('self', 71699), ('[', 55736), (']', 55736), ('if', 40272), ('return', 24021), ('def', 23557), ('', 21948), ('None', 19797), ('in', 19437), ('for', 13509), ('1', 13345), ('0', 13213), ('not', 11826), ('else', 10634), ('+', 10617), ('==', 9323), ('name', 8290), ('is', 7601), ('-', 7544) ] 🧐 发现了一个有意思的现象，( 和 ) 的词频一样，[ 和 ] 也是的，因为代码的语法就是这么规定的 然后用 doc2bow API 就可以得到每个文档（代码）的词袋模型向量 python BoW_matrix_for_code = [dictionary.doc2bow(d) for d in codes] print(BoW_matrix_for_code[0]) [ (0, 1), (1,","date":"2023-08-11","objectID":"/zh-cn/an-introduction-of-bag-of-word-model/:2:0","series":null,"tags":["NLP","Machine-Learning","AI4SE"],"title":"词袋模型","uri":"/zh-cn/an-introduction-of-bag-of-word-model/#更复杂的真实数据集"},{"categories":["NLP"],"content":" 总结现在，我们来总结一下 BoW 的一些缺点。你可能已经自己弄清楚了其中一些： 单词之间的顺序信息没有得到保留。The cat chased the dog 和 The dog chased the cat 意思完全不一样 没有语义信息。 词袋模型将每个单词视为一个独立的实体 词袋模型输出的向量是高维稀疏向量。 计算量很大，向量长度取决于你的词汇表大小 每个词都有相同的重要性。 但有些词可能提供更多信息 无法处理不在词汇表里面的单词。 如果文档包含很多不在词汇表中的单词要怎么办？ … 词袋模型有很多缺点，你可能只会在教程里面看到它。鉴于这些限制，后面人们又开发了 Word2Vec、GloVe 和基于 Transformer 的架构（例如 BERT、GPT）等更先进的模型来克服这些缺点 ","date":"2023-08-11","objectID":"/zh-cn/an-introduction-of-bag-of-word-model/:3:0","series":null,"tags":["NLP","Machine-Learning","AI4SE"],"title":"词袋模型","uri":"/zh-cn/an-introduction-of-bag-of-word-model/#总结"},{"categories":["NLP"],"content":" 参考 CountVectorizer ↩︎ ↩︎ ","date":"2023-08-11","objectID":"/zh-cn/an-introduction-of-bag-of-word-model/:4:0","series":null,"tags":["NLP","Machine-Learning","AI4SE"],"title":"词袋模型","uri":"/zh-cn/an-introduction-of-bag-of-word-model/#参考"},{"categories":["ML-DL"],"content":"介绍了如何用维度分析技巧快速求解梯度","date":"2023-07-26","objectID":"/zh-cn/a-trick-to-calculating-partial-derivatives-in-ml/","series":null,"tags":["Deep-Learning","Machine-Learning"],"title":"机器学习求解梯度的小技巧","uri":"/zh-cn/a-trick-to-calculating-partial-derivatives-in-ml/"},{"categories":["ML-DL"],"content":" 引言也许你和我一样在求解机器学习的梯度时有各种困难，即使看着相关的 Cookbook 一边推导依然是有困惑，今天我要分享的是最近学习到的一个实用技巧：在机器学习中，求解偏导数的时候可以先全部看成标量处理，最后让维度匹配即可 免责声明：运用如上的技巧并不保证梯度是正确的，可能维度是对的，但是梯度是错的，强调一下为了确保梯度计算正确请做好梯度检查 ","date":"2023-07-26","objectID":"/zh-cn/a-trick-to-calculating-partial-derivatives-in-ml/:1:0","series":null,"tags":["Deep-Learning","Machine-Learning"],"title":"机器学习求解梯度的小技巧","uri":"/zh-cn/a-trick-to-calculating-partial-derivatives-in-ml/#引言"},{"categories":["ML-DL"],"content":" 应用 💡 大写的黑色粗体字母表示矩阵，不加粗的字母都是标量 ","date":"2023-07-26","objectID":"/zh-cn/a-trick-to-calculating-partial-derivatives-in-ml/:2:0","series":null,"tags":["Deep-Learning","Machine-Learning"],"title":"机器学习求解梯度的小技巧","uri":"/zh-cn/a-trick-to-calculating-partial-derivatives-in-ml/#应用"},{"categories":["ML-DL"],"content":" 反向传播矩阵形式推导在之前的 反向传播推导 过程中，我从标量角度来推导了反向传播，因为这个比较好理解，但如果你尝试实现反向传播或者是前向传播，你会发现都是用矩阵形式，我们总是把它变成矩阵乘法，因为矩阵乘法会快很多。因此需要弄清楚「反向传播的矩阵形式」是如何进行的，下面我将利用前面提到的技巧来进行推导 为了公式简洁，下面省略了 bias 只考虑 weight 考虑一个简单的 $L$ 层的 MLP 模型，用 $\\mathbf Z^l$ 表示 $l$ 层的输出，特别的，将输入层也用 $\\mathbf Z$ 表示，有 $$\\mathbf Z^0=\\mathbf X$$ 其中 $\\mathbf X\\in\\mathcal{R}^{m\\times d}$，$m$ 为样本数量，$d$ 为每个样本的特征长度 模型 $f_\\theta$ 的输出是 $$f_\\theta(\\mathbf X)=\\mathbf Z^{L}$$ 其中 $\\theta$ 表示模型的可学习参数 相邻两层之间的关系是 $$\\mathbf Z^{l+1}=\\sigma_{l+1}(\\mathbf Z^l\\mathbf W^{l+1}),l=0,…,L-1$$ 其中 $\\sigma_{l+1}$ 为 $l+1$ 层的激活函数 维度信息如下: $$\\mathbf Z^l\\in\\mathcal{R}^{m\\times n_l}$$ $$\\mathbf W^{l+1} \\in \\mathcal R^{n_l\\times n_{l+1}}$$ 其中 $n_l$ 用于表示 $l$ 层的神经元个数 我们想要确定损失 $J$ 对模型任意可学习参数的梯度（标量对矩阵求导），这样才能用梯度下降算法更新可学习参数，假设我们要求解 $\\mathbf W^l$ 的梯度 $$ \\frac{\\partial J}{\\partial \\mathbf W^l}=\\frac{\\partial J}{\\partial\\mathbf Z^{L}}\\cdot \\frac{\\partial \\mathbf Z^{L}}{\\partial\\mathbf Z^{L-1}}\\cdot …\\cdot \\frac{\\partial \\mathbf Z^{l+1}}{\\partial\\mathbf Z^{l}}\\cdot\\frac{\\partial \\mathbf Z^{l}}{\\partial\\mathbf W^l} $$ 🤔️ 那如果求解的是关于 $\\mathbf W^{l-1}$ 的梯度呢？ $$ \\frac{\\partial J}{\\partial \\mathbf W^{l-1}}=\\frac{\\partial J}{\\partial\\mathbf Z^{L}}\\cdot \\frac{\\partial \\mathbf Z^{L}}{\\partial\\mathbf Z^{L-1}}\\cdot …\\cdot \\frac{\\partial \\mathbf Z^{l+1}}{\\partial\\mathbf Z^{l}} \\cdot \\frac{\\partial \\mathbf Z^{l}}{\\partial\\mathbf Z^{l-1}}\\cdot\\frac{\\partial \\mathbf Z^{l-1}}{\\partial\\mathbf W^{l-1}} $$ 你会发现，不同参数的梯度公式存在大量相同的部分，因此我们可以引入额外一个记号 $\\mathbf G^l$，表示损失对 $\\mathbf Z^l$ 的梯度 $$\\mathbf G^{l}=\\frac{\\partial J}{\\partial \\mathbf Z^{l}}$$ 下面我们就可以推导 $\\mathbf G^l$ 和 $\\mathbf G^{l+1}$ 的关系 $$ \\begin{equation} \\begin{aligned} \\mathbf G^{l} \u0026=\\frac{\\partial J}{\\partial \\mathbf Z^{l+1}}\\cdot\\frac{\\partial \\mathbf Z^{l+1}}{\\partial \\mathbf Z^l} \\\\\\ \u0026=\\mathbf G^{l+1}\\cdot \\frac{\\partial \\mathbf Z^{l+1}}{\\partial \\mathbf Z^l} \\\\\\ \u0026=\\mathbf G^{l+1}\\cdot \\frac{\\partial \\sigma_{l+1}(\\mathbf Z^{l}\\mathbf W^{l+1})}{\\partial \\mathbf Z^{l}\\mathbf W^{l+1}}\\cdot\\frac{\\partial \\mathbf Z^{l}\\mathbf W^{l+1}}{\\partial \\mathbf Z^l} \\\\\\ \u0026=\\mathbf G^{l+1}\\cdot \\sigma’(\\mathbf Z^{l}\\mathbf W^{l+1})\\cdot \\mathbf W^{l+1}\\ (cheat) \\end{aligned} \\end{equation} $$ 在上面的最后一行，我们把矩阵当成标量处理直接求导，然后根据前面说的，接下来让维度匹配就可以，先来看上面的每个部分的维度 $$\\mathbf G^{l+1}\\in\\mathcal{R}^{m\\times n_{l+1}}$$ $$\\sigma_{l+1}’(\\mathbf Z^{l}\\mathbf W^{l+1})\\in\\mathcal{R}^{m\\times n_{l+1}}$$ $$ \\mathbf W^{l+1}\\in\\mathcal{R}^{n_l\\times n_{l+1}} $$ 我们想要得到大小为 $m\\times n_l$ 的矩阵，因为 $$\\mathbf G^l\\in\\mathcal{R}^{m\\times n_l}$$ 所以可以这么凑 $$\\mathbf G^{l}=\\Big (\\mathbf G^{l+1}\\odot\\sigma_{l+1}’(\\mathbf Z^{l}\\mathbf W^{l+1})\\Big )(\\mathbf{W}^{l+1})^T=\\Big (\\mathbf G^{l+1}\\odot\\sigma_{l+1}’(\\mathbf Z^{l+1})\\Big )(\\mathbf{W}^{l+1})^T$$ 现在回到我们本来要做的事情——求解关于 $\\mathbf W^l$ 的梯度： $$\\frac{\\partial J}{\\partial \\mathbf W^l}=\\mathbf G^{l}\\cdot\\frac{\\partial \\mathbf Z^l}{\\mathbf W^l}$$ 让我们来展开上面的公式 $$ \\begin{equation} \\begin{aligned} \\frac{\\partial J}{\\partial \\mathbf W^l}\u0026=\\mathbf G^{l}\\cdot\\frac{\\partial \\mathbf Z^l}{\\mathbf W^l} \\\\\\ \u0026= \\mathbf G^{l}\\cdot\\frac{\\partial \\mathbf \\sigma_{l}(\\mathbf Z^{l-1}\\mathbf W^l)}{\\partial \\mathbf Z^{l-1}\\mathbf W^l}\\cdot \\frac{\\partial \\mathbf Z^{l-1}\\mathbf W^l}{\\partial\\mathbf W^l} \\\\\\ \u0026= \\mathbf G^{l}\\cdot\\mathbf \\sigma_{l}’(\\mathbf Z^{l-1}\\mathbf W^l)\\cdot \\mathbf Z^{l-1}(cheat) \\end{aligned} \\end{equation} $$ 我们想要得到和 $\\mathbf W^l$ 一样大小的矩阵：$(n_{l-1}, n_{l})$，再次把矩阵当作标量处理让最后的维度是正确的： $$ \\frac{\\partial J}{\\partial \\mathbf W^l}=(\\mathbf Z^{l-1})^T\\Big(\\mathbf G^{l}\\odot\\mathbf \\sigma_{l+1}’(\\mathbf Z^{l-1}\\mathbf W^l) \\Big )\\ =(\\mathbf Z^{l-1})^T\\Big(\\mathbf G^{l}\\odot\\mathbf \\sigma_{l+1}’(\\mathbf Z^l) \\Big )\\ $$ 利用 $\\mathbf G^l$ 和 $\\mathbf G^{l+1}$ 的关系，我们可以从 $\\mathbf G^{l+1}$ 推导出 $\\mathbf G^l$，然后也可以进一步计算 $\\mathbf W^l$ 的梯度，也就是从后往前计算，这也就是反向传播的含义 🤔️ 注意 $\\mathbf G^l$ 的计算和 $\\frac{\\partial J}{\\partial \\mathbf W^l}$ 用到了 $\\mathbf Z^{l-1}, \\mathbf Z^{l}, \\mathbf Z^{l+1}$，也就是不同层的激活函数的输出，这意味着在反向传播的时候我们需要缓存前向传播的值，缓存意味着需要消耗内存，所以这就是为啥模型越大，GPU 就需要更多的显存 ","date":"2023-07-26","objectID":"/zh-cn/a-trick-to-calculating-partial-derivatives-in-ml/:2:1","series":null,"tags":["Deep-Learning","Machine-Learning"],"title":"机器学习求解梯度的小技巧","uri":"/zh-cn/a-trick-to-calculating-partial-derivatives-in-ml/#反向传播矩阵形式推导"},{"categories":["ML-DL"],"content":" 线性回归矩阵形式梯度推导之前在 线性回归 里面我们需要求解下面这个公式 $$ \\begin{aligned} \\frac{\\partial}{\\partial \\theta}\\ J(w,b) \u0026= \\frac{\\partial}{\\partial \\theta}\\ \\frac{1}{2m}(\\mathbf X\\theta - \\vec{y})^T(\\mathbf X\\theta - \\vec{y}) \\\\\\ \\end{aligned} $$ 利用维度分析的技巧，可以这么推导 $$ \\begin{equation} \\begin{aligned} \\frac{\\partial}{\\partial \\theta}\\ J(w,b) \u0026= \\frac{\\partial}{\\partial \\theta}\\ \\frac{1}{2m}(\\mathbf X\\theta - \\vec{y})^T(\\mathbf X\\theta - \\vec{y}) \\\\\\ \u0026= \\frac{1}{2m}\\frac{\\partial(\\ \\mathbf X\\theta - \\vec{y})^T(\\mathbf X\\theta - \\vec{y}) }{\\partial (\\mathbf X\\theta-\\vec y)}\\cdot \\frac{\\partial (\\mathbf X\\theta-\\vec y)}{\\partial \\theta}\\\\\\ \u0026= \\frac{1}{2m}\\cdot2(\\mathbf X\\theta-\\vec y)\\cdot\\mathbf X\\ (cheat) \\end{aligned} \\end{equation} $$ 考虑维度信息 $$(\\mathbf X\\theta-\\vec y)\\in\\mathcal{R}^{m\\times 1}$$ $$\\mathbf X\\in\\mathcal{R}^{m\\times(n+1)}$$ 我们想要得到的是跟 $\\theta$ 一样维度大小的： $$\\theta\\in\\mathcal{R}^{(n+1)\\times 1}$$ 因此直接凑出来就好： $$\\frac{1}{m}\\mathbf X^T(\\mathbf X\\theta-\\vec y)$$ ","date":"2023-07-26","objectID":"/zh-cn/a-trick-to-calculating-partial-derivatives-in-ml/:2:2","series":null,"tags":["Deep-Learning","Machine-Learning"],"title":"机器学习求解梯度的小技巧","uri":"/zh-cn/a-trick-to-calculating-partial-derivatives-in-ml/#线性回归矩阵形式梯度推导"},{"categories":["ML-DL"],"content":" 总结尽管这是一个不严格的技巧，像是作弊一样😨，但我发现还蛮实用的✌️，学会这个技巧之后，机器学习里面的公式推导会轻松很多，当然别忘了利用梯度检查确保式子是正确的 :) ","date":"2023-07-26","objectID":"/zh-cn/a-trick-to-calculating-partial-derivatives-in-ml/:3:0","series":null,"tags":["Deep-Learning","Machine-Learning"],"title":"机器学习求解梯度的小技巧","uri":"/zh-cn/a-trick-to-calculating-partial-derivatives-in-ml/#总结"},{"categories":["ML-DL","Internal"],"content":"介绍了 Pytorch 的张量的 strides 格式原理","date":"2023-07-14","objectID":"/zh-cn/how-to-reprensent-a-tensor-or-ndarray/","series":null,"tags":["Internal","Pytorch","Deep-Learning"],"title":"Pytorch 张量的 strides 格式是什么","uri":"/zh-cn/how-to-reprensent-a-tensor-or-ndarray/"},{"categories":["ML-DL","Internal"],"content":" 引言尽管我已经使用 Numpy 和 Pytorch 好长一段时间了，但我一直不知道他们是如何实现底层的张量（tensor），而且这么高效。最近在看 Deep Learning Systems 这门课，终于有机会尝试自己实现张量，实现一遍之后对张量的理解更深刻了🧐 作为 Pytorch 的使用者有必要理解底层的张量存储原理吗？我觉得是有必要的，大多数情况下理解底层原理都能让你更好理解上层的东西，比如理解张量的存储原理之后有助于你会回答下面这几个问题 广播操作涉及到数组的拷贝吗？ Pytorch 的 contiguous 中是干什么的？为什么需要这个函数？ ","date":"2023-07-14","objectID":"/zh-cn/how-to-reprensent-a-tensor-or-ndarray/:1:0","series":null,"tags":["Internal","Pytorch","Deep-Learning"],"title":"Pytorch 张量的 strides 格式是什么","uri":"/zh-cn/how-to-reprensent-a-tensor-or-ndarray/#引言"},{"categories":["ML-DL","Internal"],"content":" 按行存储与按列存储让我们从简单的二维数组出发，二维数组在内存中占据连续的位置，但是要按行存储还是按列存储这点可能不相同 比如现在有下面这个 $2\\times 3$ 的二维数组 A python [[0.2949, 0.9608, 0.0965], [0.5463, 0.4176, 0.8146]] 如果是按行存储，那么内存中的排列（这里记为 A_in_row）是： python [0.2949, 0.9608, 0.0965, 0.5463, 0.4176, 0.8146] 按行存储的时候，要访问 (i, j) 位置的值的公式是 python A[i][j] = A_in_row[i * A.shape[1] + j] 如果是按列存储，那么内存中的排列（这里记为 A_in_col）是： python [0.2949, 0.5463, 0.9608, 0.4176, 0.0965, 0.8146] 按列存储的时候，要访问 (i, j) 位置的值的公式是 python A[i][j] = A_in_col[j * A.shape[0] + i] ","date":"2023-07-14","objectID":"/zh-cn/how-to-reprensent-a-tensor-or-ndarray/:2:0","series":null,"tags":["Internal","Pytorch","Deep-Learning"],"title":"Pytorch 张量的 strides 格式是什么","uri":"/zh-cn/how-to-reprensent-a-tensor-or-ndarray/#按行存储与按列存储"},{"categories":["ML-DL","Internal"],"content":" Strides 格式张量在底层可以是按行存储也可以是按列存储。Numpy 和 Pytorch 都采用了按行存储的方式，任何维度的张量在底层存储都占据着内存中连续的空间，那么问题来了，我们如何访问到我们想要的位置的数据？ 答案就是 strides 格式。strides 格式可以看成是前面两种索引格式的泛化版本，假设现在有一个 $N$ 维的张量 A（假设维度从 0 开始），它的底层存储为 A_internal，我们想要访问 A[i0][i1][i2]...，那么索引的方式如下： python A[i0][i1][i2]... = A_internal[ stride_offset + i0 * A.strides[0] + i1 * A.strides[1] + i2 * A.strides[2] + ... + in-1 * A.strides[n-1] ] Strides 格式有两个组成部分 offset - 表示张量相对于底层存储 A_internal 的偏移量 strides 数组，长度和张量的维度一样，strides[i] 表示张量在第 $i$ 个维度上移动“一个单位”需要在内存上跳过多少个元素 举例来说，前面提到的二维数组的例子，如果用 strides 的格式来理解的话，应该是下面这样 python A[i][j] = A_in_row[ 0 + i * A.shape[1] + j * 1 ] 即对于一个大小为 (A.shape[0], A.shape[1]) 的二维数组，它的 offset 是 0，strides = [A.shape[1], 1](row-major)。🤔️ 也就是说，每次在第一个维度上要跳跃“一个单位”，需要跳过底层的 A.shape[1] 个元素，A.shape[1] 也就是行的长度 我做了下面这张图片，希望能够帮助你理解 :) 🧐 那么如何得到 $N$ 维张量的 strides 数组？假设要求解的是 strides[k] 即第 $k$ 个维度的 stride，我们知道它的语义是「在第 $k$ 维上移动“一个单位”需要在内存上跳过多少个元素」，如果这个张量的底层存储在内存上是连续存储（紧凑格式），那就是 「$k+1,k+2,…,N-1$ 维度的大小的乘积」，如果 $k=N-1$，那么 strides[N - 1] = 1 数学公式就是下面这样， $$strides[k]=\\prod_{i=k+1}^{N-1}shape[i]$$ 💡 再次强调，上面的公式只有在张量的底层存储在内存上是连续存储（紧凑格式）的时候成立 ","date":"2023-07-14","objectID":"/zh-cn/how-to-reprensent-a-tensor-or-ndarray/:3:0","series":null,"tags":["Internal","Pytorch","Deep-Learning"],"title":"Pytorch 张量的 strides 格式是什么","uri":"/zh-cn/how-to-reprensent-a-tensor-or-ndarray/#strides-格式"},{"categories":["ML-DL","Internal"],"content":" Why strides？知道了 strides 的存储格式之后，我们还要理解为什么这么设计，strides 究竟给我们带来了什么？最大的好处是：很多关于张量的操作都可以是零拷贝（Zero-copy）的。通过 strides 格式，「底层存储」和「视图」之间是分离开的，下面我来讲解一下几个常见的操作 ","date":"2023-07-14","objectID":"/zh-cn/how-to-reprensent-a-tensor-or-ndarray/:4:0","series":null,"tags":["Internal","Pytorch","Deep-Learning"],"title":"Pytorch 张量的 strides 格式是什么","uri":"/zh-cn/how-to-reprensent-a-tensor-or-ndarray/#why-strides"},{"categories":["ML-DL","Internal"],"content":" print_internal 函数在开始之前，让我们先写一个函数获取 Pytorch 的张量底层存储 首先是 Pytorch 提供的 data_ptr() 这个方法，他会返回张量底层存储表示的第一个元素的内存地址 然后通过 Pytorch 提供的 storage().nbytes() 就可以知道张量的底层存储在内存上占据了多大的空间1，而张量的 dtype 属性则告诉了我们每个元素占据多大，比如 torch.float32 就是 4 个字节 最后通过 ctypes.string_at(address, size=-1) 函数就可以读取这个张量为 C 的字符串（buffer），而 torch.frombuffer 可以从一个 buffer 创建出 tensor 通过上面几个步骤，我们就可以还原出 Pytorch 底层的数组表示，下面命名为 print_internal 函数 python def print_internal(t: torch.Tensor): print( torch.frombuffer( ctypes.string_at(t.data_ptr(), t.storage().nbytes()), dtype=t.dtype ) ) 然后我们创建一个维度为 (1, 2, 3, 4) 的张量 t 并观察它的底层表示，后面的操作讲解会基于这个张量 t python torch.arange(0, 24).reshape(1, 2, 3, 4) print(t) # tensor([[[[ 0, 1, 2, 3], # [ 4, 5, 6, 7], # [ 8, 9, 10, 11]], # [[12, 13, 14, 15], # [16, 17, 18, 19], # [20, 21, 22, 23]]]]) print(t.stride()) # (24, 12, 4, 1) print_internal(t) # tensor([0, 1, 2, 3, # 4, 5, 6, 7, # 8, 9, 10, 11, # 12, 13, 14, 15, # 16, 17, 18, 19, # 20, 21, 22, 23]) 按照我们前面说的从张量的维度推导 stride 的方法，我们不难知道这个 tensor 的 stride 应该是 (2 * 3 * 4, 3 * 4, 4, 1) 也就是 (24, 12, 4, 1) 在 Pytorch 里面，我们可以通过调用 tensor 的 stride() 方法获得 stride，可以看到，确实跟我们手动计算出来的一样🤔️ ","date":"2023-07-14","objectID":"/zh-cn/how-to-reprensent-a-tensor-or-ndarray/:4:1","series":null,"tags":["Internal","Pytorch","Deep-Learning"],"title":"Pytorch 张量的 strides 格式是什么","uri":"/zh-cn/how-to-reprensent-a-tensor-or-ndarray/#print_internal-函数"},{"categories":["ML-DL","Internal"],"content":" permute 操作假设我们用 permute 重新排列了各个维度，那么 strides 如何变化？ python print(t.stride()) # (24, 12, 4, 1) print(t.permute((1, 2, 3, 0)).is_contiguous()) # True print(t.permute((1, 2, 3, 0)).stride()) # (12, 4, 1, 24) print(t.permute((0, 2, 3, 1)).is_contiguous()) # False print(t.permute((0, 2, 3, 1)).stride()) # (24, 4, 1, 12) print(t.permute((1, 0, 3, 2)).is_contiguous()) # False print(t.permute((1, 0, 3, 2)).stride()) # (12, 24, 1, 4) print_internal(t.permute((1, 2, 3, 0))) # tensor([0, 1, 2, 3, # 4, 5, 6, 7, # 8, 9, 10, 11, # 12, 13, 14, 15, # 16, 17, 18, 19, # 20, 21, 22, 23]) 从上面的例子我们可以看出来，permute 操作不会影响 offset，但通常情况下，permute 操作会导致底层存储不紧凑。我们可以通过 permute 之后的新的维度 new_shape 然后根据定义计算出 strides，但是更快的办法是，直接在 strides 上也做一样的 permute 操作即可。print_internal 函数的输出证明了 permute 操作是 Lazy 的2 ","date":"2023-07-14","objectID":"/zh-cn/how-to-reprensent-a-tensor-or-ndarray/:4:2","series":null,"tags":["Internal","Pytorch","Deep-Learning"],"title":"Pytorch 张量的 strides 格式是什么","uri":"/zh-cn/how-to-reprensent-a-tensor-or-ndarray/#permute-操作"},{"categories":["ML-DL","Internal"],"content":" broadcast_to 操作广播操作是比较有意思的，在不了解张量的存储原理之前，你可能以为广播操作就是在对应的维度上拷贝多份，但其实，根本就没有发生拷贝，只是修改了 strides 数组的值而已。更确切来说，Pytorch 会把被广播的维度（本来的维度大小是 1）的 stride 设置为 03 比如现在我们在第一个维度上做广播，观察广播之后的维度大小，以及 strides 数组的变化情况 python print(t.broadcast_to((2, 2, 3, 4)).is_contiguous()) # False print(t.broadcast_to((2, 2, 3, 4)).shape) # torch.Size([2, 2, 3, 4]) print(t.stride()) # (24, 12, 4, 1) print(t.broadcast_to((2, 2, 3, 4)).stride()) # (0, 12, 4, 1) print_internal(t.broadcast_to((2, 2, 3, 4))) # tensor([0, 1, 2, 3, # 4, 5, 6, 7, # 8, 9, 10, 11, # 12, 13, 14, 15, # 16, 17, 18, 19, # 20, 21, 22, 23]) 你（可能）会惊讶地发现，Pytorch 确实没有在广播的时候拷贝对应维度的张量，仅仅只是修改 strides 数组了而已。回忆 strides[i] 的含义，被广播的维度的 stride 设置为 0 意味着这个维度上移动“一个单位“并不需要在内存上跳过元素，也就是在被广播的维度上我们一直在访问的是同一块区域 ","date":"2023-07-14","objectID":"/zh-cn/how-to-reprensent-a-tensor-or-ndarray/:4:3","series":null,"tags":["Internal","Pytorch","Deep-Learning"],"title":"Pytorch 张量的 strides 格式是什么","uri":"/zh-cn/how-to-reprensent-a-tensor-or-ndarray/#broadcast_to-操作"},{"categories":["ML-DL","Internal"],"content":" reshape 操作和 contiguous 操作索引操作可能会修改 offset，因为索引之后形成的张量不一定从本来底层存储的第一个元素开始，同时索引操作可能会索引到底层存储中的「非连续」部分。因此我们可以通过索引操作来研究 reshape 操作和 contiguous 操作是如何起作用的 现在假设我们想要从 t 拿到下面这个张量 python [[[2, 6, 10], [14, 18, 22]]] 对应的索引操作如下 python print(t[:, :, :, 2]) # tensor([[[ 2, 6, 10], # [14, 18, 22]]]) 注意到这个操作同时符合我前面说的： offset 改变了，因为现在是从 2 而不是从 0 开始了 索引到的元素在本来的内存上不是连续的 下面的代码验证了我们的猜想 python print(t.storage_offset()) # 0 print(t[:, :, :, 2].storage_offset()) # 2 print(t[:, :, :, 2].is_contiguous()) # False 现在来观察底层存储 python print_internal(t[:, :, :, 2]) # tensor([ 2, 3, # 4, 5, 6, 7, # 8, 9, 10, 11, # 12, 13, 14, 15, # 16, 17, 18, 19, # 20, 21, 22, 23 # 1152921504606846976, -8070441752123218147]]) # ignore the last row because t.data_ptr() has changed but t.storage().nbytes() # kept the same. # As a result, we read 2 invalid elements and get 2 meaningless values Pytorch 的张量有个方法叫做 storage_offset 可以拿到张量相对于底层存储的偏移量，可以看到现在从底层存储的第二个位置开始了，第二个位置恰好是 t[:, :, :, 2] 的第一个元素 2。而打印出底层存储你会发现，底层存储还是本来的数组 注意这里有个小问题，因为底层存储没有变化，t.storage().nbytes() 跟原来一样。但是 data_ptr() 会给我们第二个元素的地址，导致最后 print_internal 打印底层存储的时候会多打印 2 个无效的位置（也就是上面的最后一行），所以得到了 2 个没有意义的数字 🤔️ 这个时候我们尝试执行 reshape(3, 2) 并观察底层存储情况 python print_internal(t[:, :, :, 2].reshape(3, 2)) # tensor([ 2, 3, # 4, 5, 6, 7, # 8, 9, 10, 11, # 12, 13, 14, 15, # 16, 17, 18, 19, # 20, 21, 22, 23 # 1152921504606846976, -8070441752123218147]]) reshape 操作之后发现底层存储还是没有变化，这恰好对应文档里面所说的：可能的情况下，reshape 之后，返回的张量尽可能是同一份存储4 但如果我们想要 reshape 之后的张量在底层的存储是紧凑的呢？此时就可以紧跟着调用 contiguous 方法 python print_internal(t[:, :, :, 2].reshape(3, 2).contiguous()) # tensor([ 2, 6, 10, 14, 18, 22]) 😺 可以发现，contiguous 之后确实底层存储就紧凑了，此时的 strides 数组应该符合我们前面提到的公式： python # before contiguous print(t[:, :, :, 2].reshape(3, 2).stride()) # (8, 4) # after contiguous print(t[:, :, :, 2].reshape(3, 2).contiguous().shape) # (3, 2) print(t[:, :, :, 2].reshape(3, 2).contiguous().stride()) # (2, 1) 🧐 一个比较有挑战性的问题，索引操作会如何影响 strides？ 让我们以刚才的索引操作为例子，首先，索引之后得到新的维度应该是 (1, 2, 3)，显然 [:, :, :, 2] 这样的索引导致底层存储在内存上不紧凑，因此规律不适用，那么只能从定义上出发，假设 t[:, :, :, 2] 的 strides 是 [x, y, z] 先观察 t[:, :, :, 2] 包含哪一些元素 python print(t[:, :, :, 2]) # tensor([[[ 2, 6, 10], # [14, 18, 22]]]) 因为我定义的张量是从 0 开始的整数，因此我们可以直接观察值的变化来计算 strides 的变化（这是一个小技巧） 对于 z，从 2 -\u003e 6 -\u003e 10，每次跳过了 4 个位置，所以 z = 4 对于 y，2 -\u003e 14，6 -\u003e 18，10 -\u003e 22，每次都跳过了 12 个位置，因此 y = 12 对于 x，因为底层存储并没有改变，原本的张量 t 的 stride[0] = 24，如果张量 t 的第一个维度不是 1 而是一个更大的值，我们还是每次会跳过 stride[0] 个元素，所以 x = 24 所以 t[:, :, :, 2] 的 strides 应该是 (24, 12, 4) 让我们来调用一下 API 看这是否正确 python print(t.stride()) # (24, 12, 4, 1) print(t[:, :, :, 2].stride()) # (24, 12, 4) # what if the first dimension is not 1 but 2? another_t = torch.arange(0, 48).reshape(2, 2, 3, 4) print(another_t[:, :, :, 2]) # tensor([[[ 2, 6, 10], # [14, 18, 22]], # [[26, 30, 34], # [38, 42, 46]]]) # you can see that 2 -\u003e 26, 6 -\u003e 30, 10 -\u003e 35 # , so the stride[0] = 24 is true 上面的代码验证了我们的猜想 但是，索引操作可能远远比我们这里讲解的 [:, :, :, 2] 复杂得多，比如 [2, 1:3, 1:6:3] 这种，此时 strides 和 offset 又该如何变化？这里不展开，但是可以放一个提示：把每个格式都变成 Python 的 Slice 对象，然后从 strides[i] 的定义出发进行推导 ","date":"2023-07-14","objectID":"/zh-cn/how-to-reprensent-a-tensor-or-ndarray/:4:4","series":null,"tags":["Internal","Pytorch","Deep-Learning"],"title":"Pytorch 张量的 strides 格式是什么","uri":"/zh-cn/how-to-reprensent-a-tensor-or-ndarray/#reshape-操作和-contiguous-操作"},{"categories":["ML-DL","Internal"],"content":" 总结可以看到，Pytorch 的张量的不少操作都是通过改变 strides 的 offset 或（和）strides 数组实现的，这让很多操作维持了零拷贝开销，因此效率会很高，而且，这使得我们可以把不少张量操作实现为 Lazy 的。理解 strides 格式有助于构建张量的 mental model，它能够让你更好理解张量的操作的代码。顺便推荐一下这个视频，在这个视频中，可以看到如何操纵 strides 来实现高效的卷积操作 现在我们可以回答前面我抛出的问题了： 广播操作涉及到数组的拷贝吗？ 并没有拷贝，只是修改了 strides 数组 Pytorch 的 contiguous 中是干什么的？为什么需要这个函数？ 因为 contiguous 之后，张量的底层存储是内存紧凑的，虽然有拷贝的开销，但是后续执行一些张量相关的操作的时候内存局部性会更好 ","date":"2023-07-14","objectID":"/zh-cn/how-to-reprensent-a-tensor-or-ndarray/:5:0","series":null,"tags":["Internal","Pytorch","Deep-Learning"],"title":"Pytorch 张量的 strides 格式是什么","uri":"/zh-cn/how-to-reprensent-a-tensor-or-ndarray/#总结"},{"categories":["ML-DL","Internal"],"content":" 参考 Tensor type memory usage - Memory Format - PyTorch Forums ↩︎ torch.permute - PyTorch 2.3 documentation ↩︎ torch.expand - PyTorch 2.0 documentation ↩︎ torch.reshape — PyTorch 2.0 documentation ↩︎ ","date":"2023-07-14","objectID":"/zh-cn/how-to-reprensent-a-tensor-or-ndarray/:6:0","series":null,"tags":["Internal","Pytorch","Deep-Learning"],"title":"Pytorch 张量的 strides 格式是什么","uri":"/zh-cn/how-to-reprensent-a-tensor-or-ndarray/#参考"},{"categories":["Data-Structure"],"content":"介绍了如何在 2-3-4 树上思考红黑树的插入和删除操作，减轻记忆负担","date":"2023-07-01","objectID":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/","series":null,"tags":["Data-Structure"],"title":"如何记忆红黑树的操作","uri":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/"},{"categories":["Data-Structure"],"content":" 引言如果你点进了这一篇文章，相信你也跟我一样：红黑树学一次忘一次，又要做树的旋转，又要给节点重新上色，导致每次都是学完了就忘记。我也曾经仔细阅读过 CLRS 写的《算法导论》，但是上面的分类讨论只是让我更加头疼 当然，记住一项东西的最佳方式永远都是理解它，而最近看到斯坦福的 CS166 高级数据结构课程的课件的时候，我似乎理解了红黑树————红黑树和 2-3-4 树是等同（isometry）的数据结构，他们只是用了不同的方式表示 2-3-4 树1，这意味着我们可以通过 2-3-4 树上的节点变化，进而推导出红黑树上的形状和颜色的变化，而 2-3-4 树的节点变化，是简单很多的 在开始之前，我假定你对以下的内容很熟悉 你知道 2-3-4 树或者说 B 树是什么，2-3-4 树其实就是 B 树的一种。你需要知道在 2-3-4 树上的删除和插入操作如何进行，什么时候会发生节点的 overflow、underflow，以及这种时候要如何处理 你知道如何在二叉搜索树中插入和删除节点，毕竟红黑树本身就是保证高度是 $O(log\\ n)$ 的二叉搜索树，要知道如何找到插入位置，如何确定要删除的节点等 你需要知道红黑树和 2-3-4 树的定义，需要理解红黑树有什么性质，以及在红黑树上插入节点、删除节点都可能打破哪些性质 最重要的，你不需要记住红黑树的旋转和颜色变化操作，因为只要你掌握了今天要讲的技巧，你就可以在红黑树的操作和 2-3-4 树上的操作之间建立直觉上的联系 ","date":"2023-07-01","objectID":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/:1:0","series":null,"tags":["Data-Structure"],"title":"如何记忆红黑树的操作","uri":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/#引言"},{"categories":["Data-Structure"],"content":" 节点映射定义2-3-4 树上一共只有可能有下面 3 种节点： 2-node，有 2 个孩子，含 1 个 key 3-node，有 3 个孩子，含 2 个 key 4-node，有 4 个孩子，含 3 个 key 通过节点映射关系，我们可以将 2-3-4 树上的节点转化为对应的红黑树结构，反之依然。注意他们都是黑色节点开始，后面我们会多次用到这个映射表 左边是 2-3-4 树的 2-node, 3-node, 4-node，右边是对应的红黑树结构 ","date":"2023-07-01","objectID":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/:2:0","series":null,"tags":["Data-Structure"],"title":"如何记忆红黑树的操作","uri":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/#节点映射定义"},{"categories":["Data-Structure"],"content":" 新增节点操作先来简单回顾一下，往红黑树节点中新增一个节点的步骤 红黑树是二叉搜索树，所以一开始按照二叉搜索树插入节点的办法找到要插入的位置 如果新插入的点会成为根节点（即本来的红黑树为空），则新插入的节点为黑色；其他情况则为红色，因为红黑树有个性质是从任一节点到其每个叶子节点的路径都包含相同数量的的黑色节点，让新插入的节点的颜色为红色就可以维护这个性质。下面我们只考虑新插入的节点为红色的情况 新插入的节点是红色的话这意味着可能打破红黑树的另外一个性质——不能有 2 个连续的红色节点。红黑树中通过树旋转和节点重新上色🎨解决了这个问题，但是规则比较复杂不好记 在讲解具体例子之前，先概括一下通用的思路： 找到要插入的位置插入新节点，设置新节点的颜色为红色 将红黑树上「违背规则的部分」转化为「2-3-4 树上等同的形式」 思考如果在 2-3-4 树的这个等价形式要如何处理 在 2-3-4 树上处理好之后，再转化为红黑树，此时形状和颜色都决定好了 💡 为了帮助读者理解如何在 2-3-4 树和红黑树之间变换，在变换前后的等同部分，我用了一个带颜色的透明框标记了 💡 我选择了直接用具体的数值而不是抽象的符号，因为这样会更加直观，更方便读者在 2-3-4 树和红黑树之间找到联系 ","date":"2023-07-01","objectID":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/:3:0","series":null,"tags":["Data-Structure"],"title":"如何记忆红黑树的操作","uri":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/#新增节点操作"},{"categories":["Data-Structure"],"content":" 新增节点的父节点是黑色节点一个简单情况是，新插入的红色节点的父节点是黑色，此时满足要求仍然是红黑树，不需要任何改动 ","date":"2023-07-01","objectID":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/:3:1","series":null,"tags":["Data-Structure"],"title":"如何记忆红黑树的操作","uri":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/#新增节点的父节点是黑色节点"},{"categories":["Data-Structure"],"content":" 新增节点的父节点是红色节点而且不存在 uncle 节点接下来，让我们考虑稍微复杂点的情况，新增节点的父节点是红色节点，红黑树不允许这样的情况出现。此时它可能有也可能没有 unlce 节点，让我们先考虑它没有 uncle 节点的情况，可以很轻松画出下面几种可能的形式 注意这几种都是等价的，下面我只展示上图第一个例子是如何操作的 💡 后面当我们讨论其他情况的时候，他们也可能会存在等价形式，但其实方法都大同小异，我会每次挑其中一个讲 根据之前提到的节点映射关系，插入前的红黑树正好对应 2-3-4 树上的 3-node，然后我们在红黑树中插入节点 1，与此同时，我们在 3-node 上也进行插入操作，得到了一个 4-node，4-node 符合 2-3-4 树要求，所以也不需要分裂节点，此时再根据节点映射关系转化为红黑树 此时你可能觉得似乎 2-3-4 树没有带来多大方便，因为这里一个简单右旋，然后重新染色并不是一件复杂的事情，但是之后随着情况越来越复杂，你会发现 2-3-4 树的理解角度容易理解很多🤔️ ","date":"2023-07-01","objectID":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/:3:2","series":null,"tags":["Data-Structure"],"title":"如何记忆红黑树的操作","uri":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/#新增节点的父节点是红色节点而且不存在-uncle-节点"},{"categories":["Data-Structure"],"content":" 新增节点的父节点是红色节点而且存在 uncle 节点现在让我们来考虑它有 uncle 节点的情况，它可能为黑色，也可能为红色 先来看看如果 uncle 节点为黑色的其中一种可能情况 根据节点的映射关系，我们可以把红黑树的 2, 5 映射为 2-3-4 树上的 3-node，而红黑树上的 7 就映射为一个 2-node，在红黑树上插入 1，因此也在 2, 5 这个 3-node 上插入 1，得到的 1, 2, 5 根据节点映射关系，映射为一个黑色节点加两个红色孩子节点，而 7 则映射为一个黑色节点 那如果 uncle 节点是红色呢？比如像下面这样 这个会稍微复杂一些，因为在等价的 2-3-4 树插入 1 之后我们需要对 1, 2, 5, 7 进行分裂操作，也就是将图上的节点 5 插入到父节点中，因为不知道父节点什么情况，因此节点 5 两边用省略号表示，在 2-3-4 树中往父节点插入一个节点意味着可能导致父节点也 overflow，最坏的情况我们是需要这样一路一直修改回去 另外注意一个问题，这里插入的新节点的祖先（grandparent）节点应该是红色节点，例子中的节点 5 就是新增节点 1 的祖先节点。这样才能保证从任一节点到其每个叶子节点的路径都包含相同数量的的黑色节点，但是有个例外，那就是祖先节点是红黑树的根节点的时候，那么它就应该是黑色，下图清晰展示了这 2 种可能 ","date":"2023-07-01","objectID":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/:3:3","series":null,"tags":["Data-Structure"],"title":"如何记忆红黑树的操作","uri":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/#新增节点的父节点是红色节点而且存在-uncle-节点"},{"categories":["Data-Structure"],"content":" 删除节点操作先来简单回顾一下，在红黑树节点中删除一个节点的步骤 按照二叉搜索树删除节点的方式，找到要删除的节点，假设要被删除的节点是 z 那么根据 z 的节点颜色可以分出下面两种情况 z 是红色节点，删除红色节点是比较容易的，因为不会打破红黑树的性质，就是正常的二叉搜索树删除节点的操作，这里不展开 z 是黑色节点，删除黑色节点可能打破红黑树的性质——从任一节点到其每个叶子节点的路径都包含相同数量的的黑色节点，在红黑树中，遇到这种情况仍然是需要用树的旋转和节点重新上色🎨解决问题。下面的讨论主要考虑的是这种情况 ","date":"2023-07-01","objectID":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/:4:0","series":null,"tags":["Data-Structure"],"title":"如何记忆红黑树的操作","uri":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/#删除节点操作"},{"categories":["Data-Structure"],"content":" 被删除的节点有红色右孩子 💡 注意，根据二叉搜索树的删除节点操作，我们知道要删除的节点 z 一定没有左孩子，如果它有右孩子的话，我们记为 y 💡 黄色节点表示不知道颜色或者是不关心它什么颜色 删除黑色的 z，然后用它的红色右孩子 y 代替 z ","date":"2023-07-01","objectID":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/:4:1","series":null,"tags":["Data-Structure"],"title":"如何记忆红黑树的操作","uri":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/#被删除的节点有红色右孩子"},{"categories":["Data-Structure"],"content":" 被删除的节点有黑色右孩子我们暂时用黑色的 y 代替被删除的黑色的 z，并且记 y 为 “double black” 节点，在图上，黑色节点 + 圆环就表示 “double black”2 💡 “double black” 对于红黑树而言，意味着我们要让这边有 2 个黑色节点；对于 2-3-4 树而言，那就对应 2-3-4 树中删除 2-node 的 key之后引发的 underflow 删除黑色的 z，然后用它的黑色右孩子 y 代替 z，标记 y 为 “double black” 节点 接下来我们要根据「“double black” 的兄弟节点」来分情况推导 如果兄弟节点是黑色而且有「一个红色孩子」 在上面的例子，转化为等价的 2-3-4 树上的删除节点操作，在 2-3-4 树中遇到这种情况需要执行 transfer 操作，因为兄弟节点 6, 7 是一个 3-node，还有得借。transfer 操作也就是父节点的 key 移动到被删除的节点的位置，然后兄弟节点的最小的 key 移动到父节点填补空缺 💡 注意看，现在 4 和 5 是 2 个黑色节点，先前这里是一个特殊的 “double black” 节点，现在有 2 个黑色节点了，“double black” 也就没有必要了。这也是它叫做这个名字的原因，我们需要提醒自己这里需要 2 个黑色节点 💡 注意这里节点 6 的颜色就是本来节点 5 的颜色 如果兄弟节点是黑色而且有「两个黑色孩子」 在上面的例子，转化为等价的 2-3-4 树上的删除节点操作，在 2-3-4 树中遇到这种情况需要执行 fusion 操作，因为兄弟节点 7 是一个 2-node，没得借。fusion 操作就是从父节点那边借一个 key 下来，然后和兄弟节点合并，成为一个 3-node，也就是图上的 5, 7 💡 但是注意这里的 Fusion 操作找父节点借了一个 key，这可能导致父节点 underflow 了，正如前面我们在新增节点的时候可能 overflow 理论上来说，这个例子的节点 5 应该是黑色（根据前面对节点映射的规定），这样才能满足 “double black” 的要求，但是不要忘了 5 自己是有颜色的 如果 5 本来是红色，那么把 5 变成黑色是没有问题的，因为现在的节点 7 就是红色，红黑树还是平衡的 如果 5 本来是黑色，那么把 5 变成黑色是有问题的，因为还是会少了一个黑色节点，那么节点 5 就变成了新的 “double black” 节点，我们还得向上继续调整。这恰恰是对应了 2-3-4 树中发生了 underflow 的情况，那么我们就要 bototm-up 一路调整回去。最后如果发现根节点是一个 “double black” 节点，那么把根节点变成黑色节点即可 如果兄弟节点是红色而且有「两个黑色孩子」最后一种情况，如果兄弟节点为红色，而且有 2 个黑色孩子 💡 注意，如果兄弟节点是红色，他们的共同父节点肯定是黑色，因为红黑树不允许有 2 个连续的红色节点 这个可以通过取巧的办法来转化为前面情况： 现在节点 4 的兄弟节点就是黑色节点了，转化为前面的情况，可以按照前面的办法处理 ","date":"2023-07-01","objectID":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/:4:2","series":null,"tags":["Data-Structure"],"title":"如何记忆红黑树的操作","uri":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/#被删除的节点有黑色右孩子"},{"categories":["Data-Structure"],"content":" 被删除的节点有黑色右孩子我们暂时用黑色的 y 代替被删除的黑色的 z，并且记 y 为 “double black” 节点，在图上，黑色节点 + 圆环就表示 “double black”2 💡 “double black” 对于红黑树而言，意味着我们要让这边有 2 个黑色节点；对于 2-3-4 树而言，那就对应 2-3-4 树中删除 2-node 的 key之后引发的 underflow 删除黑色的 z，然后用它的黑色右孩子 y 代替 z，标记 y 为 “double black” 节点 接下来我们要根据「“double black” 的兄弟节点」来分情况推导 如果兄弟节点是黑色而且有「一个红色孩子」 在上面的例子，转化为等价的 2-3-4 树上的删除节点操作，在 2-3-4 树中遇到这种情况需要执行 transfer 操作，因为兄弟节点 6, 7 是一个 3-node，还有得借。transfer 操作也就是父节点的 key 移动到被删除的节点的位置，然后兄弟节点的最小的 key 移动到父节点填补空缺 💡 注意看，现在 4 和 5 是 2 个黑色节点，先前这里是一个特殊的 “double black” 节点，现在有 2 个黑色节点了，“double black” 也就没有必要了。这也是它叫做这个名字的原因，我们需要提醒自己这里需要 2 个黑色节点 💡 注意这里节点 6 的颜色就是本来节点 5 的颜色 如果兄弟节点是黑色而且有「两个黑色孩子」 在上面的例子，转化为等价的 2-3-4 树上的删除节点操作，在 2-3-4 树中遇到这种情况需要执行 fusion 操作，因为兄弟节点 7 是一个 2-node，没得借。fusion 操作就是从父节点那边借一个 key 下来，然后和兄弟节点合并，成为一个 3-node，也就是图上的 5, 7 💡 但是注意这里的 Fusion 操作找父节点借了一个 key，这可能导致父节点 underflow 了，正如前面我们在新增节点的时候可能 overflow 理论上来说，这个例子的节点 5 应该是黑色（根据前面对节点映射的规定），这样才能满足 “double black” 的要求，但是不要忘了 5 自己是有颜色的 如果 5 本来是红色，那么把 5 变成黑色是没有问题的，因为现在的节点 7 就是红色，红黑树还是平衡的 如果 5 本来是黑色，那么把 5 变成黑色是有问题的，因为还是会少了一个黑色节点，那么节点 5 就变成了新的 “double black” 节点，我们还得向上继续调整。这恰恰是对应了 2-3-4 树中发生了 underflow 的情况，那么我们就要 bototm-up 一路调整回去。最后如果发现根节点是一个 “double black” 节点，那么把根节点变成黑色节点即可 如果兄弟节点是红色而且有「两个黑色孩子」最后一种情况，如果兄弟节点为红色，而且有 2 个黑色孩子 💡 注意，如果兄弟节点是红色，他们的共同父节点肯定是黑色，因为红黑树不允许有 2 个连续的红色节点 这个可以通过取巧的办法来转化为前面情况： 现在节点 4 的兄弟节点就是黑色节点了，转化为前面的情况，可以按照前面的办法处理 ","date":"2023-07-01","objectID":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/:4:2","series":null,"tags":["Data-Structure"],"title":"如何记忆红黑树的操作","uri":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/#如果兄弟节点是黑色而且有一个红色孩子"},{"categories":["Data-Structure"],"content":" 被删除的节点有黑色右孩子我们暂时用黑色的 y 代替被删除的黑色的 z，并且记 y 为 “double black” 节点，在图上，黑色节点 + 圆环就表示 “double black”2 💡 “double black” 对于红黑树而言，意味着我们要让这边有 2 个黑色节点；对于 2-3-4 树而言，那就对应 2-3-4 树中删除 2-node 的 key之后引发的 underflow 删除黑色的 z，然后用它的黑色右孩子 y 代替 z，标记 y 为 “double black” 节点 接下来我们要根据「“double black” 的兄弟节点」来分情况推导 如果兄弟节点是黑色而且有「一个红色孩子」 在上面的例子，转化为等价的 2-3-4 树上的删除节点操作，在 2-3-4 树中遇到这种情况需要执行 transfer 操作，因为兄弟节点 6, 7 是一个 3-node，还有得借。transfer 操作也就是父节点的 key 移动到被删除的节点的位置，然后兄弟节点的最小的 key 移动到父节点填补空缺 💡 注意看，现在 4 和 5 是 2 个黑色节点，先前这里是一个特殊的 “double black” 节点，现在有 2 个黑色节点了，“double black” 也就没有必要了。这也是它叫做这个名字的原因，我们需要提醒自己这里需要 2 个黑色节点 💡 注意这里节点 6 的颜色就是本来节点 5 的颜色 如果兄弟节点是黑色而且有「两个黑色孩子」 在上面的例子，转化为等价的 2-3-4 树上的删除节点操作，在 2-3-4 树中遇到这种情况需要执行 fusion 操作，因为兄弟节点 7 是一个 2-node，没得借。fusion 操作就是从父节点那边借一个 key 下来，然后和兄弟节点合并，成为一个 3-node，也就是图上的 5, 7 💡 但是注意这里的 Fusion 操作找父节点借了一个 key，这可能导致父节点 underflow 了，正如前面我们在新增节点的时候可能 overflow 理论上来说，这个例子的节点 5 应该是黑色（根据前面对节点映射的规定），这样才能满足 “double black” 的要求，但是不要忘了 5 自己是有颜色的 如果 5 本来是红色，那么把 5 变成黑色是没有问题的，因为现在的节点 7 就是红色，红黑树还是平衡的 如果 5 本来是黑色，那么把 5 变成黑色是有问题的，因为还是会少了一个黑色节点，那么节点 5 就变成了新的 “double black” 节点，我们还得向上继续调整。这恰恰是对应了 2-3-4 树中发生了 underflow 的情况，那么我们就要 bototm-up 一路调整回去。最后如果发现根节点是一个 “double black” 节点，那么把根节点变成黑色节点即可 如果兄弟节点是红色而且有「两个黑色孩子」最后一种情况，如果兄弟节点为红色，而且有 2 个黑色孩子 💡 注意，如果兄弟节点是红色，他们的共同父节点肯定是黑色，因为红黑树不允许有 2 个连续的红色节点 这个可以通过取巧的办法来转化为前面情况： 现在节点 4 的兄弟节点就是黑色节点了，转化为前面的情况，可以按照前面的办法处理 ","date":"2023-07-01","objectID":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/:4:2","series":null,"tags":["Data-Structure"],"title":"如何记忆红黑树的操作","uri":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/#如果兄弟节点是黑色而且有两个黑色孩子"},{"categories":["Data-Structure"],"content":" 被删除的节点有黑色右孩子我们暂时用黑色的 y 代替被删除的黑色的 z，并且记 y 为 “double black” 节点，在图上，黑色节点 + 圆环就表示 “double black”2 💡 “double black” 对于红黑树而言，意味着我们要让这边有 2 个黑色节点；对于 2-3-4 树而言，那就对应 2-3-4 树中删除 2-node 的 key之后引发的 underflow 删除黑色的 z，然后用它的黑色右孩子 y 代替 z，标记 y 为 “double black” 节点 接下来我们要根据「“double black” 的兄弟节点」来分情况推导 如果兄弟节点是黑色而且有「一个红色孩子」 在上面的例子，转化为等价的 2-3-4 树上的删除节点操作，在 2-3-4 树中遇到这种情况需要执行 transfer 操作，因为兄弟节点 6, 7 是一个 3-node，还有得借。transfer 操作也就是父节点的 key 移动到被删除的节点的位置，然后兄弟节点的最小的 key 移动到父节点填补空缺 💡 注意看，现在 4 和 5 是 2 个黑色节点，先前这里是一个特殊的 “double black” 节点，现在有 2 个黑色节点了，“double black” 也就没有必要了。这也是它叫做这个名字的原因，我们需要提醒自己这里需要 2 个黑色节点 💡 注意这里节点 6 的颜色就是本来节点 5 的颜色 如果兄弟节点是黑色而且有「两个黑色孩子」 在上面的例子，转化为等价的 2-3-4 树上的删除节点操作，在 2-3-4 树中遇到这种情况需要执行 fusion 操作，因为兄弟节点 7 是一个 2-node，没得借。fusion 操作就是从父节点那边借一个 key 下来，然后和兄弟节点合并，成为一个 3-node，也就是图上的 5, 7 💡 但是注意这里的 Fusion 操作找父节点借了一个 key，这可能导致父节点 underflow 了，正如前面我们在新增节点的时候可能 overflow 理论上来说，这个例子的节点 5 应该是黑色（根据前面对节点映射的规定），这样才能满足 “double black” 的要求，但是不要忘了 5 自己是有颜色的 如果 5 本来是红色，那么把 5 变成黑色是没有问题的，因为现在的节点 7 就是红色，红黑树还是平衡的 如果 5 本来是黑色，那么把 5 变成黑色是有问题的，因为还是会少了一个黑色节点，那么节点 5 就变成了新的 “double black” 节点，我们还得向上继续调整。这恰恰是对应了 2-3-4 树中发生了 underflow 的情况，那么我们就要 bototm-up 一路调整回去。最后如果发现根节点是一个 “double black” 节点，那么把根节点变成黑色节点即可 如果兄弟节点是红色而且有「两个黑色孩子」最后一种情况，如果兄弟节点为红色，而且有 2 个黑色孩子 💡 注意，如果兄弟节点是红色，他们的共同父节点肯定是黑色，因为红黑树不允许有 2 个连续的红色节点 这个可以通过取巧的办法来转化为前面情况： 现在节点 4 的兄弟节点就是黑色节点了，转化为前面的情况，可以按照前面的办法处理 ","date":"2023-07-01","objectID":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/:4:2","series":null,"tags":["Data-Structure"],"title":"如何记忆红黑树的操作","uri":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/#如果兄弟节点是红色而且有两个黑色孩子"},{"categories":["Data-Structure"],"content":" 总结经过前面的例子展示，我们发现可以在 2-3-4 树上思考要如何处理，处理完成之后转变回红黑树，而 2-3-4 树的节点插入和删除操作都是比较简单的，这也是这套方法的价值所在，最重要的是，终于可以不用记住旋转顺序和怎么交换颜色了👏 ","date":"2023-07-01","objectID":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/:5:0","series":null,"tags":["Data-Structure"],"title":"如何记忆红黑树的操作","uri":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/#总结"},{"categories":["Data-Structure"],"content":" 推荐阅读关于 2-3-4 树和红黑树的对应关系，还有下面的几个参考资源可以阅读 CS166. Balanced Trees, Part I CS166. Balanced Trees, Part II CS280. Mapping 2-3-4 trees into Red-Black trees ","date":"2023-07-01","objectID":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/:6:0","series":null,"tags":["Data-Structure"],"title":"如何记忆红黑树的操作","uri":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/#推荐阅读"},{"categories":["Data-Structure"],"content":" 参考 CS166. Balanced Trees, Part II ↩︎ Red Black Trees ↩︎ ","date":"2023-07-01","objectID":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/:7:0","series":null,"tags":["Data-Structure"],"title":"如何记忆红黑树的操作","uri":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/#参考"},{"categories":["Git"],"content":"介绍了少为人知的 git bundle 命令","date":"2023-06-16","objectID":"/zh-cn/git-bundle-tutorial/","series":null,"tags":["Git"],"title":"Git Bundle 指南","uri":"/zh-cn/git-bundle-tutorial/"},{"categories":["Git"],"content":" git bundle 是什么git bundle 是一个比较少看到的 git 命令，它的作用是把一个 git 仓库打包📦成一个文件，然后别人可以通过这个文件还原出本来的 git 仓库，而且 git bundle 还支持增量更新功能。在知道 git bundle 命令之前，我有时候打包一个 git 仓库一般就直接 tar czf some_git_repo。前阵子偶然发现了 git bundle 发现还挺实用的🍻 这个命令最好通过例子来说明，因此下面我用 HostA 和 HostB 这两个文件夹模拟两台主机，假设在 HostA 上存在某个 git 仓库 foo，目录结构如下： text ├── HostA │ └── foo │ ├── 1.txt │ ├── 2.txt │ └── 3.txt ├── HostB 其中 foo 有 3 个 commits，如下所示： text * 21486d5 (HEAD -\u003e main) add 3.txt * a051186 add 2.txt * 2820a6c add 1.txt ","date":"2023-06-16","objectID":"/zh-cn/git-bundle-tutorial/:1:0","series":null,"tags":["Git"],"title":"Git Bundle 指南","uri":"/zh-cn/git-bundle-tutorial/#git-bundle-是什么"},{"categories":["Git"],"content":" 使用场景","date":"2023-06-16","objectID":"/zh-cn/git-bundle-tutorial/:2:0","series":null,"tags":["Git"],"title":"Git Bundle 指南","uri":"/zh-cn/git-bundle-tutorial/#使用场景"},{"categories":["Git"],"content":" HostA 上首次打包首次打包那么必定是要对整个 git 仓库进行打包，打包 HostA 上的 foo 仓库的命令很简单 sh # in HostA/foo # syntax: git bundle create \u003cfilename\u003e \u003cgit-rev-list-args\u003e $ git bundle create foo.bundle HEAD main 比较难懂的是 \u003cgit-rev-list-args\u003e，它的含义是我们要把什么东西打包到这个 bundle 文件里面。这里我们是要打包 HostA 的 foo 仓库，它有一个 main 分支，同时我们把 HEAD 当前指向的位置也打包到这个 bundle 文件里面，所以用的是 HEAD main ","date":"2023-06-16","objectID":"/zh-cn/git-bundle-tutorial/:2:1","series":null,"tags":["Git"],"title":"Git Bundle 指南","uri":"/zh-cn/git-bundle-tutorial/#hosta-上首次打包"},{"categories":["Git"],"content":" HostB 上克隆仓库现在假设 HostB 上拿到了前面打包好的 foo.bundle 文件，那么还原出本来的仓库也很简单，命令如下所示 sh # in HostB # syntax: git clone \u003cfilename\u003e \u003ctarget_dir\u003e $ git clone foo.bundle foo 可以看到，提取 bundle 文件的信息就像是从一个普通的 URL 克隆仓库一样，只不过把 URL 换成了 bundle 文件的路径 此时看下这个仓库的远程仓库信息，你会发现它的远程仓库被设置成了 foo.bundle 文件 sh # in HostB/foo $ git remote -v # output: # origin \u003cpath_to_foo.bundle\u003e (fetch) # origin \u003cpath_to_foo.bundle\u003e (push) ","date":"2023-06-16","objectID":"/zh-cn/git-bundle-tutorial/:2:2","series":null,"tags":["Git"],"title":"Git Bundle 指南","uri":"/zh-cn/git-bundle-tutorial/#hostb-上克隆仓库"},{"categories":["Git"],"content":" HostA 上继续更新现在假设 HostA 上的 foo 仓库多更新了几个 commit，如下所示： text * 9ac69b0 (HEAD -\u003e main) add 5.txt -- new commit * 0350a1e add 4.txt -- new commit * 21486d5 add 3.txt * a051186 add 2.txt * 2820a6c add 1.txt 我们想要把 HostA 上这两个新的 commit 打包📦后发送给 HostB 让 HostB 可以和 HostA 保持同步。所以我们可以利用 git 提供的指定 commit range 的语法，选中这两个 commits1 sh # in HostA/foo # let's verify what will be bundled first $ git log --oneline 21486d5..main $ git bundle create increment.bundle 21486d5..main ","date":"2023-06-16","objectID":"/zh-cn/git-bundle-tutorial/:2:3","series":null,"tags":["Git"],"title":"Git Bundle 指南","uri":"/zh-cn/git-bundle-tutorial/#hosta-上继续更新"},{"categories":["Git"],"content":" HostB 上增量更新现在假设 HostB 拿到了 increment.bundle，那么用下面的命令可以提取里面的 commits sh # in HostB/foo # syntax: git fetch \u003cBUNDLE_FILE\u003e \u003cBRANCH_IN_BUNDLE\u003e:\u003cBRANCH_IN_LOCAL_REPO\u003e $ git fetch increment.bundle main:feature 上面这个命令会将 increment.bundle 文件包含的 commit 放到新的 feature 分支上 sh # in HostB/foo $ git log --oneline --graph --all # output: # * 9ac69b0 (feature) add 5.txt # * 0350a1e add 4.txt # * 21486d5 (HEAD -\u003e main, origin/main, origin/HEAD) add 3.txt # * a051186 add 2.txt # * 2820a6c add 1.txt 确定没有问题之后我们可以尝试合并 feature 分支，并删除 feature 分支 sh # in HostB/foo $ git merge feature $ git branch -d feature $ git log --oneline --graph --all # output: # * 9ac69b0 (HEAD -\u003e main) add 5.txt # * 0350a1e add 4.txt # * 21486d5 (origin/main, origin/HEAD) add 3.txt # * a051186 add 2.txt # * 2820a6c add 1.txt 🤔️ 那么能否直接将 increment.bundle 文件里的 commits 合并到 HostB 的 foo 的 main 分支上呢？也是可以的，命令是：git pull increment.bundle main:main，但是并不建议这么做，因为 HostB/foo 也有可能更新了仓库，先 fetch 再 merge 是一个好习惯 你可能还记得，HostB 上的 foo 这个仓库的远程分支被设置为某个文件，那么能否像一般使用 git 那样直接 git pull 呢？答案是肯定的，我们只需要将 increment.bundle 文件重命名为 foo.bundle 文件然后放在 git remote -v 显示的路径就行（当然改 remote 信息也可） ","date":"2023-06-16","objectID":"/zh-cn/git-bundle-tutorial/:2:4","series":null,"tags":["Git"],"title":"Git Bundle 指南","uri":"/zh-cn/git-bundle-tutorial/#hostb-上增量更新"},{"categories":["Git"],"content":" FAQ怎么知道 bundle 文件里面有什么分支可以用呢？下面的命令可以显示 bundle 文件里面所有的分支 sh # syntax: git bundle list-heads \u003cBUNDLE_FILE\u003e $ git bundle list-heads increment.bundle # output: 9ac69b08060859bc4b2172a8238cb841846ec5e0 refs/heads/main 怎么确定一个 bundle 文件能否用于当前的某个 git 仓库上呢？只需要将 bundle 文件放在这个 git 仓库里然后运行 git bundle verify sh # in HostB/foo # syntax: git bundle verify \u003cBUNDLE_FILE\u003e $ git bundle verify increment.bundle # output: # The bundle contains this ref: # 9ac69b08060859bc4b2172a8238cb841846ec5e0 refs/heads/main # The bundle requires this ref: # 21486d53326de40678a54159de656714a59b8d09 # The bundle uses this hash algorithm: sha1 # increment.bundle is okay 从上面的输出可以看到，increment.bundle 要求仓库有 21486d5 这个 commit 才能够被用来更新。前面的 HostB/foo 在同步之前的最后一个 commit 就是这个 ","date":"2023-06-16","objectID":"/zh-cn/git-bundle-tutorial/:3:0","series":null,"tags":["Git"],"title":"Git Bundle 指南","uri":"/zh-cn/git-bundle-tutorial/#faq"},{"categories":["Git"],"content":" 总结git bundle 打包 git 仓库还是很方便的，结合选取 commit range 的语法还可以只选中部分 commits 增量更新，这样这个 bundle 文件就不会太大，方便我们进行传输。最重要的是它保留了所有的 git 历史👍 ","date":"2023-06-16","objectID":"/zh-cn/git-bundle-tutorial/:4:0","series":null,"tags":["Git"],"title":"Git Bundle 指南","uri":"/zh-cn/git-bundle-tutorial/#总结"},{"categories":["Git"],"content":" 参考 Git Revision Selection ↩︎ ","date":"2023-06-16","objectID":"/zh-cn/git-bundle-tutorial/:5:0","series":null,"tags":["Git"],"title":"Git Bundle 指南","uri":"/zh-cn/git-bundle-tutorial/#参考"},{"categories":["GNN"],"content":"用 MPNN 框架解读图神经网络中的 GAT","date":"2023-05-21","objectID":"/zh-cn/understanding-graph-attention-network-through-mpnn/","series":null,"tags":["GNN","Deep-Learning","Paper","Internal"],"title":"用 MPNN 框架解读 GAT","uri":"/zh-cn/understanding-graph-attention-network-through-mpnn/"},{"categories":["GNN"],"content":" 什么是 MPNN 框架Justin Gilmer 提出了 MPNN（Message Passing Neural Network）框架1 ，用于描述被用来做图上的监督学习的图神经网络模型。我发现这是一个很好用的框架，可以很好理解不同的 GNN 模型是如何工作的，方便快速弄清楚不同的 GNN 模型之间的差别。我们考虑图 $G$ 上的一个节点 $v$，它的向量表示 $h_v$ 的更新方式如下： $$m_v^{t+1}=\\sum_{u\\in \\mathcal{N}(v)}M_t(h_v^t,h_u^t,e_{vu})$$ $$h_v^{t+1}=U_t(h_v^t,m_v^{t+1})$$ 其中 $u$ 为 $v$ 的邻居节点，$\\mathcal{N}(v)$ 则表示节点 $v$ 的所有邻居 $e_{vu}$ 是可选项，表示边上的特征（若有） $M_t$ 是消息函数，$m_v^{t+1}$ 就是所有邻居节点的消息聚合之后的结果 $U_t$ 是节点更新函数 在更新完图上所有节点的向量表示之后，我们可能需要要做图级别的分类任务，在 MPNN 框架中对应为： $$\\hat y=R({h_v^T|v\\in G})$$ 其中： $R$ 为图读出函数，输入是图上所有节点的向量表示，输出为一个特征向量用于图级别的分类任务 ","date":"2023-05-21","objectID":"/zh-cn/understanding-graph-attention-network-through-mpnn/:1:0","series":null,"tags":["GNN","Deep-Learning","Paper","Internal"],"title":"用 MPNN 框架解读 GAT","uri":"/zh-cn/understanding-graph-attention-network-through-mpnn/#什么是-mpnn-框架"},{"categories":["GNN"],"content":" 什么是 GAT 🧐 我发现将论文的公式和具体的代码联系起来总是能够帮助理解，因此下面关于 GAT 公式的讲解我会在用 MPNN 框架的基础上，同时附上相关的代码（用 ... 表示其他省略的部分）。代码来自于 DGL 官方提供的 GAT 模块的源码 🧐 GAT 可以方便堆叠多层，下面的讨论都是从某一层 $l$的某个节点 $v$ 的角度来谈的 Step 1. 对节点做线性变换$$h_v^{l}=W^lh_v^{l}$$ 设每个节点的向量表示的长度为 $F$，在第一步中，对图上每个结点的向量先做一个线性变换，其中 $W\\in\\mathcal{R}^{F’\\times F}$, 因此每个节点的向量都更新长度为 $F’$。为了区分不同层的向量，用上角标 $l$ 表示这是第 $l$ 层的。注意在第 $l$ 层中，所有节点共用同一个权重矩阵 $W$ 📒 注意后面的 $h_v^l$ 或者 $h_u^l$ 都是经过线性变换之后的 python class GATConv(nn.Module): def __init__(self, ...): ... self.fc = nn.Linear( self._in_src_feats, out_feats * num_heads, bias=False ) ... def forward(self, graph, feat, ...): \"\"\" Args ---- feat: (N, *, D_in) where D_in is the size of input feature Returns ------- torch.Tensor (N, *, num_heads, D_out) \"\"\" ... src_prefix_shape = dst_prefix_shape = feat.shape[:-1] h_src = h_dst = self.feat_drop(feat) # h_src: (N, *, D_in) feat_src = feat_dst = self.fc(h_src).view( *src_prefix_shape, self._num_heads, self._out_feats ) # feat_src/feat_dst: (N, *, num_heads, out_feat) ... 注意，上面代码中的 h_src 会出来两个一样的 feat_src 和 feat_dst 是因为 DGL 采用了数学上等价但是计算效率会更高的实现。后面会解释 Step 2. 计算注意力$$e_{vu}^l=LeakyReLU\\Big((a^l)^T[h_v^{l}||h_u^{l}]\\Big)$$ $$\\alpha_{vu}^l=Softmax_u(e_{vu}^l)$$ 第二步就是要计算中心节点 $v$ 和它的所有邻居节点之间的注意力了。在上面的公式中： $e_{vu}^l$ 表示注意力系数（attention coefficient）。论文中提到完全可以采用不同的注意力计算方式，在 GAT 的论文中，作者选择用一层前馈神经网络计算注意力2。注意这里的 $e_{vu}^l$ 跟 MPNN 的 $e_{vu}$ 是没有关系的，只是恰好记号一样了而已 $||$ 表示拼接操作，即我们会将中心节点和它对应的邻居结点的向量表示拼接起来，得到一个长度为 $2F’$ 的向量，对应公式中的 $[h_v^{l}||h_u^{l}]$，然后把它送入到前面提到的一层前馈神经网络中，对应公式中的 $(a^l)^T[h_v^{l}||h_u^{l}]$，其中 $(a^l)^T$ 指的是第 $l$ 层的单层前馈神经网络的参数 激活函数选用的是 $LeakyReLU$ 最后在节点 $v$ 的所有邻居节点之间用 Softmax 做归一化 🤔️ 步骤一和步骤二对应 MPNN 框架的 $m_v^{t+1}$ 的计算 多头注意力正如 Transformer 中有多头注意力一样，GAT 的作者同样在节点更新的时候采用了多头注意力的机制： $$h_v^{l+1}= ||^{K^l} \\sigma(\\sum_{u\\in\\mathcal{N}(i)}\\alpha_{vu}^{(k,l)}W^{(k,l)}h_u^{l})$$ 记号越来越复杂了，但是仔细思索一番还是可以理清楚的，上角标 $(k,l)$ 的意思是第 $l$ 层的第 $k$ 个头。其中 $K^l$ 为第 $l$ 层“头”的数量。上面的公式的意思就是每个“头”会计算出一个向量表示，然后不同“头”之间的会拼接起来 python class GATConv(nn.Module): def __init__(self, ...): ... self.attn_l = nn.Parameter( th.FloatTensor(size=(1, num_heads, out_feats)) ) self.attn_r = nn.Parameter( th.FloatTensor(size=(1, num_heads, out_feats)) ) self.leaky_relu = nn.LeakyReLU(negative_slope) ... def forward(self, graph, feat, ...): \"\"\" Args ---- feat: (N, *, D_in) where D_in is the size of input feature Returns ------- torch.Tensor (N, *, num_heads, D_out) \"\"\" # feat_src/feat_dst: (N, *, num_heads, out_feat) el = (feat_src * self.attn_l).sum(dim=-1).unsqueeze(-1) er = (feat_dst * self.attn_r).sum(dim=-1).unsqueeze(-1) # el/er: (N, *, num_heads, 1) graph.srcdata.update({\"ft\": feat_src, \"el\": el}) graph.dstdata.update({\"er\": er}) graph.apply_edges(fn.u_add_v(\"el\", \"er\", \"e\")) e = self.leaky_relu(graph.edata.pop(\"e\")) # e: (N, *, num_heads, 1) # normalization graph.edata[\"a\"] = self.attn_drop(edge_softmax(graph, e)) # a: (N, *, num_heads, 1) # weighted sum graph.update_all( # ft: (N, *, num_heads, out_feat) # a: (N, *, num_heads, 1) # m: (N, *, num_heads, out_feat) fn.u_mul_e(\"ft\", \"a\", \"m\"), fn.sum(\"m\", \"ft\") ) rst = graph.dstdata[\"ft\"] # rst: (N, *, num_heads, out_feat) ... DGL 的实现基于下面这个事实： $$a^T[h_v||h_u]=a_l^Th_v+a_r^Th_u$$ 为什么会更为高效呢？ 不需要存储 $[h_v||h_u]$ 这个中间变量了（DGL 会将消息存储为边的属性） 加法可以用 DGL 优化过的 fn.u_add_v 函数 Step 3. 聚合邻居消息最后节点更新的方式就是计算邻居的向量表示的加权和（基于前面算好的注意力）： $$h_v^{l+1}=\\sigma(\\sum_{u\\in \\mathcal{N}(i)}\\alpha_{vu}W^{l}h_u^{l})$$ 🤔️ 上面就对应 MPNN 框架中的 $h_v^{t+1}$ 的计算，注意 GAT 算 $h_t^{l+1}$ 的时候并不会用到自己上一层表示 $h_t^l$。同时 GAT 的提出是用于解决图上的节点分类问题，因此也没有图读出的操作。 在 GAT 的论文中，作者是要将 GAT 用于节点级别的分类任务2。假设我们堆叠了 $L$ 层的 GAT 之后，在最后一层如果还采用拼接的方式显然是不合理的。因此作者在最后一层 GAT 中，是取多个头的平均值之后才应用了激活函数，这里的激活函数如果采用 Softmax，就可以直接做节点分类了2。公式如下所示: $$final\\ embedding\\ of\\ h_v= \\sigma\\Big(\\frac{1}{K^L}\\sum_{k=1}^{K^L}\\sum_{u\\in\\mathcal{N}(i)}\\alpha_{vu}^{(k,L)}W^{(k,L)}h_u^{L}\\Big)$$ ","date":"2023-05-21","objectID":"/zh-cn/understanding-graph-attention-network-through-mpnn/:2:0","series":null,"tags":["GNN","Deep-Learning","Paper","Internal"],"title":"用 MPNN 框架解读 GAT","uri":"/zh-cn/understanding-graph-attention-network-through-mpnn/#什么是-gat"},{"categories":["GNN"],"content":" 什么是 GAT 🧐 我发现将论文的公式和具体的代码联系起来总是能够帮助理解，因此下面关于 GAT 公式的讲解我会在用 MPNN 框架的基础上，同时附上相关的代码（用 ... 表示其他省略的部分）。代码来自于 DGL 官方提供的 GAT 模块的源码 🧐 GAT 可以方便堆叠多层，下面的讨论都是从某一层 $l$的某个节点 $v$ 的角度来谈的 Step 1. 对节点做线性变换$$h_v^{l}=W^lh_v^{l}$$ 设每个节点的向量表示的长度为 $F$，在第一步中，对图上每个结点的向量先做一个线性变换，其中 $W\\in\\mathcal{R}^{F’\\times F}$, 因此每个节点的向量都更新长度为 $F’$。为了区分不同层的向量，用上角标 $l$ 表示这是第 $l$ 层的。注意在第 $l$ 层中，所有节点共用同一个权重矩阵 $W$ 📒 注意后面的 $h_v^l$ 或者 $h_u^l$ 都是经过线性变换之后的 python class GATConv(nn.Module): def __init__(self, ...): ... self.fc = nn.Linear( self._in_src_feats, out_feats * num_heads, bias=False ) ... def forward(self, graph, feat, ...): \"\"\" Args ---- feat: (N, *, D_in) where D_in is the size of input feature Returns ------- torch.Tensor (N, *, num_heads, D_out) \"\"\" ... src_prefix_shape = dst_prefix_shape = feat.shape[:-1] h_src = h_dst = self.feat_drop(feat) # h_src: (N, *, D_in) feat_src = feat_dst = self.fc(h_src).view( *src_prefix_shape, self._num_heads, self._out_feats ) # feat_src/feat_dst: (N, *, num_heads, out_feat) ... 注意，上面代码中的 h_src 会出来两个一样的 feat_src 和 feat_dst 是因为 DGL 采用了数学上等价但是计算效率会更高的实现。后面会解释 Step 2. 计算注意力$$e_{vu}^l=LeakyReLU\\Big((a^l)^T[h_v^{l}||h_u^{l}]\\Big)$$ $$\\alpha_{vu}^l=Softmax_u(e_{vu}^l)$$ 第二步就是要计算中心节点 $v$ 和它的所有邻居节点之间的注意力了。在上面的公式中： $e_{vu}^l$ 表示注意力系数（attention coefficient）。论文中提到完全可以采用不同的注意力计算方式，在 GAT 的论文中，作者选择用一层前馈神经网络计算注意力2。注意这里的 $e_{vu}^l$ 跟 MPNN 的 $e_{vu}$ 是没有关系的，只是恰好记号一样了而已 $||$ 表示拼接操作，即我们会将中心节点和它对应的邻居结点的向量表示拼接起来，得到一个长度为 $2F’$ 的向量，对应公式中的 $[h_v^{l}||h_u^{l}]$，然后把它送入到前面提到的一层前馈神经网络中，对应公式中的 $(a^l)^T[h_v^{l}||h_u^{l}]$，其中 $(a^l)^T$ 指的是第 $l$ 层的单层前馈神经网络的参数 激活函数选用的是 $LeakyReLU$ 最后在节点 $v$ 的所有邻居节点之间用 Softmax 做归一化 🤔️ 步骤一和步骤二对应 MPNN 框架的 $m_v^{t+1}$ 的计算 多头注意力正如 Transformer 中有多头注意力一样，GAT 的作者同样在节点更新的时候采用了多头注意力的机制： $$h_v^{l+1}= ||^{K^l} \\sigma(\\sum_{u\\in\\mathcal{N}(i)}\\alpha_{vu}^{(k,l)}W^{(k,l)}h_u^{l})$$ 记号越来越复杂了，但是仔细思索一番还是可以理清楚的，上角标 $(k,l)$ 的意思是第 $l$ 层的第 $k$ 个头。其中 $K^l$ 为第 $l$ 层“头”的数量。上面的公式的意思就是每个“头”会计算出一个向量表示，然后不同“头”之间的会拼接起来 python class GATConv(nn.Module): def __init__(self, ...): ... self.attn_l = nn.Parameter( th.FloatTensor(size=(1, num_heads, out_feats)) ) self.attn_r = nn.Parameter( th.FloatTensor(size=(1, num_heads, out_feats)) ) self.leaky_relu = nn.LeakyReLU(negative_slope) ... def forward(self, graph, feat, ...): \"\"\" Args ---- feat: (N, *, D_in) where D_in is the size of input feature Returns ------- torch.Tensor (N, *, num_heads, D_out) \"\"\" # feat_src/feat_dst: (N, *, num_heads, out_feat) el = (feat_src * self.attn_l).sum(dim=-1).unsqueeze(-1) er = (feat_dst * self.attn_r).sum(dim=-1).unsqueeze(-1) # el/er: (N, *, num_heads, 1) graph.srcdata.update({\"ft\": feat_src, \"el\": el}) graph.dstdata.update({\"er\": er}) graph.apply_edges(fn.u_add_v(\"el\", \"er\", \"e\")) e = self.leaky_relu(graph.edata.pop(\"e\")) # e: (N, *, num_heads, 1) # normalization graph.edata[\"a\"] = self.attn_drop(edge_softmax(graph, e)) # a: (N, *, num_heads, 1) # weighted sum graph.update_all( # ft: (N, *, num_heads, out_feat) # a: (N, *, num_heads, 1) # m: (N, *, num_heads, out_feat) fn.u_mul_e(\"ft\", \"a\", \"m\"), fn.sum(\"m\", \"ft\") ) rst = graph.dstdata[\"ft\"] # rst: (N, *, num_heads, out_feat) ... DGL 的实现基于下面这个事实： $$a^T[h_v||h_u]=a_l^Th_v+a_r^Th_u$$ 为什么会更为高效呢？ 不需要存储 $[h_v||h_u]$ 这个中间变量了（DGL 会将消息存储为边的属性） 加法可以用 DGL 优化过的 fn.u_add_v 函数 Step 3. 聚合邻居消息最后节点更新的方式就是计算邻居的向量表示的加权和（基于前面算好的注意力）： $$h_v^{l+1}=\\sigma(\\sum_{u\\in \\mathcal{N}(i)}\\alpha_{vu}W^{l}h_u^{l})$$ 🤔️ 上面就对应 MPNN 框架中的 $h_v^{t+1}$ 的计算，注意 GAT 算 $h_t^{l+1}$ 的时候并不会用到自己上一层表示 $h_t^l$。同时 GAT 的提出是用于解决图上的节点分类问题，因此也没有图读出的操作。 在 GAT 的论文中，作者是要将 GAT 用于节点级别的分类任务2。假设我们堆叠了 $L$ 层的 GAT 之后，在最后一层如果还采用拼接的方式显然是不合理的。因此作者在最后一层 GAT 中，是取多个头的平均值之后才应用了激活函数，这里的激活函数如果采用 Softmax，就可以直接做节点分类了2。公式如下所示: $$final\\ embedding\\ of\\ h_v= \\sigma\\Big(\\frac{1}{K^L}\\sum_{k=1}^{K^L}\\sum_{u\\in\\mathcal{N}(i)}\\alpha_{vu}^{(k,L)}W^{(k,L)}h_u^{L}\\Big)$$ ","date":"2023-05-21","objectID":"/zh-cn/understanding-graph-attention-network-through-mpnn/:2:0","series":null,"tags":["GNN","Deep-Learning","Paper","Internal"],"title":"用 MPNN 框架解读 GAT","uri":"/zh-cn/understanding-graph-attention-network-through-mpnn/#step-1-对节点做线性变换"},{"categories":["GNN"],"content":" 什么是 GAT 🧐 我发现将论文的公式和具体的代码联系起来总是能够帮助理解，因此下面关于 GAT 公式的讲解我会在用 MPNN 框架的基础上，同时附上相关的代码（用 ... 表示其他省略的部分）。代码来自于 DGL 官方提供的 GAT 模块的源码 🧐 GAT 可以方便堆叠多层，下面的讨论都是从某一层 $l$的某个节点 $v$ 的角度来谈的 Step 1. 对节点做线性变换$$h_v^{l}=W^lh_v^{l}$$ 设每个节点的向量表示的长度为 $F$，在第一步中，对图上每个结点的向量先做一个线性变换，其中 $W\\in\\mathcal{R}^{F’\\times F}$, 因此每个节点的向量都更新长度为 $F’$。为了区分不同层的向量，用上角标 $l$ 表示这是第 $l$ 层的。注意在第 $l$ 层中，所有节点共用同一个权重矩阵 $W$ 📒 注意后面的 $h_v^l$ 或者 $h_u^l$ 都是经过线性变换之后的 python class GATConv(nn.Module): def __init__(self, ...): ... self.fc = nn.Linear( self._in_src_feats, out_feats * num_heads, bias=False ) ... def forward(self, graph, feat, ...): \"\"\" Args ---- feat: (N, *, D_in) where D_in is the size of input feature Returns ------- torch.Tensor (N, *, num_heads, D_out) \"\"\" ... src_prefix_shape = dst_prefix_shape = feat.shape[:-1] h_src = h_dst = self.feat_drop(feat) # h_src: (N, *, D_in) feat_src = feat_dst = self.fc(h_src).view( *src_prefix_shape, self._num_heads, self._out_feats ) # feat_src/feat_dst: (N, *, num_heads, out_feat) ... 注意，上面代码中的 h_src 会出来两个一样的 feat_src 和 feat_dst 是因为 DGL 采用了数学上等价但是计算效率会更高的实现。后面会解释 Step 2. 计算注意力$$e_{vu}^l=LeakyReLU\\Big((a^l)^T[h_v^{l}||h_u^{l}]\\Big)$$ $$\\alpha_{vu}^l=Softmax_u(e_{vu}^l)$$ 第二步就是要计算中心节点 $v$ 和它的所有邻居节点之间的注意力了。在上面的公式中： $e_{vu}^l$ 表示注意力系数（attention coefficient）。论文中提到完全可以采用不同的注意力计算方式，在 GAT 的论文中，作者选择用一层前馈神经网络计算注意力2。注意这里的 $e_{vu}^l$ 跟 MPNN 的 $e_{vu}$ 是没有关系的，只是恰好记号一样了而已 $||$ 表示拼接操作，即我们会将中心节点和它对应的邻居结点的向量表示拼接起来，得到一个长度为 $2F’$ 的向量，对应公式中的 $[h_v^{l}||h_u^{l}]$，然后把它送入到前面提到的一层前馈神经网络中，对应公式中的 $(a^l)^T[h_v^{l}||h_u^{l}]$，其中 $(a^l)^T$ 指的是第 $l$ 层的单层前馈神经网络的参数 激活函数选用的是 $LeakyReLU$ 最后在节点 $v$ 的所有邻居节点之间用 Softmax 做归一化 🤔️ 步骤一和步骤二对应 MPNN 框架的 $m_v^{t+1}$ 的计算 多头注意力正如 Transformer 中有多头注意力一样，GAT 的作者同样在节点更新的时候采用了多头注意力的机制： $$h_v^{l+1}= ||^{K^l} \\sigma(\\sum_{u\\in\\mathcal{N}(i)}\\alpha_{vu}^{(k,l)}W^{(k,l)}h_u^{l})$$ 记号越来越复杂了，但是仔细思索一番还是可以理清楚的，上角标 $(k,l)$ 的意思是第 $l$ 层的第 $k$ 个头。其中 $K^l$ 为第 $l$ 层“头”的数量。上面的公式的意思就是每个“头”会计算出一个向量表示，然后不同“头”之间的会拼接起来 python class GATConv(nn.Module): def __init__(self, ...): ... self.attn_l = nn.Parameter( th.FloatTensor(size=(1, num_heads, out_feats)) ) self.attn_r = nn.Parameter( th.FloatTensor(size=(1, num_heads, out_feats)) ) self.leaky_relu = nn.LeakyReLU(negative_slope) ... def forward(self, graph, feat, ...): \"\"\" Args ---- feat: (N, *, D_in) where D_in is the size of input feature Returns ------- torch.Tensor (N, *, num_heads, D_out) \"\"\" # feat_src/feat_dst: (N, *, num_heads, out_feat) el = (feat_src * self.attn_l).sum(dim=-1).unsqueeze(-1) er = (feat_dst * self.attn_r).sum(dim=-1).unsqueeze(-1) # el/er: (N, *, num_heads, 1) graph.srcdata.update({\"ft\": feat_src, \"el\": el}) graph.dstdata.update({\"er\": er}) graph.apply_edges(fn.u_add_v(\"el\", \"er\", \"e\")) e = self.leaky_relu(graph.edata.pop(\"e\")) # e: (N, *, num_heads, 1) # normalization graph.edata[\"a\"] = self.attn_drop(edge_softmax(graph, e)) # a: (N, *, num_heads, 1) # weighted sum graph.update_all( # ft: (N, *, num_heads, out_feat) # a: (N, *, num_heads, 1) # m: (N, *, num_heads, out_feat) fn.u_mul_e(\"ft\", \"a\", \"m\"), fn.sum(\"m\", \"ft\") ) rst = graph.dstdata[\"ft\"] # rst: (N, *, num_heads, out_feat) ... DGL 的实现基于下面这个事实： $$a^T[h_v||h_u]=a_l^Th_v+a_r^Th_u$$ 为什么会更为高效呢？ 不需要存储 $[h_v||h_u]$ 这个中间变量了（DGL 会将消息存储为边的属性） 加法可以用 DGL 优化过的 fn.u_add_v 函数 Step 3. 聚合邻居消息最后节点更新的方式就是计算邻居的向量表示的加权和（基于前面算好的注意力）： $$h_v^{l+1}=\\sigma(\\sum_{u\\in \\mathcal{N}(i)}\\alpha_{vu}W^{l}h_u^{l})$$ 🤔️ 上面就对应 MPNN 框架中的 $h_v^{t+1}$ 的计算，注意 GAT 算 $h_t^{l+1}$ 的时候并不会用到自己上一层表示 $h_t^l$。同时 GAT 的提出是用于解决图上的节点分类问题，因此也没有图读出的操作。 在 GAT 的论文中，作者是要将 GAT 用于节点级别的分类任务2。假设我们堆叠了 $L$ 层的 GAT 之后，在最后一层如果还采用拼接的方式显然是不合理的。因此作者在最后一层 GAT 中，是取多个头的平均值之后才应用了激活函数，这里的激活函数如果采用 Softmax，就可以直接做节点分类了2。公式如下所示: $$final\\ embedding\\ of\\ h_v= \\sigma\\Big(\\frac{1}{K^L}\\sum_{k=1}^{K^L}\\sum_{u\\in\\mathcal{N}(i)}\\alpha_{vu}^{(k,L)}W^{(k,L)}h_u^{L}\\Big)$$ ","date":"2023-05-21","objectID":"/zh-cn/understanding-graph-attention-network-through-mpnn/:2:0","series":null,"tags":["GNN","Deep-Learning","Paper","Internal"],"title":"用 MPNN 框架解读 GAT","uri":"/zh-cn/understanding-graph-attention-network-through-mpnn/#step-2-计算注意力"},{"categories":["GNN"],"content":" 什么是 GAT 🧐 我发现将论文的公式和具体的代码联系起来总是能够帮助理解，因此下面关于 GAT 公式的讲解我会在用 MPNN 框架的基础上，同时附上相关的代码（用 ... 表示其他省略的部分）。代码来自于 DGL 官方提供的 GAT 模块的源码 🧐 GAT 可以方便堆叠多层，下面的讨论都是从某一层 $l$的某个节点 $v$ 的角度来谈的 Step 1. 对节点做线性变换$$h_v^{l}=W^lh_v^{l}$$ 设每个节点的向量表示的长度为 $F$，在第一步中，对图上每个结点的向量先做一个线性变换，其中 $W\\in\\mathcal{R}^{F’\\times F}$, 因此每个节点的向量都更新长度为 $F’$。为了区分不同层的向量，用上角标 $l$ 表示这是第 $l$ 层的。注意在第 $l$ 层中，所有节点共用同一个权重矩阵 $W$ 📒 注意后面的 $h_v^l$ 或者 $h_u^l$ 都是经过线性变换之后的 python class GATConv(nn.Module): def __init__(self, ...): ... self.fc = nn.Linear( self._in_src_feats, out_feats * num_heads, bias=False ) ... def forward(self, graph, feat, ...): \"\"\" Args ---- feat: (N, *, D_in) where D_in is the size of input feature Returns ------- torch.Tensor (N, *, num_heads, D_out) \"\"\" ... src_prefix_shape = dst_prefix_shape = feat.shape[:-1] h_src = h_dst = self.feat_drop(feat) # h_src: (N, *, D_in) feat_src = feat_dst = self.fc(h_src).view( *src_prefix_shape, self._num_heads, self._out_feats ) # feat_src/feat_dst: (N, *, num_heads, out_feat) ... 注意，上面代码中的 h_src 会出来两个一样的 feat_src 和 feat_dst 是因为 DGL 采用了数学上等价但是计算效率会更高的实现。后面会解释 Step 2. 计算注意力$$e_{vu}^l=LeakyReLU\\Big((a^l)^T[h_v^{l}||h_u^{l}]\\Big)$$ $$\\alpha_{vu}^l=Softmax_u(e_{vu}^l)$$ 第二步就是要计算中心节点 $v$ 和它的所有邻居节点之间的注意力了。在上面的公式中： $e_{vu}^l$ 表示注意力系数（attention coefficient）。论文中提到完全可以采用不同的注意力计算方式，在 GAT 的论文中，作者选择用一层前馈神经网络计算注意力2。注意这里的 $e_{vu}^l$ 跟 MPNN 的 $e_{vu}$ 是没有关系的，只是恰好记号一样了而已 $||$ 表示拼接操作，即我们会将中心节点和它对应的邻居结点的向量表示拼接起来，得到一个长度为 $2F’$ 的向量，对应公式中的 $[h_v^{l}||h_u^{l}]$，然后把它送入到前面提到的一层前馈神经网络中，对应公式中的 $(a^l)^T[h_v^{l}||h_u^{l}]$，其中 $(a^l)^T$ 指的是第 $l$ 层的单层前馈神经网络的参数 激活函数选用的是 $LeakyReLU$ 最后在节点 $v$ 的所有邻居节点之间用 Softmax 做归一化 🤔️ 步骤一和步骤二对应 MPNN 框架的 $m_v^{t+1}$ 的计算 多头注意力正如 Transformer 中有多头注意力一样，GAT 的作者同样在节点更新的时候采用了多头注意力的机制： $$h_v^{l+1}= ||^{K^l} \\sigma(\\sum_{u\\in\\mathcal{N}(i)}\\alpha_{vu}^{(k,l)}W^{(k,l)}h_u^{l})$$ 记号越来越复杂了，但是仔细思索一番还是可以理清楚的，上角标 $(k,l)$ 的意思是第 $l$ 层的第 $k$ 个头。其中 $K^l$ 为第 $l$ 层“头”的数量。上面的公式的意思就是每个“头”会计算出一个向量表示，然后不同“头”之间的会拼接起来 python class GATConv(nn.Module): def __init__(self, ...): ... self.attn_l = nn.Parameter( th.FloatTensor(size=(1, num_heads, out_feats)) ) self.attn_r = nn.Parameter( th.FloatTensor(size=(1, num_heads, out_feats)) ) self.leaky_relu = nn.LeakyReLU(negative_slope) ... def forward(self, graph, feat, ...): \"\"\" Args ---- feat: (N, *, D_in) where D_in is the size of input feature Returns ------- torch.Tensor (N, *, num_heads, D_out) \"\"\" # feat_src/feat_dst: (N, *, num_heads, out_feat) el = (feat_src * self.attn_l).sum(dim=-1).unsqueeze(-1) er = (feat_dst * self.attn_r).sum(dim=-1).unsqueeze(-1) # el/er: (N, *, num_heads, 1) graph.srcdata.update({\"ft\": feat_src, \"el\": el}) graph.dstdata.update({\"er\": er}) graph.apply_edges(fn.u_add_v(\"el\", \"er\", \"e\")) e = self.leaky_relu(graph.edata.pop(\"e\")) # e: (N, *, num_heads, 1) # normalization graph.edata[\"a\"] = self.attn_drop(edge_softmax(graph, e)) # a: (N, *, num_heads, 1) # weighted sum graph.update_all( # ft: (N, *, num_heads, out_feat) # a: (N, *, num_heads, 1) # m: (N, *, num_heads, out_feat) fn.u_mul_e(\"ft\", \"a\", \"m\"), fn.sum(\"m\", \"ft\") ) rst = graph.dstdata[\"ft\"] # rst: (N, *, num_heads, out_feat) ... DGL 的实现基于下面这个事实： $$a^T[h_v||h_u]=a_l^Th_v+a_r^Th_u$$ 为什么会更为高效呢？ 不需要存储 $[h_v||h_u]$ 这个中间变量了（DGL 会将消息存储为边的属性） 加法可以用 DGL 优化过的 fn.u_add_v 函数 Step 3. 聚合邻居消息最后节点更新的方式就是计算邻居的向量表示的加权和（基于前面算好的注意力）： $$h_v^{l+1}=\\sigma(\\sum_{u\\in \\mathcal{N}(i)}\\alpha_{vu}W^{l}h_u^{l})$$ 🤔️ 上面就对应 MPNN 框架中的 $h_v^{t+1}$ 的计算，注意 GAT 算 $h_t^{l+1}$ 的时候并不会用到自己上一层表示 $h_t^l$。同时 GAT 的提出是用于解决图上的节点分类问题，因此也没有图读出的操作。 在 GAT 的论文中，作者是要将 GAT 用于节点级别的分类任务2。假设我们堆叠了 $L$ 层的 GAT 之后，在最后一层如果还采用拼接的方式显然是不合理的。因此作者在最后一层 GAT 中，是取多个头的平均值之后才应用了激活函数，这里的激活函数如果采用 Softmax，就可以直接做节点分类了2。公式如下所示: $$final\\ embedding\\ of\\ h_v= \\sigma\\Big(\\frac{1}{K^L}\\sum_{k=1}^{K^L}\\sum_{u\\in\\mathcal{N}(i)}\\alpha_{vu}^{(k,L)}W^{(k,L)}h_u^{L}\\Big)$$ ","date":"2023-05-21","objectID":"/zh-cn/understanding-graph-attention-network-through-mpnn/:2:0","series":null,"tags":["GNN","Deep-Learning","Paper","Internal"],"title":"用 MPNN 框架解读 GAT","uri":"/zh-cn/understanding-graph-attention-network-through-mpnn/#多头注意力"},{"categories":["GNN"],"content":" 什么是 GAT 🧐 我发现将论文的公式和具体的代码联系起来总是能够帮助理解，因此下面关于 GAT 公式的讲解我会在用 MPNN 框架的基础上，同时附上相关的代码（用 ... 表示其他省略的部分）。代码来自于 DGL 官方提供的 GAT 模块的源码 🧐 GAT 可以方便堆叠多层，下面的讨论都是从某一层 $l$的某个节点 $v$ 的角度来谈的 Step 1. 对节点做线性变换$$h_v^{l}=W^lh_v^{l}$$ 设每个节点的向量表示的长度为 $F$，在第一步中，对图上每个结点的向量先做一个线性变换，其中 $W\\in\\mathcal{R}^{F’\\times F}$, 因此每个节点的向量都更新长度为 $F’$。为了区分不同层的向量，用上角标 $l$ 表示这是第 $l$ 层的。注意在第 $l$ 层中，所有节点共用同一个权重矩阵 $W$ 📒 注意后面的 $h_v^l$ 或者 $h_u^l$ 都是经过线性变换之后的 python class GATConv(nn.Module): def __init__(self, ...): ... self.fc = nn.Linear( self._in_src_feats, out_feats * num_heads, bias=False ) ... def forward(self, graph, feat, ...): \"\"\" Args ---- feat: (N, *, D_in) where D_in is the size of input feature Returns ------- torch.Tensor (N, *, num_heads, D_out) \"\"\" ... src_prefix_shape = dst_prefix_shape = feat.shape[:-1] h_src = h_dst = self.feat_drop(feat) # h_src: (N, *, D_in) feat_src = feat_dst = self.fc(h_src).view( *src_prefix_shape, self._num_heads, self._out_feats ) # feat_src/feat_dst: (N, *, num_heads, out_feat) ... 注意，上面代码中的 h_src 会出来两个一样的 feat_src 和 feat_dst 是因为 DGL 采用了数学上等价但是计算效率会更高的实现。后面会解释 Step 2. 计算注意力$$e_{vu}^l=LeakyReLU\\Big((a^l)^T[h_v^{l}||h_u^{l}]\\Big)$$ $$\\alpha_{vu}^l=Softmax_u(e_{vu}^l)$$ 第二步就是要计算中心节点 $v$ 和它的所有邻居节点之间的注意力了。在上面的公式中： $e_{vu}^l$ 表示注意力系数（attention coefficient）。论文中提到完全可以采用不同的注意力计算方式，在 GAT 的论文中，作者选择用一层前馈神经网络计算注意力2。注意这里的 $e_{vu}^l$ 跟 MPNN 的 $e_{vu}$ 是没有关系的，只是恰好记号一样了而已 $||$ 表示拼接操作，即我们会将中心节点和它对应的邻居结点的向量表示拼接起来，得到一个长度为 $2F’$ 的向量，对应公式中的 $[h_v^{l}||h_u^{l}]$，然后把它送入到前面提到的一层前馈神经网络中，对应公式中的 $(a^l)^T[h_v^{l}||h_u^{l}]$，其中 $(a^l)^T$ 指的是第 $l$ 层的单层前馈神经网络的参数 激活函数选用的是 $LeakyReLU$ 最后在节点 $v$ 的所有邻居节点之间用 Softmax 做归一化 🤔️ 步骤一和步骤二对应 MPNN 框架的 $m_v^{t+1}$ 的计算 多头注意力正如 Transformer 中有多头注意力一样，GAT 的作者同样在节点更新的时候采用了多头注意力的机制： $$h_v^{l+1}= ||^{K^l} \\sigma(\\sum_{u\\in\\mathcal{N}(i)}\\alpha_{vu}^{(k,l)}W^{(k,l)}h_u^{l})$$ 记号越来越复杂了，但是仔细思索一番还是可以理清楚的，上角标 $(k,l)$ 的意思是第 $l$ 层的第 $k$ 个头。其中 $K^l$ 为第 $l$ 层“头”的数量。上面的公式的意思就是每个“头”会计算出一个向量表示，然后不同“头”之间的会拼接起来 python class GATConv(nn.Module): def __init__(self, ...): ... self.attn_l = nn.Parameter( th.FloatTensor(size=(1, num_heads, out_feats)) ) self.attn_r = nn.Parameter( th.FloatTensor(size=(1, num_heads, out_feats)) ) self.leaky_relu = nn.LeakyReLU(negative_slope) ... def forward(self, graph, feat, ...): \"\"\" Args ---- feat: (N, *, D_in) where D_in is the size of input feature Returns ------- torch.Tensor (N, *, num_heads, D_out) \"\"\" # feat_src/feat_dst: (N, *, num_heads, out_feat) el = (feat_src * self.attn_l).sum(dim=-1).unsqueeze(-1) er = (feat_dst * self.attn_r).sum(dim=-1).unsqueeze(-1) # el/er: (N, *, num_heads, 1) graph.srcdata.update({\"ft\": feat_src, \"el\": el}) graph.dstdata.update({\"er\": er}) graph.apply_edges(fn.u_add_v(\"el\", \"er\", \"e\")) e = self.leaky_relu(graph.edata.pop(\"e\")) # e: (N, *, num_heads, 1) # normalization graph.edata[\"a\"] = self.attn_drop(edge_softmax(graph, e)) # a: (N, *, num_heads, 1) # weighted sum graph.update_all( # ft: (N, *, num_heads, out_feat) # a: (N, *, num_heads, 1) # m: (N, *, num_heads, out_feat) fn.u_mul_e(\"ft\", \"a\", \"m\"), fn.sum(\"m\", \"ft\") ) rst = graph.dstdata[\"ft\"] # rst: (N, *, num_heads, out_feat) ... DGL 的实现基于下面这个事实： $$a^T[h_v||h_u]=a_l^Th_v+a_r^Th_u$$ 为什么会更为高效呢？ 不需要存储 $[h_v||h_u]$ 这个中间变量了（DGL 会将消息存储为边的属性） 加法可以用 DGL 优化过的 fn.u_add_v 函数 Step 3. 聚合邻居消息最后节点更新的方式就是计算邻居的向量表示的加权和（基于前面算好的注意力）： $$h_v^{l+1}=\\sigma(\\sum_{u\\in \\mathcal{N}(i)}\\alpha_{vu}W^{l}h_u^{l})$$ 🤔️ 上面就对应 MPNN 框架中的 $h_v^{t+1}$ 的计算，注意 GAT 算 $h_t^{l+1}$ 的时候并不会用到自己上一层表示 $h_t^l$。同时 GAT 的提出是用于解决图上的节点分类问题，因此也没有图读出的操作。 在 GAT 的论文中，作者是要将 GAT 用于节点级别的分类任务2。假设我们堆叠了 $L$ 层的 GAT 之后，在最后一层如果还采用拼接的方式显然是不合理的。因此作者在最后一层 GAT 中，是取多个头的平均值之后才应用了激活函数，这里的激活函数如果采用 Softmax，就可以直接做节点分类了2。公式如下所示: $$final\\ embedding\\ of\\ h_v= \\sigma\\Big(\\frac{1}{K^L}\\sum_{k=1}^{K^L}\\sum_{u\\in\\mathcal{N}(i)}\\alpha_{vu}^{(k,L)}W^{(k,L)}h_u^{L}\\Big)$$ ","date":"2023-05-21","objectID":"/zh-cn/understanding-graph-attention-network-through-mpnn/:2:0","series":null,"tags":["GNN","Deep-Learning","Paper","Internal"],"title":"用 MPNN 框架解读 GAT","uri":"/zh-cn/understanding-graph-attention-network-through-mpnn/#step-3-聚合邻居消息"},{"categories":["GNN"],"content":" 实现 🤔️ 图神经网络的流行框架之一 DGL 的设计就是基于 MPNN 框架，不过他们的公式会稍有不同，他们还有一个聚合函数 $\\rho$，用于决定一个节点如何聚合从邻居那边收到的所有信息。我认为他们的公式更具有泛化性，能够适用于更多种情况。他们还贴心地写了关于如何使用 DGL 的 MPNN 相关函数的教程，推荐一看👍👍👍 至于 GAT 的实现，DGL 不仅提供了 GAT 模块，而且还写了一篇不错的用自带的 message_func 和 reduce_func 手动实现 GAT 的教程。一个完整的 GAT 任务训练脚本可以看这里 ","date":"2023-05-21","objectID":"/zh-cn/understanding-graph-attention-network-through-mpnn/:3:0","series":null,"tags":["GNN","Deep-Learning","Paper","Internal"],"title":"用 MPNN 框架解读 GAT","uri":"/zh-cn/understanding-graph-attention-network-through-mpnn/#实现"},{"categories":["GNN"],"content":" 总结以上就是如何用 MPNN 框架解释 GAT 的方法，其中加上了 DGL 的源码分析进行解释，用注意力计算节点之间的关系看起来是一个很自然的思路，可以看成是对 GCN 的一种泛化。GAT 能够很好学习到图的局部结构表示，而且计算注意力的方式可以并行，是十分高效的🍻🍻🍻 ","date":"2023-05-21","objectID":"/zh-cn/understanding-graph-attention-network-through-mpnn/:4:0","series":null,"tags":["GNN","Deep-Learning","Paper","Internal"],"title":"用 MPNN 框架解读 GAT","uri":"/zh-cn/understanding-graph-attention-network-through-mpnn/#总结"},{"categories":["GNN"],"content":" 参考 Gilmer J, Schoenholz S S, Riley P F, et al. Neural message passing for quantum chemistry[C]//International conference on machine learning. PMLR, 2017: 1263-1272. arXiv ↩︎ Veličković P, Cucurull G, Casanova A, et al. Graph attention networks[J]. arXiv preprint arXiv:1710.10903, 2017. arXiv ↩︎ ↩︎ ↩︎ ","date":"2023-05-21","objectID":"/zh-cn/understanding-graph-attention-network-through-mpnn/:5:0","series":null,"tags":["GNN","Deep-Learning","Paper","Internal"],"title":"用 MPNN 框架解读 GAT","uri":"/zh-cn/understanding-graph-attention-network-through-mpnn/#参考"},{"categories":["Exercise"],"content":"SICP 练习 2.27 答案","date":"2023-05-16","objectID":"/zh-cn/sicp-exercise-2-27/","series":null,"tags":["SICP"],"title":"SICP 练习 2.27","uri":"/zh-cn/sicp-exercise-2-27/"},{"categories":["Exercise"],"content":" 题目 Modify your reverse procedure of exercise 2.18 to produce a deep-reverse procedure that taks a list as argument and returns as its value the list with its elements reversed and with all sublists deep-reversed as well. racket (define x (list (list 1 2) (list 3 4))) ;; x - ((1 2) (3 4)) (deep-reverse x) ;; the output should be ((4 3) (2 1)) ","date":"2023-05-16","objectID":"/zh-cn/sicp-exercise-2-27/:1:0","series":null,"tags":["SICP"],"title":"SICP 练习 2.27","uri":"/zh-cn/sicp-exercise-2-27/#题目"},{"categories":["Exercise"],"content":" 答案在前面的练习 2.18 中实现的 reverse 忽略了列表中的元素可能仍然是列表的情况。这里要求的实现的 deep-reverse 则要求我们递归式翻转整个列表。 我认为这题很好体现了如何设计一个递归程序的思想，基本上弄明白下面几点函数就不会出错 递归的 base case 是什么？对于列表来说，空列表很自然就是 base case，此时返回 '() 即可 接下来如何细分情况来递归调用？ 在细分情况之前，应该记住 car 和 cdr 的特点，(cdr l) 总是返回列表，(car l) 总是返回第一个元素（但不保证是否为原子项，即第一个元素也可能为列表） deep-reverse 有什么不变量（invariants）？根据题目所说，它的参数总是为列表 根据前面两点，我们已经不难得出细分情况的标准——即检查列表的第一个元素是否为原子项 代码如下 Racket ;; invariants: the argument of deep-reverse are always a list (define (deep-reverse l) (cond ((null? l) '()) ;; base case (else (let ([remains (deep-reverse (cdr l))]) (if (pair? (car l)) ;; the arguments of append procedure should be lists too (append remains (list (deep-reverse (car l)))) (append remains (list (car l)))))))) 顺便附上一些测试用例 Racket (deep-reverse '(2 3)) (deep-reverse '((2 3))) (deep-reverse '((2 3) 1)) (deep-reverse '(5 (2 3) 1)) (deep-reverse '((4 2) (2 3) 1)) (deep-reverse '(5 (2 3) (5 2))) 🚧 完整 SICP 练习题解仍在施工中 ","date":"2023-05-16","objectID":"/zh-cn/sicp-exercise-2-27/:2:0","series":null,"tags":["SICP"],"title":"SICP 练习 2.27","uri":"/zh-cn/sicp-exercise-2-27/#答案"},{"categories":["Exercise"],"content":"SICP 练习 1.46 答案","date":"2023-05-10","objectID":"/zh-cn/sicp-exercise-1-46/","series":null,"tags":["SICP"],"title":"SICP 练习 1.46","uri":"/zh-cn/sicp-exercise-1-46/"},{"categories":["Exercise"],"content":" Question Several of the numerical methods described in this chapter are instances of an extremely general computational strategy known as iterative improvement. Iterative improvement says that, to compute something, we start with an initial guess for the answer, test if the guess is good enough, and otherwise improve the guess and continue the process using the improved guess as the new guess. Write a procedure iterative-improve that takes two procedures as arguments: a method for telling whether a guess is good enough and a method for improving a guess. Iterative-improve should return as its value a procedure that takes a guess as argument and keeps improving the guess until it is good enough. Rewrite the sqrt procedure of section 1.1.7 and the fixed-point procedure of section 1.3.3 in terms of iterative-improve. ","date":"2023-05-10","objectID":"/zh-cn/sicp-exercise-1-46/:1:0","series":null,"tags":["SICP"],"title":"SICP 练习 1.46","uri":"/zh-cn/sicp-exercise-1-46/#question"},{"categories":["Exercise"],"content":" Answer让我们总结一下题目要让我们做什么： 写一个函数，函数名为 iterative-improve，它包含了 2 个参数 第一个参数是函数，用于判断猜测是否足够好 第二个参数仍然是一个函数，用于改进猜测 用 iterative-improve 重写 fixed-point 和 sqrt 如果你一路做完了 SICP 第一章节的练习，那么你可以很轻松写出如下的代码: racket ;; test: test if a guess is good enough ;; improve: how to improve a guess (define (iterative-improve test improve) (lambda (guess) (if (test guess) guess ...))) 在函数里面用 lambda 返回另外一个函数很方便，但是这一道题要这么用有点“绕”，主要的困难来自于：我们要在 ... 的部分放什么？放 ((iterative-improve good-enough? improve) (improve guess)) 是可以的，但是我感觉这样写并不是很直观 这样的场景在写递归函数的时候其实经常出现，这种时候我们可以在主函数里面定义一个辅助函数，最后在主函数里面返回这个辅助函数即可。代码如下： racket (define (iterative-improve test improve) (define (helper guess) (if (test guess) guess (helper (improve guess)))) helper) 写完了 iterative-improve 之后，要重写 fixed-point 和 sqrt 函数是件很容易的事情。我们只需要定义好对应的 test 和 improve 是什么然后调用 iterative-improve racket (define (average x y) (/ (+ x y) 2)) (define (square x) (* x x)) (define (fixed-point f first-guess) ;; it's fine to refer a variable in the enclosing scope (define (close-enough? v) (let ([next (f v)]) (\u003c (abs (- v next)) 0.00001))) ((iterative-improve close-enough? f) first-guess)) (define (sqrt x) ;; it's fine to refer a variable in the enclosing scope (define (good-enough? v) (\u003c (abs (- (square v) x)) 0.001)) (define (improve guess) (average guess (/ x guess))) ((iterative-improve good-enough? improve) 1.0)) 🚧 完整 SICP 练习题解仍在施工中 ","date":"2023-05-10","objectID":"/zh-cn/sicp-exercise-1-46/:2:0","series":null,"tags":["SICP"],"title":"SICP 练习 1.46","uri":"/zh-cn/sicp-exercise-1-46/#answer"},{"categories":["Exercise"],"content":"SICP 练习 1.34 答案","date":"2023-05-09","objectID":"/zh-cn/sicp-exercise-1-34/","series":null,"tags":["SICP"],"title":"SICP 练习 1.34","uri":"/zh-cn/sicp-exercise-1-34/"},{"categories":["Exercise"],"content":" 题目 Suppose we define the procedure f. What happens if we (perversely) ask the interpreter to evaluate the combination (f f)? racket (define (square x) (* x x)) (define (f g) (g 2)) Then we have racket (f square) ;; 4 (f (lambda (z) (* z (+ z 1)))) ;; 6 = 2 * 3 ","date":"2023-05-09","objectID":"/zh-cn/sicp-exercise-1-34/:1:0","series":null,"tags":["SICP"],"title":"SICP 练习 1.34","uri":"/zh-cn/sicp-exercise-1-34/#题目"},{"categories":["Exercise"],"content":" 答案回忆之前书上讲的 applicative-order evaluation：我们需要先计算所有参数的值，然后将这些参数代入计算 第一步，先计算参数 f，过程如下 racket ;; replace g with f ;; (define (f g) ;; (g 2)) (f 2) 第二步：计算参数 2。注意这里的 2 被看成是参数而不是一个数字 racket ;; replace g with 2 ;; (define (f g) ;; (g 2)) (2 2) 最后就得到了 (2 2) 这个 S 表达式，它被看成是 function/procedure application。这也是求 S 表达式的值的方式 :) 但是，这里的 2 不是一个函数/过程，这也解释了为什么 Racket 输入了如下信息： text application: not a procedure; expected a procedure that can be applied to arguments given: 2 🚧 完整 SICP 练习题解仍在施工中 ","date":"2023-05-09","objectID":"/zh-cn/sicp-exercise-1-34/:2:0","series":null,"tags":["SICP"],"title":"SICP 练习 1.34","uri":"/zh-cn/sicp-exercise-1-34/#答案"},{"categories":["Course"],"content":"CS61A 的项目四 - 实现一个 Scheme 解释器的题解","date":"2023-04-21","objectID":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/","series":null,"tags":["Course"],"title":"CS61A 的项目四之 Scheme 解释器实现 (2021-Fall)","uri":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/"},{"categories":["Course"],"content":" 引言最近正在跟着《Crafting interpreter》这本书写解释器，原本书里面用 Java 实现了一个 Tree-walker 解释器 jlox，我正在用 Python 重写一遍，称为 pylox。看了这本书感觉对解释器的理解越来越深刻了，很推荐👍。此时的我突然想起来之前看完的 CS61A 的 Scheme 解释器还有几个小问题没有解决，导致它一直是未完成的状态，于是今天我打开了这个项目，打算从头到尾捋一遍，讲讲思路。 注：Scheme 解释器这个项目比较大，所以我只复制了题目描述中的重要部分，完整的描述还是要回去看项目主页。同时代码只显示核心的部分。 ","date":"2023-04-21","objectID":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:1:0","series":null,"tags":["Course"],"title":"CS61A 的项目四之 Scheme 解释器实现 (2021-Fall)","uri":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/#引言"},{"categories":["Course"],"content":" Part 1. The Evaluator","date":"2023-04-21","objectID":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:2:0","series":null,"tags":["Course"],"title":"CS61A 的项目四之 Scheme 解释器实现 (2021-Fall)","uri":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/#part-1-the-evaluator"},{"categories":["Course"],"content":" Problem 1 Implement the define and lookup methods of the Frame class…bindings is a dictionary representing the bindings in the frame…parent is the parent Frame instance…The environment for a Frame instance consists of that frame, its parent frame, and all its ancestor frames, including the Global Frame. define 函数很简单，就是一个字符串（symbol）到 Scheme 值（value）的映射，参数都给你写好了 lookup 函数的具体执行过程在本来的题目描述中已经列出来了，照着做就行，迭代和递归的解法都可以，我感觉迭代的解法会比较简单 python ... def define(self, symbol, value): \"\"\"Define Scheme SYMBOL to have VALUE.\"\"\" self.bindings[symbol] = value def lookup(self, symbol): \"\"\"Return the value bound to SYMBOL. Errors if SYMBOL is not found.\"\"\" # Case 1. we check if the symbol is in the current frame if symbol in self.bindings.keys(): return self.bindings[symbol] else: # Case 2. we check the parent of the current frame repreatly pos = self.parent while pos is not None: if symbol in pos.bindings.keys(): return pos.bindings[symbol] pos = pos.parent # Case 3. we can't find the symbol raise SchemeError(\"unknown identifier: {0}\".format(symbol)) ... ","date":"2023-04-21","objectID":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:2:1","series":null,"tags":["Course"],"title":"CS61A 的项目四之 Scheme 解释器实现 (2021-Fall)","uri":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/#problem-1"},{"categories":["Course"],"content":" Problem 2 To be able to call built-in procedures, such as +, you need to complete the BuiltinProcedure case within the scheme_apply function in scheme_eval_apply.py. Built-in procedures are applied by calling a corresponding Python function that implements the procedure. 跟着题目的要求做即可，没有什么难度。值得一提的是要和 nil 判断而不是和 None 判断，不然你可能在第三题一直得到 “incorrect number of arguments…\"，我发现我之前没有做出来就是这里没写好 python def scheme_apply(procedure, args, env): ... if isinstance(procedure, BuiltinProcedure): # Convert the Scheme list to a Python list of arguments args_list = [] pos = args while pos is not nil: if pos.first is not nil: args_list.append(pos.first) else: args_list.append(nil) pos = pos.rest # Add the current environment if procedure.expect_env == True if procedure.expect_env: args_list.append(env) # Call procedure.py_func on all arguments try: return procedure.py_func(*args_list) except TypeError as e: raise SchemeError(f\"incorrect number of arguments, {e}\") ... ","date":"2023-04-21","objectID":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:2:2","series":null,"tags":["Course"],"title":"CS61A 的项目四之 Scheme 解释器实现 (2021-Fall)","uri":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/#problem-2"},{"categories":["Course"],"content":" Problem 3 Implement the missing part of scheme_eval, which evaluates a call expression…You’ll have to recursively call scheme_eval in the first two steps…The map method of Pair returns a new Scheme list constructed by applying a one-argument function to every item in a Scheme list…Important: do not mutate the passed-in expr. That would change a program as it’s being evaluated, creating strange and incorrect effects. 这一道题也很直白，可能的一个难点是，rest.map 的参数是一个 “one-argument function”，也就是只接受一个参数，但是题目提供的 scheme_eval 有 2 个参数。所以需要对函数进行转化，当然这里可以写一个 lambda 表达式包装一下 scheme_eval。我选择用 functools 包提供的 partial 函数，它的用途就是绑定函数的部分参数并返回一个新的函数。第一次见到 partial 这种用法还是在函数式编程语言里面，不少函数式编程语言都是原生就支持这个功能。 python def scheme_eval(expr, env, _=None): # Optional third argument is ignored ... else: # Evaluate the operator(first argument) operator = scheme_eval(first, env) validate_procedure(operator) # Evaluate all of the operands(other arguments) from functools import partial operands = rest.map(partial(scheme_eval, env=env)) return scheme_apply(operator, operands, env) ","date":"2023-04-21","objectID":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:2:3","series":null,"tags":["Course"],"title":"CS61A 的项目四之 Scheme 解释器实现 (2021-Fall)","uri":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/#problem-3"},{"categories":["Course"],"content":" Problem 4 The type of the first operand tells us what is being defined…implement just the first part, which evaluates the second operand to obtain a value and binds the first operand, a symbol, to that value. Then, do_define_form returns the symbol that was bound. 这里只要求实现 define 的第一个功能——绑定变量，具体绑定的方式其实我们已经在 Problem 1 里面实现好了，就是 Frame 类的 define 方法，因此绑定变量只要调用 env.define 即可。 根据 define 绑定变量的写法: (define a some_val)，可以通过 .rest.first 拿到对应的 some_val 用 scheme_eval 进行估值 python def do_define_form(expressions, env): ... if scheme_symbolp(signature): # assigning a name to a value e.g. (define x (+ 1 2)) validate_form( expressions, 2, 2 ) # Checks that expressions is a list of length exactly 2 env.define(signature, scheme_eval(expressions.rest.first, env)) return signature ... ","date":"2023-04-21","objectID":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:2:4","series":null,"tags":["Course"],"title":"CS61A 的项目四之 Scheme 解释器实现 (2021-Fall)","uri":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/#problem-4"},{"categories":["Course"],"content":" Problem 5 Implement the do_quote_form function in scheme_forms.py so that it simply returns the unevaluated operand of the (quote ...) expression. validate_form(expressions, 1, 1) 确保输入长度为 1，即检查是否为 '... 形式，我们只需要直接返回即可 python def do_quote_form(expressions, env): validate_form(expressions, 1, 1) return expressions.first ","date":"2023-04-21","objectID":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:2:5","series":null,"tags":["Course"],"title":"CS61A 的项目四之 Scheme 解释器实现 (2021-Fall)","uri":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/#problem-5"},{"categories":["Course"],"content":" Part 2. Procedures","date":"2023-04-21","objectID":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:3:0","series":null,"tags":["Course"],"title":"CS61A 的项目四之 Scheme 解释器实现 (2021-Fall)","uri":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/#part-2-procedures"},{"categories":["Course"],"content":" Problem 6 Change the eval_all function in scheme_eval_apply.py (which is called from do_begin_form in scheme_forms.py) to complete the implementation of the begin special form (spec). A begin expression is evaluated by evaluating all sub-expressions in order. The value of the begin expression is the value of the final sub-expression. 其实这是一个递归的过程： 先检查 expressions 是否为 nil，是的话返回 None 表示没有定义 继续检查 expressions.rest 是否为 nil，是的话返回 expressions.first 的评估结果，否则继续递归调用 python def eval_all(expressions, env): if expressions is nil: return None res = scheme_eval(expressions.first, env) if expressions.rest is nil: return res else: return eval_all(expressions.rest, env) ","date":"2023-04-21","objectID":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:3:1","series":null,"tags":["Course"],"title":"CS61A 的项目四之 Scheme 解释器实现 (2021-Fall)","uri":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/#problem-6"},{"categories":["Course"],"content":" Problem 7 Implement the do_lambda_form function (spec), which creates and returns a LambdaProcedure instance 在 Problem 6 里面已经说了 LambdaProcedure 的结构，调用一下它的构造函数就行 python def do_lambda_form(expressions, env): validate_form(expressions, 2) formals = expressions.first validate_formals(formals) return LambdaProcedure(formals, expressions.rest, env) ","date":"2023-04-21","objectID":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:3:2","series":null,"tags":["Course"],"title":"CS61A 的项目四之 Scheme 解释器实现 (2021-Fall)","uri":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/#problem-7"},{"categories":["Course"],"content":" Problem 8 This method takes in two arguments: formals, which is a Scheme list of symbols, and vals, which is a Scheme list of values. It should return a new child frame, binding the formal parameters to the values. 题目的步骤已经够详细了，这里就不展开了 python def make_child_frame(self, formals, vals): if len(formals) != len(vals): raise SchemeError(\"Incorrect number of arguments to function call\") sub_frame = Frame(self) # iterate pos1, pos2 = formals, vals while pos1 is not nil: key, value = pos1.first, pos2.first sub_frame.define(key, value) pos1, pos2 = pos1.rest, pos2.rest return sub_frame ","date":"2023-04-21","objectID":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:3:3","series":null,"tags":["Course"],"title":"CS61A 的项目四之 Scheme 解释器实现 (2021-Fall)","uri":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/#problem-8"},{"categories":["Course"],"content":" Problem 9 You should first create a new Frame instance using the make_child_frame method of the appropriate parent frame, binding formal parameters to argument values. Then, evaluate each of the expressions of the body of the procedure using eval_all within this new frame. 这里刚好用了 Problem 8 写的 make_child_frame 函数 python def scheme_apply(procedure, args, env): ... elif isinstance(procedure, LambdaProcedure): child_frame = procedure.env.make_child_frame(procedure.formals, args) return eval_all(procedure.body, child_frame) ... ","date":"2023-04-21","objectID":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:3:4","series":null,"tags":["Course"],"title":"CS61A 的项目四之 Scheme 解释器实现 (2021-Fall)","uri":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/#problem-9"},{"categories":["Course"],"content":" Problem 10 Modify the do_define_form function in scheme_forms.py so that it correctly handles define (...) ...) expressions 和之前的相比，差别主要在 env.define 的第 2 个参数，用前面写好的 do_lambda_form 或者直接调用 LambdaProcedure 也可以 python def do_define_form(expressions, env): ... elif isinstance(signature, Pair) and scheme_symbolp(signature.first): # defining a named procedure e.g. (define (f x y) (+ x y)) # the signature is (f x y) formals = signature.rest # (x y) validate_formals(formals) # now we need to parse (+ x y) env.define(signature.first, LambdaProcedure(formals, expressions.rest, env)) return signature.first # f ... ","date":"2023-04-21","objectID":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:3:5","series":null,"tags":["Course"],"title":"CS61A 的项目四之 Scheme 解释器实现 (2021-Fall)","uri":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/#problem-10"},{"categories":["Course"],"content":" Problem 11 Implement do_mu_form in scheme_forms.py to evaluate the mu special form. A mu expression evaluates to a MuProcedure. Most of the MuProcedure class (defined in scheme_classes.py) has been provided for you. MuProcedure 的特别之处在于 dynamic scoping，参数的值取决于调用的时候环境里面有什么。scheme_apply 函数的参数 env 就表示了当前环境，我们只需要构造一个 child frame 并在里面评估 MuProcedure 即可 python def scheme_apply(procedure, args, env): ... elif isinstance(procedure, MuProcedure): child_frame = env.make_child_frame(procedure.formals, args) return eval_all(procedure.body, child_frame) ... def do_mu_form(expressions, env): validate_form(expressions, 2) formals = expressions.first validate_formals(formals) return MuProcedure(formals, expressions.rest) ","date":"2023-04-21","objectID":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:3:6","series":null,"tags":["Course"],"title":"CS61A 的项目四之 Scheme 解释器实现 (2021-Fall)","uri":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/#problem-11"},{"categories":["Course"],"content":" Part 3. Special Forms","date":"2023-04-21","objectID":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:4:0","series":null,"tags":["Course"],"title":"CS61A 的项目四之 Scheme 解释器实现 (2021-Fall)","uri":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/#part-3-special-forms"},{"categories":["Course"],"content":" Problem 12 Implement do_and_form and do_or_form so that and and or expressions are evaluated correctly. The logical forms and and or are short-circuiting do_and_form 和 do_or_form 都可以用递归写： do_and_form：base case 为 nil 此时返回为 True，从头到尾检查，一旦发现不为 True 的就立刻返回 do_or_form：base case 为 nil 此时返回 False，从头到尾检查，一旦发现为 True 的就立刻返回 python def do_and_form(expressions, env): # base case: (and) if expressions is nil: return True front = scheme_eval(expressions.first, env) if is_scheme_true(front): if expressions.rest is nil: return front else: return do_and_form(expressions.rest, env) else: return front def do_or_form(expressions, env): # base case: (or) if expressions is nil: return False front = scheme_eval(expressions.first, env) if is_scheme_false(front): if expressions.rest is nil: return front else: return do_or_form(expressions.rest, env) else: return front ","date":"2023-04-21","objectID":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:4:1","series":null,"tags":["Course"],"title":"CS61A 的项目四之 Scheme 解释器实现 (2021-Fall)","uri":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/#problem-12"},{"categories":["Course"],"content":" Problem 13 Fill in the missing parts of do_cond_form so that it correctly implements cond, returning the value of the first result sub-expression corresponding to a true predicate, or the result sub-expression corresponding to else. 按照题目的意思来就行 python def do_cond_form(expressions, env): ... if is_scheme_true(test): # no sub-expression if clause.rest is nil: return test return eval_all(clause.rest, env) ... ","date":"2023-04-21","objectID":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:4:2","series":null,"tags":["Course"],"title":"CS61A 的项目四之 Scheme 解释器实现 (2021-Fall)","uri":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/#problem-13"},{"categories":["Course"],"content":" Problem 14 Implement make_let_frame in scheme_forms.py, which returns a child frame of env that binds the symbol in each element of bindings to the value of its corresponding expression. The bindings Scheme list contains pairs that each contain a symbol and a corresponding expression. 遍历每一个 binding，收集参数名和值到 names 和 values 就行 python def make_let_frame(bindings, env): if not scheme_listp(bindings): raise SchemeError(\"bad bindings list in let form\") names = values = nil # bingding: (\u003cname\u003e \u003cexpression\u003e) # bingdings: ( (\u003cname1\u003e \u003cexpression1\u003e) (\u003cname2\u003e \u003cexpression2\u003e) ...) pos = bindings while pos is not nil: front = pos.first # i.e. the first binding validate_form(front, 2, 2) # verify the structure is (\u003cname\u003e \u003cexpression\u003e) names = Pair(front.first, names) values = Pair(eval_all(front.rest, env), values) pos = pos.rest validate_formals(names) return = env.make_child_frame(names, values) ","date":"2023-04-21","objectID":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:4:3","series":null,"tags":["Course"],"title":"CS61A 的项目四之 Scheme 解释器实现 (2021-Fall)","uri":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/#problem-14"},{"categories":["Course"],"content":" Problem 15 Implement the enumerate procedure, which takes in a list of values and returns a list of two-element lists, where the first element is the index of the value, and the second element is the value itself. 通过递归就可以实现，在下面我实现了一个 helper 递归函数，参数是输入 input 和索引 index： base case：输入 input 为空，则返回 '() 其他情况：递归调用，注意参数变化：input -\u003e (cdr input) 和 index -\u003e (+ index 1) scheme (define (enumerate s) (begin ;; a helper funtion (define (helper input index) (cond ((null? input) '()) ;; base case: return () if it is nil (else (cons (cons index (cons (car input) nil)) (helper (cdr input) (+ index 1)))))) ;; recursive call (helper s 0)) ) ","date":"2023-04-21","objectID":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:4:4","series":null,"tags":["Course"],"title":"CS61A 的项目四之 Scheme 解释器实现 (2021-Fall)","uri":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/#problem-15"},{"categories":["Course"],"content":" Problem 16 Implement the merge procedure, which takes in a comparator function inorder? and two lists that are sorted, and combines the two lists into a single sorted list. A comparator defines an ordering by comparing two values and returning a true value if and only if the two values are ordered. Here, sorted means sorted according to the comparator 经典算法：合并 2 个有序列表，每次取出 2 个列表的头个元素，对应下面的 (car list1) (car list2)，然后进行比较，根据不同情况进行递归调用 scheme (define (merge inorder? list1 list2) (cond ((null? list1) list2) ;; base case: list1 is empty ((null? list2) list1) ;; base case: list2 is empty ((inorder? (car list1) (car list2)) (cons (car list1) (merge inorder? (cdr list1) list2))) ;; consume list1 (else (cons (car list2) (merge inorder? list1 (cdr list2))))) ;; consume list2 ) ","date":"2023-04-21","objectID":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:4:5","series":null,"tags":["Course"],"title":"CS61A 的项目四之 Scheme 解释器实现 (2021-Fall)","uri":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/#problem-16"},{"categories":["Algorithm"],"content":"介绍了 MIT6.006 里面提到的 SRTBOT 框架，用于解决动态规划问题","date":"2023-04-09","objectID":"/zh-cn/solving-dynamic-programming-problems-using-srtbot/","series":null,"tags":["Algorithm"],"title":"用 SRTBOT 框架分析动态规划问题","uri":"/zh-cn/solving-dynamic-programming-problems-using-srtbot/"},{"categories":["Algorithm"],"content":"Changelog: 更新依赖图 @2023.04.13 ","date":"2023-04-09","objectID":"/zh-cn/solving-dynamic-programming-problems-using-srtbot/:0:0","series":null,"tags":["Algorithm"],"title":"用 SRTBOT 框架分析动态规划问题","uri":"/zh-cn/solving-dynamic-programming-problems-using-srtbot/#"},{"categories":["Algorithm"],"content":" 引言在做算法题的时候，让我头疼的经常是动态规划问题，它属于那种自己琢磨半天想不出来，但是看了答案之后会恍然大悟，下次再做的话很有可能又忘记了的一类问题。我也曾经看了很多人的题解，试图消化、吸收、应用他们的思路，但我一直找不到一个归纳得特别好的框架，似乎每个人都有自己解决动态规划的思路，将他们的思路应用在没有见过的动态规划问题的时候我总是遇到困难，而他们的方法轮似乎也无法让我处理所有的动态规划问题。这种寻寻觅觅对动态规划似懂非懂的状态，终于在我看完 MIT6.006 的课程之后发生了改变，课上老师提出了解决动态规划问题的 6 个步骤——被称为 SRTBOT 框架，我发现它是如此地好用，因此我决定写下这篇博客来与大家分享🙌 👉 总的来说，这篇博客更适合已经对动态规划有了初步了解但是还没有找到系统方法论人的阅读 ","date":"2023-04-09","objectID":"/zh-cn/solving-dynamic-programming-problems-using-srtbot/:1:0","series":null,"tags":["Algorithm"],"title":"用 SRTBOT 框架分析动态规划问题","uri":"/zh-cn/solving-dynamic-programming-problems-using-srtbot/#引言"},{"categories":["Algorithm"],"content":" 什么是动态规划问题动态规划问题的两大特征：重叠子问题和最优子结构1 重叠子问题：解决一个动态规划问题往往是将它分解为若干个重叠的子问题 最优子结构：即大问题的解可以通过组合小问题的最优解计算出来 前面的定义要特别注意的是「重叠」以及「子问题」，强调重叠是因为动态规划的厉害之处就在于它会记住解决过的子问题的答案，那么重叠的子问题越多，动态规划的优势更加明显 🤔️ 如果子问题并不重叠，那么就应该用分治法解决 上面是从定义的角度来谈动态规划问题的，从编程题目的角度来看，下面两大类问题一般都是要用动态规划算法： 最优化问题：求最值 + 重叠子问题 组合问题：求解所有可能的解法的数量 📒 或者，根据我的个人刷题经验来说：动态规划问题一般是可以暴力解决的递归问题，但是存在大量重叠子问题因此可以对其进行优化 ","date":"2023-04-09","objectID":"/zh-cn/solving-dynamic-programming-problems-using-srtbot/:2:0","series":null,"tags":["Algorithm"],"title":"用 SRTBOT 框架分析动态规划问题","uri":"/zh-cn/solving-dynamic-programming-problems-using-srtbot/#什么是动态规划问题"},{"categories":["Algorithm"],"content":" SRTBOT 框架SRTBOT 是 6 个步骤的首字母缩写，分别是2： Subproblems definition Relate subproblem solutions recursively Topological order to argue relation is acyclic and subproblems form a DAG Base cases Original problem Time analysis 下面我来分别讲讲上面每一个步骤需要做些什么✈️ ","date":"2023-04-09","objectID":"/zh-cn/solving-dynamic-programming-problems-using-srtbot/:3:0","series":null,"tags":["Algorithm"],"title":"用 SRTBOT 框架分析动态规划问题","uri":"/zh-cn/solving-dynamic-programming-problems-using-srtbot/#srtbot-框架"},{"categories":["Algorithm"],"content":" 定义子问题（Subproblems definition）包含下面几个步骤 定义子问题并用文字描述其含义，这里定义的子问题会包含参数。具体定义子问题的技巧会在后面提到 子问题的参数一般包含输入的子集，不同的动态规划问题可能有不同的输入格式：二叉树、单序列、数字等 在设计子问题的时候可以参考下面几种： 如果输入是单个序列 A 前缀形式（Prefix form）：定义 dp[i] 表示输入为 A[:i+1] 的子问题的解，注意这里的区间表示是基于 Python 的，左闭右开 后缀形式（Suffix form）：定义 dp[i] 表示输入为 A[i:] 的子问题的解 子串形式（Contiguous substrings of a sequence）：定义 dp[i][j] 表示输入为 A[i:j+1] 的子问题的解 如果输入是两个序列 A 和 B 为之前 3 种可能的笛卡尔乘积，一共有 $3\\times 3=9$ 种，视具体情况而定 比如最长公共子序列的问题，可以用 dp[i][j] 表示输入为 A[:i+1] 和 B[:i+1] 的最长公共子序列 如果输入是一个数字 k 定义 dp[k] 为输入为 k 的子问题的解 如果输入是一棵二叉树 定义 dp[r] 为输入为以 r 为根节点的子树的这个子问题的解。在树形 DP 中要注意「子问题」和「子树」这个对应的关系 📒 进阶：掌握了上面的一般思路之后，其实已经能够解决很多动态规划问题，但你有时候会发现你定义的子问题不够精确，导致难以无法关联子问题，当你在关联子问题有困难的时候总是可以尝试给你定义的子问题加上约束，或者是对子问题进行扩展。在 MIT 6.006 中称为 Subproblem Constraints and Expansion 对子问题进行扩展会更为常见一些，一般此时就是将定义的 dp[i] 变成 dp[i][j] 这样的形式，同时修改你的子问题定义。举例来说，在 198. 打家劫舍 中可以考虑额外引入一个状态记住是否偷了房屋 i 也稍微提一下对子问题的定义加上限制是什么意思，比如我们定义 dp[i] 是输入为 A[:i+1] 的解，假设每个 A[i] 存在选中与不选中两个状态，那么可以考虑将 dp[i] 定义为 输入为 A[:i+1] 而且 A[i] 一定是选中状态的时候的解（这么说可能有点抽象，待我之后找到可以这样处理的问题后贴个链接在这） 📒 你会发现，定义子问题的时候我们根本不会去思考要如何计算出来，千万不要在定义子问题的时候就开始想要怎么计算出这个值，当你使用 SRTBOT 框架分析到最后，你就自然而然知道怎么计算了~ ","date":"2023-04-09","objectID":"/zh-cn/solving-dynamic-programming-problems-using-srtbot/:3:1","series":null,"tags":["Algorithm"],"title":"用 SRTBOT 框架分析动态规划问题","uri":"/zh-cn/solving-dynamic-programming-problems-using-srtbot/#定义子问题subproblems-definition"},{"categories":["Algorithm"],"content":" 递归式关联子问题（Relate subproblem solutions recursively）试着提出一个问题——如果你知道这个问题的答案，你就能够将这个大问题分解为更小的子问题。可能用数学公式表述会更明显一点： $$ dp[i] = f(dp[j_1],dp[j_2], …, dp[j_k])\\ where\\ j_k \u003ci $$ 其中 $f$ 是一个抽象的操作，即「大问题」和「小问题」的关联方式 上面提出的问题的答案一般就是“局部暴力枚举”，这也是我们关联不同子问题的主要手段。方法是：看问题描述，从中归纳出允许的“决策”，“决策”会导致我们从一个子问题转移到另外一个子问题。思考的时候注意力放在 nums[i]、更小的子问题 dp[j_k] 和可行的决策这三者上 👻 如果一开始做动态规划想不出来也没关系，这东西熟练了之后就比较容易想到不同子问题如何通过不同的决策关联起来 🤔️ 我发现，在想办法递归关联子问题的时候，画出依赖图总是能给我很大帮助（结点为子问题，边为“决策”），依赖图不仅清晰展示了子问题之间的关联方式，还可以验证有重叠子问题出现 python dp[i] (apply f to aggregate results) / | \\ (?)/ |(?) \\(?) / | \\ dp[j_1] dp[j_2] ... / \\ / \\ / \\ ... ... ... ... ... 举例来说，在 70. 爬楼梯 问题中，每次只能爬一个台阶或者两个台阶（$K=2$），那么爬到第 i 个台阶一定是从第 i - 1 个台阶和第 i - 2 个台阶过来的，又因为求解的是所有可能的走法，因此 dp[i] = dp[i - 1] + dp[i - 2]，画出依赖图如下 python dp[i] (sum) / \\ (climb one step)/ \\(climb two steps) / \\ dp[i - 1] dp[i - 2] / \\ / \\ ... ...... ... 🤔️ 可以通过这个例子理解“局部暴力枚举”中的“局部”的含义：我们只考虑做一次决策，比如上面爬楼梯，每次爬一个台阶最后连续爬 n 个台阶 关联 dp[i] 和 dp[i - n] 这种方式就不是局部 ","date":"2023-04-09","objectID":"/zh-cn/solving-dynamic-programming-problems-using-srtbot/:3:2","series":null,"tags":["Algorithm"],"title":"用 SRTBOT 框架分析动态规划问题","uri":"/zh-cn/solving-dynamic-programming-problems-using-srtbot/#relate-subproblems"},{"categories":["Algorithm"],"content":" 根据拓扑排序确定解决子问题的顺序（Topological order to argue relation is acyclic and subproblems form a DAG）你可能在别的地方看到过动态规划问题的另外一个名字——“表格法”。因为当我们采用“自底向上”的解法解决动态规划问题的时候可以看成是在填表格。但在我看来，将动态规划看成一张有向无环图会更有助于对动态规划的理解——将子问题看成是图上的顶点，用有向边连接「小的子问题」-\u003e 「大的子问题」，这个图会构成一个有向无环图（DAG），动态规划算法其实就是 DAG 的拓扑排序过程。即「DAG 拓扑排序」=「自底向上方法」=「表格法」。上面的依赖图“自底向上”就是在做拓扑排序 🤔️ 为什么是有向无环图？首先，有向边表示了子问题之间的依赖关系也表示了我们求解子问题的顺序：要解决一个子问题，需要先求解出更小的子问题；其次，它必须是无环的，因为动态规划会记住求解过的子问题，我们不可能多次求解同一个子问题，因此它必须是无环的。 意识到动态规划的子问题求解顺序是 DAG 的拓扑排序有什么用呢？这在很大程度上帮我理解了树形 DP 问题：动态规划要先求解子问题 – 在树形 DP 中，显然“子树”和“子问题”的概念是对应的，因此要先解决子问题其实意味着计算 dp[r] 的时候应该先计算 dp[r.left] 和 dp[r.right]，而这恰恰遵循了二叉树的后序遍历顺序，因此树形 DP 问题往往是通过后序遍历实现的。如果把树看成图的话（注意边由孩子结点指向父节点），那么拓扑排序也是和后序遍历的顺序对应的 🤔️ 实际写代码的时候，你可能对如何用正确的顺序更新子问题有疑问，只要记住永远都是先解决小问题，然后才到大问题，再看一眼前面定义的关系式，你就知道更新顺序是什么了 ","date":"2023-04-09","objectID":"/zh-cn/solving-dynamic-programming-problems-using-srtbot/:3:3","series":null,"tags":["Algorithm"],"title":"用 SRTBOT 框架分析动态规划问题","uri":"/zh-cn/solving-dynamic-programming-problems-using-srtbot/#根据拓扑排序确定解决子问题的顺序topological-order-to-argue-relation-is-acyclic-and-subproblems-form-a-dag"},{"categories":["Algorithm"],"content":" 边界情况（Base cases）类似递归算法中的 base case，表示独立的最小子问题的解，是关系式推导的起点，这种信息一般可以通过看题目看出来 ","date":"2023-04-09","objectID":"/zh-cn/solving-dynamic-programming-problems-using-srtbot/:3:4","series":null,"tags":["Algorithm"],"title":"用 SRTBOT 框架分析动态规划问题","uri":"/zh-cn/solving-dynamic-programming-problems-using-srtbot/#边界情况base-cases"},{"categories":["Algorithm"],"content":" 原始问题（Original problem）通常来说，原问题一般都对应 dp[n] 或者 dp[0]，但是不要死记硬背，还是要结合题意、你定义的子问题形式。但不必担心，因为这一步通常不是求解动态规划问题的难点 ","date":"2023-04-09","objectID":"/zh-cn/solving-dynamic-programming-problems-using-srtbot/:3:5","series":null,"tags":["Algorithm"],"title":"用 SRTBOT 框架分析动态规划问题","uri":"/zh-cn/solving-dynamic-programming-problems-using-srtbot/#原始问题original-problem"},{"categories":["Algorithm"],"content":" 时间复杂度分析（Time analysis）动态规划算法就是求解所有需要求解的子问题，然后计算原始问题，假设一共有 $n$ 个子问题要求解，那么动态规划的时间复杂度可以用下面这个公式解决： $$ n * O(each\\ subproblem) + O(original\\ problem) $$ ","date":"2023-04-09","objectID":"/zh-cn/solving-dynamic-programming-problems-using-srtbot/:3:6","series":null,"tags":["Algorithm"],"title":"用 SRTBOT 框架分析动态规划问题","uri":"/zh-cn/solving-dynamic-programming-problems-using-srtbot/#时间复杂度分析time-analysis"},{"categories":["Algorithm"],"content":" 应用光是谈理论总是一知半解，只有真正开始把 SRTBOT 框架应用于动态规划问题才能够体会它的强大之处，下面是我整理的部分动态规划问题的题解，在题解里面我会谈到如何用 SRTBOT 分析动态规划问题。后序会不断把做的动态规划的题目搬运到这里来，或者也可以直接看 Leetcode 账号查看题解👻 📒 注：我的解法并不一定是最优的解法，比如有时候可以用「状态压缩」的技巧减少空间复杂度等，我可能并不会这么做，我只是将 SRTBOT 框架应用于这些动态规划问题 Problem Solution Note 70. 爬楼梯 题解 数 746. 使用最小花费爬楼梯 题解 单序列 198. 打家劫舍 题解 单序列 + 扩展子问题 322. 零钱兑换 题解 数 + 非$O(1)$ 子问题 300. 最长递增子序列 题解 单序列 + 限制子问题 5. 最长回文子串 题解 子串 91. 解码方法 题解 单序列 139. 单词拆分 题解 单序列 279. 完全平方数 题解 单数字 673. 最长递增子序列的个数 题解 单序列 62. 不同路径 题解 网格 1143. 最长公共子序列 题解 双序列 + 扩展子问题 309. 最佳买卖股票时机含冷冻期 题解 单序列 + 扩展子问题 1911. 最大子序列交替和 题解 单序列 + 扩展子问题 1220. 统计元音字母序列的数目 题解 数 + 扩展子问题 ","date":"2023-04-09","objectID":"/zh-cn/solving-dynamic-programming-problems-using-srtbot/:4:0","series":null,"tags":["Algorithm"],"title":"用 SRTBOT 框架分析动态规划问题","uri":"/zh-cn/solving-dynamic-programming-problems-using-srtbot/#应用"},{"categories":["Algorithm"],"content":" 参考 Dynamic programming - Wiki ↩︎ Lecture 15 ~ 18 of MIT 6.006 ↩︎ ","date":"2023-04-09","objectID":"/zh-cn/solving-dynamic-programming-problems-using-srtbot/:5:0","series":null,"tags":["Algorithm"],"title":"用 SRTBOT 框架分析动态规划问题","uri":"/zh-cn/solving-dynamic-programming-problems-using-srtbot/#参考"},{"categories":["ML-DL"],"content":"推导了深度学习中的反向传播算法的公式，并讨论了如何理解","date":"2023-04-04","objectID":"/zh-cn/backpropagation-tutorial/","series":null,"tags":["Deep-Learning"],"title":"反向传播公式推导和理解","uri":"/zh-cn/backpropagation-tutorial/"},{"categories":["ML-DL"],"content":" 更新：矩阵形式的反向传播可以看 这里 ","date":"2023-04-04","objectID":"/zh-cn/backpropagation-tutorial/:0:0","series":null,"tags":["Deep-Learning"],"title":"反向传播公式推导和理解","uri":"/zh-cn/backpropagation-tutorial/#"},{"categories":["ML-DL"],"content":" 引言在深度学习中，模型的优化是通过采用梯度下降法不断更新权重和偏置项，让损失越来越小。其中的核心就是反向传播算法。回忆梯度下降的公式，用 $\\theta$ 表示模型所有可学习的参数，$J$ 表示损失函数，$\\alpha$ 表示学习率，那么有 $$ \\theta \\leftarrow \\theta - \\alpha * \\frac{\\partial J}{\\partial \\theta} $$ 反向传播要求解的就是上面式子中 $\\frac{\\partial J}{\\partial \\theta}$ 这一项。只有正确高效计算出梯度，模型才可以沿着梯度的负方向更新不断优化。 📒 本文会交叉使用「参数」和「权重和偏置项」这两个术语，他们是同一个意思，都表示了模型可以学习的参数 📒 本文假定你对数学上的求导链式法则等有所了解🫡 ","date":"2023-04-04","objectID":"/zh-cn/backpropagation-tutorial/:1:0","series":null,"tags":["Deep-Learning"],"title":"反向传播公式推导和理解","uri":"/zh-cn/backpropagation-tutorial/#引言"},{"categories":["ML-DL"],"content":" 模型假设本文要讲解反向传播，那么当然要定义一个模型用于之后的推导，考虑一个简单然而很经典的三层全连接层，如下所示: 📒 为了记号方便，大写字母表示矩阵，小写字母表示向量（无下标）或者标量（有下标） 并规定如下记号： 不同层的神经元个数：输入层有 $n$ 个神经元，隐藏层有 $h$ 个神经元，输出层有 $k$ 个神经元 $x^1_j$ 表示输入的第 $j$ 个特征。记输入层第 $1$ 层 $y_j$ 表示对应输出层的第 $j$ 个输出的真实值 $w^l_{jk}$ 表示第 $l-1$ 层的第 $k$ 个神经元和第 $l$ 层的第 $j$ 个神经元这个链接对应的权重，注意这里的下角标是从后面指向前面。根据前面的隐藏层大小，可以算出权重矩阵的大小为： $W^2\\in \\mathcal{R}^{h\\times n}$ $W^3\\in \\mathcal{R}^{k\\times h}$ $b_j^l$ 表示第 $l$ 层的第 $j$ 个神经元的偏置项 $z_j^l$ 表示第 $l$ 层的第 $j$ 个神经元计算的加权和 $a_j^l$ 表示第 $l$ 层的第 $j$ 个神经元的激活函数输出值 根据上面的记号，模型的前向传播的公式如下： $$ z_j^2 = \\sum_kw_{jk}^2x^1_k+b_j^2 $$ $$ a_j^2=\\sigma(z_j^2) $$ $$ z_j^3 = \\sum_kw_{jk}^3a_k^2+b_j^3 $$ $$ a_j^3=\\sigma(z_j^3) $$ 更一般的，可以对上面的公式进行概括。$z_j^l$ 和 $a_j^l$ 的计算方式如下： $$ z_j^l=\\sum_kw_{jk}^la^{l-1}_k+b_j^l $$ $$ a_j^l=\\sigma(z_j^l) $$ 上面这两个公式很重要，特别要弄清楚式子的下标和上标的关系，他们在之后的反向传播的公式推导中会很有用 这里考虑用均值平方误差即 MSE 作为损失函数 $J$，$sigmoid$ 函数作为激活函数，当然这两个换成别的函数的话推导过程也是类似的 $$ J = \\frac{1}{2k}\\sum_{j=1}^k(a_j^L-y_j)^2 $$ ","date":"2023-04-04","objectID":"/zh-cn/backpropagation-tutorial/:2:0","series":null,"tags":["Deep-Learning"],"title":"反向传播公式推导和理解","uri":"/zh-cn/backpropagation-tutorial/#模型假设"},{"categories":["ML-DL"],"content":" 反向传播的直觉理解我发现，在深入了解细节之前，从高层次的角度理解一个概念总是能带来帮助。我们知道，深度学习模型的训练过程就是要让模型的预测 $a^L_j$ 越接近真实值 $y_j$ 越好。那么 $a^L_j$ 跟什么有关呢？根据样本的真实值 $y_j$，可以计算 $a^L_j$ 和 $y_j$ 的误差，计算出误差之后，我们肯定知道要增大还是减小 $a^L_j$ 才能让模型的预测更好。而我们能够改变的量只有：第 $L - 1$ 层和第 $L$ 层之间的每个权重 $w^L_{jk}$，偏置项 $b_j^L$，或者是第 $L-1$ 层的激活函数的输出值 $a^{L-1}_k$，但是 $a_k^{L-1}$ 并无法直接改变，它是由更前面的权重和偏置项的值决定的。当我们从后往前根据预测的误差，考虑要如何修改每一层的权重和偏置项的时候，就是在做反向传播1。 上述过程解释了 $a_j^L$ 想要如何调整模型的权重和偏置项。当然，我们还需要考虑输出层中除了$a_j^L$ 以外的神经元的“意见”。他们各自对如何改变模型的权重和偏置项的“意见”并不一定相同。最后，我们需要考虑输出层中所有神经元的意见来更新模型的权重和偏差 ","date":"2023-04-04","objectID":"/zh-cn/backpropagation-tutorial/:3:0","series":null,"tags":["Deep-Learning"],"title":"反向传播公式推导和理解","uri":"/zh-cn/backpropagation-tutorial/#反向传播的直觉理解"},{"categories":["ML-DL"],"content":" 反向传播的四个公式反向传播的核心就是下面四个公式 ","date":"2023-04-04","objectID":"/zh-cn/backpropagation-tutorial/:4:0","series":null,"tags":["Deep-Learning"],"title":"反向传播公式推导和理解","uri":"/zh-cn/backpropagation-tutorial/#反向传播的四个公式"},{"categories":["ML-DL"],"content":" 公式一$$ \\delta_j^L=\\frac{\\partial J}{\\partial a_j^L}\\sigma’(z_j^L) $$ 其中 $L$ 为模型的层数，在我们前面定义的模型中 $L=3$，$\\delta_j^L$ 表示第 $L$ 层即输出层的第 $j$ 个神经元的梯度信息 顺带一提，用矩阵和向量的角度可以把上面的公式改写为$\\delta^L=\\nabla J\\odot \\sigma’(z^L)$。其中 $\\odot$ 表示按元素（element-wise）乘 📒 公式一计算的是输出层的每个神经元的梯度 推导过程⬇️ $$ \\begin{aligned} \\delta_j^L\u0026=\\frac{\\partial J}{\\partial z_j^L} \\\\\\ \u0026=\\sum_k\\frac{\\partial J}{\\partial a_k^L}\\frac{\\partial a_k^L}{\\partial z_j^L} \\\\\\ \u0026=\\frac{\\partial J}{\\partial a_j^L}\\frac{\\partial a_j^L}{\\partial z_j^L}\\ (only\\ \\frac{\\partial a_j^L}{\\partial z_j^L}\\ne 0) \\\\\\ \u0026=\\frac{\\partial J}{\\partial a_j^L}\\frac{\\partial \\sigma(z_j^L)}{\\partial z_j^L}\\ \\\\\\ \u0026=\\frac{\\partial J}{\\partial a_j^L}\\sigma’(z_j^L) \\end{aligned} $$ ","date":"2023-04-04","objectID":"/zh-cn/backpropagation-tutorial/:4:1","series":null,"tags":["Deep-Learning"],"title":"反向传播公式推导和理解","uri":"/zh-cn/backpropagation-tutorial/#公式一"},{"categories":["ML-DL"],"content":" 公式二$$ \\delta^l=((w^{l+1})^T\\delta^{l+1})\\odot \\sigma’(z^l) $$ 📒 公式二计算的是任意层 $l$ 的梯度向量，注意这个公式如何将第 $l$ 层的梯度向量和第 $l+1$ 的梯度向量联系起来。它让我们可以用后面的层的梯度向量计算前面的层的梯度向量 推导过程⬇️ $$ \\begin{aligned} \\delta_j^l\u0026=\\frac{\\partial J}{\\partial z_j^l} \\\\\\ \u0026=\\sum_k\\frac{\\partial J}{\\partial z_k^{l+1}}\\frac{\\partial z_k^{l+1}}{\\partial z_j^l} \\\\\\ \u0026=\\sum_k\\delta_k^{l+1}\\frac{\\partial }{\\partial z_j^l}z_k^{l+1} \\end{aligned} $$ 注意其中 $\\frac{\\partial }{\\partial z_j^l}z_k^{l+1} = \\frac{\\partial }{\\partial z_j^l}\\ \\sum_pw^{l+1}_{kp}\\sigma(z_p^l)+b^{l+1}_k$ 只有当 $p=j$ 的时候才可导，因此上面公式的解是 $w^{l+1}_{kj}\\sigma’(z_j^l)$ 即，我们证明了$\\delta_j^l=\\sum_k\\delta_k^{l+1}\\ w^{l+1}_{kj}\\sigma’(z_j^l)$ $\\sum_k\\delta_k^{l+1}w^{l+1}_{kj}$ 其实就是计算 2 个向量的内积，因此可以将其改写为向量形式 - $\\delta^l=((w^{l+1})^T\\delta^{l+1})\\odot \\sigma’(z^l)$ ","date":"2023-04-04","objectID":"/zh-cn/backpropagation-tutorial/:4:2","series":null,"tags":["Deep-Learning"],"title":"反向传播公式推导和理解","uri":"/zh-cn/backpropagation-tutorial/#公式二"},{"categories":["ML-DL"],"content":" 公式三$$ \\frac{\\partial J}{\\partial b^l_j}=\\delta_j^l $$ 📒 公式三可以用来计算模型中任意一个偏置项（Bias）的梯度 推导过程⬇️ $$ \\begin{aligned} \\frac{\\partial J}{\\partial b^l_j}\u0026= \\frac{\\partial J}{\\partial z^l_j}\\frac{\\partial z^l_j}{\\partial b^l_j} \\\\\\ \u0026= \\delta_j^l \\frac{\\partial}{\\partial b^l_j}\\sum_kw^l_{jk}a^{l-1}_j+b^l_j\\\\\\ \u0026= \\delta_j^l \\end{aligned} $$ 注意上面的第一个等号和公式一的推导类似，我直接跳过了去掉 $\\sum_k$ 的过程 ","date":"2023-04-04","objectID":"/zh-cn/backpropagation-tutorial/:4:3","series":null,"tags":["Deep-Learning"],"title":"反向传播公式推导和理解","uri":"/zh-cn/backpropagation-tutorial/#公式三"},{"categories":["ML-DL"],"content":" 公式四$$ \\frac{\\partial J}{\\partial w_{jk}^l}=a_k^{l-1}\\delta_j^l $$ 📒 公式四可以用来计算模型中任意一个权重（Weight）的梯度 推导过程⬇️ $$ \\begin{aligned} \\frac{\\partial J}{\\partial w_{jk}^l}\u0026=\\frac{\\partial J}{\\partial z^l_j}\\frac{\\partial z^l_j}{\\partial w_{jk}^l} \\\\\\ \u0026=\\frac{\\partial J}{\\partial z^l_j}\\frac{\\partial }{\\partial w_{jk}^l}\\sum_pw_{jp}^la_p^{l-1}+b_j^l \\\\\\ \u0026=\\delta_j^l\\frac{\\partial }{\\partial w_{jk}^l}\\sum_kw_{jk}^la_k^{l-1}+b_j^l \\\\\\ \u0026=\\delta_j^la_k^{l-1} \\end{aligned} $$ ","date":"2023-04-04","objectID":"/zh-cn/backpropagation-tutorial/:4:4","series":null,"tags":["Deep-Learning"],"title":"反向传播公式推导和理解","uri":"/zh-cn/backpropagation-tutorial/#公式四"},{"categories":["ML-DL"],"content":" 反向传播算法基于前面讨论的公式，可以知道反向传播算法的工作流程 前向传播，计算每个 $z_j^l$，$a_j^l$ 根据公式一计算输出层的梯度向量 $\\delta^L$ 从后往前 根据公式二计算每一层的梯度向量 $\\delta^l$，注意我们总是可以根据 $\\delta^{l+1}$ 计算出 $\\delta^l$ 根据公式三可以计算出每个偏置项 $b^l_j$ 的梯度，它等于 $\\delta^l_j$ 根据公式四可以计算出每个权重 $w^l_{jk}$ 的梯度，它等于 $\\delta_j^la_k^{l-1}$ 上面这个过程也回答了——为什么反向传播是一个高效的算法这个问题 👍 根据公式二，计算第 $l$ 层的梯度向量 $\\delta^l$ 的时候 $\\delta^{l+1}$ 已经算好了，不用从头从输出层开始推导 👍 根据公式三和公式四，直接算出了损失函数对当前层权重和偏置项的梯度，而不是其他什么中间的梯度结果 ","date":"2023-04-04","objectID":"/zh-cn/backpropagation-tutorial/:4:5","series":null,"tags":["Deep-Learning"],"title":"反向传播公式推导和理解","uri":"/zh-cn/backpropagation-tutorial/#反向传播算法"},{"categories":["ML-DL"],"content":" 总结上面就是反向传播算法的整个流程，公式和记号还是颇多的～但还是比较好理解的，在复习反向传播算法的时候发现了一些可能帮助读者理解反向传播的点： 反向传播是针对单个样本的算法，所以推导的时候考虑一个样本作为模型的输入就行了 推导公式的时候从某个神经元的角度思考，然后归纳为向量形式。而不是一上来就从向量形式入手，当然实力好的当我没说 收工，感谢阅读👋 ","date":"2023-04-04","objectID":"/zh-cn/backpropagation-tutorial/:5:0","series":null,"tags":["Deep-Learning"],"title":"反向传播公式推导和理解","uri":"/zh-cn/backpropagation-tutorial/#总结"},{"categories":["ML-DL"],"content":" 参考 What is backpropagation really doing? - 3Blue1Brown ↩︎ ","date":"2023-04-04","objectID":"/zh-cn/backpropagation-tutorial/:6:0","series":null,"tags":["Deep-Learning"],"title":"反向传播公式推导和理解","uri":"/zh-cn/backpropagation-tutorial/#参考"},{"categories":["ML-DL"],"content":"机器学习中的线性回归模型指南，包括梯度下降算法推导等","date":"2023-03-15","objectID":"/zh-cn/linear-regression-model-guide-theory/","series":null,"tags":["Machine-Learning"],"title":"线性回归模型指南 - 理论部分","uri":"/zh-cn/linear-regression-model-guide-theory/"},{"categories":["ML-DL"],"content":" 引言最近，重新刷起了吴恩达的机器学习课程，系统性复习了之前学过的知识，发现又有不少收获，打算仔细整理一番👍 要谈论什么是线性回归首先要对什么是机器学习有一个基本的认识，什么是机器学习？抽象来说机器学习就是学习一个函数 $$ f(input) = output $$ 其中 $f$ 指的就是具体的机器学习模型。机器学习就是自动拟合输入 - 输出之间的关系的一套方法论。有时候我们会发现一些问题很难定义出一个具体的算法来解决，这时就是机器学习发光发热的地方了，我们可以让它从数据中自己学习、总结一些模式，做出相关的预测。这也是它和传统的算法（二分、递归等）区别的地方。不得不承认，机器学习从定义上来说就很迷人，它似乎为所有难以解决的问题提供了一套可行的解决框架。恰恰现实生活中的一些问题就是很难用传统算法解决的 📒 为此，我总觉得每个程序员都应该懂点机器学习/深度学习，它也是我们解决问题的一大工具💪 线性回归就是经典的机器学习入门模型之一，可以说是机器学习界的 “Hello world”，经典的比如波士顿房价预测项目（虽然说现在已经是烂大街的项目了） 前面的公式中，$input$ 为机器学习中所谓的特征（Feature），常用记号 $x$ 表示。而 $output$ 可以根据是预测值还是预测类别可以大致划分为回归问题（Regression problem）和分类问题（Classification problem）两大类 📒 如何理解特征？所谓特征就是，跟要预测的东西高度相关的东西。还是用预测房价作为例子，房价显然跟占地面积、绿化条件等相关，这里的占地面积等就是特征。机器学习中可以对特征分析，看哪些跟输出的关联程度高，或者运用我们的领域知识（Domain knowledge），自己选择好的特征。但总的来说，机器学习还是要求我们花费大量精力在提取好的特征上，这也是机器学习被人诟病的地方，而这个缺点在深度学习中被大大缓解，当然那是后话了 📒 机器学习无法魔法般地理解你提供的各种格式的 $input$，比如图片、文本、视频等。在机器学习中，$input$ 常常被处理为数字，才能用各种机器学习方法学习。有些特征本身就是数字，比如预测房价，房子的占地面积这个特征本身就是一个数字。当输入不是数字的时候，就需要别的手段将输入转化为数字，比如用词嵌入向量模型表示文本等，这里不展开细讲。我们暂时假设已经将输入处理为了数字的形式 今天要提到的线性回归模型就属于监督学习分类下的回归模型，它足够简单，但是又可以阐述很多机器学习的思想，用来入门是再适合不过了。话不多说，让我们开始吧 :) 📒 本文假定你对基本的微积分和线性代数有所了解，比如你需要知道行向量乘列向量如何进行以及对应的记号表示，矩阵乘法的定义，函数如何求导等 ","date":"2023-03-15","objectID":"/zh-cn/linear-regression-model-guide-theory/:1:0","series":null,"tags":["Machine-Learning"],"title":"线性回归模型指南 - 理论部分","uri":"/zh-cn/linear-regression-model-guide-theory/#引言"},{"categories":["ML-DL"],"content":" 线性回归模型线性回归的英文是 Linear regression。顾名思义，由两部分组成： Linear 的含义就是它是线性的。以二维平面为例，$y=kx+b$ 这种就是线性，画出来是一条直线，而 $y=x^2$ 这种就不是，因为它画出来为曲线 Regression 是因为它符合机器学习中对回归问题的定义——预测一个不限制范围的值 ","date":"2023-03-15","objectID":"/zh-cn/linear-regression-model-guide-theory/:2:0","series":null,"tags":["Machine-Learning"],"title":"线性回归模型指南 - 理论部分","uri":"/zh-cn/linear-regression-model-guide-theory/#线性回归模型"},{"categories":["ML-DL"],"content":" 分类 📒 为了形式的简洁下面的记号 $f(x)$ 其实省略了下标 $w,b$。$f(x)=f_{w,b}(x)$ 📒 有时候会看到有的书或者博客用 $h_\\theta$ 表示模型，我认为 $f(x)$ 比较简洁就用了这个记法 如果要进一步对线性回归模型进行细分，又可以分成如下几类 ","date":"2023-03-15","objectID":"/zh-cn/linear-regression-model-guide-theory/:3:0","series":null,"tags":["Machine-Learning"],"title":"线性回归模型指南 - 理论部分","uri":"/zh-cn/linear-regression-model-guide-theory/#分类"},{"categories":["ML-DL"],"content":" 单变量线性回归如果模型的输入特征只有一个，就叫做单变量线性回归（Univariate linear regression），此时达到了最简单的形式 $$ f(x)=wx+b $$ 在机器学习中，分别称 $w$ 和 $b$ 为权重（Weight）和偏置项（Bias） 📒 注意：$\\theta$ 为一个向量，按道理应该用 $\\vec \\theta$ 表示，但是下面为了简洁，我都省略了箭头 📒 也可以用向量的形式写，用 $\\theta=[b, w]$ 表示模型的参数，令 $\\vec x=[1, x]^T$。那么根据向量乘法的知识我们可以知道 $\\theta^T\\vec x=wx+b$ ","date":"2023-03-15","objectID":"/zh-cn/linear-regression-model-guide-theory/:3:1","series":null,"tags":["Machine-Learning"],"title":"线性回归模型指南 - 理论部分","uri":"/zh-cn/linear-regression-model-guide-theory/#单变量线性回归"},{"categories":["ML-DL"],"content":" 多变量线性回归如果模型有多个输入的特征，就叫做多变量线性回归（Multiple linear regresseion） $$ f(x)=w_1x_1+w_1x_2+…w_nx_n+b $$ 其中 $x_i$ 是不同的特征，一共有 $n$ 个特征，为此我们需要每个特征学习一个权重 $w_i$ 📒 同理，可以选择用向量的形式来写，令 $\\theta=[b, w_1, w_2, …, w_n]$，$\\vec x=[1, x_1, x_2, …, x_n]^T$，向量乘法之后也可以得到上面的形式。你会惊讶地发现，单变量线性回归和多变量线性回归有了统一的形式——$f(\\vec x)=\\theta^T\\vec x$。这在后面求解梯度的时候会带来很大的方便 ","date":"2023-03-15","objectID":"/zh-cn/linear-regression-model-guide-theory/:3:2","series":null,"tags":["Machine-Learning"],"title":"线性回归模型指南 - 理论部分","uri":"/zh-cn/linear-regression-model-guide-theory/#多变量线性回归"},{"categories":["ML-DL"],"content":" 模型如何训练","date":"2023-03-15","objectID":"/zh-cn/linear-regression-model-guide-theory/:4:0","series":null,"tags":["Machine-Learning"],"title":"线性回归模型指南 - 理论部分","uri":"/zh-cn/linear-regression-model-guide-theory/#模型如何训练"},{"categories":["ML-DL"],"content":" 损失函数定义了线性回归模型之后，我们需要衡量它的预测好坏，显然，我们希望预测的值跟实际上的值的“距离”越接近越好。在机器学习中，我们会规定一个损失函数（Cost function）衡量“距离”，损失自然是越低越好。当模型在验证集上的损失降到最低不再明显变化的时候，我们认为模型收敛了，此时得到了最好的模型 📒 在机器学习中，通常将数据划分为训练集/验证集/测试集，模型用训练集上的数据学习，在验证集上验证、调参，最后在测试集上进行泛化性验证（测试集包含没有见过的数据）。只用训练集/测试集这种划分方法，直接在测试集上调参是不正确的做法。测试集当且仅当最后你训练和调参结束，选出你认为的最好模型的的时候，在论文里面是报告结果的时候采用的 线性回归模型的损失函数最常用的是均平方误差，我更经常直接用英文的缩写 MSE（Mean square error）代指。其公式如下： $$ MSE=\\frac{1}{2m}\\sum^m_{i=1}(\\hat y^{(i)} - y^{(i)})^2 $$ 其中 $m$ 表示样本个数 上角标 ${(i)}$ 加了括号，和指数的记号进行区分，表示第 $i$ 个样本的预测/真实值 $\\hat y$ 这个记号表示线性回归模型的预测，$y$ 表示本来的真实值 📒 我采用了符合机器学习惯例的记号，推荐记住～ 📒 线性回归模型不是非要用 MSE，也可以用绝对值误差 MAE，MAE 适用于：当数据集中的异常值（Outlier）比较多的时候，降低对这种样本的敏感度 ","date":"2023-03-15","objectID":"/zh-cn/linear-regression-model-guide-theory/:4:1","series":null,"tags":["Machine-Learning"],"title":"线性回归模型指南 - 理论部分","uri":"/zh-cn/linear-regression-model-guide-theory/#损失函数"},{"categories":["ML-DL"],"content":" 梯度下降训练法前面提到当模型在验证集上的损失降到最低而且不再变化的时候，我们得到最好的模型。但是要如何让模型不断改进预测，降低损失呢？🤔 梯度下降（Gradient descent）算法是一种通用的做法 不要被这个名字所迷惑，梯度下降算法其实没有那么神秘。先整理我们目前学到了什么： 模型的预测 $\\hat y$ 跟它参数，如果是单变量线性回归模型，就是和 $w$ 和 $b$ 有关 损失函数跟模型的预测有关系，因为数据本身真实的值这个我们是无法改变的 所以损失函数实际上是一个关于模型参数的函数，在机器学习中，常用记号 $J$ 表示 先考虑简单的单变量线性回归，当它采用 MSE 作为损失函数的时候： $$ J(w, b) = \\frac{1}{2m}\\sum^m_{i=1}(f(x^{(i)})-y^{(i)})^2 = \\frac{1}{2m}\\sum^m_{i=1}(wx^{(i)} + b - y^{(i)})^2 $$ 根据 $w$ 和 $b$ 的取值不同，$J(w,b)$ 也不同，因此改进线性回归模型其实就是一直在调整这两个参数让 $J(w,b)$ 的值更小。用数学的语言来说，求解最优模型其实就是求解函数 $J(w,b)$ 的最小点 📒 回忆 $m$ 为训练集的样本个数。更为严格来说，上面的梯度下降式子是批梯度下降（Batch gradient descent），即每个计算梯度的时候用的是整个训练集上的样本。当数据集很大的时候这个方法就无法很好 Scale，此时我们就需要使用随机梯度下降（Stochastic gradient descent） 📒 只要学过导数、最小值，我们不难求解出上面公式的最小值，但这是因为线性回归模型比较简单，当模型更加复杂的时候，用数学方法求解也会更加困难，因此在实践中采用的都是梯度下降算法（不考虑强化学习，因为强化学习优化的目标一般不是一个可微的函数） 让我们暂时不考虑 $b$ 只考虑 $w$，那么此时 $J$ 是一个关于 $w$ 的函数，我们可以以 $w$ 为横轴，$J(w)$ 为纵轴画出如下的图： 📒 注意，上面的图并不严格遵循 $J(w)$ 的定义，为了方便我这里直接画了 $y=\\frac{1}{2}x^2$。但是形状应该差不多，可以用来理解梯度下降算法 从图中不难看出，当 $w=0$ 的时候 $J(w)$ 取到了最小值。假设模型当前的参数 $w=5$，计算得到损失 $J(5)=12.5$，我们要如何更新 $w$ 让模型更好呢？答案是让 $w$ 沿着梯度的反方向更新（图中红色的线为在 $w=5$ 这个点的切线），不难求出这一点的梯度（导数）是 $5$，$w$ 应该减小，因此应该是减去这个梯度（所以说是反方向），同时引入学习率 $\\alpha$ 控制更新的幅度，得到更新式子 $w \\leftarrow w - \\alpha \\cdot 5$ 📒 想象你自己站在 $w=5$ 这个点要前进到 $w=0$ 这个最小值在的点，如果学习率 $\\alpha$ 太大，你新得到的 $w$ 可能会小于 $0$，一下子越过了 $w=0$ 这个点。虽然你可以通过梯度下降再次尝试更新，但此时往往你会发现你的模型的损失一直在变化无法收敛。学习率和梯度共同控制了每次参数更新的幅度 📒 我们在只考虑 $w$ 的时候得出了该如何更新的结论——沿着梯度的反方向，考虑更多的参数的时候这个结论仍然适用，不过那就要涉及到求解偏导数乃至向量求导的知识，而且此时的 $J$ 的可视化也更为困难，所以这里不细讲。只需要记住模型的更新总是沿着梯度的反方向前进，从直觉上进行把握👻 在单变量线性回归中，梯度更新的式子如下： $$ w \\leftarrow w - \\alpha \\cdot \\frac{\\partial}{\\partial w}J(w,b) $$ 别忘了还有 $b$，它也要更新 $$ b \\leftarrow b - \\alpha \\cdot \\frac{\\partial}{\\partial b}J(w,b) $$ 我们来对其中的梯度计算进行推导 $$ \\begin{aligned} \\frac{\\partial}{\\partial w}J(w,b)\u0026=\\frac{\\partial}{\\partial w}\\frac{1}{2m}\\sum_{i=1}^m(f(x^{(i)})-y^{(i)})^2 \\\\\\ \u0026= \\frac{\\partial}{\\partial w}\\frac{1}{2m}(wx^{(i)}+b-y^{(i)})^2 \\\\\\ \u0026= \\frac{\\partial}{\\partial w}\\frac{1}{m}\\sum_{i=1}^m(f(x^{(i)})-y^{(i)})x^{(i)} \\end{aligned} $$ $$ \\begin{aligned} \\frac{\\partial}{\\partial b}J(w,b)\u0026=\\frac{\\partial}{\\partial w}\\frac{1}{2m}\\sum_{i=1}^m(f(x^{(i)})-y^{(i)})^2 \\\\\\ \u0026= \\frac{\\partial}{\\partial b}\\frac{1}{2m}(wx^{(i)}+b-y^{(i)})^2 \\\\\\ \u0026= \\frac{\\partial}{\\partial b}\\frac{1}{m}\\sum_{i=1}^m(f(x^{(i)})-y^{(i)}) \\end{aligned} $$ 如果是多变量线性回归，我们要求解每个 $\\frac{\\partial }{w_i}J(w_1,w_2, …,b)$ 显然很不方便，此时用向量形式推导梯度是最好的 在向量的形式下，损失函数 MSE 写作： $$ J(\\theta) = \\frac{1}{2m}(X\\theta - \\vec{y})^T(X\\theta - \\vec{y}) $$ 其中 $X$ 为输入的矩阵，常用大写字母表示矩阵，它的每一行为一个样本的特征值 $(x^{(i)})^T$，大小为 $(m, n+1)$ 前面提到我们有 $n$ 个特征，这里为 $n+1$ 维是因为在第一个位置插入了一个 $1$，这样相乘的时候 $1$ 会和 $b$ 做计算 $x^{(i)}$ 需要转置因为本来它本是列向量 对于单个样本是 $\\theta^T\\vec x$，对于 $m$ 个样本的计算就要用矩阵乘法 $X\\theta$ $\\theta$ 正如我们前面说的是 $[b, w_1, w_2, …, w_n]$，长为 $n + 1$ 因此 $X\\theta$ 就是模型的预测值，根据矩阵乘法的知识，我们会得到长为 $m$ 的向量，表示对每个样本的预测 $X\\theta - \\vec y$ 就是每个预测的误差 顺带一提，假设 $\\vec a$ 为列向量，$\\vec a^T\\vec a$ 得到的总是一个标量，为每个元素的平方和。如果让 $\\vec a=X\\theta -\\vec y$ 就得到了上面右边的部分，这也解释了为什么会是这个形式 🤔️ 更新：在 维度分析 这篇博客中，我展示了如何用维度分析技巧快速推导出这个公式的解，感兴趣的话可以看下 下面我们开始尝试推导这个公式的梯度，这需要你有一定的向量/矩阵求导知识，可以选择跳过🔮。不过我建议还是看看，因为机器学习里面还挺多公式推导的 $$ \\begin{aligned} \\frac{\\partial}{\\partial \\theta}\\ J(w,b) \u0026= \\frac{\\partial}{\\partial \\theta}\\ \\frac{1}{2m}(X\\theta - \\vec{y})^T(X\\theta - \\vec{y}) \\\\\\ \u0026= \\frac{1}{2m}\\frac{\\partial}{\\partial \\theta}\\ (\\theta^TX^T - \\vec{y}^T)(X\\theta - \\vec{y}) \\\\\\ \u0026= \\frac{1}{2m}\\frac{\\partial}{\\partial \\theta}\\ (\\theta^TX^TX\\theta - \\theta^TX^T\\vec y - \\vec y^TX\\theta + \\vec y^T\\vec y) \\\\\\ \u0026= \\frac{1}{2m}\\frac{\\partial}{\\partial \\theta}\\ (\\theta^TX^TX\\theta - \\theta^T(X^T\\vec y) - (X^T\\vec y)^T\\theta + \\vec y^T\\vec y) \\\\\\ \u0026= \\frac{1}{2m}\\frac{\\partial}{\\partial \\theta}\\ (\\theta^TX^TX\\theta - 2\\theta^T(X^T\\vec y) + \\vec y^T\\vec y) \\\\\\ \u0026= \\frac{1}{2m}(\\frac{\\partial}{\\partial \\theta}\\ (\\theta^TX^TX\\theta) - 2\\frac{\\partial}{\\partial \\theta}(\\theta^TX^T\\vec y))) \\\\\\ \u0026= \\frac{1}{2m}(2X^TX\\theta - 2X^T\\vec y)) \\\\\\ \u0026= \\frac{1}{m}(X^TX\\theta - X^T\\vec y)) \\\\\\ \u0026= \\frac{1}{m}X^T(X\\theta-\\vec y) \\end{aligned} $$ 几个解释： $X^T$ 的大小是 $(n+1, m)","date":"2023-03-15","objectID":"/zh-cn/linear-regression-model-guide-theory/:4:2","series":null,"tags":["Machine-Learning"],"title":"线性回归模型指南 - 理论部分","uri":"/zh-cn/linear-regression-model-guide-theory/#梯度下降训练法"},{"categories":["ML-DL"],"content":" 总结线性回归模型的理论部分就是以上的内容，本文介绍了单变量线性回归，多变量线性回归，前者可以看成是后者的一个特例。最后我们将其都用向量的形式统一了写法，并给出了向量形式下采用 MSE 作为损失函数的时候的梯度计算公式 本来还想放一下代码在这里，结果写着写着发现这一篇博客已经很长了，看来只好将线性回归模型的算法放在另一篇了🙌 ","date":"2023-03-15","objectID":"/zh-cn/linear-regression-model-guide-theory/:5:0","series":null,"tags":["Machine-Learning"],"title":"线性回归模型指南 - 理论部分","uri":"/zh-cn/linear-regression-model-guide-theory/#总结"},{"categories":["Vim-Neovim"],"content":"从零开始配置 Neovim 为一个轻量级的 IDE","date":"2023-02-08","objectID":"/zh-cn/config-neovim-from-scratch/","series":null,"tags":["Vim","Neovim"],"title":"从零开始配置 Neovim(Nvim)","uri":"/zh-cn/config-neovim-from-scratch/"},{"categories":["Vim-Neovim"],"content":" Info 更新： 2024-04-04，重写部分章节，Package Manager 从 packer.nvim 换成了 lazy.nvim 🤗。 如果之前跟着本篇教程采用 packer.nvim 进行安装的话，可以参考我迁移的时候的 commit，修改完之后记得用 :checkhealth lazy 检查下，因为还需要删除 packer.nvim 的一些旧文件 2025-03-22，将 nvim-cmp 替换为 blink.cmp，配置更简单了 进一步阅读: 如何为一门新的编程语言配置 Neovim ，以及支持第三方代码格式化工具，见下篇文章 ","date":"2023-02-08","objectID":"/zh-cn/config-neovim-from-scratch/:0:0","series":null,"tags":["Vim","Neovim"],"title":"从零开始配置 Neovim(Nvim)","uri":"/zh-cn/config-neovim-from-scratch/#"},{"categories":["Vim-Neovim"],"content":" 版本信息我使用的是 MacBook Air M3，系统版本为 macOS 15.3.2。我的 Nvim 版本信息如下 text NVIM v0.10.4 Build type: Release LuaJIT 2.1.1741730670 system vimrc file: \"$VIM/sysinit.vim\" fall-back for $VIM: \"/opt/homebrew/Cellar/neovim/0.10.4_1/share/nvim\" Run :checkhealth for more info ","date":"2023-02-08","objectID":"/zh-cn/config-neovim-from-scratch/:1:0","series":null,"tags":["Vim","Neovim"],"title":"从零开始配置 Neovim(Nvim)","uri":"/zh-cn/config-neovim-from-scratch/#版本信息"},{"categories":["Vim-Neovim"],"content":" 为什么选择 Neovim在使用 Vim 一年多之后，我越发觉得 Vim 的配置麻烦，启动加载速度也不尽人意。我也很不喜欢 Vimscript 的写法，这导致我决定使用 Neovim(Nvim)。我决定重新配置 Nvim。为什么会想要重新配置而不是迁移配置呢？因为我想顺便趁着这个机会，重新审视我本来 Vim 的配置，以及将本来用到的的插件替换为现在的 SOTA(State-of-the-art)。我自从看完 MIT 的 Missing semester 的课配置了 ~/.vimrc 之后就很长时间都没有再编辑 ~/.vimrc 文件了 我认为在配置 Nvim 的时候弄清楚每一个选项的意思是很有必要的，因此我在这篇博客中会尽量解释清楚每个选项的含义，同时将解释放在注释里面，即我尽量让我自己的配置文件是 self-contained 而且可读性强的 💡 当然，这难免有疏漏。别忘了我们永远可以在 Nvim 里面输入 :h \u003cname\u003e 来看到更为详细的解释 💡 该篇博客假定你对 Vim 有基本了解 ","date":"2023-02-08","objectID":"/zh-cn/config-neovim-from-scratch/:2:0","series":null,"tags":["Vim","Neovim"],"title":"从零开始配置 Neovim(Nvim)","uri":"/zh-cn/config-neovim-from-scratch/#为什么选择-neovim"},{"categories":["Vim-Neovim"],"content":" Nvim 配置基础知识","date":"2023-02-08","objectID":"/zh-cn/config-neovim-from-scratch/:3:0","series":null,"tags":["Vim","Neovim"],"title":"从零开始配置 Neovim(Nvim)","uri":"/zh-cn/config-neovim-from-scratch/#nvim-配置基础知识"},{"categories":["Vim-Neovim"],"content":" Lua 语言在配置 Nvim 的时候，我会尽可能用 Lua 语言写配置，因此你有必要了解一下 Lua 的基本语法和语义。可以快速浏览一下 Learn Lua in Y minutes 了解大概 ","date":"2023-02-08","objectID":"/zh-cn/config-neovim-from-scratch/:3:1","series":null,"tags":["Vim","Neovim"],"title":"从零开始配置 Neovim(Nvim)","uri":"/zh-cn/config-neovim-from-scratch/#lua-语言"},{"categories":["Vim-Neovim"],"content":" 配置文件路径Nvim 的配置目录在 ~/.config/nvim 下。在 Linux/Mac 系统上，Nvim 会默认读取 ~/.config/nvim/init.lua 文件，理论上来说可以将所有配置的东西都放在这个文件里面，但这样不是一个好的做法，因此我划分不同的文件和目录来分管不同的配置 首先看下按照本篇教程配置 Nvim 之后，目录结构看起来会是怎么样⬇️ text . ├── init.lua └── lua ├── colorscheme.lua ├── keymaps.lua ├── lsp.lua ├── options.lua └── plugins.lua 解释如下 init.lua 为 Nvim 配置的 Entry point，我们主要用来导入其他 *.lua 文件 colorscheme.lua 配置主题 keymaps.lua 配置按键映射 lsp.lua 配置 LSP options.lua 配置选项 plugins.lua 配置插件 lua 目录。当我们在 Lua 里面调用 require 加载模块（文件）的时候，它会自动在 lua 文件夹里面进行搜索 将路径分隔符从 / 替换为 .，然后去掉 .lua 后缀就得到了 require 的参数格式 ","date":"2023-02-08","objectID":"/zh-cn/config-neovim-from-scratch/:3:2","series":null,"tags":["Vim","Neovim"],"title":"从零开始配置 Neovim(Nvim)","uri":"/zh-cn/config-neovim-from-scratch/#配置文件路径"},{"categories":["Vim-Neovim"],"content":" 选项配置主要用到的就是 vim.g、vim.opt、vim.cmd 等，我制造了一个快速参照对比的表格 In Vim In Nvim Note let g:foo = bar vim.g.foo = bar set foo = bar vim.opt.foo = bar set foo = vim.opt.foo = true some_vimscript vim.cmd(some_vimscript) ","date":"2023-02-08","objectID":"/zh-cn/config-neovim-from-scratch/:3:3","series":null,"tags":["Vim","Neovim"],"title":"从零开始配置 Neovim(Nvim)","uri":"/zh-cn/config-neovim-from-scratch/#选项配置"},{"categories":["Vim-Neovim"],"content":" 按键配置在 Nvim 里面进行按键绑定的语法如下，具体的解释可以看 :h vim.keymap.set lua vim.keymap.set(\u003cmode\u003e, \u003ckey\u003e, \u003caction\u003e, \u003copts\u003e) ","date":"2023-02-08","objectID":"/zh-cn/config-neovim-from-scratch/:3:4","series":null,"tags":["Vim","Neovim"],"title":"从零开始配置 Neovim(Nvim)","uri":"/zh-cn/config-neovim-from-scratch/#按键配置"},{"categories":["Vim-Neovim"],"content":" 从零开始配置 Nvim在阅读了前面一些配置基础之后，现在我们可以从头开始，由简到易一步步配置 Nvim 了 ","date":"2023-02-08","objectID":"/zh-cn/config-neovim-from-scratch/:4:0","series":null,"tags":["Vim","Neovim"],"title":"从零开始配置 Neovim(Nvim)","uri":"/zh-cn/config-neovim-from-scratch/#从零开始配置-nvim"},{"categories":["Vim-Neovim"],"content":" 安装 Nvim我用的是 Mac，用 Homebrew 安装 Nvim 非常容易，只要运行如下命令即可1 sh $ brew install neovim 在安装完成之后，如果 ~/.config/nvim 目录不存在，创建目录并新建 init.lua 文件 sh $ mkdir ~/.config/nvim $ mkdir ~/.config/nvim/lua $ touch ~/.config/nvim/init.lua 💡 配置文件编辑保存之后，重启 Nvim 就能看到效果，后面默认每次小章节配置完成后就重启 ","date":"2023-02-08","objectID":"/zh-cn/config-neovim-from-scratch/:4:1","series":null,"tags":["Vim","Neovim"],"title":"从零开始配置 Neovim(Nvim)","uri":"/zh-cn/config-neovim-from-scratch/#安装-nvim"},{"categories":["Vim-Neovim"],"content":" 选项配置选项配置功能一览： 默认采用系统剪贴板，同时支持鼠标操控 Nvim Tab 和空格的换算 UI 界面 “智能”搜索 新建 ~/.config/nvim/lua/options.lua 文件并加入如下内容⬇️ lua -- Hint: use `:h \u003coption\u003e` to figure out the meaning if needed vim.opt.clipboard = 'unnamedplus' -- use system clipboard vim.opt.completeopt = { 'menu', 'menuone', 'noselect' } vim.opt.mouse = 'a' -- allow the mouse to be used in Nvim -- Tab vim.opt.tabstop = 4 -- number of visual spaces per TAB vim.opt.softtabstop = 4 -- number of spacesin tab when editing vim.opt.shiftwidth = 4 -- insert 4 spaces on a tab vim.opt.expandtab = true -- tabs are spaces, mainly because of python -- UI config vim.opt.number = true -- show absolute number vim.opt.relativenumber = true -- add numbers to each line on the left side vim.opt.cursorline = true -- highlight cursor line underneath the cursor horizontally vim.opt.splitbelow = true -- open new vertical split bottom vim.opt.splitright = true -- open new horizontal splits right -- vim.opt.termguicolors = true -- enabl 24-bit RGB color in the TUI vim.opt.showmode = false -- we are experienced, wo don't need the \"-- INSERT --\" mode hint -- Searching vim.opt.incsearch = true -- search as characters are entered vim.opt.hlsearch = false -- do not highlight matches vim.opt.ignorecase = true -- ignore case in searches by default vim.opt.smartcase = true -- but make it case sensitive if an uppercase is entered 然后打开 init.lua，用 require 导入刚才写的 options.lua 文件 lua require('options') ","date":"2023-02-08","objectID":"/zh-cn/config-neovim-from-scratch/:4:2","series":null,"tags":["Vim","Neovim"],"title":"从零开始配置 Neovim(Nvim)","uri":"/zh-cn/config-neovim-from-scratch/#选项配置-1"},{"categories":["Vim-Neovim"],"content":" 按键配置按键功能一览： 用 \u003cC-h/j/k/l\u003e 快速在多窗口之间移动光标 用 Ctrl + 方向键进行窗口大小的调整 选择模式下可以一直用 Tab 或者 Shift-Tab 改变缩进 新建 ~/.config/nvim/lua/keymaps.lua 文件并放入如下内容⬇️ lua -- define common options local opts = { noremap = true, -- non-recursive silent = true, -- do not show message } ----------------- -- Normal mode -- ----------------- -- Hint: see `:h vim.map.set()` -- Better window navigation vim.keymap.set('n', '\u003cC-h\u003e', '\u003cC-w\u003eh', opts) vim.keymap.set('n', '\u003cC-j\u003e', '\u003cC-w\u003ej', opts) vim.keymap.set('n', '\u003cC-k\u003e', '\u003cC-w\u003ek', opts) vim.keymap.set('n', '\u003cC-l\u003e', '\u003cC-w\u003el', opts) -- Resize with arrows -- delta: 2 lines vim.keymap.set('n', '\u003cC-Up\u003e', ':resize -2\u003cCR\u003e', opts) vim.keymap.set('n', '\u003cC-Down\u003e', ':resize +2\u003cCR\u003e', opts) vim.keymap.set('n', '\u003cC-Left\u003e', ':vertical resize -2\u003cCR\u003e', opts) vim.keymap.set('n', '\u003cC-Right\u003e', ':vertical resize +2\u003cCR\u003e', opts) ----------------- -- Visual mode -- ----------------- -- Hint: start visual mode with the same area as the previous area and the same mode vim.keymap.set('v', '\u003c', '\u003cgv', opts) vim.keymap.set('v', '\u003e', '\u003egv', opts) 然后在 init.lua 文件里面再次加上一行导入这个文件 lua ... -- 省略其他行 require('keymaps') 警告 ... 表示省略了其他部分的代码（为了节省博客的篇幅） ","date":"2023-02-08","objectID":"/zh-cn/config-neovim-from-scratch/:4:3","series":null,"tags":["Vim","Neovim"],"title":"从零开始配置 Neovim(Nvim)","uri":"/zh-cn/config-neovim-from-scratch/#按键配置-1"},{"categories":["Vim-Neovim"],"content":" 安装插件管理器一个强大的 Nvim 离不开插件的支持。我选用的是当下最为流行 lazy.nvim。它支持如下许多特性： 正确处理不同插件之间的依赖 支持定制 Lazy loading，比如基于 Event、Filetype 等 … 新建 ~/.config/nvim/lua/plugins.lua 文件并放入如下内容。下面的模板只完成了 lazy.nvim 自身的安装，还没有指定其他第三方插件 lua local lazypath = vim.fn.stdpath(\"data\") .. \"/lazy/lazy.nvim\" if not (vim.uv or vim.loop).fs_stat(lazypath) then vim.fn.system({ \"git\", \"clone\", \"--filter=blob:none\", \"https://github.com/folke/lazy.nvim.git\", \"--branch=stable\", -- latest stable release lazypath, }) end vim.opt.rtp:prepend(lazypath) require(\"lazy\").setup({}) 💡 在 lazy.nvim 指定第三方插件很简单，只需要在 require(\"lazy\").setup({ ... }) 的 ... 里面声明插件 然后在 init.lua 文件里面再次加上一行导入这个文件 lua ... -- 省略其他行 require('plugins') 此时你重启 Nvim 会发现黑屏没显示，这是因为 lazy.nvim 在安装自己，静待片刻即可☕️。等待 Dashboard 出现之后，可以输入 :Lazy 试试，如果看到了弹出了 lazy.nvim 的窗口，那就安装成功了🎉 技巧 Tip：用 :q 退出 lazy.nvim 的窗口 ","date":"2023-02-08","objectID":"/zh-cn/config-neovim-from-scratch/:4:4","series":null,"tags":["Vim","Neovim"],"title":"从零开始配置 Neovim(Nvim)","uri":"/zh-cn/config-neovim-from-scratch/#安装插件管理器"},{"categories":["Vim-Neovim"],"content":" 主题配置 注意 macOS 自带的 Terminal.app 只支持 ANSI 256，在安装完 monokai 主题后，你可能会发现显示整个画面变成蓝色。使用颜色支持更丰富的 Terminal 可以解决这个问题（比如 iTerm2、Kitty） 我喜欢的主题是 monokai.nvim，在 plugins.lua 进行修改 lua ... -- 省略其他行 require(\"lazy\").setup({ \"tanvirtin/monokai.nvim\", }) 保存更改并重启就可以看到 lazy.nvim 在帮我们安装插件了，新建并编辑 ~/.config/nvim/lua/colorscheme.lua 文件 lua -- define your colorscheme here local colorscheme = 'monokai_pro' local is_ok, _ = pcall(vim.cmd, \"colorscheme \" .. colorscheme) if not is_ok then vim.notify('colorscheme ' .. colorscheme .. ' not found!') return end 这里用到的 pcall 是 Lua 里面的 protected call，它会返回一个 bool 变量表示是否执行成功（跟 Go 语言的 err 功能类似）。这里采用 pcall 而不是直接在 init.lua 文件里面加上 vim.cmd('colorscheme monokai_pro') 是为了避免主题没有安装的情况下打开 Nvim 看到一大堆报错信息2 最后在 init.lua 文件里面导入就行 lua ... -- 省略其他行 require('colorscheme') ","date":"2023-02-08","objectID":"/zh-cn/config-neovim-from-scratch/:4:5","series":null,"tags":["Vim","Neovim"],"title":"从零开始配置 Neovim(Nvim)","uri":"/zh-cn/config-neovim-from-scratch/#主题配置"},{"categories":["Vim-Neovim"],"content":" 自动补全插件 Warning blink.cmp 还在 beta 版本，这意味着变动会比较大，而且可能会遇到不少 Bug。但我目前日常使用下来没有问题 :) 之前本文的自动补全插件采用的是 nvim-cmp，但配置上较为繁琐。现在有了 blink.cmp 插件，配置会比较简单而且自动补全特别快 在 plugins.lua里新增这个插件并做好配置 lua ... -- 省略其他行 require(\"lazy\").setup({ ... -- 省略其他行 { \"saghen/blink.cmp\", -- optional: provides snippets for the snippet source dependencies = { \"rafamadriz/friendly-snippets\" }, -- use a release tag to download pre-built binaries version = \"*\", -- AND/OR build from source, requires nightly: https://rust-lang.github.io/rustup/concepts/channels.html#working-with-nightly-rust -- build = 'cargo build --release', -- If you use nix, you can build from source using latest nightly rust with: -- build = 'nix run .#build-plugin', opts = { -- 'default' (recommended) for mappings similar to built-in completions (C-y to accept) -- 'super-tab' for mappings similar to vscode (tab to accept) -- 'enter' for enter to accept -- 'none' for no mappings -- -- All presets have the following mappings: -- C-space: Open menu or open docs if already open -- C-n/C-p or Up/Down: Select next/previous item -- C-e: Hide menu -- C-k: Toggle signature help (if signature.enabled = true) -- -- See :h blink-cmp-config-keymap for defining your own keymap keymap = { -- Each keymap may be a list of commands and/or functions preset = \"enter\", -- Select completions [\"\u003cUp\u003e\"] = { \"select_prev\", \"fallback\" }, [\"\u003cDown\u003e\"] = { \"select_next\", \"fallback\" }, [\"\u003cTab\u003e\"] = { \"select_next\", \"fallback\" }, [\"\u003cS-Tab\u003e\"] = { \"select_prev\", \"fallback\" }, -- Scroll documentation [\"\u003cC-b\u003e\"] = { \"scroll_documentation_up\", \"fallback\" }, [\"\u003cC-f\u003e\"] = { \"scroll_documentation_down\", \"fallback\" }, -- Show/hide signature [\"\u003cC-k\u003e\"] = { \"show_signature\", \"hide_signature\", \"fallback\" }, }, appearance = { -- 'mono' (default) for 'Nerd Font Mono' or 'normal' for 'Nerd Font' -- Adjusts spacing to ensure icons are aligned nerd_font_variant = \"mono\", }, sources = { -- `lsp`, `buffer`, `snippets`, `path` and `omni` are built-in -- so you don't need to define them in `sources.providers` default = { \"lsp\", \"path\", \"snippets\", \"buffer\" }, -- Sources are configured via the sources.providers table }, -- (Default) Rust fuzzy matcher for typo resistance and significantly better performance -- You may use a lua implementation instead by using `implementation = \"lua\"` or fallback to the lua implementation, -- when the Rust fuzzy matcher is not available, by using `implementation = \"prefer_rust\"` -- -- See the fuzzy documentation for more information fuzzy = { implementation = \"prefer_rust_with_warning\" }, completion = { -- The keyword should only matchh against the text before keyword = { range = \"prefix\" }, menu = { -- Use treesitter to highlight the label text for the given list of sources draw = { treesitter = { \"lsp\" }, }, }, -- Show completions after tying a trigger character, defined by the source trigger = { show_on_trigger_character = true }, documentation = { -- Show documentation automatically auto_show = true, }, }, -- Signature help when tying signature = { enabled = true }, }, opts_extend = { \"sources.default\" }, } }) 关注其中的 opts 配置选项即可，关键的几个解释如下 keymap - 用于配置按键映射，格式也很好理解 preset = \"enter\" 表示用 回车键 确定当前选中的补全项 select_prev, select_next 用于在各个候选项中进行选择，我这里配置了 2 套按键，支持用⬆️/⬇️，或者用 Tab/Shift-Tab 进行补全项的选择 scroll_documentation_up, scroll_documentation_down 用于滚动 API 的文档，我配置的是 Ctrl-b, Ctrl-f trigger = { show_on_trigger_character = true } - 输入字符之后就会展示所有可用补全项 documentation = { auto_show = true } - 自动显示当前被选中补全项的文档 🎙️ 到这为止，重新启动 Nvim 后，等待插件安装完成后应该就能够用初步的自动补全功能了～ ","date":"2023-02-08","objectID":"/zh-cn/config-neovim-from-scratch/:4:6","series":null,"tags":["Vim","Neovim"],"title":"从零开始配置 Neovim(Nvim)","uri":"/zh-cn/config-neovim-from-scratch/#自动补全插件"},{"categories":["Vim-Neovim"],"content":" LSP 配置要把 Nvim 变成 IDE 就势必要借助于 LSP3，自己安装和配置 LSP 是比较繁琐的。不同的 LSP 安装方法不同，也不方便后续管理。mason.nvim 和配套的 mason-lspconfig.nvim 这两个插件很好解决了这个问题 🤗 首先修改 plugins.lua 文件，增加对应的插件 lua ... -- 省略其他行 require(\"lazy\").setup({ -- LSP manager \"williamboman/mason.nvim\", \"williamboman/mason-lspconfig.nvim\", \"neovim/nvim-lspconfig\", ... -- 省略其他行 }) 新建一个 ~/.config/nvim/lua/lsp.lua 文件并编辑，首先配置 mason 和 mason-lspconfig lua require('mason').setup({ ui = { icons = { package_installed = \"✓\", package_pending = \"➜\", package_uninstalled = \"✗\" } } }) require('mason-lspconfig').setup({ -- A list of servers to automatically install if they're not already installed ensure_installed = { 'pylsp', 'lua_ls', 'rust_analyzer' }, }) 💡 我们想要用什么语言的 LSP 就在 ensure_installed 里面加上，完整的列表可以看 server_configurations。我个人常用的就 python/rust 这两个编程语言，而因为我们都用 Lua 语言来配置 Nvim，所以也加上了 lua_ls 配置好 mason-lspconfig 之后，接下来就可以配置 nvim-lspconfig 了。因为配置的代码比较长，下面只展示了 pylsp 的配置，其他语言的配置大同小异。如果有疑惑，可以查看该文件的最新版本 💡 每个 LSP 都存在自己可以配置的选项，你可以自己去对应 LSP 的 GitHub 仓库查阅更多信息。如果要用默认配置的话，基本上每一个新的语言都只需要设置 on_attach = on_attach 编辑 ~/.config/nvim/lua/lsp.lua 文件新增如下内容 lua ... -- 省略其他行 -- Set different settings for different languages' LSP -- LSP list: https://github.com/neovim/nvim-lspconfig/blob/master/doc/server_configurations.md -- How to use setup({}): https://github.com/neovim/nvim-lspconfig/wiki/Understanding-setup-%7B%7D -- - the settings table is sent to the LSP -- - on_attach: a lua callback function to run after LSP atteches to a given buffer local lspconfig = require('lspconfig') -- Customized on_attach function -- See `:help vim.diagnostic.*` for documentation on any of the below functions local opts = { noremap = true, silent = true } vim.keymap.set('n', '\u003cspace\u003ee', vim.diagnostic.open_float, opts) vim.keymap.set('n', '[d', vim.diagnostic.goto_prev, opts) vim.keymap.set('n', ']d', vim.diagnostic.goto_next, opts) vim.keymap.set('n', '\u003cspace\u003eq', vim.diagnostic.setloclist, opts) -- Use an on_attach function to only map the following keys -- after the language server attaches to the current buffer local on_attach = function(client, bufnr) -- Enable completion triggered by \u003cc-x\u003e\u003cc-o\u003e vim.api.nvim_buf_set_option(bufnr, 'omnifunc', 'v:lua.vim.lsp.omnifunc') -- See `:help vim.lsp.*` for documentation on any of the below functions local bufopts = { noremap = true, silent = true, buffer = bufnr } vim.keymap.set('n', 'gD', vim.lsp.buf.declaration, bufopts) vim.keymap.set('n', 'gd', vim.lsp.buf.definition, bufopts) vim.keymap.set('n', 'K', vim.lsp.buf.hover, bufopts) vim.keymap.set('n', 'gi', vim.lsp.buf.implementation, bufopts) vim.keymap.set('n', '\u003cC-k\u003e', vim.lsp.buf.signature_help, bufopts) vim.keymap.set('n', '\u003cspace\u003ewa', vim.lsp.buf.add_workspace_folder, bufopts) vim.keymap.set('n', '\u003cspace\u003ewr', vim.lsp.buf.remove_workspace_folder, bufopts) vim.keymap.set('n', '\u003cspace\u003ewl', function() print(vim.inspect(vim.lsp.buf.list_workspace_folders())) end, bufopts) vim.keymap.set('n', '\u003cspace\u003eD', vim.lsp.buf.type_definition, bufopts) vim.keymap.set('n', '\u003cspace\u003ern', vim.lsp.buf.rename, bufopts) vim.keymap.set('n', '\u003cspace\u003eca', vim.lsp.buf.code_action, bufopts) vim.keymap.set('n', 'gr', vim.lsp.buf.references, bufopts) vim.keymap.set(\"n\", \"\u003cspace\u003ef\", function() vim.lsp.buf.format({ async = true }) end, bufopts) end -- Configure each language -- How to add LSP for a specific language? -- 1. use `:Mason` to install corresponding LSP -- 2. add configuration below lspconfig.pylsp.setup({ on_attach = on_attach, }) 上面的按键绑定的意思是很直观的，这里就不多解释啦 最后在 init.lua 文件里面加上 lua ... -- 省略其他行 require('lsp') 重启 Nvim 之后，你应该可以在下面的状态栏看到 Mason 正在下载并安装前面我们指定的 LSP（注意此时不能关闭 Nvim），可以输入 :Mason 查看安装进度。在你等待安装的过程中，可以输入 g? 查看更多帮助信息了解如何使用 mason 插件 大功告成🎉🎉🎉 ","date":"2023-02-08","objectID":"/zh-cn/config-neovim-from-scratch/:4:7","series":null,"tags":["Vim","Neovim"],"title":"从零开始配置 Neovim(Nvim)","uri":"/zh-cn/config-neovim-from-scratch/#lsp-配置"},{"categories":["Vim-Neovim"],"content":" 总结这样配置下来，我们成功把 Nvim 变成了一个轻量级的 IDE，它支持代码高亮、代码补全、语法检查等功能，而且是完全开源免费的，虽然还有些简陋，但已经是可以用的了 🤗 我发现自从学了 Vim 之后，我总在其他各种代码编辑器、IDE 看是不是支持 Vim。大多数情况下，它们对 Vim 的支持都不是很让人满意，还容易有快捷键冲突等问题。因此我选择将 Nvim 变成 IDE，并将配置文件托管在我的 Martinlwx/dotfiles 上。这样在新的机器上只要安装好 Nvim 并克隆配置，静待片刻之后就可以在不同的机器上获得一样的编程体验 打磨定制化工具是需要付出一定精力的。为了理解每个选项都在干啥，我不得不查找各种资料。但我仍相信这是值得的，理解你的工具利于你做扩展和定制化。本文已经尽可能采用了比较简单的配置，还有很多美化、私人定制化的内容可以配置，更别提其他很多优秀的第三方插件都还没有提及，这些就留给读者自己去探索发现了 ","date":"2023-02-08","objectID":"/zh-cn/config-neovim-from-scratch/:5:0","series":null,"tags":["Vim","Neovim"],"title":"从零开始配置 Neovim(Nvim)","uri":"/zh-cn/config-neovim-from-scratch/#总结"},{"categories":["Vim-Neovim"],"content":" 参考 Installing-Neovim ↩︎ Adding a colorscheme/theme ↩︎ Language Server Protocol - Wiki ↩︎ ","date":"2023-02-08","objectID":"/zh-cn/config-neovim-from-scratch/:6:0","series":null,"tags":["Vim","Neovim"],"title":"从零开始配置 Neovim(Nvim)","uri":"/zh-cn/config-neovim-from-scratch/#参考"},{"categories":["Programming-Languages"],"content":"Python 的类型提示的简单介绍","date":"2023-01-13","objectID":"/zh-cn/type-hints-in-python/","series":null,"tags":["Python"],"title":"Python 的类型提示：是什么以及为什么","uri":"/zh-cn/type-hints-in-python/"},{"categories":["Programming-Languages"],"content":" Info 更新： 2025-03-02: 进行了格式修改，常见使用场景章节里面新增 Never 返回类型、collections.abc 的抽象类型 ","date":"2023-01-13","objectID":"/zh-cn/type-hints-in-python/:0:0","series":null,"tags":["Python"],"title":"Python 的类型提示：是什么以及为什么","uri":"/zh-cn/type-hints-in-python/#"},{"categories":["Programming-Languages"],"content":" 引言一开始吸引我学习 Python 的是它的动态语言特性，以及它的鸭子类型（Duck typing）系统——我们不关心具体的类型是什么，我们只关心它的行为。得益于 Python 的动态语言特性，我们不需要声明具体类型，这很大程度上加快了开发速度，而且去掉了不少心智负担，再加上强大的第三方库支持，Python 成为了我最爱用的编程语言😺 而随着 PEP 4841 的提出，Python 决定引入类型提示（Type hint），这似乎又向静态类型语言看齐了？但其实非也，Python 仍然是一门动态编程语言，它的类型提示是可选项，加不加都可以，不会对程序运行产生影响。 这样听起来似乎没有必要专门写这篇博客来介绍 Python 的类型提示特性，但我发现写类型提示还是有不少好处的： 可以使用类型检查工具对代码进行检查，比如 Mypy IDE 的代码补全会更加智能，推荐的 API 更准确，我们用错了 API 也能及时发现。这可能是我选择写类型提示的最大动力 对抗代码复杂性。类型提示暴露了 API 的不少信息。作为开发者，我们只要看一下这样的函数签名就能知道个大概，而不用经常去看文档 ","date":"2023-01-13","objectID":"/zh-cn/type-hints-in-python/:1:0","series":null,"tags":["Python"],"title":"Python 的类型提示：是什么以及为什么","uri":"/zh-cn/type-hints-in-python/#引言"},{"categories":["Programming-Languages"],"content":" 函数的类型提示语法早在 Python 3.0，类型提示的语法就已经确定了下来2： 函数参数：name[: type] [ = default_val ]，其中 [] 表示这是可选项 函数返回类型：用 -\u003e return_type 表示 我们可以通过函数的 __annotations__ 属性访问到参数的类型信息，该属性返回一个字典，key 为参数名，value 为类型。不推荐直接访问该属性，而应该通过 inspect 模块（$\\ge$ Python 3.10）或者 typing 模块（Python 3.5 ~ 3.9）里面的对应方法来获取这个信息。如下所示： python def maximum(a: float, b: float) -\u003e float: \"\"\" A simple function to return the maximum elements of two floats\"\"\" return max(a, b) # \u003e= Python 3.10, do this import inspect assert inspect.get_annotations(maximum) == maximum.__annotations__ # Python 3.5 ~ 3.9 import typing assert typing.get_type_hints(maximum) == maximum.__annotations__ inspect.get_annotations(maximum) # {'a': float, 'b': float, 'return': float} Waring 再次强调，类型提示信息不会对程序的运行产生任何影响，这意味着即使我们违背了类型提示信息，程序也可以正常运行。只是静态代码检查工具会对此抛出警告 python # returns the maximum of two strings # , but we declared the arguments should be float! maximum('hello', 'world') # 'world' ","date":"2023-01-13","objectID":"/zh-cn/type-hints-in-python/:2:0","series":null,"tags":["Python"],"title":"Python 的类型提示：是什么以及为什么","uri":"/zh-cn/type-hints-in-python/#函数的类型提示语法"},{"categories":["Programming-Languages"],"content":" 变量的类型提示语法在 Python 3.6 之前，如果要给一个变量加上类型提示只能使用 Type comments，也就是在注释里面用 # type ... 声明1，但在 PEP 526 中提出了变量的类型提示语法，和函数参数的语法是类似的3 python a: int # undefined typed value a: int = 0 # typed value with default value ","date":"2023-01-13","objectID":"/zh-cn/type-hints-in-python/:3:0","series":null,"tags":["Python"],"title":"Python 的类型提示：是什么以及为什么","uri":"/zh-cn/type-hints-in-python/#变量的类型提示语法"},{"categories":["Programming-Languages"],"content":" 常见使用场景","date":"2023-01-13","objectID":"/zh-cn/type-hints-in-python/:4:0","series":null,"tags":["Python"],"title":"Python 的类型提示：是什么以及为什么","uri":"/zh-cn/type-hints-in-python/#常见使用场景"},{"categories":["Programming-Languages"],"content":" 简单的内建类型这里说的简单内建类型就是：int、str 等，也可以是第三方库里面定义的类型。前面提到的 maximum 函数的 2 个参数就是用 float ","date":"2023-01-13","objectID":"/zh-cn/type-hints-in-python/:4:1","series":null,"tags":["Python"],"title":"Python 的类型提示：是什么以及为什么","uri":"/zh-cn/type-hints-in-python/#简单的内建类型"},{"categories":["Programming-Languages"],"content":" Any 类型Any 表示什么类型都有可能。但它跟 object 并不相同1 基本上，我们可以认为一个不包含类型提示的函数的参数类型和返回类型都是 Any python def foo(x): ... # it assumes: def foo(x: Any) -\u003e Any: ... ","date":"2023-01-13","objectID":"/zh-cn/type-hints-in-python/:4:2","series":null,"tags":["Python"],"title":"Python 的类型提示：是什么以及为什么","uri":"/zh-cn/type-hints-in-python/#any-类型"},{"categories":["Programming-Languages"],"content":" Never 类型Never 作为函数返回值的类型提示的意思是：永远不会返回值。因此有这么 2 种情况 该函数会使用诸如 sys.exit 的方法，直接结束运行 该函数总是会抛出异常 比如 python from typing import Never def foobar() -\u003e Never: raise ValueError(\"This is a NoReturn function\") ","date":"2023-01-13","objectID":"/zh-cn/type-hints-in-python/:4:3","series":null,"tags":["Python"],"title":"Python 的类型提示：是什么以及为什么","uri":"/zh-cn/type-hints-in-python/#never-类型"},{"categories":["Programming-Languages"],"content":" 集合类型和映射类型我们称集合里面的每个东西为 item，那么我们如何给集合和 item 都加上类型提示信息？Python 采用 [] 记号支持这个特性，[] 里面指定 item 的类型。比如，一个包含字符串的列表这个类型可以写作 list[str]，非常清楚。 Tip 注意：Python 3.9 发布了 PEP 585 4，允许我们直接使用自带的 list、dict 等而无需使用 typing 模块对应的类型。下面我列出了不同，更为详细的请查阅原文 4： \u003c Python 3.9 $\\ge$ Python 3.9 typing.Tuple tuple typing.Dict dict typing.List list typing.Set set typing.Frozenset frozenset typing.Type type typing.AbstractSet collections.abc.Set typing.ContextManager contextlib.AbstractContextManager typing.AsyncContextManager contextlib.AbstractAsyncContextManager typing.Pattern, typing.re.Pattern re.Pattern typing.Match, typing.re.Match re.Match 后面我会使用最新的语法 python string_list: list[str] = ['hello', 'world'] # tuple[type1, type2, ..., typen] with fixed size date: tuple[int, int, int] = (2023, 1, 11) string_count: dict[str, int] = { 'hello': 1, 'world': 2, } 下面的 join_str_list 函数接受一个包含字符串的列表，用空格将他们连接起来，然后返回这个字符串 python def join_str_list(string_list: list[str]) -\u003e str: \"\"\" join all string in a list\"\"\" return ' '.join(string_list) print(join_str_list(string_list)) # hello world print(inspect.get_annotations(join_str_list)) # {'string_list': list[str], 'return': \u003cclass 'str'\u003e} Tip 在 Python 3.9+，我们可以使用 tuple[type1, ...] 表示类型全都是 type1 的任意长度的 tuple python def sum_variable_integers(data: tuple[int, ...]): \"\"\" Sum all integers of a tuple\"\"\" sum_val = 0 for integer in data: sum_val += integer return sum_val print(sum_variable_integers((1, 2, 3))) # 6 print(sum_variable_integers((3,))) # 3 那如果我们想要表示一个可能存放任何类型的值的 list 呢？我们可以利用 Any 类型： python list[Any] 但其实直接用 list 就可以，而且更为简洁 Info 如果这 3 个基本的集合类型不能满足你的要求，可以查阅 collections.abc 的文档 ","date":"2023-01-13","objectID":"/zh-cn/type-hints-in-python/:4:4","series":null,"tags":["Python"],"title":"Python 的类型提示：是什么以及为什么","uri":"/zh-cn/type-hints-in-python/#集合类型和映射类型"},{"categories":["Programming-Languages"],"content":" collections.abc 的抽象类型前面的 list, dict, set 应该不难理解，但存在一个更好的实践，那就是用 collections.abc 里面的抽象类型。这有什么好处呢？好处就是我们可以区分可变和不可变两种情况 以 dict 为例，Python 的 collections.abc 有 2 个 dict 的抽象基类：Mapping 和 MutableMapping，分别用于不可变、可变两种场景。比如下面这个例子，Mapping 表示不可变的字典类型，我们尝试用 pop 方法看会发生什么 python from collections.abc import Mapping def read_only(v: Mapping[str, int]): v.pop() 用 Mypy 做类型检查会发现报错了 :0 sh $ mypy . main.py:17: error: \"Mapping[str, int]\" has no attribute \"pop\" [attr-defined] Found 1 error in 1 file (checked 1 source file) Tip 同理，对于 set，collections.abc 有 MutableSet 和 Set；对于 list，collections.abc 有 MutableSequence 和 Sequence ","date":"2023-01-13","objectID":"/zh-cn/type-hints-in-python/:4:5","series":null,"tags":["Python"],"title":"Python 的类型提示：是什么以及为什么","uri":"/zh-cn/type-hints-in-python/#collectionsabc-的抽象类型"},{"categories":["Programming-Languages"],"content":" 类型别名（Type alias）有时候，类型会变得很复杂而且很长，我们并不想要在每一个地方都写上一长串的类型提示。那么我们应该怎么做呢？一个通常的做法是为其取一个有意义的别名。定义别名的方法也很简单： python AliasName = Type 拿前面的 date 日期类型作为例子。date 类型被我定义为一个 tuple，每个位置上的类型都是 int。那么，list[tuple[int, int, int] 表示「日期列表」这种类型。为了让代码更有可读性，我们可以给他起个别名叫做 Date，看下面的例子： python Date = tuple[int, int, int] DateList = list[Date] def print_date_list(l: DateList): \"\"\" Print all dates in the format `year-month-day` in the date list\"\"\" for year, month, day in l: print(f'{year}-{month}-{day}') print_date_list([(2022, 1, 1), (2023, 1, 3)]) # 2022-1-1 # 2023-1-3 print(inspect.get_annotations(print_date_list)) # {'l': list[tuple[int, int, int]]} 类型别名的语法很容易和定义全局变量混淆，所以 PEP 613（$\\ge$ Python 3.10）提出了更加 explicit 的方式5： python AliasName: TypeAlias = Type python from typing import TypeAlias Date: TypeAlias = tuple[int, int, int] ","date":"2023-01-13","objectID":"/zh-cn/type-hints-in-python/:4:6","series":null,"tags":["Python"],"title":"Python 的类型提示：是什么以及为什么","uri":"/zh-cn/type-hints-in-python/#类型别名type-alias"},{"categories":["Programming-Languages"],"content":" 参数化的泛型其他编程语言中经常使用大写字母比如 T 等表示参数化的泛型，在 Python 里面，我们使用 TypeVar 关键字，如同文档所说，一共有 3 种用法： python T = TypeVar('T') # Can be anything S = TypeVar('S', bound=str) # Can be any subtype of str A = TypeVar('A', str, bytes) # Must be exactly str or bytes 总的来说，TypeVar 提供了 2 种方式让我们对泛型作出限制： 用 bound=some_type，那么我们就只能传入 some_type 的 subtype 直接指定允许的类型 Info 关于 subtype 的定义可以参考 PEP 4836，概括来说为 2 点：a）每个类型都是自己的 subtype。b）OOP 中，子类是父类的 subtype python from typing import TypeVar GenericString = TypeVar('GenericString', str, bytes) def process(s: GenericString): \"\"\" The GenericString can be either str or bytes\"\"\" ... Info 实际上 Python 已经帮你定义好了可能是 str 也可能是 bytes 的类型——typing.AnyStr ","date":"2023-01-13","objectID":"/zh-cn/type-hints-in-python/:4:7","series":null,"tags":["Python"],"title":"Python 的类型提示：是什么以及为什么","uri":"/zh-cn/type-hints-in-python/#参数化的泛型"},{"categories":["Programming-Languages"],"content":" Union 类型Union[type1, type2, ...] 表示实际上的类型可能是 type1 或者 type2 等。在 Python 3.10 里面，新引入了 | 记号，可以用来代替 Union 的写法，再也不用写 from typing import Union 了7。其实 | 表示或这种关系还挺常见的，比如 OCaml 定义一个 Variant Type 的时候会用 | 分隔不同的类型，Rust 的 Pattern Matching 会用 | 合并不同的 Case。举例如下： python def parse(s: str | int) -\u003e int | None: \"\"\" Parse `s` and get an integer value. The `s` may be a string. Return None if fail \"\"\" if isinstance(s, str): if not s.isdigit(): return None else: return int(s) elif isinstance(s, int): return s inspect.get_annotations(parse) # {'s': str | int, 'return': int | None} ","date":"2023-01-13","objectID":"/zh-cn/type-hints-in-python/:4:8","series":null,"tags":["Python"],"title":"Python 的类型提示：是什么以及为什么","uri":"/zh-cn/type-hints-in-python/#union-类型"},{"categories":["Programming-Languages"],"content":" Optional 类型Optional[type1] 用于表示类型可能是 type1 也可能是 None，在很多编程语言里面都可以看到它的影子，比如：在 Haskell 中它叫做 Maybe 类型，在 Rust它就叫做 option。利用 | 的写法，Optional[type1] 可以简写为 type1 | None 一个经典的例子是一个可能发生除 0 错误的 divide 函数 python def divide(a: int, b: int) -\u003e int | None: if b == 0: return None return a // b ","date":"2023-01-13","objectID":"/zh-cn/type-hints-in-python/:4:9","series":null,"tags":["Python"],"title":"Python 的类型提示：是什么以及为什么","uri":"/zh-cn/type-hints-in-python/#optional-类型"},{"categories":["Programming-Languages"],"content":" 可调用对象（Callable）下面用函数作为例子，Python 的函数是 first-class object，所以函数可以是另一个函数的参数或者返回值。类型提示对此的支持是： python Callable[[ParamType1, ParamType2], ReturnType] 让我们定义一个 apply 函数，入参为可调用对象和要处理的数据，将这个可调用对象应用在数据上 python # from typing import Callable # Python \u003c 3.9 from collections.abc import Callable def apply(f: Callable[[str | int], int | None], data: list): \"\"\" Apply callable object on data. The `Callable[[str | int], int | None]` is the type hints of `parse` we aforementioned \"\"\" for d in data: print(f(d)) apply(parse, ['hello', 123]) # None # 123 ","date":"2023-01-13","objectID":"/zh-cn/type-hints-in-python/:4:10","series":null,"tags":["Python"],"title":"Python 的类型提示：是什么以及为什么","uri":"/zh-cn/type-hints-in-python/#可调用对象callable"},{"categories":["Programming-Languages"],"content":" 类在 Python 3.11 里面8提出了 Self 类型，表示当前类的实例。有了 Self 之后在写 Python 的类的时候就很方便，我们可以在一个类的定义里面使用 Self 代指当前的类的实例。再也不需要用 TypeVar 先引入了 python from typing import Self class Shape: def set_scale(self, scale: float) -\u003e Self: self.scale = scale return self ","date":"2023-01-13","objectID":"/zh-cn/type-hints-in-python/:4:11","series":null,"tags":["Python"],"title":"Python 的类型提示：是什么以及为什么","uri":"/zh-cn/type-hints-in-python/#类"},{"categories":["Programming-Languages"],"content":" 总结以上就是本篇博客的全部内容，我其实只谈到了我认为比较有用的一些类型提示使用场景，不少的高级特性比如 Static protocol9 等没有提到，这些内容留给读者自己探索。 我对类型提示的态度仍然是：当它变得复杂的时候就不用，除非这个代价是值得的。 根据我的开发经验，下面附上关于类型提示的几点建议🎯： 决定要加上什么类型提示的时候，考虑这个类型能够做什么。Python 3.8 提出的 static protocols 就很好解决了这点9。感觉有点像 Rust 中的 traits 对于函数返回类型，力求返回的类型越精确越好 通过了代码静态类型检查也不意味着程序就没有 bug 了，软件测试才是软件工程领域保证软件质量的标准做法～ 将这份 cheatsheet 加入你的书签👍 ","date":"2023-01-13","objectID":"/zh-cn/type-hints-in-python/:5:0","series":null,"tags":["Python"],"title":"Python 的类型提示：是什么以及为什么","uri":"/zh-cn/type-hints-in-python/#总结"},{"categories":["Programming-Languages"],"content":" 参考 PEP 484. Type Hints ↩︎ ↩︎ ↩︎ PEP 3107. Function Annotations ↩︎ PEP 526. Syntax for Variable Annotations ↩︎ PEP 585. Type Hinting Generics In Standard Collections ↩︎ ↩︎ PEP 613. Explicit Type Aliases ↩︎ PEP 483. The Theory of Type Hints ↩︎ PEP 604. Allow writing union types as X | Y ↩︎ PEP 673. Self Type ↩︎ PEP 544. Protocols: Structural subtyping (static duck typing) ↩︎ ↩︎ ","date":"2023-01-13","objectID":"/zh-cn/type-hints-in-python/:6:0","series":null,"tags":["Python"],"title":"Python 的类型提示：是什么以及为什么","uri":"/zh-cn/type-hints-in-python/#参考"},{"categories":["Programming-Languages"],"content":"Python 中的解包操作符的简单介绍","date":"2022-12-05","objectID":"/zh-cn/unpacking-in-python/","series":null,"tags":["Python"],"title":"Python 3.5 的解包操作符","uri":"/zh-cn/unpacking-in-python/"},{"categories":["Programming-Languages"],"content":" 引言今天我想要聊聊 Python 中用于解包（Unpacking）的两个操作符号——* 和 ** ","date":"2022-12-05","objectID":"/zh-cn/unpacking-in-python/:1:0","series":null,"tags":["Python"],"title":"Python 3.5 的解包操作符","uri":"/zh-cn/unpacking-in-python/#引言"},{"categories":["Programming-Languages"],"content":" 基本用法* 最为常见的用法是用来表示乘法。但我们也可以将 * 用于任意一个可迭代对象（iterable object）1上，表示我们想要提取里面所有的值 📒 Python 自带的可迭代对象包括：list, tuple, set, 和 dict ","date":"2022-12-05","objectID":"/zh-cn/unpacking-in-python/:2:0","series":null,"tags":["Python"],"title":"Python 3.5 的解包操作符","uri":"/zh-cn/unpacking-in-python/#基本用法"},{"categories":["Programming-Languages"],"content":" Starred assignment/expression随着 Python 3.0 的发布，Python 支持使用 * 来解包任意可迭代对象2。这个被称之为 Starred assignment，也叫做 Starred expressions。我也有看到称之为 parallel assignment 的。 我们可以在 = 左边声明一个特殊的变量表示捕获所有变量。看下面这个直观的例子： python \u003e\u003e\u003e first, *rest, last = [1, 2, 3, 4, 5] \u003e\u003e\u003e first 1 \u003e\u003e\u003e rest [2, 3, 4] \u003e\u003e\u003e last 5 📒 语法很简单：一个星号后面紧跟着变量名 - *foo。我们可以在 = 左边任意位置放置它，但是只能最多使用一次这样的变量。以及，foo 的类型为 list 在我看来，Python 的这个特性很大程度上提高了代码的可读性 不过它也有一些局限： 我们不能仅仅在 = 左边使用一个 *foo 当成唯一的被赋值目标。= 左侧必须是一个 list 或者是 tuple 如果 = 右边的值的数量不够用于解包的话，程序就会报错 下面的例子证明了这两点： python *first = [1, 2, 3] Cell In [1], line 1 *first = [1, 2, 3] ^ SyntaxError: starred assignment target must be in a list or tuple python # just add `,` would be fine # now the LHS is a tuple *first, = [1, 2, 3] first [1, 2, 3] python first, second, *rest = [1] --------------------------------------------------------------------------- ValueError Traceback (most recent call last) Cell In [3], line 1 ----\u003e 1 first, second, *rest = [1] ValueError: not enough values to unpack (expected at least 2, got 1) 📒 常见的一个做法是将 * 和 _ 结合在一起使用（也就是 *_），表示我们不关心它捕获的变量 python first, *_ = [1, 2, 3] first ","date":"2022-12-05","objectID":"/zh-cn/unpacking-in-python/:2:1","series":null,"tags":["Python"],"title":"Python 3.5 的解包操作符","uri":"/zh-cn/unpacking-in-python/#starred-assignmentexpression"},{"categories":["Programming-Languages"],"content":" 更进一步从 Python 3.5 开始，我们可以在更多的情况下使用 * 和 **3 情况1⃣️：在函数调用里面，我们想要使用几次就可以使用几次 python foo, bar = {'a': 1, 'b': 2}, {'c': 3, 'd': 4} dict(**foo, **bar) # dict is a function 📒dict 中的 keys 的优先级是右边大于左边。换句话说，后面出现的 key 的值总是会覆盖前面出现的。看下面这个例子 python {**{'a': 1, 'b': 2}, **{'a': 3}} {'a': 3, 'b': 2} 📒当我们在函数调用里面使用 ** 的时候，需要注意一个问题：我们需要确保没有重复的 key python dict(**{'a': 1, 'b': 2}, **{'a': 3}) --------------------------------------------------------------------------- TypeError Traceback (most recent call last) Cell In [5], line 1 ----\u003e 1 dict(**{'a': 1, 'b': 2}, **{'a': 3}) TypeError: dict() got multiple values for keyword argument 'a' 情况2⃣️：我们可以在 tuple/list/set/dict 字面值中使用。但是不能在 list/set/dict comprehensions 里面使用😺 python # an example drawn from PEP 448 \u003e\u003e\u003e *range(4), 4 (0, 1, 2, 3, 4) \u003e\u003e\u003e [*range(4), 4] [0, 1, 2, 3, 4] \u003e\u003e\u003e {*range(4), 4} {0, 1, 2, 3, 4} \u003e\u003e\u003e {'x': 1, **{'y': 2}} {'x': 1, 'y': 2} {'x': 1, 'y': 2} python matrix = [ [1, 2, 3] [4, 5, 6] ] [*sublist for sublist in matrix] Cell In [7], line 5 [*sublist for sublist in matrix] ^ SyntaxError: iterable unpacking cannot be used in comprehension ","date":"2022-12-05","objectID":"/zh-cn/unpacking-in-python/:2:2","series":null,"tags":["Python"],"title":"Python 3.5 的解包操作符","uri":"/zh-cn/unpacking-in-python/#更进一步"},{"categories":["Programming-Languages"],"content":" 总结Python 的解包操作符让编程轻松很多。它提供了一种直观的解构可迭代对象的手段。在这个操作符的帮助下，我们可以避免一些愚蠢的索引错误🙅 ","date":"2022-12-05","objectID":"/zh-cn/unpacking-in-python/:3:0","series":null,"tags":["Python"],"title":"Python 3.5 的解包操作符","uri":"/zh-cn/unpacking-in-python/#总结"},{"categories":["Programming-Languages"],"content":" 参考 Python iterators ↩︎ PEP 3132. Extended Iterable Unpacking ↩︎ PEP 448. Additional Unpacking Generalizations ↩︎ ","date":"2022-12-05","objectID":"/zh-cn/unpacking-in-python/:4:0","series":null,"tags":["Python"],"title":"Python 3.5 的解包操作符","uri":"/zh-cn/unpacking-in-python/#参考"},{"categories":["Programming-Languages"],"content":"Python3.6 引入的 f-strings 的简单介绍","date":"2022-11-16","objectID":"/zh-cn/f-strings-in-python/","series":null,"tags":["Python"],"title":"Python3.6 的 f-strings","uri":"/zh-cn/f-strings-in-python/"},{"categories":["Programming-Languages"],"content":" 信息 更新： 2024-04-19，重写全文，根据使用场景分类，方便作为 cheatsheet ","date":"2022-11-16","objectID":"/zh-cn/f-strings-in-python/:0:0","series":null,"tags":["Python"],"title":"Python3.6 的 f-strings","uri":"/zh-cn/f-strings-in-python/#"},{"categories":["Programming-Languages"],"content":" 引言字符串格式化绝对可以算得上日常生活中最为常用的功能之一，我们经常需要输出各种字符串还需要精确控制其格式 在一些过时的 Python 教程上，还可以看到使用 % 来格式化字符串。但其实在 Python3.6 之后，f-strings 已经成了格式化字符串的最优解，优点包括： 可以在字符串字面值（String literal）里面内嵌表达式 可读性非常强 下面的简单对比就可以看出 f-strings 在可读性上的优势： python name = \"Martin\" f\"My name is {name}\" 'My name is Martin' python name = \"Martin\" \"My name is %s\" % name 'My name is Martin' 在上面的例子中我们分别用两种格式化字符串的方式实现了同样功能 看一眼 f-strings 就知道这个字符串是要输出名字（当然这要求你用的是有意义的变量，比如这里用的是 name）。而如果用旧的 % 字符串格式化字符串，则稍微显得不那么自然，我们首先会看到 %s 占位符，此时我们需要向右看才知道这里会放置什么变量 这里的例子不长所以没啥差别，但是如果用 % 格式化的字符串很长的话，看代码就会有割裂感，你的眼睛需要来回左右移动。而且这不仅仅是阅读代码上不大自然，如果是自己写很长的字符串，还得核对一遍占位符和变量的顺序是否一致，这无疑是一个负担 😫 注意 f-strings 对 Python 版本的最低要求是 3.6 ","date":"2022-11-16","objectID":"/zh-cn/f-strings-in-python/:1:0","series":null,"tags":["Python"],"title":"Python3.6 的 f-strings","uri":"/zh-cn/f-strings-in-python/#引言"},{"categories":["Programming-Languages"],"content":" 语法规则f-strings 的语法规则很简单，简单来说，它只是在普通字符串（\"...\" or '...') 的前面加上了 f 前缀，这样你就得到了一个 f-strings python f\"...\" # or f'...' 在 f-strings 里面，我们可以放置形如 {expression} 的文本，它的意思是：Python 会帮我们对这个表达式求值，并进行格式化的输出 当然，只是求值还不够，有时候我们想要进行各种控制 浮点数的精度 是否要显示正负数的 + 或者是 - … 而这些则是通过 format_specifier 进行控制，它包含了多个可选的配置项。从语法上看，format_specifier 接在 expression 后面，两者之间用 : 隔开，所以确切来说，f-strings 的语法规则是下面这样的 python f\"...{expression:format_specifier}...\" 下面我们来按照功能进行分类，看看用 f-strings 我们都可以做些什么 ","date":"2022-11-16","objectID":"/zh-cn/f-strings-in-python/:2:0","series":null,"tags":["Python"],"title":"Python3.6 的 f-strings","uri":"/zh-cn/f-strings-in-python/#语法规则"},{"categories":["Programming-Languages"],"content":" 各种使用场景","date":"2022-11-16","objectID":"/zh-cn/f-strings-in-python/:3:0","series":null,"tags":["Python"],"title":"Python3.6 的 f-strings","uri":"/zh-cn/f-strings-in-python/#各种使用场景"},{"categories":["Programming-Languages"],"content":" 基本使用我们先考虑最简单的情况：不包含任何 format_specifier。下面是一个简单的例子 python left, right = 3, 5 f\"{left} + {right} = {left + right}\" '3 + 5 = 8' 技巧 用 {} 来充当占位符就很自然引申出一个问题——如果要在字符串里面输出 {} 这两个字符怎么办？答案也很简单，我们只要用 {{}} 即可 python f\"{{}}\" '{}' 值得一提的还有，expression 里面不允许出现 : 和 ! 和 \\ 实际上 expression 里面也很少会包含这几个字符。\\ 的一个使用场景是用来转义 ' 或者 \"，但其实只要我们内外用的是不同的引号格式即可 至于 :，在 PEP4981 里面举例可能应用场景是 lambda 表达式，此时我们只需用一对括号将 lambda 表达式括起来即可： python # Note that we need to add () around the lambda expression f\"{(lambda x: x + 1)(3)}\" '4' ","date":"2022-11-16","objectID":"/zh-cn/f-strings-in-python/:3:1","series":null,"tags":["Python"],"title":"Python3.6 的 f-strings","uri":"/zh-cn/f-strings-in-python/#基本使用"},{"categories":["Programming-Languages"],"content":" 不同表示Python 对象一般会有 2 种字符串的表示，分别对应 __str__ 和 __repr__ 方法，其中前者一般是面向客户的，可读性较好；后者一般是面向开发者的，便于调试程序。f-strings 对此提供了支持，我们可以指定要用哪一种 python {foo:!s} # it's equal to call str(foo) first {foo:!r} # similarily, call repr(foo) first {foo:!a} # similarily，call ascii(foo) first ","date":"2022-11-16","objectID":"/zh-cn/f-strings-in-python/:3:2","series":null,"tags":["Python"],"title":"Python3.6 的 f-strings","uri":"/zh-cn/f-strings-in-python/#不同表示"},{"categories":["Programming-Languages"],"content":" 补齐与对齐补齐和对齐涉及到下面几个问题 要用什么字符补齐？下面用 fill 表示 要补齐到多长？下面用 width 表示 要如何对齐？下面用 align 表示 因此，补齐和对齐的语法规则是 [[fill]align][width] 注意 在语法规则里面，[] 表示这是可选的部分 其中 align 支持下面这几种对齐方式： python \u003c # left-aligned \u003e # right-aligned ^ # centered = # only valid for numeric types, pad between sign and digits 举例如下 python f\"{-1:*^9}\" # set `fill` to *, and set width to 9 '***-1****' python f\"{-1:*\u003e9}\" # set `fill` to *, and set width to 9 '*******-1' python f\"{-1:*\u003c9}\" # set `fill` to *, and set width to 9 '-1*******' python f\"{-1:*=9}\" # set `fill` to *, and set width to 9 '-*******1' ","date":"2022-11-16","objectID":"/zh-cn/f-strings-in-python/:3:3","series":null,"tags":["Python"],"title":"Python3.6 的 f-strings","uri":"/zh-cn/f-strings-in-python/#补齐与对齐"},{"categories":["Programming-Languages"],"content":" 符号位的显示支持下面这几种 python + # both positive and negative - # only negative (default) space # a leading spaces for positive and minus sign for negative python f\"{1:+}\" '+1' python f\"{-1:+}\" '-1' python assert f\"{1}\" == f\"{1:-}\" # because it's the default behavior ","date":"2022-11-16","objectID":"/zh-cn/f-strings-in-python/:3:4","series":null,"tags":["Python"],"title":"Python3.6 的 f-strings","uri":"/zh-cn/f-strings-in-python/#符号位的显示"},{"categories":["Programming-Languages"],"content":" 浮点数精度浮点数要保留 n 位小数我们就用 .nf，跟 C/C++ 的 printf 有点像，比如 python x = 1.23456 f\"{x:.1f}\" '1.2' python x = 1.23456 f\"{x:.3f}\" '1.235' ","date":"2022-11-16","objectID":"/zh-cn/f-strings-in-python/:3:5","series":null,"tags":["Python"],"title":"Python3.6 的 f-strings","uri":"/zh-cn/f-strings-in-python/#浮点数精度"},{"categories":["Programming-Languages"],"content":" -0.0 的问题从 Python3.11 起，增加了可选的 z 用来处理 -0.。因为调查显示2，大多数情况下我们都不想得到 -0.0 这样的输出 python x = -0.0001 f\"{x:.1f}\" # set the precision to 1, so it will round to -0.0 '-0.0' python x = -0.0001 f\"{x:z.1f}\" # with z, we will get 0.0 rather than -0.0 '0.0' ","date":"2022-11-16","objectID":"/zh-cn/f-strings-in-python/:3:6","series":null,"tags":["Python"],"title":"Python3.6 的 f-strings","uri":"/zh-cn/f-strings-in-python/#-00-的问题"},{"categories":["Programming-Languages"],"content":" 不同进制的表示Python 提供了几个方便的函数，比如 bin，oct 等来获得不同进制的表示，根据 f-strings 的定义，我们可以选择写出 {bin(a)} 来获得 a 的二进制的表示（其他进制的表示同理）。但 f-strings 其实已经帮你考虑到这点了，它默认支持如下的进制表示 python b # base 2 o # base 8 d # base 10 x # base 16, low-case letters X # base 16, upper-case letters 技巧 可以加上 #，就会添加对应进制表示的前缀，比如 0b 等 python f\"{15:b}\" # represent 15 in base 2 '1111' python f\"{15:#b}\" # represent 15 in base 2, use # to add prefix 0b '0b1111' python f\"{15:#X}\" # represent 15 in base 16, use # to add prefix 0X '0XF' ","date":"2022-11-16","objectID":"/zh-cn/f-strings-in-python/:3:7","series":null,"tags":["Python"],"title":"Python3.6 的 f-strings","uri":"/zh-cn/f-strings-in-python/#不同进制的表示"},{"categories":["Programming-Languages"],"content":" 千分位分隔符在金融或者经济学里面，经常会用 , 作为千分位分隔符，f-strings 对此提供了支持，除此之外，还可以指定 _ 作为千分位的分隔符34: python f\"{123456789:,}\" '123,456,789' python f\"{1234.56789:,}\" '1,234.56789' python f\"{123456789:_}\" '123_456_789' python f\"{1234.56789:_}\" '1_234.56789' ","date":"2022-11-16","objectID":"/zh-cn/f-strings-in-python/:3:8","series":null,"tags":["Python"],"title":"Python3.6 的 f-strings","uri":"/zh-cn/f-strings-in-python/#千分位分隔符"},{"categories":["Programming-Languages"],"content":" Trick从 Python3.8 起，我们可以用 {expression=} 的形式，它会自动帮我们转换成 expression={expression}5，这有什么用呢？ 在调试 Python 程序的时候，我经常会写出如下的 f-strings 输出我关心的变量的值，但有点麻烦的是，我不得不写两次变量的名字 python f\"left={left}, right={right}\" 'left=3, right=5' 可以看到，里面存在一些冗余，因此，一个更好的方式是 python f\"{left=}, {right=}\" 'left=3, right=5' ","date":"2022-11-16","objectID":"/zh-cn/f-strings-in-python/:3:9","series":null,"tags":["Python"],"title":"Python3.6 的 f-strings","uri":"/zh-cn/f-strings-in-python/#trick"},{"categories":["Programming-Languages"],"content":" 总结在我刚开始学习 Python 的时候，当时的教程都是在用 % 来格式化输出，后来的推荐是 str.format 方法。而到了 f-string 随着 Python3.6 发布之后，似乎统一了字符串输出的 Best practice，大家都在用这个。这也是符合 Python 设计哲学的——应该只有一种显而易见的方式做到一件事🚀 ","date":"2022-11-16","objectID":"/zh-cn/f-strings-in-python/:4:0","series":null,"tags":["Python"],"title":"Python3.6 的 f-strings","uri":"/zh-cn/f-strings-in-python/#总结"},{"categories":["Programming-Languages"],"content":" 参考 PEP 498. Literal String Interpolation ↩︎ PEP 682. Format Specifier for Signed Zero ↩︎ PEP 378. Format Specifier for Thousands Separator ↩︎ PEP 515. Underscores in Numeric Literals ↩︎ https://docs.python.org/3/whatsnew/3.8.html#f-strings-support-for-self-documenting-expressions-and-debugging ↩︎ ","date":"2022-11-16","objectID":"/zh-cn/f-strings-in-python/:5:0","series":null,"tags":["Python"],"title":"Python3.6 的 f-strings","uri":"/zh-cn/f-strings-in-python/#参考"},{"categories":["Programming-Languages"],"content":"海象表达式的简单介绍","date":"2022-10-29","objectID":"/zh-cn/walrus-operator-in-python/","series":null,"tags":["Python"],"title":"海象表达式简明教程（Python 3.8）","uri":"/zh-cn/walrus-operator-in-python/"},{"categories":["Programming-Languages"],"content":" 引言今天要说的是在 Python3.8 中引入的新特性：海象运算符（Walrus operator），这是一个备受争议的特性，但它最后还是通过并发布了🤔 在 Python 中，赋值语句（=）并不是 expression 而是 statement。海象表达式则是 expression。关于 statement 和 expression 的区别可以简单理解为：expression 总是会返回值，而 statement 不返回值。 两者的区别可以看下面的代码： python # `=` is a statement, so it will print no value x = 5 python # `:=` is an expression, so it will evaluate to a value # not recommended :) (x := 5) 5 📒 这里海象表达式需要加上 () 是为了避免造成混淆。毕竟在 Python设计哲学-Zen 里面提到了一条：“There should be one– and preferably only one –obvious way to do it.\"。如果不加 () 就能使用的话，开发者就会陷入到该用哪一个的困惑之中🤕️ 在 C/C++ 中，= 是 expression。如果你有相关的编程背景的话，你可能对下面的代码不陌生 c // = will store the value in the LHS(left-hand-side) variable. // , and it has the value of the LHS // so we store the result of `foo` function call to `a` // , then we check if `a` \u003e 0 while ( (a = foo(...)) \u003e 0 ) { ... } 但是在 Python 3.8 之前是无法做到类似的事情的，因为 = 在 Python 里面是一个 statement，并不会返回值。这就是海象表达式发挥作用的地方 🤩 ","date":"2022-10-29","objectID":"/zh-cn/walrus-operator-in-python/:1:0","series":null,"tags":["Python"],"title":"海象表达式简明教程（Python 3.8）","uri":"/zh-cn/walrus-operator-in-python/#引言"},{"categories":["Programming-Languages"],"content":" 语法规则 海象表达式的语法很简单：NAME := EXPRESSION。:= 左边放变量名，右边则是表达式。表达式的值会被绑定到 NAME 上。 这里的 NAME 不能是属性或者索引 python # a dummy example. we bind `1 + 2 + 3` to `res` for future usage if (res := 1 + 2 + 3) \u003e 5: print(f\"res is {res}\") res is 6 python class foo: val: int = 0 some_foo = foo() (some_foo.val := 1) Input In [4] (some_foo.val := 1) ^ SyntaxError: cannot use assignment expressions with attribute python x = [1, 2, 3] (x[1] := 3) Input In [5] (x[1] := 3) ^ SyntaxError: cannot use assignment expressions with subscript 关于 NAME 的作用域 海象表达式不会引入新的作用域 🤩 NAME 可以在当前的作用域使用，同时有个例外：如果是在 list/dict/set comprehension 里面使用。则是是在 enclosing scope 里面. 可以看下面的例子： python s = [1, 2, 3] # the list comprehension forms a new scope. # its enclosing scope is the global scope double_s = [item * 2 for item in s] # `item` is not in the global scope :) print(item) --------------------------------------------------------------------------- NameError Traceback (most recent call last) Input In [6], in \u003ccell line: 7\u003e() 4 double_s = [item * 2 for item in s] 6 # `item` is not in the global scope :) ----\u003e 7 print(item) NameError: name 'item' is not defined python s = [1, 2, 3] # the list comprehension forms a new scope. # its enclosing scope is the global scope double_s = [last := item * 2 for item in s] # so we can use `last` variable here print(last) 优先级规则：除了比 , 高，比其他的都低 python x = 1, 2 x (1, 2) python (x := 1, 2) x 1 ","date":"2022-10-29","objectID":"/zh-cn/walrus-operator-in-python/:2:0","series":null,"tags":["Python"],"title":"海象表达式简明教程（Python 3.8）","uri":"/zh-cn/walrus-operator-in-python/#语法规则"},{"categories":["Programming-Languages"],"content":" 适用场景 📒 结合参考了1的内容和平常的编程经验。感觉海象表达式最方便的还是：处理返回值可能为 None 的函数 对于返回值可能为 None 的函数，以前经常是先用 = 赋值语句保存函数的返回结果。不为 None 的时候要使用返回值来进行下一步处理。此时代码看起来大概是这样： python some_thing = foo(....) if some_thing: ... else: ... 下面用 re 库举例子 python import re # define a regex pattern to extract digits in a string DIGIT_PATTERN = r'\\d+' text = 'There are 10 dogs' # re.search will return None if no match was found. match = re.search(DIGIT_PATTERN, text) if match: # group(0) will return the entire match print(f\"Find match: {match.group(0)}\") else: print(\"Not match was found\") Find match: 10 为了能在后面使用 match.group() 的时候 Python 解释器不会返回 AttributeError: 'NoneType' object has no attribute 'group' 错误，我们不得不用一个中间变量 match 暂时保存 re.search 的返回值对其进行检查，显得似乎有点冗余。我们无法直接将他们连起来：re.search(DIGIT_PATTERN, text).group(0) 📒 插点题外话：在 Rust 里面，可能返回 None 的返回类型是 Option\u003cT\u003e。我们可以使用 ? 来处理这种情况，它会尝试提取里面的值，如果失败了就会尽早终止报错。所以在 Rust 里面，我们可以这样（假设 Rust 也有类似的 API）：re.search(DIGIT_PATTERN, text)?.group(0) 🍺 另外一点是：可读性稍弱，当然这是个人的主观感受。有一点不舒服是：只有可能在 match is not None 的时候我们才会使用 match 变量，我们不会在 else 分支里面使用。但是如果很快地从上往下看代码的话，单独另起一行的 match = ... 就像是后面都可以使用一样🤣 此时我们可以选择用 := 来绑定其返回值 python if match := re.search(DIGIT_PATTERN, text): # group(0) will return the entire match print(f\"Find match: {match.group(0)}\") else: print(\"Not match was found\") Find match: 10 1 里面提到支持 := 的一个理由是：调查显示，开发者往往喜欢写比较少行的代码而不是让代码更短。这里我们就少写了一行代码。同时看一眼就知道 match 的作用域👏 类似的，在 while 循环中我们也可以借用这个特性 python val = foo(...) while val: # do something while val is not None val = foo(...) ","date":"2022-10-29","objectID":"/zh-cn/walrus-operator-in-python/:3:0","series":null,"tags":["Python"],"title":"海象表达式简明教程（Python 3.8）","uri":"/zh-cn/walrus-operator-in-python/#适用场景"},{"categories":["Programming-Languages"],"content":" 🆚 =几个值得一提的不同： = 是 statement，:= 是 expression。这也决定了他们的适用场景是不同的 只有 = 支持foo = bar = 1 这种连续使用的情况；而且 = 左边可以是 foo.bar 这种属性，或者是 foo[1] 这种索引的形式，但是 := 左边只能是一个简单的变量名 = 支持 += 这种 augmented 的形式，但是 := 不行 ","date":"2022-10-29","objectID":"/zh-cn/walrus-operator-in-python/:4:0","series":null,"tags":["Python"],"title":"海象表达式简明教程（Python 3.8）","uri":"/zh-cn/walrus-operator-in-python/#-"},{"categories":["Programming-Languages"],"content":" 总结在我看来，海象表达式在我前面提到的引用场景中是挺有用的（推荐使用👍），可读性提高不少🚀。但是1中的某些例子我觉得可能是负优化了👀 ","date":"2022-10-29","objectID":"/zh-cn/walrus-operator-in-python/:5:0","series":null,"tags":["Python"],"title":"海象表达式简明教程（Python 3.8）","uri":"/zh-cn/walrus-operator-in-python/#总结"},{"categories":["Programming-Languages"],"content":" 参考 PEP 572. Assignment Expressions ↩︎ ↩︎ ↩︎ ","date":"2022-10-29","objectID":"/zh-cn/walrus-operator-in-python/:6:0","series":null,"tags":["Python"],"title":"海象表达式简明教程（Python 3.8）","uri":"/zh-cn/walrus-operator-in-python/#参考"},{"categories":["Programming-Languages"],"content":"Python 3.10 的 pattern matching 的简单介绍","date":"2022-10-16","objectID":"/zh-cn/pattern-matching-in-python/","series":null,"tags":["Python"],"title":"模式匹配简明教程（Python 3.10）","uri":"/zh-cn/pattern-matching-in-python/"},{"categories":["Programming-Languages"],"content":" 引言今天我想要谈一下 Python 3.10 提出的新特性1——模式匹配🎉 学习过 C 语言的人想必对下面的 switch 语句不陌生， c switch (expression) { case constant_1: // statements break; case constant_2: // statements break; // Fall through // the value of the expression can be either constant_3 or constant_4 :) case constant_3: case constant_4: // statements default: // default statements } 概括一下，C 语言的 switch 语句的几点规则： expression 必须是 int 或者 char 类型；constant 必须是 int 或 char 常量 switch 语句的执行过程： 计算出 expression 的值，拿着这个值从上到下检查是否和某一条 case 语句的 constant 相等，如果一样就会执行里面的 statements 和后面的 case 语句的 statements，除非遇到了 break。这个特性叫做 Fall through，我们可以利用这个特性，将多个 case 语句堆叠在一起，表示逻辑上的「或」的关系 存在 default 表示默认情况，用于兜底，当前面的 case 语句都匹配失败的时候执行 Python 则并没有提供 switch 语句，我们可以用 if...elif..elif..else 达到同样的效果，举例来说，假设我们要根据 list 的长度执行不同的操作，我们可以这么写： python some_list = [1, 2, 3, 4, 5] if len(some_list) == 1: # do something when the length is 1 ... # or more pythonic way: elif len(some_list) in [3, 5]: elif len(some_list) == 3 or len(some_list) == 5: # do something when the length is 3 or 5 ... else: ... 上面这一连串的 if...elif..elif..else 其实可读性稍微差些，另外它还违反了 DRY(Don’t repeat yourself) 原则，我们多次写下 len(some_list) 当然我们可以选择先用一个变量 length 记住 some_list 的长度，这样就可以让我们少打一些代码，但若情况更复杂写，这个技巧也不适用了 解决上面的一个更优雅的方式就是本文要讲到的：Pattern matching ⬇️ python match len(some_list): case 1: # do something when the length is 1 ... case 3 | 5: # do something when the length is 3 or 5 ... case _: # equal to the `default:` ... ","date":"2022-10-16","objectID":"/zh-cn/pattern-matching-in-python/:1:0","series":null,"tags":["Python"],"title":"模式匹配简明教程（Python 3.10）","uri":"/zh-cn/pattern-matching-in-python/#引言"},{"categories":["Programming-Languages"],"content":" 基本的语法下面我给出 Pattern matching 的基本语法 python match subject: case \u003cpattern_1\u003e: \u003caction_1\u003e case \u003cpattern_2\u003e: \u003caction_2\u003e case \u003cpattern_3\u003e: \u003caction_3\u003e # [Optional] wildcard to cover all situations case _: \u003caction_wildcard\u003e 从语法上看，和前面 C 语言的 switch 语句差不多。区别在于： 虽然都是从上到下进行检查，但是 Python 的 pattern matching 不存在 Fall through 情况，只会执行匹配的 case 语句里面的代码。执行完就退出。所以也不用在每个 case 的代码块里最后加一个 break 没有 default 关键字，但是我们可以用 case _ 来捕获所有的情况，这其实用到了后面会讲到的 Wildcard pattern 这里的 subject 和 pattern 比 C 语言的强大多了，不仅仅是整型和字符类型，pattern 彼此之间还可以组合嵌套。后面会对其进行详细说明 ","date":"2022-10-16","objectID":"/zh-cn/pattern-matching-in-python/:2:0","series":null,"tags":["Python"],"title":"模式匹配简明教程（Python 3.10）","uri":"/zh-cn/pattern-matching-in-python/#基本的语法"},{"categories":["Programming-Languages"],"content":" Patterns在 pattern matching 里面，Pattern 主要有下面两个作用： 对 subject 的结构进行约束（structure constrait） 可以使用变量绑定 subject 的某些部分（bind variables），用于后续的处理，见 Capture pattern 下面我们对不同的 patterns 进行探讨 :) 为了避免造成困惑，有必要提前进行一下说明：在 pattern matching 匹配序列时候，() 和 [] 都是可选的。比如，case foo, bar 和 case (foo, bar) 和 case [foo, bar] 都是等价的。这点和我们给序列做 unpacking 的时候一致 ","date":"2022-10-16","objectID":"/zh-cn/pattern-matching-in-python/:3:0","series":null,"tags":["Python"],"title":"模式匹配简明教程（Python 3.10）","uri":"/zh-cn/pattern-matching-in-python/#patterns"},{"categories":["Programming-Languages"],"content":" Capture patternCapture pattern 的意思是说我们在检查 pattern 是否匹配的时候，可以用变量名绑定到它的任意一个部分，我们就可以在匹配成功之后使用这些变量 python some_list = [\"foo\", \"bar\"] match some_list: # we want to match a seq which has length = 2 # , we also use `first` and `second` to capture \\ # the 1st and 2nd elements here. case [first, second]: # we can access first, second now print(f'the 1st element: {first}, 2nd element: {second}') the 1st element: foo, 2nd element: bar 经常跟序列打交道的人想必对下面的代码不会陌生，我们可以用 *\u003cname\u003e 来 unpacking python *before, last = [1, 2, 3, 4] assert last == 4, \"Error\" first, *middle, last = [1, 2, 3, 4] assert first == 1 and last == 4, \"Error\" first, *rest = [1, 2, 3, 4] assert first == 1, \"Error\" 类似的，在 pattern matching 里面也可以这样，用一个变量捕获多个值 python some_list = [\"foo\", \"bar\", \"another_foo\", \"another_bar\"] match some_list: # we want to match a seq # , we also use `*rest` to capture the remaining elements case [first, *rest]: print(f'the 1st element: {first}, 2nd element: {rest}') the 1st element: foo, 2nd element: ['bar', 'another_foo', 'another_bar'] ","date":"2022-10-16","objectID":"/zh-cn/pattern-matching-in-python/:3:1","series":null,"tags":["Python"],"title":"模式匹配简明教程（Python 3.10）","uri":"/zh-cn/pattern-matching-in-python/#capture-pattern"},{"categories":["Programming-Languages"],"content":" Literal patternLiteral pattern 指的是我们可以指定字面值来对 Pattern 进行约束。这里的字面值可以是 number literal, string literals, True, False 还有 None 📒 对于 number literals 和 string literals 这两者 Python 会使用 == 进行比较，而对于 True/False/None 这三个则是使用 is 来进行判断。注意这个细节 python some_list = [\"foo\", \"bar\"] match some_list: # we want to match a seq which has length = 2 # , the 1st element should be equal to \"foo\" # , and we use `second` to capture the 2nd element case [\"foo\", second]: print(f'the 2nd element: {second}') the 2nd element: bar python some_list = [True] match some_list: case [1]: print(f'Matched, 1 == True') Matched, 1 == True ","date":"2022-10-16","objectID":"/zh-cn/pattern-matching-in-python/:3:2","series":null,"tags":["Python"],"title":"模式匹配简明教程（Python 3.10）","uri":"/zh-cn/pattern-matching-in-python/#literal-pattern"},{"categories":["Programming-Languages"],"content":" Wildcard pattern这个其实在 Python 里面挺常见，我们常常使用 _ 表示我们不关心某个变量是多少。在 pattern matching 里面，_ 会和任何的东西匹配，但是不会绑定任何变量 python some_list = [\"foo\", \"bar\"] match some_list: # we want to match a seq which has length = 2 # , the 1st element should be equal to \"foo\" # , and we use `_` to ignore the 2nd value case [\"foo\", _]: print(f'the 2nd value: {_}') # you should see empty output because we aren't binding value here the 2nd value: 另外一个常见的用法就是之前出现过的 case _，因为 _会匹配任何情况，所以常常把 case _ 放在最后表示默认情况 python some_list = [\"foo\", \"bar\"] match some_list: # this case branch will not be matched case [\"bar\", _]: print('Match successfully') case _: print('Default case') Default case ","date":"2022-10-16","objectID":"/zh-cn/pattern-matching-in-python/:3:3","series":null,"tags":["Python"],"title":"模式匹配简明教程（Python 3.10）","uri":"/zh-cn/pattern-matching-in-python/#wildcard-pattern"},{"categories":["Programming-Languages"],"content":" Or pattern就像 if 条件语句我们可以使用 or 表示多种可能的匹配情况，在 pattern matching 里面我们也有类似的语法。跟其他大多数语言一样，Python 选择使用 | 来表达「或」的逻辑关系。我们可以很方便声明备选项 python some_list1 = [\"foo\"] some_list2 = [\"bar\"] match some_list1: # we want to match a seq which has length = 1 # , the 1st element can be \"foo\" or \"bar\" case [\"foo\" | \"bar\"]: print('[First match] Match foo or bar') match some_list2: case [\"foo\" | \"bar\"]: print('[Second match] Match foo or bar') [First match] Match foo or bar [Second match] Match foo or bar 上面的 Or pattern 的缺点是：我们无法知道我们具体匹配到了什么哪一个 ","date":"2022-10-16","objectID":"/zh-cn/pattern-matching-in-python/:3:4","series":null,"tags":["Python"],"title":"模式匹配简明教程（Python 3.10）","uri":"/zh-cn/pattern-matching-in-python/#or-pattern"},{"categories":["Programming-Languages"],"content":" As pattern在上一个例子中，我们可能匹配到多个选项，那么如何知道我们具体匹配到哪一个选项呢？因为我们可能需要根据具体匹配到的东西来决定要如何处理。在 pattern matching 里面，可以使用 as 来绑定变量 python some_list = [\"foo\"] match some_list: # we want to match a seq which has length = 1 # , the 1st element can be \"foo\" or \"bar\" # we bind matched string literal with `matched_element` case (\"foo\" | \"bar\") as matched_element: print(f'Match {matched_element}') ","date":"2022-10-16","objectID":"/zh-cn/pattern-matching-in-python/:3:5","series":null,"tags":["Python"],"title":"模式匹配简明教程（Python 3.10）","uri":"/zh-cn/pattern-matching-in-python/#as-pattern"},{"categories":["Programming-Languages"],"content":" Class patternPython 是一个动态类型语言，有时我们也会有需要根据类型来决定是否要匹配的时候。我们当然可以选择自己在后面使用 isinstance() 来判断，但还有更好的方法。下面我将从从基本的例子出发带大家看看如何加上类型约束 python some_list = [\"foo\", 1, 3.14] match some_list: # match without type constraints case [s, v1, v2]: if isinstance(s, str) and isinstance(v1, int) and isinstance(v2, float): print(f'Match {s} - {v1} - {v2}') Match foo - 1 - 3.14 第一个写法：考虑用 Capture pattern，类型约束放代码块里 python some_list = [\"foo\", 1, 3.14] match some_list: # match with type constraints case [str() as s, int() as v1, float() as v2]: print(f'Match {s} - {v1} - {v2}') Match foo - 1 - 3.14 此时我们在 pattern 里加上类型约束，这里写法上类似 Literal pattern，我们在对应位置声明我们想要匹配的类型，同时为了后面能输出，我们还需要 as 关键字将其绑定到变量上。但上面的写法过于冗长，好在 Python 为我们提供了语法糖🍬 python some_list = [\"foo\", 1, 3.14] match some_list: # match with type constraints case [str(s), int(v1), float(v2)]: print(f'Match {s} - {v1} - {v2}') Match foo - 1 - 3.14 ","date":"2022-10-16","objectID":"/zh-cn/pattern-matching-in-python/:3:6","series":null,"tags":["Python"],"title":"模式匹配简明教程（Python 3.10）","uri":"/zh-cn/pattern-matching-in-python/#class-pattern"},{"categories":["Programming-Languages"],"content":" Mapping pattern前面都是对于一个序列的匹配，这里则是对 dict 的匹配。相信在看完前面的各种 pattern 的例子之后，理解 dict 的匹配也没有什么难度。但有下面几点注意事项： dict 的匹配是通过限制 Key-Value 的结构。其中 Key 必须是字面值或者枚举类型的值（出于性能的考量），Value 则没有这个限制 使用 **\u003cname\u003e 来捕获我们没有写在 pattern 里面的 Key-Value pair。否则默认是忽略掉的 但是 **_ 是不行的，因为本来就忽略掉，而 **_ 中的 _ 表示不绑定任何匹配的东西，纯粹是多此一举 python some_dict = { 'first_name': 'foo', 'second_name': 'bar' } match some_dict: case {'first_name': first_name}: print(f'[First match] The first_name: {first_name}') match some_dict: case {'first_name': first_name, **rest}: print(f'[Second match] The rest: {rest}') [First match] The first_name: foo [Second match] The rest: {'second_name': 'bar'} ","date":"2022-10-16","objectID":"/zh-cn/pattern-matching-in-python/:3:7","series":null,"tags":["Python"],"title":"模式匹配简明教程（Python 3.10）","uri":"/zh-cn/pattern-matching-in-python/#mapping-pattern"},{"categories":["Programming-Languages"],"content":" Value pattern使用「有名字的变量」作为参数值或澄清特定值的含义是很好的编程风格，这是 Literal pattern 欠缺的。比如 case (HttpStatus.OK, body) 是比 case (200, body) 好的 在 Python 里面要实现 Value pattern 的挑战是要和前面的 Capture pattern 区分开，要让 Python 可以区分我们是要加一个「有名字的常量」这个约束还是我们在使用 Capture pattern 绑定变量。关于这点的讨论可以参见2 最后 Python 提供的解决方案是一个受限的 Value pattern，它仅支持 foo.bar 这种形式的 Value pattern。比较常见的就是用于枚举类型，看下面这个例子 python from enum import Enum class HttpStatusCode(Enum): CONTINUE = 100 OK = 200 some_list = [HttpStatusCode[\"OK\"]] match some_list: case [HttpStatusCode.OK as status_code]: print(f\"Receive {status_code}\") Receive HttpStatusCode.OK ","date":"2022-10-16","objectID":"/zh-cn/pattern-matching-in-python/:3:8","series":null,"tags":["Python"],"title":"模式匹配简明教程（Python 3.10）","uri":"/zh-cn/pattern-matching-in-python/#value-pattern"},{"categories":["Programming-Languages"],"content":" 将 Pattern matching 用在一个类上如果只能将 pattern matching 用在内建的类型上，似乎用处没有那么大。但其实 Python 还允许我们对自己自定义的类的对象使用 pattern matching。 考虑到应用场景，我们对一个对象做 pattern matching 的时候常常是想要检查这个对象是否为某个类，我们还可能关心它的某些字段，想要提取对应的字段的值。但是在 Python 里，这个实现起来有困难2，主要是类的字段非常多，大部分是 __repr__ 这种 magic methods，而且这些字段是无序的。因为是无序的，我们无法直接在 pattern 里面按位置绑定变量，看下面这个例子： python class Point: \"\"\" A simple class represents a Point in a 2D\"\"\" def __init__(x: int, y: int): self.x = x self.y = y some_point = Point(1, 2) match some_point: # the intuitive way, we want to match a Point type # , and we want to bind the `x` and `y` and their two fields respectively case Point(x, y): print(f\"The x: {x}\") print(f\"The y: {y}\") --------------------------------------------------------------------------- TypeError Traceback (most recent call last) Input In [17], in \u003ccell line: 7\u003e() 4 self.x = x 5 self.y = y ----\u003e 7 some_point = Point(1, 2) 9 match some_point: 10 # the intuitive way, we want to match a Point type 11 # , and we want to bind the `x` and `y` and their two fields respectively 12 case Point(x, y): 13 print(f\"The x: {x}\") 14 print(f\"The y: {y}\") TypeError: Point.__init__() takes 2 positional arguments but 3 were given Python 提供了两种解决办法，从语法上看，跟我们在调用函数的时候非常像：我们可以选择按照位置传递参数，也可以选择用 foo=bar 这种形式 先说简单的这种：用 foo=bar 的形式对字段进行约束，并且绑定变量到字段上。 foo=bar 的意思是我们要求这个类有 foo 字段，同时我们想要将 bar 绑定到实例上的 foo 字段上 python class Point: \"\"\" A simple class represents a Point in a 2D\"\"\" def __init__(self, x: int, y: int): self.x = x self.y = y some_point = Point(1, 2) match some_point: # the intuitive way, we want to match a Point type # , and we want to bind the `x` and `y` and their two fields respectively case Point(x=x, y=y): print(f\"The x: {x}\") print(f\"The y: {y}\") The x: 1 The y: 2 另外一种解决办法是：修改类的 __match_args__ 属性，该属性规定了字段的顺序 python class Point: \"\"\" A simple class represents a Point in a 2D\"\"\" # we tell python that the order is first \"x\" and then \"y\" __match_args__ = (\"x\", \"y\") def __init__(self, x: int, y: int): self.x = x self.y = y some_point = Point(1, 2) match some_point: # the intuitive way, we want to match a Point type # , and we want to bind the `x` and `y` and their two fields respectively case Point(x, y): print(f\"The x: {x}\") print(f\"The y: {y}\") The x: 1 The y: 2 如果你对 @dataclass 很熟悉的话3，上面的代码可以大大简化，看下面 python from dataclasses import dataclass @dataclass(match_args=True) class Point: \"\"\" A simple class represents a Point in a 2D\"\"\" x: int y: int print(f\"The order is {Point.__match_args__}\") some_point = Point(1, 2) match some_point: # the intuitive way, we want to match a Point type # , and we want to bind the `x` and `y` and their two fields respectively case Point(x, y): print(f\"The x: {x}\") print(f\"The y: {y}\") The order is ('x', 'y') The x: 1 The y: 2 ","date":"2022-10-16","objectID":"/zh-cn/pattern-matching-in-python/:4:0","series":null,"tags":["Python"],"title":"模式匹配简明教程（Python 3.10）","uri":"/zh-cn/pattern-matching-in-python/#将-pattern-matching-用在一个类上"},{"categories":["Programming-Languages"],"content":" Guard有时候我们不仅关心模式是否匹配，我们还要加上某些限制。 试考虑这么一种情况，你要匹配有两个 int 值的序列，但是第一个元素要比第二个大，那要怎么写呢？结合前面的 Class pattern，我们不难写出下面的代码： python some_list = [3, 4] match some_list: case [int(first), int(second)]: if first \u003e second: ... else: print(\"Expect first \u003e second. Match failed\") Expect first \u003e second. Match failed 上面的写法固然可以，我们在代码块里面自己用 if 语句再检查一遍就行。但就像类型约束一样，Python 已经考虑到了这个需求，因此它提供了 Guard 💂‍♀️ 机制，使得我们可以把 if 语句这个判断挪到 pattern 的后面。这样可读性会强很多。遵循的语法规则如下所示： python match subject: case \u003cpattern\u003e if \u003cexpression\u003e: ... 在 \u003cpattern\u003e 后面跟上一个 if 语句，用来在 \u003cpattern\u003e 匹配之后对其进行限制 注意 Python 在这里 Evaluate 的顺序 先看 \u003cpattern\u003e 是否匹配 匹配的话，如果有绑定变量就绑定对应的变量 此时再看 if \u003cexpression\u003e 语句是否返回 True。这里的 \u003cexpression\u003e 可以用上一步绑定的变量。 当且仅当 \u003cpattern\u003e 匹配 + if 语句返回 True 的时候才会执行相应的代码块。否则检查不通过，继续尝试匹配下一个 \u003cpattern\u003e python some_list = [3, 4] match some_list: case [int(first), int(second)] if first \u003e second: print(\"Match successfully!\") ","date":"2022-10-16","objectID":"/zh-cn/pattern-matching-in-python/:5:0","series":null,"tags":["Python"],"title":"模式匹配简明教程（Python 3.10）","uri":"/zh-cn/pattern-matching-in-python/#guard"},{"categories":["Programming-Languages"],"content":" 总结相比于使用 if...elif...elif...else，我会更喜欢 pattern matching 多一些，出于下面几点原因： 我们可以很方便地在匹配的时候绑定值用于后续处理 个人觉得可读性比较强，代码看起来没有那么乱 pattern matching 的各种 patterns 其实是可以嵌套组合的，这也是 pattern matching 真正强大的地方 上面就是 Python 3.10 引入的 pattern matching 的简短介绍🚀 ","date":"2022-10-16","objectID":"/zh-cn/pattern-matching-in-python/:6:0","series":null,"tags":["Python"],"title":"模式匹配简明教程（Python 3.10）","uri":"/zh-cn/pattern-matching-in-python/#总结"},{"categories":["Programming-Languages"],"content":" 参考 What’s new in Python 3.10 ↩︎ PEP 635 – Structural Pattern Matching: Motivation and Rationale ↩︎ ↩︎ dataclasses - documentation ↩︎ ","date":"2022-10-16","objectID":"/zh-cn/pattern-matching-in-python/:7:0","series":null,"tags":["Python"],"title":"模式匹配简明教程（Python 3.10）","uri":"/zh-cn/pattern-matching-in-python/#参考"},{"categories":["System-Programming"],"content":" 引言如果你一直都是是用动态语言，比如 Python、Javascript 这种，你很可能并不会注意到栈和堆的区别。因为这些语言有垃圾收集器（Garbage collector，GC）存在，会自动帮你做好内存管理，你只要集中注意力编程即可。坏消息是 GC 并不是没有成本的事情，实际上设计再好的 GC 算法，也会降低代码的性能。如果你接触编程的时间足够久，那么想必你可能会听到过什么“递归层数太深栈爆炸了”这种话，此时你可能会点开搜索引擎稍微了解一下栈和堆的区别，有可能你就刚好点进了这一篇文章 :) 📒 虽然 GC 会降低代码性能，但是免去了开发人员手动管理内存的心智负担，可以大大加速软件开发的速度，这是牺牲性能换取开发速度。但到了软件后期出现性能瓶颈的时候，就不得不研究如何重构甚至重写关键部分的代码提高性能了。 这里的栈和堆并不是数据结构里面的堆和栈，而是指内存管理的两种机制。了解栈和堆的细节差异有助于我们理解一些比较接近底层的编程语言，这里说的编程语言比如 Rust、C 和 C++ 等。在 Rust 中，最为重要的概念就是所有权的问题，Rust 的很多设计都是围绕它展开，掌握了所有权就能在学习 Rust 的时候如鱼得水😄。 ","date":"2022-09-19","objectID":"/zh-cn/what-is-the-heap-and-stack/:1:0","series":null,"tags":["System-programming"],"title":"什么是堆和栈","uri":"/zh-cn/what-is-the-heap-and-stack/#引言"},{"categories":["System-Programming"],"content":" 程序在内存上的布局我们知道，要运行一个程序必须将程序加载到内存里面，在程序运行的过程中，数据也是需要读取到内存上的，那么你有没有想过这一切在内存上是如何分布的呢？下面我会给出一个比较简单的示意图1：如下所示： 在上图中，不同部分存放的东西分别是： text：存放代码 data：存放初始化过的静态变量（Initialized static variables），比如全局变量、静态变量 bss：存放未经初始化的静态变量（Uninitialized static data），比如 C 语言的 static int i heap stack 关于栈和堆会在后面进行单独说明 📒 这里要记住的就是：栈和堆是在向彼此靠近的，栈是从高地址 -\u003e 低地址增长，而堆是低地址 -\u003e 高地址增长。这样你在看汇编代码的时候看到入栈时 sp 指针是做减法你就能理解了。 📒 虽然看起来，随着我们申请内存越来越多，栈和堆可能会冲突（因为他们在彼此靠近），但是实际上并不需要担心这个问题，因为：1）这个布局是发生在虚拟内存上的，现在的处理器一般是 64 位的，容量非常大。2）在它们冲突之前，很有可能你的物理内存早就耗尽了，还是先担心这个 ","date":"2022-09-19","objectID":"/zh-cn/what-is-the-heap-and-stack/:2:0","series":null,"tags":["System-programming"],"title":"什么是堆和栈","uri":"/zh-cn/what-is-the-heap-and-stack/#程序在内存上的布局"},{"categories":["System-Programming"],"content":" 栈","date":"2022-09-19","objectID":"/zh-cn/what-is-the-heap-and-stack/:3:0","series":null,"tags":["System-programming"],"title":"什么是堆和栈","uri":"/zh-cn/what-is-the-heap-and-stack/#栈"},{"categories":["System-Programming"],"content":" 术语 Stack pointer(SP)：实际上是一个寄存器，里面存放栈顶的地址 Stack frame：当发生函数调用的时候就会创建 Stack frame。可以理解为它包含了函数调用的相关数据。比如函数的参数、函数的返回地址、函数的局部变量（除了分配在堆上的）等。一连串的 Stack frame 就构成了调用栈（Call stack） 入栈：在栈上申请空间 出栈：在栈上释放空间 ","date":"2022-09-19","objectID":"/zh-cn/what-is-the-heap-and-stack/:3:1","series":null,"tags":["System-programming"],"title":"什么是堆和栈","uri":"/zh-cn/what-is-the-heap-and-stack/#术语"},{"categories":["System-Programming"],"content":" 栈上的内存管理是如何进行的栈最大的特点就是先进后出（Last in first out, LIFO），这是我们在栈上申请空间和释放空间的时候的遵循的模式，这也是它叫做栈的原因。在内存上申请空间其实并不神秘，就是要标记哪些范围的地址是这个程序要用的。对栈来说，只要修改 stack pointer 的值即可，自然的，从栈底（下图中的 A）到栈顶（sp 指向的位置）就是我们栈上申请了的空间 下面的图1就展现了这个简单的逻辑： 这里仍要再次强调，栈是从高地址 -\u003e 低地址增长，所以上图从左到右是高地址 -\u003e 低地址，所以在栈上申请空间（入栈）的时候实际上 sp 是做减法. 函数调用也是用栈完成的，简单来说： 调用函数的时候：修改 sp 指针 -\u003e 构造被调用的函数的 stack frame，其中包括函数参数和其他一些必要的数据，将其入栈 -\u003e 进入 Callee 函数退出的时候：上面的过程反过来就行 对这个过程的详细解释可以参考 2 📒 在栈上申请内存空间的时候需要担心的问题是：不要申请太多导致栈爆了（也就是大名鼎鼎的 Stack Overflow）。这一点在写递归函数的时候要特别注意。你可以选择改成迭代的算法，也可以考虑增加栈的大小限制。比如在 Python 里面可以用 sys.getrecursionlimit() 来修改栈的大小限制。有的编程语言还会对尾递归进行优化，此时也可以选择将普通的递归函数改写为尾递归的形式。 ","date":"2022-09-19","objectID":"/zh-cn/what-is-the-heap-and-stack/:3:2","series":null,"tags":["System-programming"],"title":"什么是堆和栈","uri":"/zh-cn/what-is-the-heap-and-stack/#栈上的内存管理是如何进行的"},{"categories":["System-Programming"],"content":" 以斐波那契数列的递归函数看栈的变化CS 课程中讲解递归的时候一般都会讲到斐波那契数列，现在我们用 F(n) 表示斐波那契数列的第 n 个值，那么有： F(0) = 0 F(1) = 1 F(n) = F(n - 1) + F(n - 2) 以 F(4) 为例，递归计算的方式如下： text F(4) = F(3) + F(2) = F(2) + F(1) + F(1) + F(0) = F(1) + F(0) + F(1) + F(1) + F(0) = 3 * F(1) + 2 * F(0) 如果我们忽略一些细节，感受函数调用的过程中栈的变化情况，那么大概如下所示： 注： 下面的 F(n) 表示每个函数自己的 stack frame python stack: F(4) stack: F(4) | F(3) # F(4): enter F(3) stack: F(4) | F(3) | F(2) # F(3): enter F(2) stack: F(4) | F(3) | F(2) | F(1) # F(2): enter F(1), F(1) is the base case, ready to exit function call stack: F(4) | F(3) | F(2) # Function return, return to the body of F(2) stack: F(4) | F(3) | F(2) | F(0) # F(2): enter F(0), F(0) is the base case, ready to exit function call stack: F(4) | F(3) | F(2) # Function return, return to the body of F(2) stack: F(4) | F(3) | F(1) # F(3): enter F(1), F(1) is the base case, ready to exit function call stack: F(4) | F(3) # Function return, return to the body of F(3) stack: F(4) # Function return, return to the body of F(4) stack: F(4) | F(2) # F(4): enter F(2) stack: F(4) | F(2) | F(1) # F(2): enter F(1), F(1) is the base case, ready to exit function call stack: F(4) | F(2) # Function return, return to the body of F(2) stack: F(4) | F(2) | F(0) # F(2): enter F(0), F(0) is the base case, ready to exit function call stack: F(4) | F(2) # Function return, return to the body of F(2) stack: F(4) # Function return, return to the body of F(4) ","date":"2022-09-19","objectID":"/zh-cn/what-is-the-heap-and-stack/:3:3","series":null,"tags":["System-programming"],"title":"什么是堆和栈","uri":"/zh-cn/what-is-the-heap-and-stack/#以斐波那契数列的递归函数看栈的变化"},{"categories":["System-Programming"],"content":" 栈上存放的是什么数据栈上的内存空间管理是通过修改 sp 指针的值实现的，很容易知道下面几点： 栈上的内存申请和释放都十分高效，为 O(1)，只要修改 sp 的值即可 栈的这种 LIFO 的逻辑比较简单，编译器其实就能帮我们处理好，作为开发者我们不需要干预这个过程 修改 sp 指针决定要申请多大的空间，意味着我们必须知道要申请的数据有多大（编译时要能确定），所以栈适合存放的数据是固定已知大小的。而大小不固定的数据是用堆来解决的 ","date":"2022-09-19","objectID":"/zh-cn/what-is-the-heap-and-stack/:3:4","series":null,"tags":["System-programming"],"title":"什么是堆和栈","uri":"/zh-cn/what-is-the-heap-and-stack/#栈上存放的是什么数据"},{"categories":["System-Programming"],"content":" 堆栈的不足之处是：无法处理大小可变的数据，我们无法知道此时 sp 的值要修改为多少。 如何在大小可变的数据和栈之间搭建起桥梁呢？这就需要用到指针了。虽然实际存储的数据大小未知，但是指针的大小是固定已知的（只要保证寻址范围能覆盖到整个内存就行，一般跟机器字长相等），所以我们可以在栈上存储一个固定大小的指针，让这个它指向堆上存储的真正数据。 ","date":"2022-09-19","objectID":"/zh-cn/what-is-the-heap-and-stack/:4:0","series":null,"tags":["System-programming"],"title":"什么是堆和栈","uri":"/zh-cn/what-is-the-heap-and-stack/#堆"},{"categories":["System-Programming"],"content":" 堆上的内存管理是如何进行的正如前面提到的，在堆上申请内存其实就是在堆上找到一个足够大的空间，并返回这个位置的指针，而后指针入栈。 后面我们想要访问这个数据的时候，就对指针解引用即可。C 语言或者 Rust 里面的 * 操作符就是用来干这个的。不知道看到这里，以前难懂的指针是不是稍微能理解一点了 :) 不同于栈里面简单修改 sp 指针即可，堆上的内存管理复杂得多。包括下面几点： 堆上可以分配的内存的位置是任意的、大小也是任意的（不超过物理内存大小即可），而栈只要遵循先进后出就行。为了管理堆上已分配和待分配堆空间，我们需要设计相应的算法和数据结构，这就给堆上的内存管理带来很大的困难 在堆上申请空间的效率也比较低。最基本的，我们起码要找到一个足够大小的空间，这个找的过程肯定是比直接修改 sp 的值耗时的。 还要处理好「碎片化」的问题。因为堆上申请空间是这边分配一块那边分配一块，在重复的申请空间和释放空间的过程中，会在内存里面留下很多碎片。极端的情况是：碎片加起来的可分配大小满足你的要求，但是因为他们散落在内存各个地方无法利用从而导致了内存不足 📒 堆上可以分配的内存比较大，但是需要更良好的管理机制来处理这种比较复杂的情况。对开发人员来说，也造成了一定的负担，我们无法依赖编译器自动帮我们处理，而是要自己手动管理内存，比如在 C 语言中你进行了 malloc() 函数申请空间之后要是忘记用 free() 释放，那么你的程序就会存在内存泄露的问题。更别谈还有其他的诸如悬垂指针等问题。 ","date":"2022-09-19","objectID":"/zh-cn/what-is-the-heap-and-stack/:4:1","series":null,"tags":["System-programming"],"title":"什么是堆和栈","uri":"/zh-cn/what-is-the-heap-and-stack/#堆上的内存管理是如何进行的"},{"categories":["System-Programming"],"content":" 堆上存放的是什么数据对堆上内存空间的分配有一定了解之后，我们不难得出下面的几个结论： 堆上存放的是容量可变的数据。更灵活的同时，代价是牺牲了一点性能 有时候也可以是固定大小的数据，但是你不想放在栈上。为什么会有这种情况？比如，在 Rust 里面，栈上的数据是默认生成拷贝，有时候出于性能的考量，你可能想要把很大的数据放在堆上，避免多次拷贝带来的开销。不知道看到这里你们有没有想到我们常常说函数参数传递引用比传递值效率更高这个优化呢？ ","date":"2022-09-19","objectID":"/zh-cn/what-is-the-heap-and-stack/:4:2","series":null,"tags":["System-programming"],"title":"什么是堆和栈","uri":"/zh-cn/what-is-the-heap-and-stack/#堆上存放的是什么数据"},{"categories":["System-Programming"],"content":" 总结 栈和堆都是内存管理里面的概念，他们跟数据结构里的栈和堆的概念不一样。栈之所以叫做栈是因为我们在进行内存申请和分配的时候都遵循 LIFO 模式，而堆这个名字则是体现了堆上面的数据毫无组织。 通常来说，在栈上申请和释放内存空间是比较高效的。为此，Rust 里面默认都是在栈上操作 栈上一般放「固定大小」的数据，堆上一般放「大小可变」的数据。但是有时候出于性能的考量，也会在堆上存放固定大小的数据 在 CS 这门学科里面，经常可以看到分层的设计，比如计算机网络的 OSI 模型。包括编程语言本身也可以分为高级语言和低级语言。6.172 性能工程的老师说的一句话分享给你们—— “很多时候你要学好这一层的东西是必须了解下面一层的东西，你不一定要会用下一层的东西，但是知道下一层的细节会帮助你学这一层”。至少对我来说，知道了栈和堆的区别之后，下面的几个问题在我看来有了很合理的解释： C/C++ 语言的指针是用来干什么的？他们为什么存在？ 为什么尾递归优化会存在？为什么在写递归函数的时候都要考虑递归层数太深的问题？ 为什么 Rust 默认数据放在栈上？ 为什么以前会看到 C/C++ 传递函数参数的时候要用引用这种说法，说这样会比较快？ 📒 在 CS 里面，我认为最重要的概念就是封装。逐层封装，对上一层隐藏细节的这种设计实在很不错。 选择带有 GC 好上手但效率较低的语言还是选择自己手动管理内存让代码效率更高呢？这点其实取决于你手头的工作。如果要开发速度当然是前者了，如果注重性能那就是后者。当然，夹在中间的是没有 GC + 基本不用自己手动管理内存 + 效率高的 Rust 语言🚀，要不学点 Rust😉 ⚠️ 本文在组织的时候可以忽略了一些细节，我只讲了我认为比较重要的几点。如果想要了解更多，值得一看的材料参考下面的资料引用 ","date":"2022-09-19","objectID":"/zh-cn/what-is-the-heap-and-stack/:5:0","series":null,"tags":["System-programming"],"title":"什么是堆和栈","uri":"/zh-cn/what-is-the-heap-and-stack/#总结"},{"categories":["System-Programming"],"content":" 参考 6.172. Performance engineering of software systems - Lecture 11 \u0026\u0026 Lecture 12 ↩︎ ↩︎ Stack frame ↩︎ ","date":"2022-09-19","objectID":"/zh-cn/what-is-the-heap-and-stack/:6:0","series":null,"tags":["System-programming"],"title":"什么是堆和栈","uri":"/zh-cn/what-is-the-heap-and-stack/#参考"},{"categories":["Vim-Neovim"],"content":"How to use vim's macro system","date":"2022-07-02","objectID":"/zh-cn/vim-macro-101/","series":null,"tags":["Vim","Neovim"],"title":"Vim Macro 101","uri":"/zh-cn/vim-macro-101/"},{"categories":["Vim-Neovim"],"content":" 引言在我学习 Vim 的过程中，最具有启发意义的一句话是： Vim 其实是一门“编程语言” 很早之前我就接触过 Vim，但是当时 Vim 的按键组合对我来说很难记，再加上 Vim 的界面实在太过于复古，于是我就转向了比较现代的文本编辑器。但当我学完 Missing semester 这门课程的时候，我对 Vim 的看法有了改观：它远远不止是一个文本编辑器，各种 Vim 的命令的排列组合更像是在写代码，背后都是有逻辑的！ 这似乎和这篇博客要讨论的主题没有关系。但其实不是这样的，认识到 Vim 是一门编程语言是一件重要的事情。程序员经常通过编程来避免重复操作，不同人对编程语言的偏好各不相同。如果把 Vim 看成一门编程语言，那么它应该也可以做到类似的事情，今天要研究的就是——如何使用 Vim 来避免重复操作。 下面假定你对 Vim 有一定的了解 : ) ","date":"2022-07-02","objectID":"/zh-cn/vim-macro-101/:1:0","series":null,"tags":["Vim","Neovim"],"title":"Vim Macro 101","uri":"/zh-cn/vim-macro-101/#引言"},{"categories":["Vim-Neovim"],"content":" 什么是 Vim 里面的宏在 Vim 里面，我们可以用 . 重复上一次的“更改”。但如果我们想要重复一系列地更改呢？答案是：用 Vim 的宏就可以。通过使用宏，我们可以录制一系列的操作，并把他们存放在指定的寄存器里面，后续就可以重复执行。如果你检查寄存器里面的内容的话，你会发现：宏不过就是一连串的字符序列。 ","date":"2022-07-02","objectID":"/zh-cn/vim-macro-101/:2:0","series":null,"tags":["Vim","Neovim"],"title":"Vim Macro 101","uri":"/zh-cn/vim-macro-101/#什么是-vim-里面的宏"},{"categories":["Vim-Neovim"],"content":" 基本指南","date":"2022-07-02","objectID":"/zh-cn/vim-macro-101/:3:0","series":null,"tags":["Vim","Neovim"],"title":"Vim Macro 101","uri":"/zh-cn/vim-macro-101/#基本指南"},{"categories":["Vim-Neovim"],"content":" 怎么录制一个宏步骤： 在 normal 模式下，按 q\u003cregister\u003e. 这里的意思是：先按 q 然后选择一个寄存器 register 来存放待会录制的宏 可以选用的寄存器 regitser 包括: 0-9，a-z 和 \" 开始录制宏，如果上一步没有问题的话，此时你应该会看到左下角显示 recording @\u003cregister\u003e。从此刻起，你所有的操作都会被记录下来 再次按下 q 退出录制 ","date":"2022-07-02","objectID":"/zh-cn/vim-macro-101/:3:1","series":null,"tags":["Vim","Neovim"],"title":"Vim Macro 101","uri":"/zh-cn/vim-macro-101/#怎么录制一个宏"},{"categories":["Vim-Neovim"],"content":" 怎么查看宏的内容前面提到，Vim 会把我们录制的宏存放在指定的寄存器里面。查看宏的内容很简单，用一个简单的 :reg 命令就行： sh :reg \u003cregister\u003e 里面你会看到一些奇怪的字符，比如： ^[ 是 \u003cESC\u003e 键 \u003c80\u003ekb 是 BAKESPACE 键 ","date":"2022-07-02","objectID":"/zh-cn/vim-macro-101/:3:2","series":null,"tags":["Vim","Neovim"],"title":"Vim Macro 101","uri":"/zh-cn/vim-macro-101/#怎么查看宏的内容"},{"categories":["Vim-Neovim"],"content":" 怎么执行宏 在一个文件里面执行宏 @\u003cregister\u003e: 执行存放在 \u003cregister\u003e 这个寄存器里面的宏 @@：执行我们上一次调用的宏 如果想要多次执行的话，在命令的前面先输入 [COUNT] 表示要执行多少次。 e.g. 100@@ 的意思是：执行上一次调用的宏 100 次 自己计算 [COUNT] 的值应该是多大太枯燥了，好在当我们设置一个很大的值的时候，超过的部分会被 Vim 忽略 :) 在多个文件里面执行同一个宏当然，如果只能在一个文件里面重复执行宏的话，能解决的问题还比较局限。一个很经典的场景是我们想要对一堆文件执行一样的操作，我们总不可能一个个地处理文件。这绝对违反了 DRY（Don’t Repeat Yourself）原则 Vim 允许我们同时打开多个文件然后一个个编辑。不仅如此，它还支持我们在所有打开的文件上执行指定的宏。 比如，我们想要编辑当前目录下的所有 txt 文件，只要在命令行输入 vim *.txt 就可以打开所有文件（每个文件对应一个 buffer，整体可以看成是一个 buffer 列表）。在这个模式下我们可以一个个文件地编辑，编辑完毕之后按 :wn 保存当前文件的更改并跳转到下一个文件。但我们也能一次性对这个文件列表里的所有文件进行更改： 先用第一个文件录制宏，录制完成之后，在 normal 模式下输入 :edit! 撤销对第一个文件的更改（不然后续批处理文件的时候第一个文件会被修改两次） 在 normal 模式下，输入命令 :bufdo execute \"normal @\u003cregister\u003e\" | update. 关于 bufdo 的说明可以在 Vim 里面输入 :h bufdo 查看。可以理解为对所有的 buffer 执行指定的操作 这里的 normal @\u003cregister\u003e 的意思就是在 normal 模式下执行 @\u003cregister\u003e 里面的宏 更多的细节可以看 这里 ","date":"2022-07-02","objectID":"/zh-cn/vim-macro-101/:3:3","series":null,"tags":["Vim","Neovim"],"title":"Vim Macro 101","uri":"/zh-cn/vim-macro-101/#怎么执行宏"},{"categories":["Vim-Neovim"],"content":" 怎么执行宏 在一个文件里面执行宏 @: 执行存放在 这个寄存器里面的宏 @@：执行我们上一次调用的宏 如果想要多次执行的话，在命令的前面先输入 [COUNT] 表示要执行多少次。 e.g. 100@@ 的意思是：执行上一次调用的宏 100 次 自己计算 [COUNT] 的值应该是多大太枯燥了，好在当我们设置一个很大的值的时候，超过的部分会被 Vim 忽略 :) 在多个文件里面执行同一个宏当然，如果只能在一个文件里面重复执行宏的话，能解决的问题还比较局限。一个很经典的场景是我们想要对一堆文件执行一样的操作，我们总不可能一个个地处理文件。这绝对违反了 DRY（Don’t Repeat Yourself）原则 Vim 允许我们同时打开多个文件然后一个个编辑。不仅如此，它还支持我们在所有打开的文件上执行指定的宏。 比如，我们想要编辑当前目录下的所有 txt 文件，只要在命令行输入 vim *.txt 就可以打开所有文件（每个文件对应一个 buffer，整体可以看成是一个 buffer 列表）。在这个模式下我们可以一个个文件地编辑，编辑完毕之后按 :wn 保存当前文件的更改并跳转到下一个文件。但我们也能一次性对这个文件列表里的所有文件进行更改： 先用第一个文件录制宏，录制完成之后，在 normal 模式下输入 :edit! 撤销对第一个文件的更改（不然后续批处理文件的时候第一个文件会被修改两次） 在 normal 模式下，输入命令 :bufdo execute \"normal @\" | update. 关于 bufdo 的说明可以在 Vim 里面输入 :h bufdo 查看。可以理解为对所有的 buffer 执行指定的操作 这里的 normal @ 的意思就是在 normal 模式下执行 @ 里面的宏 更多的细节可以看 这里 ","date":"2022-07-02","objectID":"/zh-cn/vim-macro-101/:3:3","series":null,"tags":["Vim","Neovim"],"title":"Vim Macro 101","uri":"/zh-cn/vim-macro-101/#在一个文件里面执行宏"},{"categories":["Vim-Neovim"],"content":" 怎么执行宏 在一个文件里面执行宏 @: 执行存放在 这个寄存器里面的宏 @@：执行我们上一次调用的宏 如果想要多次执行的话，在命令的前面先输入 [COUNT] 表示要执行多少次。 e.g. 100@@ 的意思是：执行上一次调用的宏 100 次 自己计算 [COUNT] 的值应该是多大太枯燥了，好在当我们设置一个很大的值的时候，超过的部分会被 Vim 忽略 :) 在多个文件里面执行同一个宏当然，如果只能在一个文件里面重复执行宏的话，能解决的问题还比较局限。一个很经典的场景是我们想要对一堆文件执行一样的操作，我们总不可能一个个地处理文件。这绝对违反了 DRY（Don’t Repeat Yourself）原则 Vim 允许我们同时打开多个文件然后一个个编辑。不仅如此，它还支持我们在所有打开的文件上执行指定的宏。 比如，我们想要编辑当前目录下的所有 txt 文件，只要在命令行输入 vim *.txt 就可以打开所有文件（每个文件对应一个 buffer，整体可以看成是一个 buffer 列表）。在这个模式下我们可以一个个文件地编辑，编辑完毕之后按 :wn 保存当前文件的更改并跳转到下一个文件。但我们也能一次性对这个文件列表里的所有文件进行更改： 先用第一个文件录制宏，录制完成之后，在 normal 模式下输入 :edit! 撤销对第一个文件的更改（不然后续批处理文件的时候第一个文件会被修改两次） 在 normal 模式下，输入命令 :bufdo execute \"normal @\" | update. 关于 bufdo 的说明可以在 Vim 里面输入 :h bufdo 查看。可以理解为对所有的 buffer 执行指定的操作 这里的 normal @ 的意思就是在 normal 模式下执行 @ 里面的宏 更多的细节可以看 这里 ","date":"2022-07-02","objectID":"/zh-cn/vim-macro-101/:3:3","series":null,"tags":["Vim","Neovim"],"title":"Vim Macro 101","uri":"/zh-cn/vim-macro-101/#在多个文件里面执行同一个宏"},{"categories":["Vim-Neovim"],"content":" 怎么修改已经录制好的宏 简单情况设想你在录制一个很长的宏，突然录到一半不小心按下了 q 键结束了录制。重新录制肯定很繁琐，Vim 允许我们直接在某个录制好了的宏后面继续追加操作。办法就是用 q\u003cREGISTER\u003e，这里的 \u003cREGISTER\u003e 表示 A-Z 中的一个字母。比如之前录制到一半的宏在 a，那么追加的时候就要用 A 复杂情况如果要编辑的位置是在宏的中间呢？从头开始录制宏肯定不是一个好的选择。前面提到过，宏的本质上只是存储在寄存器里面的字符序列。我们只需要修改寄存器里的内容就行，具体操作如下： 在 normal 模式下，按下 G 跳转到当前文件的最后一行（其实别的行也可以，只是跳转到最后一行我们编辑宏的时候比较不会受到干扰），然后输入 :put \u003cregister\u003e 命令，对应寄存器里面的内容就会被粘贴在下一行 接下来直接修改这个内容就行 编辑完成之后（确保光标还在这一行），按下 :d \u003cregister\u003e 就可以把当前行的内容存回原来的寄存器 下面是一个简单的例子，我录制了一个宏放在寄存器 y 里面，功能是：在当前行的末尾追加 world，现在我想要修改这个宏，改成追加 hello world ","date":"2022-07-02","objectID":"/zh-cn/vim-macro-101/:3:4","series":null,"tags":["Vim","Neovim"],"title":"Vim Macro 101","uri":"/zh-cn/vim-macro-101/#怎么修改已经录制好的宏"},{"categories":["Vim-Neovim"],"content":" 怎么修改已经录制好的宏 简单情况设想你在录制一个很长的宏，突然录到一半不小心按下了 q 键结束了录制。重新录制肯定很繁琐，Vim 允许我们直接在某个录制好了的宏后面继续追加操作。办法就是用 q，这里的 表示 A-Z 中的一个字母。比如之前录制到一半的宏在 a，那么追加的时候就要用 A 复杂情况如果要编辑的位置是在宏的中间呢？从头开始录制宏肯定不是一个好的选择。前面提到过，宏的本质上只是存储在寄存器里面的字符序列。我们只需要修改寄存器里的内容就行，具体操作如下： 在 normal 模式下，按下 G 跳转到当前文件的最后一行（其实别的行也可以，只是跳转到最后一行我们编辑宏的时候比较不会受到干扰），然后输入 :put 命令，对应寄存器里面的内容就会被粘贴在下一行 接下来直接修改这个内容就行 编辑完成之后（确保光标还在这一行），按下 :d 就可以把当前行的内容存回原来的寄存器 下面是一个简单的例子，我录制了一个宏放在寄存器 y 里面，功能是：在当前行的末尾追加 world，现在我想要修改这个宏，改成追加 hello world ","date":"2022-07-02","objectID":"/zh-cn/vim-macro-101/:3:4","series":null,"tags":["Vim","Neovim"],"title":"Vim Macro 101","uri":"/zh-cn/vim-macro-101/#简单情况"},{"categories":["Vim-Neovim"],"content":" 怎么修改已经录制好的宏 简单情况设想你在录制一个很长的宏，突然录到一半不小心按下了 q 键结束了录制。重新录制肯定很繁琐，Vim 允许我们直接在某个录制好了的宏后面继续追加操作。办法就是用 q，这里的 表示 A-Z 中的一个字母。比如之前录制到一半的宏在 a，那么追加的时候就要用 A 复杂情况如果要编辑的位置是在宏的中间呢？从头开始录制宏肯定不是一个好的选择。前面提到过，宏的本质上只是存储在寄存器里面的字符序列。我们只需要修改寄存器里的内容就行，具体操作如下： 在 normal 模式下，按下 G 跳转到当前文件的最后一行（其实别的行也可以，只是跳转到最后一行我们编辑宏的时候比较不会受到干扰），然后输入 :put 命令，对应寄存器里面的内容就会被粘贴在下一行 接下来直接修改这个内容就行 编辑完成之后（确保光标还在这一行），按下 :d 就可以把当前行的内容存回原来的寄存器 下面是一个简单的例子，我录制了一个宏放在寄存器 y 里面，功能是：在当前行的末尾追加 world，现在我想要修改这个宏，改成追加 hello world ","date":"2022-07-02","objectID":"/zh-cn/vim-macro-101/:3:4","series":null,"tags":["Vim","Neovim"],"title":"Vim Macro 101","uri":"/zh-cn/vim-macro-101/#复杂情况"},{"categories":["Vim-Neovim"],"content":" 总结这只是对 Vim 的宏的一个简单介绍，它只是 Vim 强大功能的冰山一角，当你掌握更多 Vim 的其他操作的时候（比如搜索与替换，快速定位到某个位置），把他们结合起来 Vim 将会变得很强大。如果这篇博客可以让你对 Vim 产生兴趣那就再好不过。希望本篇博客对你有所帮助😉 ","date":"2022-07-02","objectID":"/zh-cn/vim-macro-101/:4:0","series":null,"tags":["Vim","Neovim"],"title":"Vim Macro 101","uri":"/zh-cn/vim-macro-101/#总结"},{"categories":["Compiler"],"content":"use the semantic actions to generate the symbol tables in ANTLR4","date":"2022-05-28","objectID":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/","series":null,"tags":["Compiler","Course"],"title":"How to use the semantic actions to generate the symbol tables in ANTLR4","uri":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/"},{"categories":["Compiler"],"content":" 什么是 semantic actions当 Parser 处理输入的代码的时候不仅要判断是否语法和句法都正确，还可以执行一些有用的操作，这些操作就叫做 Semantic actions。其实也就是一段代码，一般嵌入在在语法文件的规则里面。那么当 parser 应用这个规则的时候就会执行你设置的这段代码。换个角度理解，semantic actions 其实就是“触发器”，触发条件就是 parser 应用了对应的规则。 今天这篇文章要探讨的就是一个关于 semantic actions 的应用——实现一个简单的 symbol table，用到的工具是 ANTLR4。 ","date":"2022-05-28","objectID":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/:1:0","series":null,"tags":["Compiler","Course"],"title":"How to use the semantic actions to generate the symbol tables in ANTLR4","uri":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/#什么是-semantic-actions"},{"categories":["Compiler"],"content":" 什么是 symbol table编译器在处理我们的代码的时候会在内部维护一个 symbol table，用来存储程序里面所有关于变量的信息：变量名、数据类型、变量所属的作用域等。symbol table 可以是下面这种形式： Symbol name Type Scope bar function, double extern x double function parameter foo function, double global count int function parameter sum double block local i int for-loop statement ","date":"2022-05-28","objectID":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/:2:0","series":null,"tags":["Compiler","Course"],"title":"How to use the semantic actions to generate the symbol tables in ANTLR4","uri":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/#什么是-symbol-table"},{"categories":["Compiler"],"content":" 如何在 ANTLR 的语法文件里面注入动作ANTLR4 是一个强大的 parse generator，我们只要编写好语法文件，就能让它帮我们自动生成 Parser，生成的 Parser 可以支持多种目标语言，比如我自己用的是 Python，那么最后生成的 Parser 就是 Python 文件。 ANTLR4 也提供了方法让我们可以在语法文件里面插入动作，这些动作最后都会被 ANTLR4 注入到生成的 Parser 文件里面。因此，动作用什么语言写取决于你输出 Parser 的目标语言是什么 ⚠️这里假定你对如何编写 ANTLR4 的语法文件（*.g4）有基本了解，不会进行赘述，本文只集中介绍如何在语法文件里面插入动作 ","date":"2022-05-28","objectID":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/:3:0","series":null,"tags":["Compiler","Course"],"title":"How to use the semantic actions to generate the symbol tables in ANTLR4","uri":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/#如何在-antlr-的语法文件里面注入动作"},{"categories":["Compiler"],"content":" 动作注入的位置和方法下面是简化的生成的 Parser 文件的代码模板。总体上来看，我们能注入的位置如下所示： python \u003cheader\u003e class xxxParser(Parser): ... \u003cmember\u003e def rule(self): ... \u003caction\u003e 下面我对每个位置的不同语法进行说明： \u003cheader\u003eANTLR4 本来就是用 Java 写的，所以如果你用的目标语言也是 Java 的话，这个会比较用得到。一般就是用来放 import 语句的。如果是 python 的话哪里都能 import 就比较没差。要往这个位置注入代码的格式如下（放在 *.g4 文件里面，下同） antlr @header{ everything here will go to \u003cheader\u003e } \u003cmember\u003e这个放的就是类的成员，可以是字段也可以是方法。ANTLR4 支持往 Lexer 和 Parser 分别或者同时注入代码。要往这个位置注入代码的格式如下： antlr @members { everything here will go to \u003cmember\u003e in xxxLexer \u0026\u0026 xxxParser } @Lexer::members { everything here will go to \u003cmember\u003e in xxxLexer } @Parser::members { everything here will go to \u003cmember\u003e in xxxParser } ⚠️在我使用的 antlr4-python3-runtime 中（4.10），还无法在插入类的字段进行注释 \u003caction\u003e在 ANTLR4 中，动作是用花括号 {\u003cspecific-language-here\u003e} 括起来的代码。正如前面提到的，看你最后输出的 Parser 想要是什么语言，你就用什么语言写动作。 动作一般会放在一条规则的某个 symbol 之后，意思是说在 parser 应用这条规则的时候执行到这里就执行相应的动作。这里的 symbol 可以是 terminal 也可以是 nonterminal。 我们可以用 $symbol.attr 的方式访问到对应的属性，有下面这几个： python $terminal.text # origin text $terminal.type # an integer stands for type $terminal.attributes $terminal.line # the line number $terminal.pos # the position of the first char in the line，0-based $terminal.index $terminal.channel # the channel of this terminal, won't discuss in this post $terminal.int # return an interger if this terminal is an integer $nonterminal.text # origin text $nonterminal.start # 1st Token $nonterminal.stop # last Token $nonterminal.ctx # return context object ","date":"2022-05-28","objectID":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/:3:1","series":null,"tags":["Compiler","Course"],"title":"How to use the semantic actions to generate the symbol tables in ANTLR4","uri":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/#动作注入的位置和方法"},{"categories":["Compiler"],"content":" 动作注入的位置和方法下面是简化的生成的 Parser 文件的代码模板。总体上来看，我们能注入的位置如下所示： python class xxxParser(Parser): ... def rule(self): ... 下面我对每个位置的不同语法进行说明： ANTLR4 本来就是用 Java 写的，所以如果你用的目标语言也是 Java 的话，这个会比较用得到。一般就是用来放 import 语句的。如果是 python 的话哪里都能 import 就比较没差。要往这个位置注入代码的格式如下（放在 *.g4 文件里面，下同） antlr @header{ everything here will go to } 这个放的就是类的成员，可以是字段也可以是方法。ANTLR4 支持往 Lexer 和 Parser 分别或者同时注入代码。要往这个位置注入代码的格式如下： antlr @members { everything here will go to in xxxLexer \u0026\u0026 xxxParser } @Lexer::members { everything here will go to in xxxLexer } @Parser::members { everything here will go to in xxxParser } ⚠️在我使用的 antlr4-python3-runtime 中（4.10），还无法在插入类的字段进行注释 在 ANTLR4 中，动作是用花括号 {} 括起来的代码。正如前面提到的，看你最后输出的 Parser 想要是什么语言，你就用什么语言写动作。 动作一般会放在一条规则的某个 symbol 之后，意思是说在 parser 应用这条规则的时候执行到这里就执行相应的动作。这里的 symbol 可以是 terminal 也可以是 nonterminal。 我们可以用 $symbol.attr 的方式访问到对应的属性，有下面这几个： python $terminal.text # origin text $terminal.type # an integer stands for type $terminal.attributes $terminal.line # the line number $terminal.pos # the position of the first char in the line，0-based $terminal.index $terminal.channel # the channel of this terminal, won't discuss in this post $terminal.int # return an interger if this terminal is an integer $nonterminal.text # origin text $nonterminal.start # 1st Token $nonterminal.stop # last Token $nonterminal.ctx # return context object ","date":"2022-05-28","objectID":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/:3:1","series":null,"tags":["Compiler","Course"],"title":"How to use the semantic actions to generate the symbol tables in ANTLR4","uri":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/#header"},{"categories":["Compiler"],"content":" 动作注入的位置和方法下面是简化的生成的 Parser 文件的代码模板。总体上来看，我们能注入的位置如下所示： python class xxxParser(Parser): ... def rule(self): ... 下面我对每个位置的不同语法进行说明： ANTLR4 本来就是用 Java 写的，所以如果你用的目标语言也是 Java 的话，这个会比较用得到。一般就是用来放 import 语句的。如果是 python 的话哪里都能 import 就比较没差。要往这个位置注入代码的格式如下（放在 *.g4 文件里面，下同） antlr @header{ everything here will go to } 这个放的就是类的成员，可以是字段也可以是方法。ANTLR4 支持往 Lexer 和 Parser 分别或者同时注入代码。要往这个位置注入代码的格式如下： antlr @members { everything here will go to in xxxLexer \u0026\u0026 xxxParser } @Lexer::members { everything here will go to in xxxLexer } @Parser::members { everything here will go to in xxxParser } ⚠️在我使用的 antlr4-python3-runtime 中（4.10），还无法在插入类的字段进行注释 在 ANTLR4 中，动作是用花括号 {} 括起来的代码。正如前面提到的，看你最后输出的 Parser 想要是什么语言，你就用什么语言写动作。 动作一般会放在一条规则的某个 symbol 之后，意思是说在 parser 应用这条规则的时候执行到这里就执行相应的动作。这里的 symbol 可以是 terminal 也可以是 nonterminal。 我们可以用 $symbol.attr 的方式访问到对应的属性，有下面这几个： python $terminal.text # origin text $terminal.type # an integer stands for type $terminal.attributes $terminal.line # the line number $terminal.pos # the position of the first char in the line，0-based $terminal.index $terminal.channel # the channel of this terminal, won't discuss in this post $terminal.int # return an interger if this terminal is an integer $nonterminal.text # origin text $nonterminal.start # 1st Token $nonterminal.stop # last Token $nonterminal.ctx # return context object ","date":"2022-05-28","objectID":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/:3:1","series":null,"tags":["Compiler","Course"],"title":"How to use the semantic actions to generate the symbol tables in ANTLR4","uri":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/#member"},{"categories":["Compiler"],"content":" 动作注入的位置和方法下面是简化的生成的 Parser 文件的代码模板。总体上来看，我们能注入的位置如下所示： python class xxxParser(Parser): ... def rule(self): ... 下面我对每个位置的不同语法进行说明： ANTLR4 本来就是用 Java 写的，所以如果你用的目标语言也是 Java 的话，这个会比较用得到。一般就是用来放 import 语句的。如果是 python 的话哪里都能 import 就比较没差。要往这个位置注入代码的格式如下（放在 *.g4 文件里面，下同） antlr @header{ everything here will go to } 这个放的就是类的成员，可以是字段也可以是方法。ANTLR4 支持往 Lexer 和 Parser 分别或者同时注入代码。要往这个位置注入代码的格式如下： antlr @members { everything here will go to in xxxLexer \u0026\u0026 xxxParser } @Lexer::members { everything here will go to in xxxLexer } @Parser::members { everything here will go to in xxxParser } ⚠️在我使用的 antlr4-python3-runtime 中（4.10），还无法在插入类的字段进行注释 在 ANTLR4 中，动作是用花括号 {} 括起来的代码。正如前面提到的，看你最后输出的 Parser 想要是什么语言，你就用什么语言写动作。 动作一般会放在一条规则的某个 symbol 之后，意思是说在 parser 应用这条规则的时候执行到这里就执行相应的动作。这里的 symbol 可以是 terminal 也可以是 nonterminal。 我们可以用 $symbol.attr 的方式访问到对应的属性，有下面这几个： python $terminal.text # origin text $terminal.type # an integer stands for type $terminal.attributes $terminal.line # the line number $terminal.pos # the position of the first char in the line，0-based $terminal.index $terminal.channel # the channel of this terminal, won't discuss in this post $terminal.int # return an interger if this terminal is an integer $nonterminal.text # origin text $nonterminal.start # 1st Token $nonterminal.stop # last Token $nonterminal.ctx # return context object ","date":"2022-05-28","objectID":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/:3:1","series":null,"tags":["Compiler","Course"],"title":"How to use the semantic actions to generate the symbol tables in ANTLR4","uri":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/#action"},{"categories":["Compiler"],"content":" 举个例子 ⚠️下面都只会给出部分代码，完整的代码在我的 Github 项目 ⚠️因为这个项目要求把 warning 输出在其他输出前面，所以我用 warning_list 和 output_list 来存储，最后再一起输出 下面以普渡大学 2015 年的开设的编译器课程的项目作业为例，整个项目要实现一个 Micro 语言的编译器，关于 Micro 语言的语法，可以在这里看到。下面我会对步骤三的作业要求进行一个简单的介绍。 在这个作业中我们要构建一个 symbol table，并在相应的时刻输出相关的信息： 每当我们进入一个新的作用域之前（可以是函数，也可以是代码块），要进行相关的输出 如果遇到变量声明，就输出变量名和变量类型，有值的话也要输出。 如果声明的变量在外部作用域已经声明过的话要输出：SHADOW WARNING \u003cvar_name\u003e，适用于有嵌套的作用域出现的情况 如果在当前作用域已经有同名的变量，就要输出：DECLARATION ERROR \u003cvar_name\u003e。如果出现了这种情况，那么最后程序只输出这个信息 text Symbol table \u003cscope_name\u003e name \u003cvar_name\u003e type \u003ctype_name\u003e name \u003cvar_name\u003e type \u003ctype_name\u003e value \u003cstring_value\u003e ","date":"2022-05-28","objectID":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/:4:0","series":null,"tags":["Compiler","Course"],"title":"How to use the semantic actions to generate the symbol tables in ANTLR4","uri":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/#举个例子"},{"categories":["Compiler"],"content":" 数据结构的选取及对应的方法🤔先要解决的问题是，要用什么数据结构表示 symbol table？一个 symbol table 应该要满足下面的特点： 要能够支持高效率地查询 要能够支持高效率地插入，因为程序中可能包含大量的变量声明 要能够记录变量的作用域 不难想出，支持高效率查询和插入的数据结构就是「哈希表」。为了维护变量的作用域，可以把同个作用域下的变量放在同个哈希表里面，用一个列表来记住所有的变量作用域，也就是说是 [{scope1}, {scope2},...] 这样。同时维护一个 self.current_scope 来记住当前处于哪一个变量作用域里面。每当有一个新的作用域出现的时候，保存当前的作用域，往列表里插入一个新的作用域，再更新 self.current_scope。 📒 这里的 list 其实就是用来模拟栈 🤔我们要实现什么样的方法？起码要有下面这几个： lookup(identifier, value)：插入变量到当前的 symbol table 里面。根据这个项目作业的要求，还应该查询是否变量已经被声明过 enter_new_scope()：保存当前的 symbol table，进入下一个变量作用域并初始化为空 exit_scope()：清空当前的 symbol table，找到上一个 symbol table 所以对应 @parser:members 里面的代码如下 python @parser::members { def init(self): self.current_scope = None self.block_count = 0 self.warning_list = [] # just for printing self.output_list = [] # just for printing self.declaration_error = '' def enter_new_scope(self): if not hasattr(self, '_scopes'): setattr(self, '_scopes', []) # save the current_scope import copy if len(self._scopes) \u003e 0: self._scopes.append(copy.deepcopy(self.current_scope)) self._scopes.append({}) self.current_scope = self._scopes[-1] def exit_scope(self): del self._scopes[-1] if len(self._scopes) \u003e 0: self.current_scope = self._scopes[-1] def lookup(self, identifier, value): # check all scopes found = False for scope in self._scopes[:-1][::-1]: #print(f\"the scope: {scope}\") if identifier in scope: found = True if found: self.warning_list.append(f\"SHADOW WARNING {identifier}\") # only record the 1st declaration error if identifier in self.current_scope and self.declaration_error == '': self.declaration_error = f\"DECLARATION ERROR {identifier}\" self.current_scope[identifier] = value } ","date":"2022-05-28","objectID":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/:4:1","series":null,"tags":["Compiler","Course"],"title":"How to use the semantic actions to generate the symbol tables in ANTLR4","uri":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/#数据结构的选取及对应的方法"},{"categories":["Compiler"],"content":" 注入动作到变量声明中🧐接下来就是要在对应的语法规则里面注入动作。我们想要在定义变量的时候输出相关的信息，所以我们先要观察在 Micro 语言中变量声明的规则是怎么样的，如下所示： antlr ... var_decl : var_type id_list ';' ; var_type : 'FLOAT' | 'INT' ; any_type : var_type | 'VOID' ; id_list : id id_tail ; id_tail : ',' id id_tail | ; ... 可以看到，声明变量对应的是 var_decl 规则，一次可以声明一至多个变量，每一个变量之间用 , 隔开的，所以我们可以在这条规则的末尾最后注入如下的动作代码。 ⚠️要注意如果你也是使用 python 的话，这里所以缩进会有点怪，因为每一行都要从最左边开始，但最后生成的代码是没有问题的 antlr ... var_decl : var_type id_list ';' { # NOTE: the indentation is correct, ANLTR4 will handle this for us :) # for all variable declarations, we should output the name \u0026\u0026 type # in the same variable declaration, it means all of the variables have the same type for variable in $id_list.text.split(','): self.lookup(variable, None) self.output_list.append(f\"name {variable} type {$var_type.text}\") } ; ... 我们用 $id_list.text 来获取本来的变量声明对应的文本，用 $var_type.text 来获取对应的变量类型 ","date":"2022-05-28","objectID":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/:4:2","series":null,"tags":["Compiler","Course"],"title":"How to use the semantic actions to generate the symbol tables in ANTLR4","uri":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/#注入动作到变量声明中"},{"categories":["Compiler"],"content":" 关于变量作用域的处理下面以 program 规则为例（函数和代码块的类似），progarm 规则是 Micro 语法的起始规则，规定了 Micro 程序应该要有的大框架，规则如下所示： antlr program : 'PROGRAM' id 'BEGIN' pgm_body 'END' ; 我们处理完 PROGRAM 这个 token 之后就可以初始化第一个作用域（全局作用域），最后要处理完程序再退出这个全局作用域，所以我们可以很快想到应该把动作注入在哪里 antlr program : 'PROGRAM' id 'BEGIN' pgm_body 'END' ; ^ ^ | 2 最后插入相关的动作 antlr program : 'PROGRAM' { self.init() self.output_list.append(\"Symbol table GLOBAL\") self.enter_new_scope() } id 'BEGIN' pgm_body 'END' { self.exit_scope() # output everything after we parsing this program if self.declaration_error != '': print(self.declaration_error) else: if len(self.warning_list) \u003e 0: print('\\n'.join(self.warning_list)) print('\\n'.join(self.output_list)) } ; ","date":"2022-05-28","objectID":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/:4:3","series":null,"tags":["Compiler","Course"],"title":"How to use the semantic actions to generate the symbol tables in ANTLR4","uri":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/#关于变量作用域的处理"},{"categories":["Compiler"],"content":" 扩展阅读前面只涉及到简单的动作注入，ANTLR4 其实支持的功能还更多： 比如我们可以让 nonterminal 返回值 在同一条规则如果出现多个同名的 nonterminal 的话可以起名字 下面是来自书中的一个例子，就很好地展示了上面两个用法 antlr e returns [int v] : a=e op=('*'|'/') b=e {$v = self.eval($a.v, $op, $b.v)} | a=e op=('+'|'-') b=e {$v = self.eval($a.v, $op, $b.v)} | INT {$v = $INT.int} | ID ","date":"2022-05-28","objectID":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/:5:0","series":null,"tags":["Compiler","Course"],"title":"How to use the semantic actions to generate the symbol tables in ANTLR4","uri":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/#扩展阅读"},{"categories":["Compiler"],"content":" 总结从这个例子中我们可以学习到要如何在 ANTLR4 里面使用动作，生成 symbol table 只是其中一个运用。在代码里面注入动作是很符合直觉的做法，可以快速实现自己想要的功能。不过缺点也很明显，它是 language-dependent 的，也就是说你一旦换了 ANTLR 输出的目标语言，你注入的动作全部要改成新的目标语言。另外就是会让本来干净的语法文件一团糟。 ","date":"2022-05-28","objectID":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/:6:0","series":null,"tags":["Compiler","Course"],"title":"How to use the semantic actions to generate the symbol tables in ANTLR4","uri":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/#总结"},{"categories":["Compiler"],"content":" 参考 Symbol table - wiki 《ANTLR4 权威指南》 ","date":"2022-05-28","objectID":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/:7:0","series":null,"tags":["Compiler","Course"],"title":"How to use the semantic actions to generate the symbol tables in ANTLR4","uri":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/#参考"},{"categories":["Algorithm"],"content":"介绍了摩尔投票法","date":"2022-03-24","objectID":"/zh-cn/boyer-moore-majority-voting-algorithm-explained/","series":null,"tags":["Algorithm"],"title":"摩尔投票法","uri":"/zh-cn/boyer-moore-majority-voting-algorithm-explained/"},{"categories":["Algorithm"],"content":" 引言 今天又做到了 Leetcode 169. 多数元素 这一道题. 我依稀记得最优的解法叫做什么摩尔投票法. 但是我对它的印象竟然只有这个名字本身了 Orz. 对于这个算法本身倒是忘得一干二净. 于是我打算系统性地学习一下这个算法的原理, 并将它总结出来写成这篇博客. 不知道在哪里看到的一句话 : 当你开始教别人的时候, 你就真的掌握它了 所以, 我今天在这里打算跟大家分享这个算法, 并试图以浅显的语言让你也学会这个方法, 那么让我们开始吧 :) ","date":"2022-03-24","objectID":"/zh-cn/boyer-moore-majority-voting-algorithm-explained/:1:0","series":null,"tags":["Algorithm"],"title":"摩尔投票法","uri":"/zh-cn/boyer-moore-majority-voting-algorithm-explained/#引言"},{"categories":["Algorithm"],"content":" 先从简单的方法开始聊起如果从来没有听说过摩尔投票法, 我们会如何尝试解决这个问题, 起码要有下面的思路: 用空间换时间, 也就是用一个哈希表把每个元素出现的次数记下来, 然后我们再检查一遍我们的哈希表并找到其中出现次数大于 $\\lfloor n/2\\rfloor$ 的就可以.这样时间复杂度和空间复杂度都是 $O(n)$ 尝试对数组进行排序, 因为我们要找的元素超过了数组一半的长度, 这意味着它一定会出现在数组的中间位置. 这个也不难想到, 但是用排序的话虽然空间复杂度是 $O(1)$, 但是时间复杂度还是大于 $O(n)$ 的, *比如如果你采用的是快速排序的话, 时间复杂度就是 $O(nlogn)$ 那么有没有一种方法可以做到时间复杂度是 $O(n)$, 空间复杂度是 $O(1)$ 呢? 也就是结合了上面两个方法的优点. 有的, 答案就是摩尔投票法 ! ","date":"2022-03-24","objectID":"/zh-cn/boyer-moore-majority-voting-algorithm-explained/:2:0","series":null,"tags":["Algorithm"],"title":"摩尔投票法","uri":"/zh-cn/boyer-moore-majority-voting-algorithm-explained/#先从简单的方法开始聊起"},{"categories":["Algorithm"],"content":" 摩尔投票法 问题描述: 假设我们的数组有 $n$ 个元素, 我们要找到其中出现次数超过一半的元素 算法流程: 从这 $n$ 个元素中选一个作为 candidate，记录它的票数为 votes = 1. 此时我们的数组中还有 $n-1$ 个元素, 我们每次都取出一个元素(记为 current), 并重复执行以下的步骤(一共 n-1 次) 将它和我们当前的 candidate 做比较, 如果它们的值一样, 那么 votes++, 也就是投赞同票 如果它们的值不一样, votes--, 也就是投反对票. 如果此时 votes = 0 的话, 那么 candidate \u003c- current, 也就是说我们让 current 成为了新的 candidate, 并记 votes = 1 最后 candidate 的值就可能是我们想要的出现次数超过一半的元素, 此时我们得再遍历一遍数组进行计数看它到底是不是 在看完上面的算法流程之后, 你可能跟我一样感到很困惑. 为什么这样最后我们就能找到出现次数超过一半的元素. 其实只要想明白一个原理就很简单 💡 出现次数超过 $\\lfloor n/2\\rfloor$ 次的元素如果存在, 此时数组中的其他元素一定是出现次数小于 $\\lfloor n/2\\rfloor$ 的 这句话有什么用呢 ? 因为摩尔投票法的做法其实就是投票 可以是投赞同票, 此时相当于我们在统计这个元素出现的次数 可以是投反对票. 相当于我们撤销了一个同意票, 就是抵消抵消抵消!!! 但是因为出现次数超过一半的元素加起来的票数(赞同票) \u003e 剩下所有不是的(反对票)这件事是一定成立的, 所以无论怎样最后赢的永远是出现次数超过一半的元素. 于是我们就找到了 :) 如果还是不懂可以看看下面的这个 GIF 图理解一下~ ","date":"2022-03-24","objectID":"/zh-cn/boyer-moore-majority-voting-algorithm-explained/:3:0","series":null,"tags":["Algorithm"],"title":"摩尔投票法","uri":"/zh-cn/boyer-moore-majority-voting-algorithm-explained/#摩尔投票法"},{"categories":["Algorithm"],"content":" 代码 java class Solution { public int majorityElement(int[] nums) { if (nums.length \u003c 2) { return nums[0]; } int candidates = nums[0]; int votes = 1; // step 1. start to vote for (int i = 0; i \u003c nums.length; i++) { if (nums[i] != candidates) { votes -= 1; if (votes == 0) { candidates = nums[i]; votes = 1; } } else { votes += 1; } } // step2. check int occurs = 0; for (var val: nums) { if (candidates == val) { occurs += 1; } } if (occurs \u003e= nums.length / 2) { return candidates; } else { return -1; } } } ","date":"2022-03-24","objectID":"/zh-cn/boyer-moore-majority-voting-algorithm-explained/:4:0","series":null,"tags":["Algorithm"],"title":"摩尔投票法","uri":"/zh-cn/boyer-moore-majority-voting-algorithm-explained/#代码"},{"categories":["Algorithm"],"content":" FAQ Q: 为什么还需要第二轮检查呢? 能不能直接看 votes 呢? A: 不能, 首先这个「出现次数超过一半」的元素不一定存在. 比如 [1,2,3]. 另外就算它存在, 遍历完数组之后, 此时 votes 也不一定是它的真实票数. 比如 [1, 2, 2, 2, 3] 最后 3 会投反对票导致 votes - 1 ","date":"2022-03-24","objectID":"/zh-cn/boyer-moore-majority-voting-algorithm-explained/:5:0","series":null,"tags":["Algorithm"],"title":"摩尔投票法","uri":"/zh-cn/boyer-moore-majority-voting-algorithm-explained/#faq"},{"categories":["Course"],"content":"CS61A 的项目三之 Ants vs SomeBees 实现 (2021-Fall)","date":"2022-03-10","objectID":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/","series":null,"tags":["Course"],"title":"CS61A 的项目三之 Ants vs SomeBees 实现 (2021-Fall)","uri":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/"},{"categories":["Course"],"content":" Intro 前两个项目还算简单, 比较不复杂. 但是今天这个第三个项目难度确实是上升了(看游戏规则就知道这个有多复杂了). 感觉像是植物大战僵尸 所以我打算为他写一篇博客来整理一下写代码时候的思路. 话不多说, 让我们进入正题吧 ! ","date":"2022-03-10","objectID":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/:1:0","series":null,"tags":["Course"],"title":"CS61A 的项目三之 Ants vs SomeBees 实现 (2021-Fall)","uri":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/#intro"},{"categories":["Course"],"content":" Phase 1: Basic gameplay ","date":"2022-03-10","objectID":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/:2:0","series":null,"tags":["Course"],"title":"CS61A 的项目三之 Ants vs SomeBees 实现 (2021-Fall)","uri":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/#phase-1-basic-gameplay"},{"categories":["Course"],"content":" Problem 1 (1 pt) Part A: Currently, there is no cost for placing any type of Ant, and so there is no challenge to the game. The base class Ant has a food_cost of zero. Override this class attribute for HarvesterAnt and ThrowerAnt according to the “Food Cost” column in the table below. Part B: Now that placing an Ant costs food, we need to be able to gather more food! To fix this issue, implement the HarvesterAnt class. A HarvesterAnt is a type of Ant that adds one food to the gamestate.food total as its action. 根据题目的要求设置 HarversterAnt 和 ThrowerAnt 的属性, 同时实现 HarvesterAnt 的 action 方法, 让它可以在每次行动的时候给 food + 1 python class HarvesterAnt(Ant): \"\"\"HarvesterAnt produces 1 additional food per turn for the colony.\"\"\" name = 'Harvester' implemented = True food_cost = 2 def action(self, gamestate): \"\"\"Produce 1 additional food for the colony. gamestate -- The GameState, used to access game state information. \"\"\" gamestate.food += 1 class ThrowerAnt(Ant): \"\"\"ThrowerAnt throws a leaf each turn at the nearest Bee in its range.\"\"\" name = 'Thrower' implemented = True damage = 1 food_cost = 3 ","date":"2022-03-10","objectID":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/:2:1","series":null,"tags":["Course"],"title":"CS61A 的项目三之 Ants vs SomeBees 实现 (2021-Fall)","uri":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/#problem-1-1-pt"},{"categories":["Course"],"content":" Problem 2 (1 pt) In this problem, you’ll complete Place.__init__ by adding code that tracks entrances. Right now, a Place keeps track only of its exit. We would like a Place to keep track of its entrance as well. A Place needs to track only one entrance. Tracking entrances will be useful when an Ant needs to see what Bees are in front of it in the tunnel. However, simply passing an entrance to a Place constructor will be problematic; we would need to have both the exit and the entrance before creating a Place! (It’s a chicken or the egg problem.) To get around this problem, we will keep track of entrances in the following way instead. Place.__init__ should use this logic: A newly created Place always starts with its entrance as None. If the Place has an exit, then the exit’s entrance is set to that Place. 其实这个赛道有点像数据结构中的双向链表的结构, 往左边用 .exit, 往右边用 .entrance 方法. 要求已经在上面给出, 没什么难度 python class Place: \"\"\"A Place holds insects and has an exit to another Place.\"\"\" is_hive = False def __init__(self, name, exit=None): \"\"\"Create a Place with the given NAME and EXIT. name -- A string; the name of this Place. exit -- The Place reached by exiting this Place (may be None). \"\"\" self.name = name self.exit = exit self.bees = [] # A list of Bees self.ant = None # An Ant self.entrance = None # A Place # Phase 1: Add an entrance to the exit if exit is not None: self.exit.entrance = self ","date":"2022-03-10","objectID":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/:2:2","series":null,"tags":["Course"],"title":"CS61A 的项目三之 Ants vs SomeBees 实现 (2021-Fall)","uri":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/#problem-2-1-pt"},{"categories":["Course"],"content":" Problem 3 (1 pt) In order for a ThrowerAnt to throw a leaf, it must know which bee to hit. The provided implementation of the nearest_bee method in the ThrowerAnt class only allows them to hit bees in the same Place. Your job is to fix it so that a ThrowerAnt will throw_at the nearest bee in front of it that is not still in the Hive. This includes bees that are in the same Place as a ThrowerAnt Hint: All Places have an is_hive attribute which is True when that place is the Hive. Change nearest_bee so that it returns a random Bee from the nearest place that contains bees. Your implementation should follow this logic: Start from the current Place of the ThrowerAnt. For each place, return a random bee if there is any, and if not, inspect the place in front of it (stored as the current place’s entrance). If there is no bee to attack, return None. 现在我们要给 ThrowerAnt 加上功能, 这样才能让它攻击距离它最近的蜜蜂🐝. 注意如果蜜蜂和他在同一个格子里, 也是可以攻击的. 我们的工作要求是遍历每个格子(就跟你遍历链表一样)找到第一个有蜜蜂的格子, 随机返回一个蜜蜂 python def nearest_bee(self): \"\"\"Return the nearest Bee in a Place that is not the HIVE, connected to the ThrowerAnt's Place by following entrances. This method returns None if there is no such Bee (or none in range). \"\"\" pos = self.place while pos.entrance is not None: if not pos.is_hive: if len(pos.bees) \u003e 0: return random_bee(pos.bees) pos = pos.entrance return None ","date":"2022-03-10","objectID":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/:2:3","series":null,"tags":["Course"],"title":"CS61A 的项目三之 Ants vs SomeBees 实现 (2021-Fall)","uri":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/#problem-3-1-pt"},{"categories":["Course"],"content":" Phase 2: Ants! ","date":"2022-03-10","objectID":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/:3:0","series":null,"tags":["Course"],"title":"CS61A 的项目三之 Ants vs SomeBees 实现 (2021-Fall)","uri":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/#phase-2-ants"},{"categories":["Course"],"content":" Problem 4 (2 pt) A ThrowerAnt is a powerful threat to the bees, but it has a high food cost. In this problem, you’ll implement two subclasses of ThrowerAnt that are less costly but have constraints on the distance they can throw: The LongThrower can only throw_at a Bee that is found after following at least 5 entrance transitions. It cannot hit Bees that are in the same Place as it or the first 4 Places in front of it. If there are two Bees, one too close to the LongThrower and the other within its range, the LongThrower should only throw at the farther Bee, which is within its range, instead of trying to hit the closer Bee. The ShortThrower can only throw_at a Bee that is found after following at most 3 entrance transitions. It cannot throw at any bees further than 3 Places in front of it. Neither of these specialized throwers can throw_at a Bee that is exactly 4 Places away. 现在我们要实现两个类, LongThrower 和 ShortThrower. 两个都是 ThrowererAnt 的子类, 其实从他们的名字可以看出来他们的区别在于攻击范围的不同. 思路: 我们如何表示攻击范围这个概念呢 ? 其实很简单, 在 problem 3 中我们找到最近的蜜蜂的时候就是一个格子一个格子前进的, 我们可以同时计算步数, 那么我们就这道这个距离, 再配合 min_range 和 max_range 这两个参数(类变量, 表示这个类对应的蚂蚁的攻击范围, 只有落在这个区间的才行) 同时要注意我们不能影响 problem 3 中的结果, 这也容易想到, 我们让 min_range=-1, max_range=float('inf'), 这样就相当于没有限制了 ~! 而且因为面向对象程序设计的优势, 我们省去了不少代码量. python # In problem 3 class ThrowerAnt(Ant): \"\"\"ThrowerAnt throws a leaf each turn at the nearest Bee in its range.\"\"\" name = 'Thrower' implemented = True damage = 1 food_cost = 3 min_range = -1 max_range = float('inf') def nearest_bee(self): \"\"\"Return the nearest Bee in a Place that is not the HIVE, connected to the ThrowerAnt's Place by following entrances. This method returns None if there is no such Bee (or none in range). \"\"\" steps_cnt = 0 pos = self.place while pos.entrance is not None: if steps_cnt \u003e self.max_range: return None if not pos.is_hive: if len(pos.bees) \u003e 0 and steps_cnt \u003e= self.min_range: return random_bee(pos.bees) pos = pos.entrance steps_cnt += 1 return None class ShortThrower(ThrowerAnt): \"\"\"A ThrowerAnt that only throws leaves at Bees at most 3 places away.\"\"\" name = 'Short' food_cost = 2 # OVERRIDE CLASS ATTRIBUTES HERE implemented = True # Change to True to view in the GUI max_range = 3 class LongThrower(ThrowerAnt): \"\"\"A ThrowerAnt that only throws leaves at Bees at least 5 places away.\"\"\" name = 'Long' food_cost = 2 # OVERRIDE CLASS ATTRIBUTES HERE implemented = True # Change to True to view in the GUI min_range = 5 ","date":"2022-03-10","objectID":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/:3:1","series":null,"tags":["Course"],"title":"CS61A 的项目三之 Ants vs SomeBees 实现 (2021-Fall)","uri":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/#problem-4-2-pt"},{"categories":["Course"],"content":" Problem 5 (3 pt) Implement the FireAnt, which does damage when it receives damage. Specifically, if it is damaged by amount health units, it does a damage of amount to all bees in its place (this is called reflected damage). If it dies, it does an additional amount of damage, as specified by its damage attribute, which has a default value of 3 as defined in the FireAnt class. To implement this, override FireAnt’s reduce_health method. Your overriden method should call the reduce_health method inherited from the superclass (Ant) to reduce the current FireAnt instance’s health. Calling the inherited reduce_health method on a FireAnt instance reduces the insect’s health by the given amount and removes the insect from its place if its health reaches zero or lower. 这个 FireAnt 有点意思的, 当他收到伤害的时候会反弹自己受到的伤害到当前格子所有的蜜蜂上, 同时如果它因此死了还能对这些蜜蜂再一次造成伤害(这一次取决于自己的攻击力) 这个比较 tricky 的地方是：当前格子的所有蜜蜂是一个 list, 也就是我们可能要在迭代访问 list 的时候修改这个 list, ==这个我们遍历它的拷贝即可== 最后代码如下: python class FireAnt(Ant): \"\"\"FireAnt cooks any Bee in its Place when it expires.\"\"\" name = 'Fire' damage = 3 food_cost = 5 implemented = True # Change to True to view in the GUI def __init__(self, health=3): \"\"\"Create an Ant with a HEALTH quantity.\"\"\" super().__init__(health) def reduce_health(self, amount): \"\"\"Reduce health by AMOUNT, and remove the FireAnt from its place if it has no health remaining. Make sure to reduce the health of each bee in the current place, and apply the additional damage if the fire ant dies. \"\"\" # FireAnt attack bees for bee in self.place.bees[:]: bee.reduce_health(amount) # FireAnt will be dead if self.health \u003c= amount: for bee in self.place.bees[:]: bee.reduce_health(self.damage) super().reduce_health(amount) else: super().reduce_health(amount) ","date":"2022-03-10","objectID":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/:3:2","series":null,"tags":["Course"],"title":"CS61A 的项目三之 Ants vs SomeBees 实现 (2021-Fall)","uri":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/#problem-5-3-pt"},{"categories":["Course"],"content":" Phase 3: More Ants! ","date":"2022-03-10","objectID":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/:4:0","series":null,"tags":["Course"],"title":"CS61A 的项目三之 Ants vs SomeBees 实现 (2021-Fall)","uri":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/#phase-3-more-ants"},{"categories":["Course"],"content":" Problem 6 (1 pt) We are going to add some protection to our glorious home base by implementing the WallAnt, an ant that does nothing each turn. A WallAnt is useful because it has a large health value. Unlike with previous ants, we have not provided you with a class header. Implement the WallAnt class from scratch. Give it a class attribute name with the value 'Wall' (so that the graphics work) and a class attributeimplemented with the value True (so that you can use it in a game). 从零实现一个 WallAnt, 这种蚂蚁生命值高, 其他倒是没什么 python class WallAnt(Ant): \"\"\"WallAnt has a large health value\"\"\" name = 'Wall' damage = 0 food_cost = 4 implemented = True def __init__(self, health=4): super().__init__(health) ","date":"2022-03-10","objectID":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/:4:1","series":null,"tags":["Course"],"title":"CS61A 的项目三之 Ants vs SomeBees 实现 (2021-Fall)","uri":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/#problem-6-1-pt"},{"categories":["Course"],"content":" Problem 7 (3 pt) Implement the HungryAnt, which will select a random Bee from its place and eat it whole. After eating a Bee, a HungryAnt must spend 3 turns chewing before eating again. If there is no bee available to eat, HungryAnt will do nothing. Give HungryAnt a chew_duration class attribute that stores the number of turns that it will take a HungryAnt to chew (set to 3). Also, give each HungryAnt an instance attribute chew_countdown that counts the number of turns it has left to chew (initialized to 0, since it hasn’t eaten anything at the beginning. You can also think of chew_countdown as the number of turns until a HungryAnt can eat another Bee). Implement the action method of the HungryAnt: First, check if it is chewing; if so, decrement its chew_countdown. Otherwise, eat a random Bee in its place by reducing the Bee’s health to 0. Make sure to set the chew_countdownwhen a Bee is eaten! 从零实现一个 HungryAnt, 可以随机吞下一整只蜜蜂!!!!但是它要花费 chew_duration 来咀嚼才能进行下一次攻击. 这个不就是植物大战僵尸里面的食人花嘛!!! 我们只要判断当前它是否处于咀嚼状态即可. 这里题目是有挖坑的, 测试样例里面可能在运行的时候会修改 chew_duration 的值, 注意别被坑了! python class HungryAnt(Ant): \"\"\"HungryAnt will select a random bee from its place and eat it whole\"\"\" name = 'Hungry' damage = 0 food_cost = 4 implemented = True chew_duration = 3 def __init__(self, health=1): super().__init__(health) self.chew_countdown = 0 def action(self, gamestate): # it is chewing if self.chew_countdown != 0: self.chew_countdown -= 1 # it is not chewing else: if len(self.place.bees) \u003e 0: # WARNING: the test cases may change the chew_duration variable in runtime self.chew_countdown = self.chew_duration bee = random_bee(self.place.bees) bee.reduce_health(bee.health) ","date":"2022-03-10","objectID":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/:4:2","series":null,"tags":["Course"],"title":"CS61A 的项目三之 Ants vs SomeBees 实现 (2021-Fall)","uri":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/#problem-7-3-pt"},{"categories":["Course"],"content":" Problem 8 (3 pt) A BodyguardAnt differs from a normal ant because it is a ContainerAnt; it can contain another ant and protect it, all in one Place. When a Bee stings the ant in a Place where one ant contains another, only the container is damaged. The ant inside the container can still perform its original action. If the container perishes, the contained ant still remains in the place (and can then be damaged). Each ContainerAnt has an instance attribute ant_contained that stores the ant it contains. This ant, ant_contained, initially starts off as None to indicate that there is no ant being stored yet. Implement the store_ant method so that it sets the ContainerAnt’s ant_contained instance attribute to the passed in antargument. Also implement the ContainerAnt’s action method to perform its ant_contained’s action if it is currently containing an ant. 这里要实现的蚂蚁也很有意思, 它可以把其他蚂蚁保护起来. 甚至可以和被保护的蚂蚁一起呆在同一个格子里面. 这里注意几个细节: BodyguardAnt 不能保护 BodyguardAnt !(🈲️止套娃) 当 BodyguardAnt 和被保护的蚂蚁在同一个格子的时候, 要让 place.ant 始终指向 BodyguardAnt 这里其实还涉及到挺多要改的地方的(可能会漏放某些代码, 完整的建议看我的仓库) python class Ant(Insect): \"\"\"An Ant occupies a place and does work for the colony.\"\"\" implemented = False # Only implemented Ant classes should be instantiated food_cost = 0 is_container = False ... def add_to(self, place): if place.ant is None: place.ant = self else: assert ( (place.ant is None) or self.can_contain(place.ant) or place.ant.can_contain(self) ), 'Two ants in {0}'.format(place) if place.ant.is_container and place.ant.can_contain(self): place.ant.store_ant(self) elif self.is_container and self.can_contain(place.ant): self.store_ant(place.ant) # the place.ant should refer to the container ant place.ant = self Insect.add_to(self, place) class ContainerAnt(Ant): \"\"\" ContainerAnt can share a space with other ants by containing them. \"\"\" is_container = True def __init__(self, *args, **kwargs): super().__init__(*args, **kwargs) self.ant_contained = None def can_contain(self, other): # we can't have two BodyguardAnt in the same place if self.ant_contained is None and not other.is_container: return True def store_ant(self, ant): self.ant_contained = ant def remove_ant(self, ant): if self.ant_contained is not ant: assert False, \"{} does not contain {}\".format(self, ant) self.ant_contained = None def remove_from(self, place): # Special handling for container ants (this is optional) if place.ant is self: # Container was removed. Contained ant should remain in the game place.ant = place.ant.ant_contained Insect.remove_from(self, place) else: # default to normal behavior Ant.remove_from(self, place) def action(self, gamestate): if self.ant_contained is not None: return self.ant_contained.action(gamestate) class BodyguardAnt(ContainerAnt): \"\"\"BodyguardAnt provides protection to other Ants.\"\"\" name = 'Bodyguard' food_cost = 4 implemented = True # Change to True to view in the GUI def __init__(self, health=2): super().__init__(health) ","date":"2022-03-10","objectID":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/:4:3","series":null,"tags":["Course"],"title":"CS61A 的项目三之 Ants vs SomeBees 实现 (2021-Fall)","uri":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/#problem-8-3-pt"},{"categories":["Course"],"content":" Problem 9 (1 pt) The BodyguardAnt provides great defense, but they say the best defense is a good offense. The TankAnt is a container that protects an ant in its place and also deals 1 damage to all bees in its place each turn. We have not provided you with a class header. Implement the TankAnt class from scratch. Give it a class attribute name with the value 'Tank' (so that the graphics work) and a class attribute implemented with the value True (so that you can use it in a game). You should not need to modify any code outside of the TankAnt class. If you find yourself needing to make changes elsewhere, look for a way to write your code for the previous question such that it applies not just to BodyguardAnt and TankAnt objects, but to container ants in general. 根据题目的描述可以知道 TankAnt 是一种特殊的 ContainerAnt, 我们要从零实现它的功能, 它的攻击方式比较特殊, 是自己保护的蚂蚁的攻击方式 + 对当前格子的蜜蜂造成自己攻击力的伤害 python class TankAnt(ContainerAnt): name = 'Tank' damage = 1 food_cost = 6 implemented = True def __init__(self, health=2): super().__init__(health) def action(self, gamestate): if self.ant_contained is not None: self.ant_contained.action(gamestate) # 1 damage for all the bees for bee in self.place.bees[:]: bee.reduce_health(self.damage) ","date":"2022-03-10","objectID":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/:4:4","series":null,"tags":["Course"],"title":"CS61A 的项目三之 Ants vs SomeBees 实现 (2021-Fall)","uri":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/#problem-9-1-pt"},{"categories":["Course"],"content":" Phase 4: Water and Might ","date":"2022-03-10","objectID":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/:5:0","series":null,"tags":["Course"],"title":"CS61A 的项目三之 Ants vs SomeBees 实现 (2021-Fall)","uri":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/#phase-4-water-and-might"},{"categories":["Course"],"content":" Problem 10 (1 pt) Let’s add water to the colony! Currently there are only two types of places, the Hive and a basic Place. To make things more interesting, we’re going to create a new type of Place called Water. Only an insect that is waterproof can be placed in Water. In order to determine whether an Insect is waterproof, add a new class attribute to the Insect class named is_waterproof that is set to False. Since bees can fly, set their is_waterproof attribute to True, overriding the inherited value. Now, implement the add_insect method for Water. First, add the insect to the place regardless of whether it is waterproof. Then, if the insect is not waterproof, reduce the insect’s health to 0. Do not repeat code from elsewhere in the program. Instead, use methods that have already been defined. 为了让地形更有趣, 我们要增加一种地形 - Water, 只有能在水里的活动的生物才能被放在这种地形中(蜜蜂会飞当然都可以, 蚂蚁目前还没有) 记得还要修改很多类, 增加类属性 is_waterproof, 下面我就放 Water 类的代码 python class Water(Place): \"\"\"Water is a place that can only hold waterproof insects.\"\"\" def add_insect(self, insect): \"\"\"Add an Insect to this place. If the insect is not waterproof, reduce its health to 0.\"\"\" super().add_insect(insect) if not insect.is_waterproof: insect.reduce_health(insect.health) ","date":"2022-03-10","objectID":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/:5:1","series":null,"tags":["Course"],"title":"CS61A 的项目三之 Ants vs SomeBees 实现 (2021-Fall)","uri":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/#problem-10-1-pt"},{"categories":["Course"],"content":" Problem 11 (1 pt) Currently there are no ants that can be placed on Water. Implement the ScubaThrower, which is a subclass of ThrowerAnt that is more costly and waterproof, but otherwise identical to its base class. A ScubaThrower should not lose its health when placed in Water. We have not provided you with a class header. Implement the ScubaThrower class from scratch. Give it a class attribute name with the value 'Scuba' (so that the graphics work) and remember to set the class attributeimplemented with the value True (so that you can use it in a game). 从零实现一个 ScubaThrower, 听名字可以看出来应该是一种特殊的 ThrowerAnt. 特殊在: 能放在 Water 里 python class ScubaThrower(ThrowerAnt): name = 'Scuba' food_cost = 6 is_waterproof = True implemented = True def __init__(self, health=1): super().__init__(health) ","date":"2022-03-10","objectID":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/:5:2","series":null,"tags":["Course"],"title":"CS61A 的项目三之 Ants vs SomeBees 实现 (2021-Fall)","uri":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/#problem-11-1-pt"},{"categories":["Course"],"content":" Problem 12 (3 pt) Finally, implement the QueenAnt. The queen is a waterproof ScubaThrower that inspires her fellow ants through her bravery. In addition to the standard ScubaThrower action, the QueenAnt doubles the damage of all the ants behind her each time she performs an action. Once an ant’s damage has been doubled, it is not doubled again for subsequent turns. However, with great power comes great responsibility. The QueenAnt is governed by three special rules: If the queen ever has its health reduced to 0, the ants lose. You will need to override Ant.reduce_health in QueenAnt and call ants_lose() in that case in order to signal to the simulator that the game is over. (The ants also still lose if any bee reaches the end of a tunnel.) There can be only one queen. A second queen cannot be constructed. To check if an Ant can be constructed, we use the Ant.construct() class method to either construct an Ant if possible, or return None if not. You will need to override Ant.construct as a class method of QueenAnt in order to add this check. To keep track of whether a queen has already been created, you can use an instance variable added to the current GameState. The queen cannot be removed. Attempts to remove the queen should have no effect (but should not cause an error). You will need to override Ant.remove_from in QueenAnt to enforce this condition. 终于来到了最后一题(除了额外的题目以外), 我们要实现一个女王蚁🐜. 它有以下几个特性: 可以在水中行走 思路: 题目也说了它是一种 ScrubaThrower, 根据这个描述其实就抽象概括出了它是 ScrubaThrower 的子类. 它在行动后会把在它后面的蚂蚁们的攻击力都翻倍, 但是不可以多次翻倍 思路: 如何表示 “在后面” 这个关系 ? 根据前面的题目我们可以知道. 右边为正方向, 所以 “在后面” 实际上就是在左边, 我们可以通过访问 Place 的 .exit 方法不断获取到它左边(后面的)的 思路: 如何表示不能多次翻倍 ? 很容易想到, 我们需要通过设置一个标记来表示当前的蚂蚁是否已经攻击力翻倍过, 所以我们直接在 Ant 类里加一个实例变量即可 思路: 这里还要注意如何处理 GuardAnt, 因为实际上它守护的蚂蚁是可能被替换为新的蚂蚁, 此时我们就要让这个新的被守护的蚂蚁的攻击力翻倍. ==注意细细体会这里代码是怎么写的== 只能有一个女王蚁🐜 思路: 如何做到即使我们多次调用女王蚁🐜的构造函数也不会有多的女王蚁🐜 ? 这个依赖于一个游戏变量叫做 gamestate, 我们仍然是通过加标记的方式, 只不过这次我们是在 GameState 这个类里加一个 has_queen 表示当前是否已经有女王蚁🐜 女王蚁🐜不能被移除 思路: 这个简单, 我们什么都不做就行了 最后代码大概如下(结合上面的解释细细体会~~) python class QueenAnt(ScubaThrower): \"\"\"The Queen of the colony. The game is over if a bee enters her place.\"\"\" name = 'Queen' food_cost = 7 implemented = True # Change to True to view in the GUI @classmethod def construct(cls, gamestate): \"\"\" Returns a new instance of the Ant class if it is possible to construct, or returns None otherwise. Remember to call the construct() method of the superclass! \"\"\" if cls.food_cost \u003e gamestate.food: print('Not enough food remains to place ' + cls.__name__) return # I add a class variable to indict if we have created a QueenAnt() if not gamestate.has_queen: gamestate.has_queen = True return super().construct(gamestate) else: return None def action(self, gamestate): \"\"\"A queen ant throws a leaf, but also doubles the damage of ants in her tunnel. \"\"\" super().action(gamestate) pos = self.place.exit while pos: if pos.ant is not None: if not pos.ant.is_doubled: pos.ant.is_doubled = True pos.ant.buff() if pos.ant.is_container and pos.ant.ant_contained is not None: # the pos.ant.ant_contained may change if not pos.ant.ant_contained.is_doubled: pos.ant.ant_contained.buff() pos.ant.ant_contained.is_doubled = True pos = pos.exit def reduce_health(self, amount): \"\"\"Reduce health by AMOUNT, and if the QueenAnt has no health remaining, signal the end of the game. \"\"\" if self.health \u003c= amount: ants_lose() def remove_from(self, place): return None ","date":"2022-03-10","objectID":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/:5:3","series":null,"tags":["Course"],"title":"CS61A 的项目三之 Ants vs SomeBees 实现 (2021-Fall)","uri":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/#problem-12-3-pt"},{"categories":["Course"],"content":" Extra Credit (2 pt) Implement two final thrower ants that do zero damage, but instead apply a temporary “status” on the actionmethod of a Bee instance that they throw_at. This “status” lasts for a certain number of turns, after which it ceases to take effect. We will be implementing two new ants that inherit from ThrowerAnt. SlowThrower throws sticky syrup at a bee, slowing it for 3 turns. When a bee is slowed, it can only move on turns when gamestate.time is even, and can do nothing otherwise. If a bee is hit by syrup while it is already slowed, it is slowed for an additional 3 turns. ScaryThrower intimidates a nearby bee, causing it to back away instead of advancing. (If the bee is already right next to the Hive and cannot go back further, it should not move. To check if a bee is next to the Hive, you might find the is_hive instance attribute of Places useful). Bees remain scared until they have tried to back away twice. Bees cannot try to back away if they are slowed and gamestate.time is odd. Once a bee has been scared once, it can’t be scared ever again. 实现两种特殊的蚂蚁类, 本身没有伤害, 但是能给蜜蜂加上 debuff. SlowThrower 可以让蜜蜂减速, 让他们只能在当前时间为偶数的时候前进否则什么事情也干不了. 这个效果可以维持三个回合, 但是这个 debuff 可以无限叠加 ScaryThrower 会让蜜蜂后退, 注意如果不能再后退的话, 就要保持不动. 该效果维持两回合. 但是如果被减速就会继续保持不动, 这个 debuff 只能上一次 这一题, 真的, 难度完全是上来了. 我调了挺久的 bug 才成功. 下面我来讲一下设计思路: SlowThrower 设置 is_slow 变量表示当前的蜜蜂是否被减速, 同时设置 slow_turns 来记住剩余几回合可以解除这个状态 每个回合, 如果当前的蜜蜂被减速了, 它只能看当前的游戏时间是否为偶数, 如果是的话就可以前进, 否则在原地不动, **但不论你动不动, slow_turns -= 1 永远都成立 ScaryThrower 类似 is_slow 和 slow_turns 设置了 is_scared 和 scared_turns 我们暂时先不考虑当前蜜蜂是否被减速了(这样思考问题会比较简单). 显然, 我们每回合要做的事情是让 scared_turns -= 1, 然后是否为 scared 其实决定着蜜蜂的前进方向. 有了这个基础之后我们再来思考被减速带情况下又该如何, 显然我们前面这样是有问题的, 题目说了如果被减速会原地保持不动, 但是我们却让 scared_turns -= 1, 所以我们需要多加一个判断, 也就是被减速 + 被 scared 的情况下如果我们没有成功移动, 那么我们需要撤销我们对 scared_turns 的更改 知道了上面的设计思路, 理解下面的代码就不难了(这里删去了无关的代码): python class Bee(Insect): \"\"\"A Bee moves from place to place, following exits and stinging ants.\"\"\" name = 'Bee' damage = 1 is_waterproof = True # 2 flags is_slow = False is_scared = False # turns remained slow_turns = 0 scared_turns = 0 # we can't scare a bee twice has_been_scared = False def action(self, gamestate): \"\"\"A Bee's action stings the Ant that blocks its exit if it is blocked, or moves to the exit of its current place otherwise. gamestate -- The GameState, used to access game state information. \"\"\" if self.is_scared: destination = self.place.entrance self.scared_turns -= 1 else: destination = self.place.exit if self.is_slow: self.slow_turns -= 1 if self.slow_turns == 0: self.is_slow = False if gamestate.time % 2 == 0 and self.health \u003e 0 and destination is not None: self.move_to(destination) else: # is_slow + is_scared, we need to cancel `self.scared_turns -= 1` \\ # if we didn't move self.scared_turns += 1 else: if self.blocked(): self.sting(self.place.ant) elif self.health \u003e 0 and destination is not None: self.move_to(destination) # we can't put this in side `if self.is_scared`, why? # because only when we run if self.is_slow we can know # should we cancel it or not if self.scared_turns == 0: self.is_scared = False # Extra credit: Special handling for bee direction def slow(self, length): \"\"\"Slow the bee for a further LENGTH turns.\"\"\" self.is_slow = True self.slow_turns += length def scare(self, length): \"\"\" If this Bee has not been scared before, cause it to attempt to go backwards LENGTH times. \"\"\" # a bee can't be scared twice if self.has_been_scared: return else: self.is_scared = True self.scared_turns += length self.has_been_scared = True ","date":"2022-03-10","objectID":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/:5:4","series":null,"tags":["Course"],"title":"CS61A 的项目三之 Ants vs SomeBees 实现 (2021-Fall)","uri":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/#extra-credit-2-pt"},{"categories":["Course"],"content":" Optional Problems ","date":"2022-03-10","objectID":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/:6:0","series":null,"tags":["Course"],"title":"CS61A 的项目三之 Ants vs SomeBees 实现 (2021-Fall)","uri":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/#optional-problems"},{"categories":["Course"],"content":" Optional Problem 1 Implement the NinjaAnt, which damages all Bees that pass by, but can never be stung. A NinjaAnt does not block the path of a Bee that flies by. To implement this behavior, first modify the Ant class to include a new class attribute blocks_path that is set to True, then override the value of blocks_path to Falsein the NinjaAnt class. Second, modify the Bee’s method blocked to return False if either there is no Ant in the Bee’s place or if there is an Ant, but its blocks_path attribute is False. Now Bees will just fly past NinjaAnts. Finally, we want to make the NinjaAnt damage all Bees that fly past. Implement the action method in NinjaAntto reduce the health of all Bees in the same place as the NinjaAnt by its damage attribute. Similar to the FireAnt, you must iterate over a potentially changing list of bees. 忍者蚁🥷🐜哈哈哈哈, 注意几个细节: 无法被蜜蜂攻击 不会堵住蜜蜂的路, 但是会对经过的蜜蜂造成伤害 这个问题比较简单, 解法也几乎都写在了问题描述里面 python class Bee(Insect): \"\"\"A Bee moves from place to place, following exits and stinging ants.\"\"\" def blocked(self): \"\"\"Return True if this Bee cannot advance to the next Place.\"\"\" if self.place.ant is None: return False if not self.place.ant.blocks_path: return False return True class NinjaAnt(Ant): \"\"\"NinjaAnt does not block the path and damages all bees in its place. This class is optional. \"\"\" name = 'Ninja' damage = 1 food_cost = 5 blocks_path = False implemented = True # Change to True to view in the GUI def action(self, gamestate): for bee in self.place.bees[:]: bee.reduce_health(self.damage) ","date":"2022-03-10","objectID":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/:6:1","series":null,"tags":["Course"],"title":"CS61A 的项目三之 Ants vs SomeBees 实现 (2021-Fall)","uri":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/#optional-problem-1"},{"categories":["Course"],"content":" Optional Problem 2 The LaserAnt shoots out a powerful laser, damaging all that dare to stand in its path. Both Bees and Ants, of all types, are at risk of being damaged by LaserAnt. When a LaserAnt takes its action, it will damage all Insects in its place (excluding itself, but including its container if it has one) and the Places in front of it, excluding the Hive. If that were it, LaserAnt would be too powerful for us to contain. The LaserAnt has a base damage of 2. But, LaserAnt’s laser comes with some quirks. The laser is weakened by 0.25 each place it travels away fromLaserAnt’s place. Additionally, LaserAnt has limited battery. Each time LaserAnt actually damages an Insect its laser’s total damage goes down by 0.0625 (1/16). If LaserAnt’s damage becomes negative due to these restrictions, it simply does 0 damage instead. 激光🐜, 注意几个特性: 伤害自己格子所在的所有生物, 甚至包括整条路径上的所有生物 但是每次对其他生物造成伤害的时候伤害会衰减, 每次减去 0.0625 激光的威力跟它离激光蚁🐜的距离也有关系, 距离每多一个格子, 就会减去 0.25 只要处理好两个函数即可 calculate_damage : 这个要注意的地方是, 如果算出来的伤害 \u003c 0, 那么你就需要返回 0 insects_in_front : 这个要返回一个 dict 表示每个生物距离激光🐜的距离. 我这了是分成当前格子和剩下的格子这样来处理, 一边遍历所有格子一边计算距离和把生物加到我们的 dict里. python class LaserAnt(ThrowerAnt): name = 'Laser' food_cost = 10 implemented = True # Change to True to view in the GUI damage = 2 def __init__(self, health=1): super().__init__(health) self.insects_shot = 0 self.current_damage = LaserAnt.damage def insects_in_front(self): \"\"\"Return a dict contains every Insect\"\"\" dis = {} for bee in self.place.bees: dis[bee] = 0 # take care of the ContainerAnt if self.place.ant is not self: dis[self.place.ant] = 0 pos = self.place.entrance distance = 1 while pos.entrance is not None: if not pos.is_hive: for bee in pos.bees: dis[bee] = distance if pos.ant is not None: dis[pos.ant] = distance # take care of the ContainerAnt if pos.ant.is_container and pos.ant.ant_contained is not None: dis[pos.ant.ant_contained] = distance distance += 1 pos = pos.entrance return dis def calculate_damage(self, distance): damage_result = self.damage - 0.0625 * self.insects_shot - 0.25 * distance return damage_result if damage_result \u003e 0 else 0 def action(self, gamestate): insects_and_distances = self.insects_in_front() for insect, distance in insects_and_distances.items(): damage = self.calculate_damage(distance) insect.reduce_health(damage) if damage: self.insects_shot += 1 ","date":"2022-03-10","objectID":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/:6:2","series":null,"tags":["Course"],"title":"CS61A 的项目三之 Ants vs SomeBees 实现 (2021-Fall)","uri":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/#optional-problem-2"},{"categories":["Course"],"content":"UCB CS61A 的题目答案","date":"2022-03-03","objectID":"/zh-cn/lab14-cs61a-of-ucb/","series":null,"tags":["Course"],"title":"Lab14 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab14-cs61a-of-ucb/"},{"categories":["Course"],"content":" Trees ","date":"2022-03-03","objectID":"/zh-cn/lab14-cs61a-of-ucb/:1:0","series":null,"tags":["Course"],"title":"Lab14 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab14-cs61a-of-ucb/#trees"},{"categories":["Course"],"content":" Q1: Prune Min Write a function that prunes a Tree t mutatively. t and its branches always have zero or two branches. For the trees with two branches, reduce the number of branches from two to one by keeping the branch that has the smaller label value. Do nothing with trees with zero branches. Prune the tree in a direction of your choosing (top down or bottom up). The result should be a linear tree. 递归的细节: 叶子结点 : 直接返回 只有一个分支 : 虽然当前节点满足条件, 但是它的子树里可能有不符合条件的节点, 所以我们要递归裁剪分支 有两个分支 : 找到较小的分支, 把较大的分支裁剪掉(用 del) python def prune_min(t): \"\"\"Prune the tree mutatively. \"\"\" # base case: the leaf node has 0 children if t.is_leaf(): return # go deeper if it has 1 child if len(t.branches) == 1: prune_min(t.branches[0]) left, right = t.branches[0], t.branches[1] if left.label \u003c right.label: del t.branches[1] # prune right branch prune_min(left) else: del t.branches[0] # prune left branch prune_min(right) ","date":"2022-03-03","objectID":"/zh-cn/lab14-cs61a-of-ucb/:1:1","series":null,"tags":["Course"],"title":"Lab14 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab14-cs61a-of-ucb/#q1-prune-min"},{"categories":["Course"],"content":" Regex ","date":"2022-03-03","objectID":"/zh-cn/lab14-cs61a-of-ucb/:2:0","series":null,"tags":["Course"],"title":"Lab14 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab14-cs61a-of-ucb/#regex"},{"categories":["Course"],"content":" Q4: Address First Line Write a regular expression that parses strings and returns any expressions which contain the first line of a US mailing address. US mailing addresses typically contain a block number, which is a sequence of 3-5 digits, following by a street name. The street name can consist of multiple words but will always end with a street type abbreviation, which itself is a sequence of 2-5 English letters. The street name can also optionally start with a cardinal direction (“N”, “E”, “W”, “S”). Everything should be properly capitalized. Proper capitalization means that the first letter of each name is capitalized. It is fine to have things like “WeirdCApitalization” match. See the doctests for some examples. 我们在这里要匹配美国的邮件地址, 下面是关于这个的正则表达式的细节: 开头有 3 - 5 个数字 然后是一个街道的名字, 可能会有多个单词, 但是结尾一定是街道类型的缩写(2 - 5 个英文字母) 但是街道名字也有可能是 “N”, “E”, “W”, “S” 这四个字母开头 ps. 上面说到的是 “properly capitalized“ 的单词, 具体定义可以看问题描述. 我的理解就是单词的开头一定要是大写, 后面就随便了~~ 下面我们分解问题, 把整个要匹配的地址分为上面提到的几个部分: 区号 : 这个简单, \\d{2,5} 即可 可能的 “N”, “E”, “W”, “S” 开头, 这个也简单, 用 (?:[NSWE] )? 注意里面有一个空格 然后就是街道名字要怎么写了, 街道名字可能包含多个单词, 每个单词都要求开头大写, 所以我们可以整合出这样的正则表达式: [A-Z][A-Za-z]*(?: [A-Z][A-Za-z]*)*. 首先要有一个单词, 然后后面可以有任意个空格 + 单词的组合 最后是要有街道类型的缩写, 注意这里仍然要是单词开头大写, 其他任意, 本来是 2 - 5 个字母, 现在去掉了开头的第一个大写字母之后, 剩下 1 - 4 个字母. [A-Z][A-Za-z]{1,4}\\b. 最后的 \\b 是让正则表达式只匹配单词的结尾. python def address_oneline(text): \"\"\" Finds and returns expressions in text that represent the first line of a US mailing address. \"\"\" block_number = r'\\d{3,5}' cardinal_dir = r'(?:[NSWE] )?' # whitespace is important! street = r'[A-Z][A-Za-z]*(?: [A-Z][A-Za-z]*)*' type_abbr = r' [A-Z][A-Za-z]{1,4}\\b' street_name = f\"{cardinal_dir}{street}{type_abbr}\" return re.findall(f\"{block_number} {street_name}\", text) ","date":"2022-03-03","objectID":"/zh-cn/lab14-cs61a-of-ucb/:2:1","series":null,"tags":["Course"],"title":"Lab14 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab14-cs61a-of-ucb/#q4-address-first-line"},{"categories":["Course"],"content":" SQL ","date":"2022-03-03","objectID":"/zh-cn/lab14-cs61a-of-ucb/:3:0","series":null,"tags":["Course"],"title":"Lab14 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab14-cs61a-of-ucb/#sql"},{"categories":["Course"],"content":" Q5: Opening Times You’d like to have lunch before 1pm. Create a opening table with the names of all Pizza places that open before 1pm, listed in reverse alphabetical order. 找到开店时间在下午一点前的, 注意数据库里的时间是 24 小时制 sql CREATE TABLE opening AS SELECT name FROM pizzas WHERE open \u003c 13 ORDER BY name DESC; ","date":"2022-03-03","objectID":"/zh-cn/lab14-cs61a-of-ucb/:3:1","series":null,"tags":["Course"],"title":"Lab14 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab14-cs61a-of-ucb/#q5-opening-times"},{"categories":["Course"],"content":" Q6: Double Pizza If two meals are more than 6 hours apart, then there’s nothing wrong with going to the same pizza place for both, right? Create a double table with three columns. The first columns is the earlier meal, the second is the later meal, and the third is the name of a pizza place. Only include rows that describe two meals that are more than 6 hours apart and a pizza place that is open for both of the meals. The rows may appear in any order. 考察表的联合, 注意细节: 两顿饭之间间隔要超过六个小时 第一顿饭的开始时间到第二顿饭的结束时间要在饭店的营业时间内 sql create TABLE double AS SELECT m1.meal, m2.meal, p.name FROM meals AS m1, meals AS m2, pizzas AS p WHERE m2.time - m1.time \u003e 6 AND m1.time \u003e= p.open AND m2.time \u003c= p.close; ","date":"2022-03-03","objectID":"/zh-cn/lab14-cs61a-of-ucb/:3:2","series":null,"tags":["Course"],"title":"Lab14 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab14-cs61a-of-ucb/#q6-double-pizza"},{"categories":["Course"],"content":" Objects ","date":"2022-03-03","objectID":"/zh-cn/lab14-cs61a-of-ucb/:4:0","series":null,"tags":["Course"],"title":"Lab14 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab14-cs61a-of-ucb/#objects"},{"categories":["Course"],"content":" Q7: Player First, let’s implement the Player class. Fill in the debate and speech methods, that take in another Player other, and implement the correct behavior as detailed above. Here are two additional things to keep in mind: In the debate method, you should call the provided random function, which returns a random float between 0 and 1. The player should gain 50 popularity if the random number is smaller than the probability described above, and lose 50 popularity otherwise. Neither players’ popularity should ever become negative. If this happens, set it equal to 0 instead. 计算方法在规则里面已经给出, 这里要注意 speech 方法里面要修改 votes 和 popularity python class Player: def __init__(self, name): self.name = name self.votes = 0 self.popularity = 100 def debate(self, other): prob1 = max(0.1, self.popularity / (self.popularity + other.popularity)) #prob2 = max(0.1, other.popularity / (self.popularity + other.popularity)) if random() \u003e prob1: self.popularity -= 50 else: self.popularity += 50 if self.popularity \u003c 0: self.popularity = 0 def speech(self, other): self.votes += (self.popularity // 10) self.popularity += (self.popularity // 10) other.popularity -= (other.popularity // 10) def choose(self, other): return self.speech ","date":"2022-03-03","objectID":"/zh-cn/lab14-cs61a-of-ucb/:4:1","series":null,"tags":["Course"],"title":"Lab14 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab14-cs61a-of-ucb/#q7-player"},{"categories":["Course"],"content":" Q8: Game Now, implement the Game class. Fill in the play method, which should alternate between the two players, starting with p1, and have each player take one turn at a time. The choose method in the Player class returns the method, either debate or speech, that should be called to perform the action. In addition, fill in the winner property method, which should return the player with more votes, or None if the players are tied. 根据 self.turn 是奇数还是偶数来决定当前轮到谁, 注意 choose 方法返回的仍然是函数, 所以你需要给他参数才行 python class Game: def __init__(self, player1, player2): self.p1 = player1 self.p2 = player2 self.turn = 0 def play(self): while not self.game_over: if self.turn % 2 == 0: self.p1.choose(self.p2)(self.p2) else: self.p2.choose(self.p1)(self.p1) self.turn += 1 return self.winner @property def game_over(self): return max(self.p1.votes, self.p2.votes) \u003e= 50 or self.turn \u003e= 10 @property def winner(self): if self.p1.votes \u003e self.p2.votes: return self.p1 else: return self.p2 ","date":"2022-03-03","objectID":"/zh-cn/lab14-cs61a-of-ucb/:4:2","series":null,"tags":["Course"],"title":"Lab14 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab14-cs61a-of-ucb/#q8-game"},{"categories":["Course"],"content":" Q9: New Players The choose method in the Player class is boring, because it always returns the speech method. Let’s implement two new classes that inherit from Player, but have more interesting choose methods. Implement the choose method in the AggressivePlayer class, which returns the debate method if the player’s popularity is less than or equal to other’s popularity, and speech otherwise. Also implement the choose method in the CautiousPlayer class, which returns the debate method if the player’s popularity is 0, and speech otherwise. 翻译一下题目的意思即可 :) python class AggressivePlayer(Player): def choose(self, other): if self.popularity \u003c= other.popularity: return self.debate else: return self.speech class CautiousPlayer(Player): def choose(self, other): if self.popularity == 0: return self.debate else: return self.speech ","date":"2022-03-03","objectID":"/zh-cn/lab14-cs61a-of-ucb/:4:3","series":null,"tags":["Course"],"title":"Lab14 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab14-cs61a-of-ucb/#q9-new-players"},{"categories":["Course"],"content":" Tree Recursion Define the function add_trees, which takes in two trees and returns a new tree where each corresponding node from the first tree is added with the node from the second tree. If a node at any particular position is present in one tree but not the other, it should be present in the new tree as well. Hint: You may want to use the built-in zip function to iterate over multiple sequences at once. 这一题要我们把一棵树合并到另外一棵树上去. 注意区分谁是主体(对后面思考如何递归解决很有用). 如何用递归解决? base case: 我们是把树 t2 加到树 t1 上, 那如果 t2 是 None 的话不就不用加了吗 ? 是的, 这个就是我们的一个 base case 🤗 在 t2 不为空的基础上, 如果 t1 因为空呢 ? 显然, 这个时候两棵树相加的结果就是 t2, 所以我们返回 t2 即可. 递归分解 这个时候我们可以保证 t1 和 t2 都是非空的, 但是我们无法保证他们两个的孩子数目是一样多的, 所以我们无法根据提示里使用 zip. 因为 zip 在处理两个两个不一样长的序列的时候, 长的序列多的部分是被忽略的. 这里应该用 itertools 里面的 zip_longest, 如果一个序列已经为空会返回 None. 这样我们才能保证这样递归调用最后可以回到我们前面讨论的 base case 中. 那我们在当前节点做的事情就是: 相加两个节点的 label, 然后对他们的子树都递归调用即可. 🚀 python def add_trees(t1, t2): # base case: no need to add_trees anymore if t2 is None: return t1 if t1 is None: return t2 else: # both of t1 and t2 are not None # however, the number of children may not equal return Tree(t1.label + t2.label, [add_trees(x, y) for x, y in zip_longest(t1.branches, t2.branches)]) ","date":"2022-03-03","objectID":"/zh-cn/lab14-cs61a-of-ucb/:5:0","series":null,"tags":["Course"],"title":"Lab14 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab14-cs61a-of-ucb/#tree-recursion"},{"categories":["Course"],"content":" Linked Lists ","date":"2022-03-03","objectID":"/zh-cn/lab14-cs61a-of-ucb/:6:0","series":null,"tags":["Course"],"title":"Lab14 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab14-cs61a-of-ucb/#linked-lists"},{"categories":["Course"],"content":" Q11: Fold Left Write the left fold function by filling in the blanks. 这个是自顶向下计算的, 也就是我们在进入更深层的递归调用之前会先计算结果, 并将这个结果传递下去, 当我们到达了空结点(说明我们做完了所有的运算)就得到了结果. 所以 base case 里面的 z 已经不是一开始的 z 了, 而是我们最后要得到的运算结果的 z python def foldl(link, fn, z): \"\"\" Left fold \u003e\u003e\u003e lst = Link(3, Link(2, Link(1))) \u003e\u003e\u003e foldl(lst, sub, 0) # (((0 - 3) - 2) - 1) -6 \u003e\u003e\u003e foldl(lst, add, 0) # (((0 + 3) + 2) + 1) 6 \u003e\u003e\u003e foldl(lst, mul, 1) # (((1 * 3) * 2) * 1) 6 \"\"\" if link is Link.empty: return z z = fn(z, link.first) return foldl(link.rest, fn, z) ","date":"2022-03-03","objectID":"/zh-cn/lab14-cs61a-of-ucb/:6:1","series":null,"tags":["Course"],"title":"Lab14 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab14-cs61a-of-ucb/#q11-fold-left"},{"categories":["Course"],"content":" Q12: Fold Right Now write the right fold function. 其实这个问题会比 Q1 更为简单, 更符合我们对递归的认知. 我们从最底层逐层返回结果运算. 可以看下面的例子理解一下 python def foldr(link, fn, z): \"\"\" Right fold \u003e\u003e\u003e lst = Link(3, Link(2, Link(1))) \u003e\u003e\u003e foldr(lst, sub, 0) # (3 - (2 - (1 - 0))) 2 \u003e\u003e\u003e foldr(lst, add, 0) # (3 + (2 + (1 + 0))) 6 \u003e\u003e\u003e foldr(lst, mul, 1) # (3 * (2 * (1 * 1))) 6 \"\"\" if link.rest is Link.empty: return fn(link.first, z) return fn(link.first, foldr(link.rest, fn, z)) ","date":"2022-03-03","objectID":"/zh-cn/lab14-cs61a-of-ucb/:6:2","series":null,"tags":["Course"],"title":"Lab14 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab14-cs61a-of-ucb/#q12-fold-right"},{"categories":["Course"],"content":" Regex ","date":"2022-03-03","objectID":"/zh-cn/lab14-cs61a-of-ucb/:7:0","series":null,"tags":["Course"],"title":"Lab14 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab14-cs61a-of-ucb/#regex-1"},{"categories":["Course"],"content":" Q13: Basic URL Validation In this problem, we will write a regular expression which matches a URL. URLs look like the following: For example, in the link https://cs61a.org/resources/#regular-expressions, we would have: Scheme: https Domain Name: cs61a.org Path to the file: /resources/ Anchor: #regular-expressions The port and parameters are not present in this example and you will not be required to match them for this problem. You can reference this documentation from MDN if you’re curious about the various parts of a URL. For this problem, a valid domain name consists of any sequence of letters, numbers, dashes, and periods. For a URL to be “valid,” it must contain a valid domain name and will optionally have a scheme, path, and anchor. A valid scheme will either be http or https. Valid paths start with a slash and then must be a valid path to a file or directory. This means they should match something like /composingprograms.html or path/to/file but not /composing.programs.html/. A valid anchor starts with #. While they are more complicated, for this problem assume that valid anchors will then be followed by letters, numbers, hyphens, or underscores. Hint 1: You can use \\ to escape special characters in regex. \u003eHint 2: The provided code already handles making the scheme, path, and anchor optional by using non-capturing groups. 要学会将复杂的正则表达式进行拆解, 一个部分一个部分的完成. 题目已经为我们完成了这个工作. 接下来我讲解一下每个部分的设计要点 scheme : 这个简单, 要么是 http 要么是 https, 我们可以用 (?:...) 来写 domain : www 可以有也可以没有, 可以用 (?:...)? 来表达这点 path to the file: 包含下面三种可能的格式: /path/to/file.extension, /path, /file.extension anchor : 这个可能包括字母、数字、短横线 -, 下划线 _ python def match_url(text): scheme = r'(?:https|http)://' domain = r'(?:\\w+\\.)?\\w+\\.\\w+' path = r'(?:/\\w+|/(\\w+/)*)(\\w+\\.\\w+)?' anchor = r'#[\\w\\-_]*' return bool(re.match(rf\"^(?:{scheme})?{domain}(?:{path})?(?:{anchor})?$\", text)) ","date":"2022-03-03","objectID":"/zh-cn/lab14-cs61a-of-ucb/:7:1","series":null,"tags":["Course"],"title":"Lab14 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab14-cs61a-of-ucb/#q13-basic-url-validation"},{"categories":["Course"],"content":" BNF ","date":"2022-03-03","objectID":"/zh-cn/lab14-cs61a-of-ucb/:8:0","series":null,"tags":["Course"],"title":"Lab14 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab14-cs61a-of-ucb/#bnf"},{"categories":["Course"],"content":" Q14: Simple CSV CSV, which stands for “Comma Separated Values,” is a file format to store columnar information. We will write a BNF grammar for a small subset of CSV, which we will call SimpleCSV. Create a grammar that reads SimpleCSV, where a file contains rows of words separated by commas. Words are characters [a-zA-Z] (and may be blank!) Spaces are not allowed in the file. 写一个简单的 csv 文件的 BNF, 这里说的简单是因为: 值只能是单词, 分隔符一定是 , 细节: 有可能有 ,,, 的情况出现, 所以我们需要在 word 里面用 | 来算上不放任何字符的情况 text lines: line (newline line)* | line newline | line line: word (\",\" word)* word: WORD | newline: \"\\n\" %import common.WORD ","date":"2022-03-03","objectID":"/zh-cn/lab14-cs61a-of-ucb/:8:1","series":null,"tags":["Course"],"title":"Lab14 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab14-cs61a-of-ucb/#q14-simple-csv"},{"categories":["Course"],"content":"The simple solutions of hw10 of CS61A of UCB","date":"2022-03-02","objectID":"/zh-cn/hw10-of-cs61a-of-ucb/","series":null,"tags":["Course"],"title":"Hw10 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/hw10-of-cs61a-of-ucb/"},{"categories":["Course"],"content":" BNF ","date":"2022-03-02","objectID":"/zh-cn/hw10-of-cs61a-of-ucb/:1:0","series":null,"tags":["Course"],"title":"Hw10 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/hw10-of-cs61a-of-ucb/#bnf"},{"categories":["Course"],"content":" Q1: Grouping and Pipes In this question, you will add support for grouping and piping. Recall that grouping allows for an entire regular expression to be treated as a single unit, and piping allows for a pattern to match an expression on either side. Combined, these will let us create patterns which match multiple strings! Define the group and pipe expressions in your grammar. A group consists of any regex expression surrounded by parentheses (()). A pipe operator consists of a regex expression, followed by a pipe (|) character, and lastly followed by another regex expression. For example, r\"apples\" would match exactly the phrase “apples” in an input. If we wanted our pattern from before to match “oranges” as well, we could expand our rstring to do so using groupings and pipes: r\"(apples)|(oranges)\". Hint: note that groups and pipes are valid regex expressions on their own! You may need to update a previously defined expression. 给本来用来匹配正则表达式的 BNF 添加功能: group 和 pipe. 其实怎么实现这一写已经在描述里面给出了, 我这里就提一点: group 和 pipe 本身也是 ?regex 的一部分, 所以要把他们加到 ?regex 里面 text ?start: rstring rstring: \"r\\\"\" regex* \"\\\"\" ?regex: character | word | group | pipe group: \"(\" regex* \")\" pipe: regex \"|\" regex character: LETTER | NUMBER word: WORD %ignore /\\s+/ %import common.LETTER %import common.NUMBER %import common.WORD ","date":"2022-03-02","objectID":"/zh-cn/hw10-of-cs61a-of-ucb/:1:1","series":null,"tags":["Course"],"title":"Hw10 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/hw10-of-cs61a-of-ucb/#q1-grouping-and-pipes"},{"categories":["Course"],"content":" Q2: Classes Now, we will add support for character classes. Recall that character classes allow for the pattern to match any singular character defined within the class. The class itself consists either of individual characters, or ranges of characters. Specifically, we define the following: A range consists of either NUMBERs or LETTERs separated by a hyphen (-). A class expression consists of any number of characters or character ranges surrounded by square brackets ([]). Note that for this question, a range may only consist of either NUMBERs or LETTERs; this means that while [0-9] and [A-Z] are valid ranges, [0-Z] would not be a valid range. In addition, the characters and ranges in a class may appear in any order and any number of times. For example, [ad-fc0-9], [ad-f0-9c], [a0-9d-fc], and [0-9ad-fc] are all valid classes. 这次要加上的功能是 ?-? 和 [] 的功能, 具体怎么做同样在问题描述里面给出了. 这里讲一下注意的点: range 的 - 左右两边要是对应的, 所以 character \"-\" character 这种写法是错的 在 [] 里, 要么是 range, 要么是 character, 可以用 (range|character) 表示，后面用 * 表示 any number [] 本身也是合法的正则表达式, 所以要放在 ?regex 里面 text ?start: rstring rstring: \"r\\\"\" regex* \"\\\"\" ?regex: character | word | group | pipe | class group: \"(\" regex* \")\" pipe: regex \"|\" regex range: NUMBER \"-\" NUMBER | LETTER \"-\" LETTER class: \"[\" (range|character)* \"]\" character: LETTER | NUMBER word: WORD %ignore /\\s+/ %import common.LETTER %import common.NUMBER %import common.WORD ","date":"2022-03-02","objectID":"/zh-cn/hw10-of-cs61a-of-ucb/:1:2","series":null,"tags":["Course"],"title":"Hw10 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/hw10-of-cs61a-of-ucb/#q2-classes"},{"categories":["Course"],"content":" Q3: Quantifiers Lastly, we will add support for quantifiers. Recall that quantifiers allow for a pattern to match a specified number of a unit. Specifically, we define the following: A plus_quant expression consists of a group, a character, or a class, followed by a plus symbol (+). A star_quant expression consists of a group, a character, or a class, followed by a star symbol (*). A num_quant expression consists of either a group, a character, or a class, followed by one of the following: a NUMBER enclosed in curly braces ({}); a range of NUMBERs (separated by a comma (,), which may potentially be open on only one side. For example, {2,7}, {2,}, and {,7} are valid numeric quantifiers. {,} is not valid. Hint: these three quantifiers share many similarities. Consider defining additional expressions in this question! 可以发现这三个 _quant 都是 group 或者 character 或者 class开头, 所以这里可以定义一个 ?tmp: class | group | character 避免重复. 同时定义 ?quants: plus_quant | star_quant | num_quant, 放在 ?regex 里 这里 num_quant 需要枚举下面这几种情况 {NUMBER, NUMBER} or {NUMBER} -\u003e (NUMBER (\",\", NUMBER)?) {NUMBER,} -\u003e (NUMBER \",\") {,NUMBER} -\u003e (\",\" NUMBER) text rstring: \"r\\\"\" regex* \"\\\"\" ?regex: character | word | group | pipe | class | quants group: \"(\" regex* \")\" pipe: regex \"|\" regex range: NUMBER \"-\" NUMBER | LETTER \"-\" LETTER class: \"[\" range* character* range* character* \"]\" ?tmp: class | group | character plus_quant: tmp \"+\" star_quant: tmp \"*\" num_quant: tmp \"{\" ((NUMBER (\",\" NUMBER)?) | (NUMBER \",\") | (\",\" NUMBER)) \"}\" ?quants: plus_quant | star_quant | num_quant character: LETTER | NUMBER word: WORD %ignore /\\s+/ %import common.LETTER %import common.NUMBER %import common.WORD ","date":"2022-03-02","objectID":"/zh-cn/hw10-of-cs61a-of-ucb/:1:3","series":null,"tags":["Course"],"title":"Hw10 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/hw10-of-cs61a-of-ucb/#q3-quantifiers"},{"categories":["Course"],"content":" SQL ","date":"2022-03-02","objectID":"/zh-cn/hw10-of-cs61a-of-ucb/:2:0","series":null,"tags":["Course"],"title":"Hw10 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/hw10-of-cs61a-of-ucb/#sql"},{"categories":["Course"],"content":" Q4: Size of Dogs The Fédération Cynologique Internationale classifies a standard poodle as over 45 cm and up to 60 cm. The sizes table describes this and other such classifications, where a dog must be over the min and less than or equal to the max in height to qualify as a size. Create a size_of_dogs table with two columns, one for each dog’s name and another for its size. 要根据狗的体型大小来决定它的 size. 这个就是一个基本的 select ... from ... where 的写法. 我们这里可以把两个表连接起来得到所有可能的结果, 然后用 where 来选出符合条件的. 注意这里用 alias 会比较简洁 mysql CREATE TABLE size_of_dogs AS SELECT d.name, s.size FROM dogs as d, sizes as s where d.height \u003c= s.max and d.height \u003e s.min; ","date":"2022-03-02","objectID":"/zh-cn/hw10-of-cs61a-of-ucb/:2:1","series":null,"tags":["Course"],"title":"Hw10 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/hw10-of-cs61a-of-ucb/#q4-size-of-dogs"},{"categories":["Course"],"content":" Q5: By Parent Height Create a table by_parent_height that has a column of the names of all dogs that have a parent, ordered by the height of the parent from tallest parent to shortest parent. 用 ORDER BY 来进行排序, 注意是降序所以用 DESC mysql CREATE TABLE siblings AS SELECT p1.child AS dogone, p2.child AS dogtwo, s1.size AS dogonesize, s2.size AS dogtwosize FROM parents AS p1, parents AS p2, size_of_dogs AS s1, size_of_dogs AS s2 WHERE p1.parent = p2.parent AND p1.child \u003c p2.child AND p1.child = s1.name AND p2.child = s2.name; -- Use `\u003c` to filter the result -- `!=` is not enough, you will get `barack clinton` and `clinton barack` in the same time ","date":"2022-03-02","objectID":"/zh-cn/hw10-of-cs61a-of-ucb/:2:2","series":null,"tags":["Course"],"title":"Hw10 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/hw10-of-cs61a-of-ucb/#q5-by-parent-height"},{"categories":["Course"],"content":" Q6: Sentences There are two pairs of siblings that have the same size. Create a table that contains a row with a string for each of these pairs. Each string should be a sentence describing the siblings by their size. Each sibling pair should appear only once in the output, and siblings should be listed in alphabetical order (e.g. \"barack plus clinton...\" instead of \"clinton plus barack...\"), as follows: Hint: First, create a helper table containing each pair of siblings. This will make comparing the sizes of siblings when constructing the main table easier. Hint: If you join a table with itself, use AS within the FROM clause to give each table an alias. Hint: In order to concatenate two strings into one, use the || operator. 完成了 Q5 之后这一题就很简单了. mysql CREATE TABLE sentences AS SELECT \"The two siblings, \" || dogone || \" plus \" || dogtwo || \" have the same size: \" || dogonesize FROM siblings WHERE dogonesize = dogtwosize AND dogone \u003c dogtwo; ","date":"2022-03-02","objectID":"/zh-cn/hw10-of-cs61a-of-ucb/:2:3","series":null,"tags":["Course"],"title":"Hw10 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/hw10-of-cs61a-of-ucb/#q6-sentences"},{"categories":["Course"],"content":"the simple solutions for lab12 of CS61A of UCB","date":"2022-03-02","objectID":"/zh-cn/lab12-ca61a-of-ucb/","series":null,"tags":["Course"],"title":"Lab12 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab12-ca61a-of-ucb/"},{"categories":["Course"],"content":" Regular Expressions ","date":"2022-03-02","objectID":"/zh-cn/lab12-ca61a-of-ucb/:1:0","series":null,"tags":["Course"],"title":"Lab12 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab12-ca61a-of-ucb/#regular-expressions"},{"categories":["Course"],"content":" Q1: Calculator Ops Write a regular expression that parses strings written in the 61A Calculator language and returns any expressions which have two numeric operands, leaving out the parentheses around them. 写一个符合 (operand operator1 operator2) 格式的正则表达式. 这个是比较简单的, 因为这里的运算符只有 +, -, *, /. 我们用 [] 括起来就可以, 但是要注意**- 需要用 \\ 转义** python def calculator_ops(calc_str): \"\"\" Finds expressions from the Calculator language that have two numeric operands and returns the expression without the parentheses. \"\"\" return re.findall(r'[+\\-*/] \\d+ \\d+', calc_str) ","date":"2022-03-02","objectID":"/zh-cn/lab12-ca61a-of-ucb/:1:1","series":null,"tags":["Course"],"title":"Lab12 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab12-ca61a-of-ucb/#q1-calculator-ops"},{"categories":["Course"],"content":" BNF ","date":"2022-03-02","objectID":"/zh-cn/lab12-ca61a-of-ucb/:2:0","series":null,"tags":["Course"],"title":"Lab12 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab12-ca61a-of-ucb/#bnf"},{"categories":["Course"],"content":" Q3: Linked List BNF In this problem, we’re going to define a BNF that parses integer Linked Lists created in Python. We won’t be handling Link.empty. For reference, here are some examples of Linked Lists: Your implementation should be able to handle nested Linked Lists, such as the third example below. Link(2) Link(12, Link(2)) Link(5, Link(7, Link(Link(8, Link(9))))) 要写一个能匹配链表(除了空结点的)的 Context-free grammar. 例子已经在问题的描述里面给出了 思路是这样的: 链表的开头肯定是 Link(, 然后我们可以把链表里面分为 link_first 和 link_rest 部分, 他们要么是数字, 要么就是另一个链表. 至于链表的语法是这样的: link_first 和 link_rest 有可能是链表也有可能是普通的数字; link_rest 可能是空的. 根据这些规则, 我们可以写出 BNF text link: \"Link(\" link_first \")\" | \"Link(\" link_first \",\" link_rest \")\" ?link_first: NUMBER | link ?link_rest: NUMBER | link %ignore /\\s+/ %import common.NUMBER ","date":"2022-03-02","objectID":"/zh-cn/lab12-ca61a-of-ucb/:2:1","series":null,"tags":["Course"],"title":"Lab12 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab12-ca61a-of-ucb/#q3-linked-list-bnf"},{"categories":["Course"],"content":" Q4: Tree BNF Now, we will define a BNF to parse Trees with integer leaves created in Python. Here are some examples of Trees: Your implementation should be able to handle Trees with no branches and one or more branches. Tree(2) Tree(6, [Tree(1), Tree(3, [Tree(1), Tree(2)])]) 给树定义一个 CFG: tree_node: 可以是只有一个节点的树, 也可以是有结点还有分支的树, 注意分支可以有任意个(包括 0), 所以我们可以用正则表达式中的 + ?label: 就是数字, 直接用 NUMBER 即可 branches: 可以是只有一个节点, 或者有多个节点(此时我们要把 , 号匹配进去) text tree_node: \"Tree(\" label \")\" | \"Tree(\" label \",\" branches* \")\" ?label: NUMBER branches: \"[\" tree_node \"]\" | \"[\" tree_node \",\" tree_node+ \"]\" %ignore /\\s+/ %import common.NUMBER ","date":"2022-03-02","objectID":"/zh-cn/lab12-ca61a-of-ucb/:2:2","series":null,"tags":["Course"],"title":"Lab12 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab12-ca61a-of-ucb/#q4-tree-bnf"},{"categories":["Course"],"content":"The simple solutions of hw09 of CS61A of UCB","date":"2022-03-01","objectID":"/zh-cn/hw09-of-cs61a-of-ucb/","series":null,"tags":["Course"],"title":"Hw09 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/hw09-of-cs61a-of-ucb/"},{"categories":["Course"],"content":" Q2: Roman Numerals Write a regular expression that finds any string of letters that resemble a Roman numeral and aren’t part of another word. A Roman numeral is made up of the letters I, V, X, L, C, D, M and is at least one letter long. For the purposes of this problem, don’t worry about whether or not a Roman numeral is valid. For example, “VIIIII” is not a Roman numeral, but it is fine if your regex matches it. 要我们写正则表达式, 注意题目给出的关键信息: 可能出现的字符是 I, V, X, L, C, D, M, 表示或这个关系可以用 [] 至少会出现 1 个字符. 表达至少有一个在正则表达式中可以用 + 这些字母出现的时候不能是其他单词的一部分. 这个可以用 \\b. 根据文档里说的, 它是用来匹配单词开头或者是结尾的(Matches the empty string, but only at the beginning or end of a word) python def roman_numerals(text): \"\"\" Finds any string of letters that could be a Roman numeral (made up of the letters I, V, X, L, C, D, M). \"\"\" return re.findall(r'\\b[IVXLCDM]+\\b', text) ","date":"2022-03-01","objectID":"/zh-cn/hw09-of-cs61a-of-ucb/:0:1","series":null,"tags":["Course"],"title":"Hw09 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/hw09-of-cs61a-of-ucb/#q2-roman-numerals"},{"categories":["Course"],"content":" Q3: CS Classes On reddit.com, there is an /r/berkeley subreddit for discussions about everything UC Berkeley. However, there is such a large amount of CS-related posts that those posts are auto-tagged so that readers can choose to ignore them or read only them. Write a regular expression that finds strings that resemble a CS class- starting with “CS”, followed by a number, and then optionally followed by “A”, “B”, or “C”. Your search should be case insensitive, so both “CS61A” and “cs61a” would match. 提取正则表达式的关键信息: 不管是开头的 CS 还是末尾的 ABC 都是大小写不敏感的. 用 [] 枚举即可 CS 和后面的数字之间可能有空格, 这个我们用 ? 即可. python def cs_classes(post): \"\"\" Returns strings that look like a Berkeley CS class, starting with \"CS\", followed by a number, optionally ending with A, B, or C and potentially with a space between \"CS\" and the number. Case insensitive. \"\"\" return bool(re.search(r'[Cc][Ss] ?\\d+[ABCabc]?', post)) ","date":"2022-03-01","objectID":"/zh-cn/hw09-of-cs61a-of-ucb/:0:2","series":null,"tags":["Course"],"title":"Hw09 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/hw09-of-cs61a-of-ucb/#q3-cs-classes"},{"categories":["Course"],"content":" Q4: Time for Times You’re given a body of text and told that within it are some times. Write a regular expression which, for a few examples, would match the following: text ['05:24', '7:23', '23:59', '12:22', '00:00'] but would not match these invalid “times” text ['05:64', '70:23'] You may find non-capturing groups helpful to use for this question. 也就是要匹配时间的格式, 而且要是有效时间(00:00 ~ 23:59), 注意要处理下面四个数字的关系 第一位: 可以有前导 0 或者省略, 1 也是合法的. 难点在于 2, 因为我们知道当格式是 2?:?? 的时候最多只能到 23:59 第二位: 这个在开头不是 2 的时候就是 0 ~ 9 第三位和第四位: 00 ~ 59 这么一想这一道题还挺复杂 :( 然后我去看看提示发现了一个好用的写法 (?:...), 表示我们想匹配但是不把 () 里的结果保存下来返回. 还有末尾的 AM 就可以用 (?:AM)? 来处理 python def match_time(text): return re.findall(r'(?:[01]?\\d|2[0-3]):[0-5][0-9](?:AM)?', text) ","date":"2022-03-01","objectID":"/zh-cn/hw09-of-cs61a-of-ucb/:0:3","series":null,"tags":["Course"],"title":"Hw09 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/hw09-of-cs61a-of-ucb/#q4-time-for-times"},{"categories":["Course"],"content":" Q5: Most Common Area Code Write a function which takes in a body of text and finds the most common area code. Area codes must be part of a valid phone number. To solve this problem, we will first write a regular expression which finds valid phone numbers and captures the area code. See the docstring of area_codes for specifics on what qualifies as a valid phone number. 大家都知道电话前面会有区号, 现在这一题要求我们找到出现次数最多的区号, 首先要匹配所有的电话号码的区号(area_codes). 然后返回出现次数最多的区号就好了. 注意正则表达式的特征: 电话号码有 10 位 区号是前三位, 有的会用括号 () 括起来有的不会 区号和电话号码之间以及电话号码的前三位和后四位之间可能有空格或者是 - 怎么表示可能出现的 () 呢? 其实用上一题的 (?:...)? 这种格式就可以 🤗 python def area_codes(text): \"\"\" Finds all phone numbers in text and captures the area code. Phone numbers have 10 digits total and may have parentheses around the area code, and hyphens or spaces after the third and sixth digits. \"\"\" return re.findall(r'(?:\\()?(\\d{3})(?:\\)?)(?: |-)?\\d{3}(?: |-)?\\d{4}\\b', text) def most_common_code(text): \"\"\" Takes in an input string which contains at least one phone number (and may contain more) and returns the most common area code among all phone numbers in the input. If there are multiple area codes with the same frequency, return the first one that appears in the input text. \"\"\" area_codes_list = area_codes(text) cnts = [area_codes_list.count(e) for e in area_codes_list] # count every area_code max_cnt_idx = cnts.index(max(cnts)) # get the index of the max value return area_codes_list[max_cnt_idx] ","date":"2022-03-01","objectID":"/zh-cn/hw09-of-cs61a-of-ucb/:0:4","series":null,"tags":["Course"],"title":"Hw09 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/hw09-of-cs61a-of-ucb/#q5-most-common-area-code"},{"categories":["Course"],"content":"the simple solutions for lab11 of CS61A of UCB","date":"2022-03-01","objectID":"/zh-cn/lab11-cs61a-of-ucb/","series":null,"tags":["Course"],"title":"Lab11 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab11-cs61a-of-ucb/"},{"categories":["Course"],"content":" Context ","date":"2022-03-01","objectID":"/zh-cn/lab11-cs61a-of-ucb/:1:0","series":null,"tags":["Course"],"title":"Lab11 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab11-cs61a-of-ucb/#context"},{"categories":["Course"],"content":" Problem 1 Important: Your code for this part should go in buffer.py. Your job in this part is to implement the current and pop_first methods of the Buffer class. current should return the current token of the current line we’re on in the Buffer instance without removing it. If there are no more tokens in the current line, then current should move onto the next valid line, and return the first token of this line. If there are no more tokens left to return from the entire source (we’ve reached the end of all input lines), then current should return None (this logic is already provided for you in the except StopIteration block). If we call current multiple times in a row, we should get the same result since calls to current won’t change what token we’re returning. You may find self.index helpful while implementing these functions, but you are not required to reference it in your solution. Hint: What instance attribute can we use to keep track of where we are in the current line? Hint: If we’ve reached the end of the current line, then self.more_on_line() will return False. In that case, how do we “reset” our position to the beginning of the next line? pop_first should return the current token of the Buffer instance, and move onto the next potential token (to be returned on the next call to pop_first). If there are no more tokens left to return from the entire source (we’ve reached the end of all input lines), then pop_first should return None. Hint: Do we need to update anything to move onto the next potential token? 要在 buffer.py 文件里面实现两个函数: current 和 pop_first 函数 其中 current 函数有下面几个要求: 返回的是当前行对应位置的 token, 如果没有了才会移动到下一个有效的行, 然后返回那一行的第一个 token. 关于这个它已经提供了一个函数 self.more_on_line() 来判断当前行是否还有 token 我们没有处理 如果整个文件已经读取完了就返回 None. 这也也简单, 我们知道当一个 iterator 我们读取完的时候返回的是 StopIteration 在同一行内多次调用的时候, 结果应该一样. **显然我们这里可以用 self.index 这个变量来控制. 至于 pop_first 函数比较简单, 因为它调用一下 current 函数和增加 self.index 即可 python class Buffer: \"\"\"A Buffer provides a way of accessing a sequence of tokens across lines. Its constructor takes an iterator, called \"the source\", that returns the next line of tokens as a list each time it is queried, or None to indicate the end of data. The Buffer in effect concatenates the sequences returned from its source and then supplies the items from them one at a time through its pop_first() method, calling the source for more sequences of items only when needed. In addition, Buffer provides a current method to look at the next item to be supplied, without sequencing past it. The __str__ method prints all tokens read so far, up to the end of the current line, and marks the current token with \u003e\u003e. \"\"\" def __init__(self, source): self.index = 0 self.source = source self.current_line = () self.current() def pop_first(self): \"\"\"Remove the next item from self and return it. If self has exhausted its source, returns None.\"\"\" current = self.current() self.index += 1 return current def current(self): \"\"\"Return the current element, or None if none exists.\"\"\" # if there are any token in current line we don't return while not self.more_on_line(): self.index = 0 try: self.current_line = next(self.source) except StopIteration: self.current_line = () return None return self.current_line[self.index] def more_on_line(self): return self.index \u003c len(self.current_line) ","date":"2022-03-01","objectID":"/zh-cn/lab11-cs61a-of-ucb/:1:1","series":null,"tags":["Course"],"title":"Lab11 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab11-cs61a-of-ucb/#problem-1"},{"categories":["Course"],"content":" Internal Representations ","date":"2022-03-01","objectID":"/zh-cn/lab11-cs61a-of-ucb/:2:0","series":null,"tags":["Course"],"title":"Lab11 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab11-cs61a-of-ucb/#internal-representations"},{"categories":["Course"],"content":" Problem 2 Important: Your code for this part should go in scheme_reader.py. Your job in this part is to write the parsing functionality, which consists of two mutually recursive functions:scheme_read and read_tail. Each function takes in a single src parameter, which is a Buffer instance. scheme_read removes enough tokens from src to form a single expression and returns that expression in the correct internal representation. read_tail expects to read the rest of a list or Pair, assuming the open parenthesis of that list or Pair has already been removed by scheme_read. It will read expressions (and thus remove tokens) until the matching closing parenthesis ) is seen. This list of expressions is returned as a linked list of Pair instances. In short, scheme_read returns the next single complete expression in the buffer and read_tail returns the rest of a list or Pair in the buffer. Both functions mutate the buffer, removing the tokens that have already been processed. The behavior of both functions depends on the first token currently in src. They should be implemented as follows: scheme_read: If the current token is the string \"nil\", return the nil object. If the current token is (, the expression is a pair or list. Call read_tail on the rest of src and return its result. If the current token is ', the rest of the buffer should be processed as a quote expression. You will implement this portion in the next problem. If the next token is not a delimiter, then it must be a primitive expression (i.e. a number, boolean). Return it. Provided If none of the above cases apply, raise an error. Provided read_tail: If there are no more tokens, then the list is missing a close parenthesis and we should raise an error. Provided If the token is ), then we’ve reached the end of the list or pair. Remove this token from the buffer and return the nil object. If none of the above cases apply, the next token is the operator in a combination. For example, src could contain + 2 3). To parse this: scheme_read the next complete expression in the buffer. Call read_tail to read the rest of the combination until the matching closing parenthesis. Return the results as a Pair instance, where the first element is the next complete expression from (1) and the second element is the rest of the combination from (2). 这一题的代码和下一题的放在一起 :) ","date":"2022-03-01","objectID":"/zh-cn/lab11-cs61a-of-ucb/:2:1","series":null,"tags":["Course"],"title":"Lab11 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab11-cs61a-of-ucb/#problem-2"},{"categories":["Course"],"content":" Problem 3 Important: Your code for this part should go in scheme_reader.py. Your task in this problem is to complete the implementation of scheme_read by allowing the function to now be able to handle quoted expressions. In Scheme, quoted expressions such as '\u003cexpr\u003e are equivalent to (quote \u003cexpr\u003e). That means that we need to wrap the expression following ' (which you can get by recursively calling scheme_read) into the quote special form, which is a Scheme list (as with all special forms). In our representation, a Pair represents a Scheme list. You should therefore wrap the expression following ' in a Pair. For example, 'bagel, or [\"'\", \"bagel\"] after being tokenized, should be represented as Pair('quote', Pair('bagel', nil)). '(1 2) (or [\"'\", \"(\", 1, 2, \")\"]) should be represented as Pair('quote', Pair(Pair(1, Pair(2, nil)), nil)). 这个要我们实现 Scheme 中的 ' 机制, 其实任务描述中的 which you can get by recursively calling scheme_read 已经告诉我们怎么解决这个问题的了, 新建一个 Pair, 它的第一个元素是 quote, 剩下的元素我们调用 scheme_reader 即可, 因为其实跟在 ' 后面的是 expression, 而 scheme_read 就是处理这个的. python def scheme_read(src): \"\"\"Read the next expression from SRC, a Buffer of tokens. \"\"\" if src.current() is None: raise EOFError val = src.pop_first() # Get and remove the first token if val == 'nil': return nil elif val == '(': return read_tail(src) elif val == \"'\": return Pair('quote', Pair(scheme_read(src), nil)) elif val not in DELIMITERS: return val else: raise SyntaxError('unexpected token: {0}'.format(val)) def read_tail(src): \"\"\"Return the remainder of a list in SRC, starting before an element or ). \"\"\" try: if src.current() is None: raise SyntaxError('unexpected end of file') elif src.current() == ')': src.pop_first() return nil else: return Pair(scheme_read(src), read_tail(src)) except EOFError: raise SyntaxError('unexpected end of file') ","date":"2022-03-01","objectID":"/zh-cn/lab11-cs61a-of-ucb/:2:2","series":null,"tags":["Course"],"title":"Lab11 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab11-cs61a-of-ucb/#problem-3"},{"categories":["Course"],"content":"The simple solutions of hw08 of CS61A of UCB","date":"2022-02-28","objectID":"/zh-cn/hw08-of-cs61a-of-ucb/","series":null,"tags":["Course"],"title":"Hw08 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/hw08-of-cs61a-of-ucb/"},{"categories":["Course"],"content":" Q1: My Filter Write a procedure my-filter, which takes a predicate func and a list lst, and returns a new list containing only elements of the list that satisfy the predicate. The output should contain the elements in the same order that they appeared in the original list. Note: Make sure that you are not just calling the built-in filter function in Scheme - we are asking you to re-implement this! 写一个可以用在列表上的过滤函数, 如果 func 对元素的判断结果是 #t, 我们就保留这个元素 base case: 空列表, 否则我们就递归分解处理这个问题, 如果当前的元素的值符合条件就把它包括进去否则排除掉 scheme (define (my-filter func lst) (cond ((null? lst) '()) ((func (car lst)) (cons (car lst) (my-filter func (cdr lst)))) (else (my-filter func (cdr lst)))) ) ","date":"2022-02-28","objectID":"/zh-cn/hw08-of-cs61a-of-ucb/:0:1","series":null,"tags":["Course"],"title":"Hw08 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/hw08-of-cs61a-of-ucb/#q1-my-filter"},{"categories":["Course"],"content":" Q2: Interleave Implement the function interleave, which takes a two lists s1 and s2 as arguments. interleave should return a new list that interleaves the elements of the two lists. (In other words, the resulting list should contain elements alternating between s1 and s2.) If one of the input lists to interleave is shorter than the other, then interleave should alternate elements from both lists until one list has no more elements, and then the remaining elements from the longer list should be added to the end of the new list. 返回一个新的列表, 里面是两个输入的列表的元素交替出现后的结果. 用递归的思路来解决这个问题: 当两个列表都空的时候显然要添加的是 nil. 至于如何递归分解问题: 我们可以采用轮流交换 s1 和 s2 这两个参数. 下面假设我们函数的第一个参数为 first_param, 第二个参数为 second_param. 我们在递归分解的时候就每次都取当前第一个列表的 (car first_param), 然后我们递归调用 (interleave second_param (cdr first_param)). **相当于每次我们递归调用都会往结果里添加一个第一个列表的第一个元素. 那么如果这个第一个列表为空呢?, 我们递归调用 (interleave second_param first_param). scheme (define (interleave s1 s2) (cond ((and (null? s1) (null? s2)) nil) ; base case: return nil if both are empty ((null? s1) (interleave s2 s1)) ; change the positions of s1 and s2 (else (cons (car s1) (interleave s2 (cdr s1))))) ; we always insert (car s1) to the result :) ) ","date":"2022-02-28","objectID":"/zh-cn/hw08-of-cs61a-of-ucb/:0:2","series":null,"tags":["Course"],"title":"Hw08 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/hw08-of-cs61a-of-ucb/#q2-interleave"},{"categories":["Course"],"content":" Q3: Accumulate Fill in the definition for the procedure accumulate, which merges the first n natural numbers (ie. 1 to n, inclusive) according to the following parameters: merger: a function of two arguments start: a number with which we start merging with n: the number of natural numbers to merge term: a function of one argument that computes the nth term of a sequence For example, we can find the product of all the numbers from 1 to 5 by using the multiplication operator as the merger, and starting our product at 1: 算前 n 个数字的“和”(用区间表示是 [1, n]), 给定的参数包括起始值是多少, 两个数之间如何算“和”, 以及如何算出第 i 个数字的值 难点在于, Scheme 里面也没有 while 循环, 我们得把这个算法改为递归的版本. 首先先想一下 base case 是什么, 显然是 n = 1 的时候, 这个时候我们根据 merge 来算 start 和 term(i) 的“和”, 其他情况我们递归分解处理 n - 1 这个子问题 scheme (define (accumulate merger start n term) (cond ((= n 1) (merger (term n) start)) ; base case: n = 1 (else (merger (term n) (accumulate merger start (- n 1) term)))) ) ","date":"2022-02-28","objectID":"/zh-cn/hw08-of-cs61a-of-ucb/:0:3","series":null,"tags":["Course"],"title":"Hw08 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/hw08-of-cs61a-of-ucb/#q3-accumulate"},{"categories":["Course"],"content":" Q4: No Repeats Implement no-repeats, which takes a list of numbers lst as input and returns a list that has all of the unique elements of lst in the order that they first appear, but no repeats. For example, (no-repeats (list 5 4 5 4 2 2))evaluates to (5 4 2). Hint: How can you make the first time you see an element in the input list be the first and only time you see the element in the resulting list you return? Hint: You may find it helpful to use the my-filter procedure with a helper lambda function to use as a filter. To test if two numbers are equal, use the = procedure. To test if two numbers are not equal, use the notprocedure in combination with =. 这一题要求我们对列表做去重工作, 提示说是用 Q1 的 my-filter 函数 显然 base case 是列表为空的时候, 这个时候我们直接返回 nil, 而如果不是空, 我们就要在 (cdr lst) 中删除所有值为 (car lst) 的元素, 这个刚好可以用我们在 Q1 中写的 my-filter 函数 (ps. 因为多了一组括号找 bug 找了好久 😢) scheme (define (no-repeats lst) (cond ((null? lst) nil) (else (cons (car lst) (no-repeats ; choose the elements that are not equal to `car lst` (my-filter (lambda (x) (not (= x (car lst)))) (cdr lst)))))) ) ","date":"2022-02-28","objectID":"/zh-cn/hw08-of-cs61a-of-ucb/:0:4","series":null,"tags":["Course"],"title":"Hw08 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/hw08-of-cs61a-of-ucb/#q4-no-repeats"},{"categories":["Course"],"content":"The simple solutions of hw06 of CS61A of UCB","date":"2022-02-27","objectID":"/zh-cn/hw06-of-cs61a-of-ucb/","series":null,"tags":["Course"],"title":"Hw06 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/hw06-of-cs61a-of-ucb/"},{"categories":["Course"],"content":" OOP ","date":"2022-02-27","objectID":"/zh-cn/hw06-of-cs61a-of-ucb/:1:0","series":null,"tags":["Course"],"title":"Hw06 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/hw06-of-cs61a-of-ucb/#oop"},{"categories":["Course"],"content":" Q1: Vending Machine In this question you’ll create a vending machine that only outputs a single product and provides change when needed. Create a class called VendingMachine that represents a vending machine for some product. A VendingMachineobject returns strings describing its interactions. Remember to match exactly the strings in the doctests – including punctuation and spacing! Fill in the VendingMachine class, adding attributes and methods as appropriate, such that its behavior matches the following doctests: According to the wiki, a vending machine is an automated machine that provides items to consumers after cash, or other forms of payment are inserted into the machine or otherwise made 这里说的 vending machine 其实也就是常见的自动售货机, 我们要为其写一个类实现应该有的功能. 这里的要求更为简单, 因为我们要实现的自动售货机只有一样东西可以卖, 而且每次只会买一件. 注意下面要实现函数的逻辑即可: restock, 补充商品, 这个比较简单 add_funds 商品有库存的时候才会记住你付了多少钱 商品没有库存的时候直接退款给你 vend 商品有库存的时候 你支付的钱💰如果足够就可以买 💰 不够的话会告诉你还差多少钱 不要忘记购买成功后库存要 - 1 商品没有库存 提示要补充货物 python class VendingMachine: \"\"\"A vending machine that vends some product for some price. \"\"\" def __init__(self, product, price): self.product = product self.price = price self.balance = 0 self.stocks = 0 def restock(self, num): \"\"\"Restock num items to our vending machine\"\"\" self.stocks += num return f\"Current {self.product} stock: {self.stocks}\" def add_funds(self, fund): \"\"\"Add funds to balance, return funds if no stocks\"\"\" if self.stocks != 0: self.balance += fund return f\"Current balance: ${self.balance}\" else: return f\"Nothing left to vend. Please restock. Here is your ${fund}.\" def vend(self): \"\"\"Vend a product\"\"\" if self.stocks == 0: return 'Nothing left to vend. Please restock.' else: if self.balance \u003c self.price: return f\"You must add ${self.price - self.balance} more funds.\" else: change = self.balance - self.price self.balance = 0 self.stocks -= 1 if change == 0: return f\"Here is your {self.product}.\" else: return f\"Here is your {self.product} and ${change} change.\" ","date":"2022-02-27","objectID":"/zh-cn/hw06-of-cs61a-of-ucb/:1:1","series":null,"tags":["Course"],"title":"Hw06 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/hw06-of-cs61a-of-ucb/#q1-vending-machine"},{"categories":["Course"],"content":" Q2: Mint A mint is a place where coins are made. In this question, you’ll implement a Mint class that can output a Coin with the correct year and worth. Each Mint instance has a year stamp. The update method sets the year stamp to the present_year class attribute of the Mint class. The create method takes a subclass of Coin and returns an instance of that class stamped with the mint’s year (which may be different from Mint.present_year if it has not been updated.) A Coin’s worth method returns the cents value of the coin plus one extra cent for each year of age beyond 50. A coin’s age can be determined by subtracting the coin’s year from the present_year class attribute of the Mint class. 这一题要我们实现铸币厂的类, 可以制造出年份和面值都正确的硬币. python class Mint: \"\"\"A mint creates coins by stamping on years. \"\"\" present_year = 2021 def __init__(self): self.update() def create(self, kind): return kind(self.year) def update(self): self.year = Mint.present_year class Coin: def __init__(self, year): self.year = year def worth(self): age = Mint.present_year - self.year if age \u003e 50: return self.cents + (age - 50) else: return self.cents ","date":"2022-02-27","objectID":"/zh-cn/hw06-of-cs61a-of-ucb/:1:2","series":null,"tags":["Course"],"title":"Hw06 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/hw06-of-cs61a-of-ucb/#q2-mint"},{"categories":["Course"],"content":" Linked Lists ","date":"2022-02-27","objectID":"/zh-cn/hw06-of-cs61a-of-ucb/:2:0","series":null,"tags":["Course"],"title":"Hw06 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/hw06-of-cs61a-of-ucb/#linked-lists"},{"categories":["Course"],"content":" Q3: Store Digits Write a function store_digits that takes in an integer n and returns a linked list where each element of the list is a digit of n. Important: Do not use any string manipulation functions like str and reversed 简单来说, 就是要把整数 n 的每一位存储到链表里面. 这个用迭代的方法做就很简单, 我们可以每次 %10 来获得最后一位, 采用链表的头插法来构建链表, 头插法就是每次我们都新建结点插入到链表的开头. 这里用了哨兵结点. python def store_digits(n): \"\"\"Stores the digits of a positive number n in a linked list. \"\"\" sentinel = Link(0) while n \u003e 0: all_but_last, last = n // 10, n % 10 # every time we insert node in the front of the linklist new_node = Link(n % 10, sentinel.rest) sentinel.rest = new_node n = all_but_last return sentinel.rest ","date":"2022-02-27","objectID":"/zh-cn/hw06-of-cs61a-of-ucb/:2:1","series":null,"tags":["Course"],"title":"Hw06 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/hw06-of-cs61a-of-ucb/#q3-store-digits"},{"categories":["Course"],"content":" Q4: Mutable Mapping Implement deep_map_mut(fn, link), which applies a function fn onto all elements in the given linked list link. If an element is itself a linked list, apply fn to each of its elements, and so on. Your implementation should mutate the original linked list. Do not create any new linked lists. Hint: The built-in isinstance function may be useful. text \u003e\u003e\u003e s = Link(1, Link(2, Link(3, Link(4)))) \u003e\u003e\u003e isinstance(s, Link) True \u003e\u003e\u003e isinstance(s, int) False 对嵌套链表的每个元素应用 fn 函数, 显然这个要用递归方法来解决. 具体解题思路可以看下面的代码 python def deep_map_mut(fn, link): \"\"\"Mutates a deep link by replacing each item found with the result of calling fn on the item. Does NOT create new Links (so no use of Link's constructor) \"\"\" # base case 1. do thing if it is empty if link is Link.empty: return # base case 2. if it is an integer if isinstance(link, int): link = fn(link) if isinstance(link.first, int): link.first = fn(link.first) else: deep_map_mut(fn, link.first) deep_map_mut(fn, link.rest) ","date":"2022-02-27","objectID":"/zh-cn/hw06-of-cs61a-of-ucb/:2:2","series":null,"tags":["Course"],"title":"Hw06 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/hw06-of-cs61a-of-ucb/#q4-mutable-mapping"},{"categories":["Course"],"content":" Q5: Two List Implement a function two_list that takes in two lists and returns a linked list. The first list contains the values that we want to put in the linked list, and the second list contains the number of each corresponding value. Assume both lists are the same size and have a length of 1 or greater. Assume all elements in the second list are greater than 0. 有两个列表: 一个表示值, 一个表示这个值应该重复插入几次. 用这种方式构建一个链表, 用链表的尾插法即可(每次把新的节点插入到链表末尾). 这里同样用了哨兵结点 python def two_list(vals, amounts): \"\"\" Returns a linked list according to the two lists that were passed in. Assume vals and amounts are the same size. Elements in vals represent the value, and the corresponding element in amounts represents the number of this value desired in the final linked list. Assume all elements in amounts are greater than 0. Assume both lists have at least one element. \"\"\" idx = 0 sentinel = Link(0) pos = sentinel while idx \u003c len(vals): val, amount = vals[idx], amounts[idx] for _ in range(amount): new_node = Link(val) pos.rest = new_node pos = pos.rest idx += 1 return sentinel.rest ","date":"2022-02-27","objectID":"/zh-cn/hw06-of-cs61a-of-ucb/:2:3","series":null,"tags":["Course"],"title":"Hw06 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/hw06-of-cs61a-of-ucb/#q5-two-list"},{"categories":["Course"],"content":" Extra Questions ","date":"2022-02-27","objectID":"/zh-cn/hw06-of-cs61a-of-ucb/:3:0","series":null,"tags":["Course"],"title":"Hw06 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/hw06-of-cs61a-of-ucb/#extra-questions"},{"categories":["Course"],"content":" Q6: Next Virahanka Fibonacci Object Implement the next method of the VirFib class. For this class, the value attribute is a Fibonacci number. The next method returns a VirFib instance whose value is the next Fibonacci number. The next method should take only constant time. Note that in the doctests, nothing is being printed out. Rather, each call to .next() returns a VirFib instance. The way each VirFib instance is displayed is determined by the return value of its __repr__ method. Hint: Keep track of the previous number by setting a new instance attribute inside next. You can create new instance attributes for objects at any point, even outside the __init__ method. 这题要求我们写一个类, 每次调用它的方法就可以算出下一个斐波那契数 ","date":"2022-02-27","objectID":"/zh-cn/hw06-of-cs61a-of-ucb/:3:1","series":null,"tags":["Course"],"title":"Hw06 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/hw06-of-cs61a-of-ucb/#q6-next-virahanka-fibonacci-object"},{"categories":["Course"],"content":" Q7: Is BST Write a function is_bst, which takes a Tree t and returns True if, and only if, t is a valid binary search tree, which means that: Each node has at most two children (a leaf is automatically a valid binary search tree) The children are valid binary search trees For every node, the entries in that node’s left child are less than or equal to the label of the node For every node, the entries in that node’s right child are greater than the label of the node An example of a BST is: Note that, if a node has only one child, that child could be considered either the left or right child. You should take this into consideration. Hint: It may be helpful to write helper functions bst_min and bst_max that return the minimum and maximum, respectively, of a Tree if it is a valid binary search tree. 写一个函数判断输入是否为二叉搜索树, 根据提示我们需要先实现两个辅助函数: bst_min 和 bst_max, 返回输入的树的最小和最大值 写代码要注意下面几点: 左子树最小值 \u003c= 当前节点. 而不是 \u003c 当前节点如果只有一个子树, 那么在那边都可以, 这里要做两种情况的判定 python def is_bst(t): \"\"\"Returns True if the Tree t has the structure of a valid BST. \"\"\" def bst_min(t): \"\"\"Return the min value of the tree t\"\"\" if t.is_leaf(): return t.label sub_branch_min = min([bst_min(b) for b in t.branches]) return min(t.label, sub_branch_min) def bst_max(t): \"\"\"Return the max value of the tree t\"\"\" if t.is_leaf(): return t.label sub_branch_max = max([bst_max(b) for b in t.branches]) return max(t.label, sub_branch_max) # base case 1. a leaf node is a BST if t.is_leaf(): return True # base case 2. each node has at most 2 children if len(t.branches) \u003e 2: return False # base case 3. a node with a single child # it can be considered either the left or the right if len(t.branches) == 1: return (bst_max(t.branches[0]) \u003c t.label or bst_min(t.branches[0]) \u003e t.label) \\ and is_bst(t.branches[0]) left_max = bst_max(t.branches[0]) right_min = bst_min(t.branches[1]) return left_max \u003c= t.label \u003c right_min and is_bst(t.branches[0]) and is_bst(t.branches[1]) ","date":"2022-02-27","objectID":"/zh-cn/hw06-of-cs61a-of-ucb/:3:2","series":null,"tags":["Course"],"title":"Hw06 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/hw06-of-cs61a-of-ucb/#q7-is-bst"},{"categories":["Course"],"content":"the simple solutions for lab10 of CS61A of UCB","date":"2022-02-27","objectID":"/zh-cn/lab10-cs61a-of-ucb/","series":null,"tags":["Course"],"title":"Lab10 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab10-cs61a-of-ucb/"},{"categories":["Course"],"content":" Q2: Over or Under Define a procedure over-or-under which takes in a number num1 and a number num2 and returns the following: -1 if num1 is less than num2 0 if num1 is equal to num2 1 if num1 is greater than num2 Challenge: Implement this in 2 different ways using if and cond! text (define (over-or-under num1 num2) 'YOUR-CODE-HERE ) 代码其实本身不难, 主要是适应 scheme 语言的写法, 条件分支有两种写法: (if \u003cpredicate\u003e \u003cconsequent\u003e \u003calternative\u003e) (cond (\u003ccondition\u003e \u003cconsequent\u003e) ...) scheme (define (over-or-under num1 num2) (if (\u003c num1 num2) (print -1)) (if (= num1 num2) (print 0)) (if (\u003e num1 num2) (print 1)) ) (define (over-or-under num1 num2) (cond ( (\u003c num1 num2) (print -1) ) ( (= num1 num2) (print 0) ) ( (\u003e num1 num2) (print 1) )) ) ","date":"2022-02-27","objectID":"/zh-cn/lab10-cs61a-of-ucb/:1:0","series":null,"tags":["Course"],"title":"Lab10 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab10-cs61a-of-ucb/#q2-over-or-under"},{"categories":["Course"],"content":" Q3: Make Adder Write the procedure make-adder which takes in an initial number, num, and then returns a procedure. This returned procedure takes in a number inc and returns the result of num + inc. Hint: To return a procedure, you can either return a lambda expression or define another nested procedure. Remember that Scheme will automatically return the last clause in your procedure. You can find documentation on the syntax of lambda expressions in the 61A scheme specification! 实现高阶函数的功能, 依旧是锻炼 scheme 语言的掌握程度的. 题目都是之前课上讲过的. 这里我用匿名函数来实现 scheme (define (make-adder num) (lambda (inc) (+ num inc)) ) ","date":"2022-02-27","objectID":"/zh-cn/lab10-cs61a-of-ucb/:1:1","series":null,"tags":["Course"],"title":"Lab10 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab10-cs61a-of-ucb/#q3-make-adder"},{"categories":["Course"],"content":" Q4: Compose Write the procedure composed, which takes in procedures f and g and outputs a new procedure. This new procedure takes in a number x and outputs the result of calling f on g of x. 用 scheme 语言实现符合数学中的复合函数, 也就是高阶函数. 这里同样可以用 lambda 函数 scheme (define (composed f g) (lambda (x) (f (g x) ) ) ) ","date":"2022-02-27","objectID":"/zh-cn/lab10-cs61a-of-ucb/:1:2","series":null,"tags":["Course"],"title":"Lab10 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab10-cs61a-of-ucb/#q4-compose"},{"categories":["Course"],"content":" Q5: Make a List In this problem you will create the list with the following box-and-pointer diagram: Challenge: try to create this list in multiple ways, and using multiple list constructors!要求 题目要求我们按照给定的链表结构来生成对应的链表. 主要考察的是对 scheme 语言中 list 的掌握. 可以有多种实现方式 cons 的方式, 这个方式很容易眼花, 最好是写完之后在这里 验证一下. 这里我真的写得头有点晕 😢 list 的方式, 这个代码会比较短, 注意我们每次在调用 (list ...) 相当于在链表中多创建了一个方向 scheme (define lst (cons (cons 1 nil) (cons 2 (cons (cons 3 (cons 4 nil)) (cons 5 nil)))) ) (define lst (list (list 1) 2 (list 3 4) 5) ) ","date":"2022-02-27","objectID":"/zh-cn/lab10-cs61a-of-ucb/:1:3","series":null,"tags":["Course"],"title":"Lab10 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab10-cs61a-of-ucb/#q5-make-a-list"},{"categories":["Course"],"content":" Q6: Remove Implement a procedure remove that takes in a list and returns a new list with all instances of item removed from lst. You may assume the list will only consist of numbers and will not have nested lists. Hint: You might find the built-in filter procedure useful (though it is definitely possible to complete this question without it). You can find information about how to use filter in the 61A Scheme builtin specification! 这一题就是要我们在 scheme 的列表中移除掉值等于 item 的元素然后返回新的这个列表. 其实 scheme 的列表也就是链表. 所以这一题等效于我们要在链表中移除指定值的元素. 显然, 这可以用递归来解决! 而且这一道题说没有嵌套列表的情况存在, 这一道题就更简单了 ! 显然 base case 就是链表为空的情况, 我们直接返回空. 否则: 当前节点的值 = item, 我们删除它, 递归处理子链表 当前节点的值 != item, 我们保留它, 递归处理子链表 scheme (define (remove item lst) (cond ( (null? lst) '() ) ; base case ( (= item (car lst)) (remove item (cdr lst))) ; exclude item ( else (cons (car lst) (remove item (cdr lst))))) ; include item ) ","date":"2022-02-27","objectID":"/zh-cn/lab10-cs61a-of-ucb/:1:4","series":null,"tags":["Course"],"title":"Lab10 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab10-cs61a-of-ucb/#q6-remove"},{"categories":["Course"],"content":"the simple solutions for lab09 of CS61A of UCB","date":"2022-02-26","objectID":"/zh-cn/lab09-cs61a-of-ucb/","series":null,"tags":["Course"],"title":"Lab09 题解 (UCB CS61A@2021-Fall)","uri":"/zh-cn/lab09-cs61a-of-ucb/"},{"categories":["Course"],"content":" Recursion and Tree Recursion ","date":"2022-02-26","objectID":"/zh-cn/lab09-cs61a-of-ucb/:1:0","series":null,"tags":["Course"],"title":"Lab09 题解 (UCB CS61A@2021-Fall)","uri":"/zh-cn/lab09-cs61a-of-ucb/#recursion-and-tree-recursion"},{"categories":["Course"],"content":" Q1: Subsequences A subsequence of a sequence S is a subset of elements from S, in the same order they appear in S. Consider the list [1, 2, 3]. Here are a few of it’s subsequences [], [1, 3], [2], and [1, 2, 3]. Write a function that takes in a list and returns all possible subsequences of that list. The subsequences should be returned as a list of lists, where each nested list is a subsequence of the original input. In order to accomplish this, you might first want to write a function insert_into_all that takes an item and a list of lists, adds the item to the beginning of each nested list, and returns the resulting list. 这一道题要求我们返回一个列表的所有可能子序列, 返回的格式是列表的列表, 每一个都是可能的子序列 题目要求我们首先完成一个函数: 功能是把 item 添加到嵌套列表的每个子列表的开头, 这个其实用 list comprehension 就可以了. python def insert_into_all(item, nested_list): \"\"\"Return a new list consisting of all the lists in nested_list, but with item added to the front of each. You can assume that nested_list is a list of lists. \"\"\" return [[item] + l for l in nested_list] 这其实是题目给我们的提示, 我们现在思考有了这个函数我们要怎么找到所有可能的子序列呢? 我们可以递归分解问题: 将要处理的元素分为「当前元素」+「所有剩下的元素」，并且假设「所有剩下的元素」的所有可能子序列（用 tmp 表示）已经求解出来了（你会发现递归函数经常是这样思考的）. 那么问题就变成了如何得到包含「当前元素」的子序列，一个可行的办法是——把当前元素加到 tmp 中的每个子序列。然后再将这个新得到的列表和 tmp 拼接起来即可。这刚好就用上了题目让我们实现的 insert_into_all() 函数. 最后我们要思考什么是 base case. 显然如果一个空的列表的子序列为空列表; 如果列表长度为 1, 则存在两个可能子序列 - 它自己 + 空列表. 最后我们就可以写出这样的代码 python def subseqs(s): \"\"\"Return a nested list (a list of lists) of all subsequences of S. The subsequences can appear in any order. You can assume S is a list. \"\"\" if len(s) \u003c= 1: return [[], s] if s !=[] else [[]] else: tmp = subseqs(s[1:]) return insert_into_all(s[0], tmp) + tmp ","date":"2022-02-26","objectID":"/zh-cn/lab09-cs61a-of-ucb/:1:1","series":null,"tags":["Course"],"title":"Lab09 题解 (UCB CS61A@2021-Fall)","uri":"/zh-cn/lab09-cs61a-of-ucb/#q1-subsequences"},{"categories":["Course"],"content":" Q2: Non-Decreasing Subsequences Just like the last question, we want to write a function that takes a list and returns a list of lists, where each individual list is a subsequence of the original input. This time we have another condition: we only want the subsequences for which consecutive elements are nondecreasing. For example, [1, 3, 2] is a subsequence of [1, 3, 2, 4], but since 2 \u003c 3, this subsequence would not be included in our result. Fill in the blanks to complete the implementation of the non_decrease_subseqs function. You may assume that the input list contains no negative elements. You may use the provided helper function insert_into_all, which takes in an item and a list of lists and inserts the item to the front of each list. 这一道题是在 Q1 的基础上改编而来的, 相当于提出了一个更高的要求, 我们要求子序列同时是非降序的. 根据题目的提示，我们也许会用到 insert_into_all 函数, 所以不妨来思考一个问题: 当我们把「当前元素」加到「所有剩下的元素」的子序列（注意，从定义上来说, 这些子序列肯定都是满足题目要求的非降序子序列）的时候要注意什么问题? 显然, 「当前元素」应该比这些非降序子序列的第一个元素还要小或者是相等, 我们才可以把「当前元素」添加到它们的开头. 如果不满足这个要求呢？我们直接舍弃掉「当前元素」就好. 现在再来看 subseq_helper 函数，它的 prev 参数的含义就很清楚了，它表示我们在构造子序列的时候子序列允许的最小值 python def non_decrease_subseqs(s): \"\"\"Assuming that S is a list, return a nested list of all subsequences of S (a list of lists) for which the elements of the subsequence are strictly nondecreasing. The subsequences can appear in any order. \"\"\" def subseq_helper(s, prev): if not s: return [[]] elif s[0] \u003c prev: return subseq_helper(s[1:], prev) else: a = subseq_helper(s[1:], s[0]) # include s[0] b = subseq_helper(s[1:], prev) # exclude s[0] return insert_into_all(s[0], a) + b return subseq_helper(s, 0) ","date":"2022-02-26","objectID":"/zh-cn/lab09-cs61a-of-ucb/:1:2","series":null,"tags":["Course"],"title":"Lab09 题解 (UCB CS61A@2021-Fall)","uri":"/zh-cn/lab09-cs61a-of-ucb/#q2-non-decreasing-subsequences"},{"categories":["Course"],"content":" Q3: Number of Trees A full binary tree is a tree where each node has either 2 branches or 0 branches, but never 1 branch. Write a function which returns the number of unique full binary tree structures that have exactly n leaves. For those interested in combinatorics, this problem does have a closed form solution): 题意: 有 n 个叶子结点的完全二叉树可能有几种 ? 答案是卡特兰数, 所以我们要实现的其实是卡特兰数的递归写法. 至于为什么是卡特兰数我也想不大明白, 比较能接受的解释是, 完全二叉树的左右子树肯定也是完全二叉树, 假设左子树有 1 个叶子结点, 右子树就有 n - 1 个叶子结点, 那么此时就有 f(1) * f(n - 1) 种可能, 类似的, 如果左子树有 2 个叶子结点, 那就是 f(2) * f(n - 2), 这样累加起来就是卡特兰数. ps: 这里的完全二叉树不是严格意义上的, 确切来说这里指的是所有节点的度只能为 0 或者 2 的树 python def num_trees(n): \"\"\"Returns the number of unique full binary trees with exactly n leaves. E.g., \"\"\" if n == 1 or n == 2: return 1 # catalan number ans = 0 for i in range(1, n): ans += num_trees(i) * num_trees(n - i) return ans ","date":"2022-02-26","objectID":"/zh-cn/lab09-cs61a-of-ucb/:1:3","series":null,"tags":["Course"],"title":"Lab09 题解 (UCB CS61A@2021-Fall)","uri":"/zh-cn/lab09-cs61a-of-ucb/#q3-number-of-trees"},{"categories":["Course"],"content":" Generators ","date":"2022-02-26","objectID":"/zh-cn/lab09-cs61a-of-ucb/:2:0","series":null,"tags":["Course"],"title":"Lab09 题解 (UCB CS61A@2021-Fall)","uri":"/zh-cn/lab09-cs61a-of-ucb/#generators"},{"categories":["Course"],"content":" Q4: Merge Implement merge(incr_a, incr_b), which takes two iterables incr_a and incr_b whose elements are ordered. merge yields elements from incr_a and incr_b in sorted order, eliminating repetition. You may assume incr_aand incr_b themselves do not contain repeats, and that none of the elements of either are None. You may notassume that the iterables are finite; either may produce an infinite stream of results. You will probably find it helpful to use the two-argument version of the built-in next function: next(incr, v) is the same as next(incr), except that instead of raising StopIteration when incr runs out of elements, it returns v. See the doctest for examples of behavior. merge 函数的功能是合并两个有序的可迭代对象, 同时要做去重的工作, 可以假设两个有序的可迭代对象本身是没有元素重复的, 而且没有任何一个元素是 None. 同时不可以假定这两个可迭代对象是有限序列, 它们可能无序的(这样你就不能暴力合并为一个有序可迭代对象再去重) 因为两个可迭代对象本身不包含重复元素, 所以这一道题处理起来比较简单, 我们只要重复下面的过程: 如果两个可迭代对象都是非空 各取一个元素进行比较 如果一样大: 返回一个, 同时两个 iterator 都要往后移动 其中一个比较小: 返回小的这个, 移动小的这个可迭代对象的 iterator, 大的元素的 iterator 不动 如果重复上面的操作导致其中一个已经空了, 那么接下来的问题就比较简单了, 此时我们只要用 while 循环不断从某一个可迭代对象中返回元素即可. 代码如下: python def merge(incr_a, incr_b): \"\"\"Yield the elements of strictly increasing iterables incr_a and incr_b, removing repeats. Assume that incr_a and incr_b have no repeats. incr_a or incr_b may or may not be infinite sequences. \"\"\" iter_a, iter_b = iter(incr_a), iter(incr_b) next_a, next_b = next(iter_a, None), next(iter_b, None) # both are non-empty while next_a is not None and next_b is not None: val_a, val_b = next_a, next_b if val_a == val_b: yield next_a next_a, next_b = next(iter_a, None), next(iter_b, None) elif val_a \u003c val_b: yield next_a next_a = next(iter_a, None) else: yield next_b next_b = next(iter_b, None) # incr_a is not empty while next_a: yield next_a next_a = next(iter_a, None) # incr_b is not empty while next_b: yield next_b next_b = next(iter_b, None) ","date":"2022-02-26","objectID":"/zh-cn/lab09-cs61a-of-ucb/:2:1","series":null,"tags":["Course"],"title":"Lab09 题解 (UCB CS61A@2021-Fall)","uri":"/zh-cn/lab09-cs61a-of-ucb/#q4-merge"},{"categories":["Course"],"content":" Objects ","date":"2022-02-26","objectID":"/zh-cn/lab09-cs61a-of-ucb/:3:0","series":null,"tags":["Course"],"title":"Lab09 题解 (UCB CS61A@2021-Fall)","uri":"/zh-cn/lab09-cs61a-of-ucb/#objects"},{"categories":["Course"],"content":" Q5: Bank Account Implement the class Account, which acts as a a Bank Account. Account should allow the account holder to deposit money into the account, withdraw money from the account, and view their transaction history. The Bank Account should also prevents a user from withdrawing more than the current balance. Transaction history should be stored as a list of tuples, where each tuple contains the type of transaction and the transaction amount. For example a withdrawal of 500 should be stored as (‘withdraw’, 500) Hint: You can call the str function on an integer to get a string representation of the integer. You might find this function useful when implementing the __repr__ and __str__ methods. Hint: You can alternatively use fstrings to implement the __repr__ and __str__ methods cleanly. 实现一个 Account 类, 要求有以下功能: 存款 取款, 钱不够的时候不让取 查看操作历史. 转账历史是 tuple 的列表, 每个 tuple 包括了操作的类型和转账的金额 整体上而言这题不难, 看 __repr__ 我们可以知道要求返回存款和取款的次数, 这里可以用两个变量来记住. python class Account: \"\"\"A bank account that allows deposits and withdrawals. It tracks the current account balance and a transaction history of deposits and withdrawals. \"\"\" interest = 0.02 def __init__(self, account_holder): self.balance = 0 self.holder = account_holder self.transactions = [] self.withdraw_cnt = 0 self.deposit_cnt = 0 def deposit(self, amount): \"\"\"Increase the account balance by amount, add the deposit to the transaction history, and return the new balance. \"\"\" self.balance += amount self.transactions.append(('deposit', amount)) self.deposit_cnt += 1 return self.balance def withdraw(self, amount): \"\"\"Decrease the account balance by amount, add the withdraw to the transaction history, and return the new balance. \"\"\" if self.balance \u003e amount: self.balance -= amount self.transactions.append(('withdraw', amount)) self.withdraw_cnt += 1 return self.balance # prevent illegal withdraw return self.balance def __str__(self): return f\"{self.holder}'s Balance: ${self.balance}\" def __repr__(self): return f\"Accountholder: {self.holder}, Deposits: {self.deposit_cnt}, Withdraws: {self.withdraw_cnt}\" ","date":"2022-02-26","objectID":"/zh-cn/lab09-cs61a-of-ucb/:3:1","series":null,"tags":["Course"],"title":"Lab09 题解 (UCB CS61A@2021-Fall)","uri":"/zh-cn/lab09-cs61a-of-ucb/#q5-bank-account"},{"categories":["Course"],"content":" Mutable Lists ","date":"2022-02-26","objectID":"/zh-cn/lab09-cs61a-of-ucb/:4:0","series":null,"tags":["Course"],"title":"Lab09 题解 (UCB CS61A@2021-Fall)","uri":"/zh-cn/lab09-cs61a-of-ucb/#mutable-lists"},{"categories":["Course"],"content":" Q6: Trade In the integer market, each participant has a list of positive integers to trade. When two participants meet, they trade the smallest non-empty prefix of their list of integers. A prefix is a slice that starts at index 0. Write a function trade that exchanges the first m elements of list first with the first n elements of list second, such that the sums of those elements are equal, and the sum is as small as possible. If no such prefix exists, return the string 'No deal!' and do not change either list. Otherwise change both lists and return 'Deal!'. A partial implementation is provided. Hint: You can mutate a slice of a list using slice assignment. To do so, specify a slice of the list [i:j] on the left-hand side of an assignment statement and another list on the right-hand side of the assignment statement. The operation will replace the entire given slice of the list from i inclusive to j exclusive with the elements from the given list. The slice and the given list need not be the same length. text \u003e\u003e\u003e a = [1, 2, 3, 4, 5, 6] \u003e\u003e\u003e b = a \u003e\u003e\u003e a[2:5] = [10, 11, 12, 13] \u003e\u003e\u003e a [1, 2, 10, 11, 12, 13, 6] \u003e\u003e\u003e b [1, 2, 10, 11, 12, 13, 6] Additionally, recall that the starting and ending indices for a slice can be left out and Python will use a default value. lst[i:] is the same as lst[i:len(lst)], and lst[:j] is the same as lst[0:j]. 题意: 交换两个列表的开头几个元素(m 和 n 可以不等长), 使得两边被用来交换的子列表的和(前缀和)是一样的, 而且这个和要越小越好. 在代码里已经为我们提供了交换元素的函数, 我们要做的就是让 m 和 n 停在正确的位置(他们的和一样), 这里用 while 循环来实现, 只要两个的索引是有效的(不然他们会一直增加, while 循环就会变为死循环)而且前缀和不想等, 我们移动 m 或者 n 指针. python def trade(first, second): \"\"\"Exchange the smallest prefixes of first and second that have equal sum. \"\"\" m, n = 1, 1 equal_prefix = lambda: sum(first[:m]) == sum(second[:n]) while m \u003c= len(first) and n \u003c= len(second) and not equal_prefix(): if sum(first[:m]) \u003c sum(second[:n]): m += 1 else: n += 1 if equal_prefix(): first[:m], second[:n] = second[:n], first[:m] return 'Deal!' else: return 'No deal!' ","date":"2022-02-26","objectID":"/zh-cn/lab09-cs61a-of-ucb/:4:1","series":null,"tags":["Course"],"title":"Lab09 题解 (UCB CS61A@2021-Fall)","uri":"/zh-cn/lab09-cs61a-of-ucb/#q6-trade"},{"categories":["Course"],"content":" Q7: Shuffle Define a function shuffle that takes a sequence with an even number of elements (cards) and creates a new list that interleaves the elements of the first half with the elements of the second half. To interleave two sequences s0 and s1 is to create a new sequence such that the new sequence contains (in this order) the first element of s0, the first element of s1, the second element of s0, the second element of s1, and so on. If the two lists are not the same length, then the leftover elements of the longer list should still appear at the end. Note: If you’re running into an issue where the special heart / diamond / spades / clubs symbols are erroring in the doctests, feel free to copy paste the below doctests into your file as these don’t use the special characters and should not give an “illegal multibyte sequence” error. 这一道题就是要我们完成洗牌的功能, 洗牌的意思是前一半和后一半的元素交替出现, 举例来说:[0, 1, 2, 3, 4, 5] = [0, 3, 1, 4, 2, 5]. 你可以看到奇数索引的是后一半的元素, 偶数索引的是前一半元素. 这一道题的关键在于弄清楚洗牌之后的索引和原来的索引对应的关系, 总结来来说:[0, 1, ..., len(cards) // 2, len(cards) // 2 + 1, ...]. 你可以发现前一半和后一半对应位置的元素的索引相差 len(cards) // 2 python def shuffle(cards): \"\"\"Return a shuffled list that interleaves the two halves of cards. \"\"\" assert len(cards) % 2 == 0, 'len(cards) must be even' half = len(cards) // 2 shuffled = [] for i in range(half): shuffled.append(cards[i]) shuffled.append(cards[i + half]) return shuffled ","date":"2022-02-26","objectID":"/zh-cn/lab09-cs61a-of-ucb/:4:2","series":null,"tags":["Course"],"title":"Lab09 题解 (UCB CS61A@2021-Fall)","uri":"/zh-cn/lab09-cs61a-of-ucb/#q7-shuffle"},{"categories":["Course"],"content":" Linked Lists ","date":"2022-02-26","objectID":"/zh-cn/lab09-cs61a-of-ucb/:5:0","series":null,"tags":["Course"],"title":"Lab09 题解 (UCB CS61A@2021-Fall)","uri":"/zh-cn/lab09-cs61a-of-ucb/#linked-lists"},{"categories":["Course"],"content":" Q8: Insert Implement a function insert that takes a Link, a value, and an index, and inserts the value into the Link at the given index. You can assume the linked list already has at least one element. Do not return anything – insert should mutate the linked list. Note: If the index is out of bounds, you should raise an IndexError with: text raise IndexError('Out of bounds!') 根据指定的索引 index 在链表中插入元素, 如果索引非法, 抛出错误 这一题有点奇怪的地方在于, 它要求我们在原来的链表上进行修改, 但是如果我们要在链表的开头进行插入一个新节点, 会无法通过它的 link is other_link 的判断(因为插入后链表头是一个新的节点), 所以我这里想的办法是每次在插入前我们拷贝当前结点, 然后修改当前结点的值为想要插入的值, 这样等效于我们做了插入 python def insert(link, value, index): \"\"\"Insert a value into a Link at the given index. \"\"\" pos = link current_index = 0 while pos is not Link.empty: if current_index == index: # make a copy of current node, and modify the current node's value \\ # which is equal to insert a new node :) current_copy = Link(pos.first, pos.rest) origin_next = pos.rest pos.first = value pos.rest = current_copy #print(f\"link: {link.first}\") return pos = pos.rest current_index += 1 raise IndexError('Out of bounds!') ","date":"2022-02-26","objectID":"/zh-cn/lab09-cs61a-of-ucb/:5:1","series":null,"tags":["Course"],"title":"Lab09 题解 (UCB CS61A@2021-Fall)","uri":"/zh-cn/lab09-cs61a-of-ucb/#q8-insert"},{"categories":["Course"],"content":" Q9: Deep Linked List Length A linked list that contains one or more linked lists as elements is called a deep linked list. Write a function deep_len that takes in a (possibly deep) linked list and returns the deep length of that linked list. The deep length of a linked list is the total number of non-link elements in the list, as well as the total number of elements contained in all contained lists. See the function’s doctests for examples of the deep length of linked lists. Hint: Use isinstance to check if something is an instance of an object. Deep Linked List Length 其实就是一个可能包含链表为结点的嵌套链表结构. 这一道题要求我们算这种嵌套列表一共有多少个元素. 其实就是之前做的摊平链表的那种题目. 显然, 这是符合递归的嵌套结构, 所以我们可以用递归的办法解决. base case 就是空链表或者它是一个元素而不是链表. 其他情况我们就递归处理链表的第一个节点和除了第一个结点以外的子链表 🤗 python def deep_len(lnk): \"\"\" Returns the deep length of a possibly deep linked list. \"\"\" # base case 1. an empty node if lnk is Link.empty: return 0 # base case 2. an integer elif isinstance(lnk, int): return 1 else: return deep_len(lnk.first) + deep_len(lnk.rest) ","date":"2022-02-26","objectID":"/zh-cn/lab09-cs61a-of-ucb/:5:2","series":null,"tags":["Course"],"title":"Lab09 题解 (UCB CS61A@2021-Fall)","uri":"/zh-cn/lab09-cs61a-of-ucb/#q9-deep-linked-list-length"},{"categories":["Course"],"content":" Q10: Linked Lists as Strings Kevin and Jerry like different ways of displaying the linked list structure in Python. While Kevin likes box and pointer diagrams, Jerry prefers a more futuristic way. Write a function make_to_string that returns a function that converts the linked list to a string in their preferred style. Hint: You can convert numbers to strings using the str function, and you can combine strings together using +. text \u003e\u003e\u003e str(4) '4' \u003e\u003e\u003e 'cs ' + str(61) + 'a' 'cs 61a' 简单来说就是想要根据不同人的需求来打印链表, 具体格式就是 front + 当前结点的值 + mid + 子链表的 + back 这样 python def make_to_string(front, mid, back, empty_repr): \"\"\" Returns a function that turns linked lists to strings. \"\"\" def printer(lnk): if lnk is Link.empty: return empty_repr else: return front + str(lnk.first) + mid + printer(lnk.rest) + back return printer ","date":"2022-02-26","objectID":"/zh-cn/lab09-cs61a-of-ucb/:5:3","series":null,"tags":["Course"],"title":"Lab09 题解 (UCB CS61A@2021-Fall)","uri":"/zh-cn/lab09-cs61a-of-ucb/#q10-linked-lists-as-strings"},{"categories":["Course"],"content":" Trees ","date":"2022-02-26","objectID":"/zh-cn/lab09-cs61a-of-ucb/:6:0","series":null,"tags":["Course"],"title":"Lab09 题解 (UCB CS61A@2021-Fall)","uri":"/zh-cn/lab09-cs61a-of-ucb/#trees"},{"categories":["Course"],"content":" Q11: Long Paths Implement long_paths, which returns a list of all paths in a tree with length at least n. A path in a tree is a list of node labels that starts with the root and ends at a leaf. Each subsequent element must be from a label of a branch of the previous value’s node. The length of a path is the number of edges in the path (i.e. one less than the number of nodes in the path). Paths are ordered in the output list from left to right in the tree. See the doctests for some examples. 返回一个嵌套列表, 每个子列表表示长度至少为 n 的路径. 这里说的路径一定是叶子结点的路径 ! 路径的长度可以理解为从根结点出发到达叶子结点经过的边数. 这一道题其实是经典的递归与回溯问题, 我们要为其写一个 helper 函数, 要记住我们当前经过的点的路径, 以及路径的长度. 递归与回溯的模板大概如下: python def function_name(p): # base case ... dothing thing ... # recursively solve this problem recall what you have done 放到我们这里就是我们要在往更深层递归的时候加上当前节点的 label, 当我们回溯的时候撤销我们对之前的添加. 代码如下: python def long_paths(t, n): \"\"\"Return a list of all paths in t with length at least n. \"\"\" path_list = [] def helper(t, current_path, length): nonlocal path_list if t.is_leaf(): current_path.append(t.label) if length \u003e= n: # warning: we need to pass a copy instead fo a ref path_list.append(current_path[:]) current_path.pop() return current_path.append(t.label) for b in t.branches: helper(b, current_path, length + 1) current_path.pop() helper(t, [], 0) return path_list ","date":"2022-02-26","objectID":"/zh-cn/lab09-cs61a-of-ucb/:6:1","series":null,"tags":["Course"],"title":"Lab09 题解 (UCB CS61A@2021-Fall)","uri":"/zh-cn/lab09-cs61a-of-ucb/#q11-long-paths"},{"categories":["Course"],"content":"the simple solutions for lab08 of CS61A of UCB","date":"2022-02-24","objectID":"/zh-cn/lab08-cs61a-of-ucb/","series":null,"tags":["Course"],"title":"Lab08 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab08-cs61a-of-ucb/"},{"categories":["Course"],"content":" Q2: Convert Link Write a function convert_link that takes in a linked list and returns the sequence as a Python list. You may assume that the input list is shallow; that is none of the elements is another linked list. Try to find both an iterative and recursive solution for this problem! 迭代的算法很简单, 我们只要创建一个 result list 来存储结果, 遍历链表的同时记住访问过的数即可 python def convert_link(link): \"\"\"Takes a linked list and returns a Python list with the same elements. \"\"\" result = [] while link is not Link.empty: result.append(int(link.first)) link = link.rest return result 递归的算法也简单, base case 就是我们遇到了空结点的时候, 这个时候返回的是空的值, 其他情况我们递归分解: 当前结点 + 链表的剩余结点 python def convert_link(link): \"\"\"Takes a linked list and returns a Python list with the same elements. \"\"\" # recursive solution if link is Link.empty: return [] else: return [int(link.first)] + convert_link(link.rest) ","date":"2022-02-24","objectID":"/zh-cn/lab08-cs61a-of-ucb/:0:1","series":null,"tags":["Course"],"title":"Lab08 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab08-cs61a-of-ucb/#q2-convert-link"},{"categories":["Course"],"content":" Trees ","date":"2022-02-24","objectID":"/zh-cn/lab08-cs61a-of-ucb/:1:0","series":null,"tags":["Course"],"title":"Lab08 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab08-cs61a-of-ucb/#trees"},{"categories":["Course"],"content":" Q4: Square Write a function label_squarer that mutates a Tree with numerical labels so that each label is squared. 遍历树的所有节点, 将它的 label 都改为 label 的平方 python def label_squarer(t): \"\"\"Mutates a Tree t by squaring all its elements. \"\"\" # base case if t.is_leaf(): t.label = t.label ** 2 # check every branch for b in t.branches: t.label = t.label ** 2 # change the current node's label label_squarer(b) # change branches ","date":"2022-02-24","objectID":"/zh-cn/lab08-cs61a-of-ucb/:1:1","series":null,"tags":["Course"],"title":"Lab08 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab08-cs61a-of-ucb/#q4-square"},{"categories":["Course"],"content":" Q5: Cumulative Mul Write a function cumulative_mul that mutates the Tree t so that each node’s label becomes the product of its label and all labels in the subtrees rooted at the node. 这一题的意思是: 我们要让每个节点的 label 等于它的所有孩子节点的 label 的乘积, 显然, 这是一个递归问题 base case 就是叶子结点, 此时返回叶子节点的 label. 递归分解问题就是遍历节点的每一个子树, 获得每个子节点返回值再乘以当前结点的 label. 注意我这里用到了 math.prod 这个函数返回可迭代对象的连乘结果, 如果你也要这样使用, 你应该在文件的开头写 import math python def cumulative_mul(t): \"\"\"Mutates t so that each node's label becomes the product of all labels in \"\"\" # base case if t.is_leaf(): return t.label # get all label value in subtree vals = [cumulative_mul(b) for b in t.branches] # calculate t.label *= math.prod(vals) ","date":"2022-02-24","objectID":"/zh-cn/lab08-cs61a-of-ucb/:1:2","series":null,"tags":["Course"],"title":"Lab08 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab08-cs61a-of-ucb/#q5-cumulative-mul"},{"categories":["Course"],"content":" Q6: Add Leaves Implement add_d_leaves, a function that takes in a Tree instance t and a number v. We define the depth of a node in t to be the number of edges from the root to that node. The depth of root is therefore 0. For each node in the tree, you should add d leaves to it, where d is the depth of the node. Every added leaf should have a label of v. If the node at this depth has existing branches, you should add these leaves to the end of that list of branches. For example, you should be adding 1 leaf with label v to each node at depth 1, 2 leaves to each node at depth 2, and so on. Here is an example of a tree t(shown on the left) and the result after add_d_leaves is applied with v as 5. 翻译一下这一道题的意思: 我们要根据结点在树中的高度(根结点高度为 0)来给结点添加子节点, 这里说的符合条件是 label 为 v. 高度为 d 就增加 d 个子节点. 这题第一个困难是要如何获取当前结点的高度, 因为有了高度我们才能知道要增加多少个子节点, 我们可以维护一个参数表示当前结点的高度. 每当我们往树的更深一层前进的时候我们就将它 +1. base case 就是在叶子结点, 我们根据它的高度增加子结点. 然后对于当前的节点, 我们需要对它的每个孩子节点重复这个步骤, 同时也要判断当前节点是否需要添加子节点 python def add_d_leaves(t, v): \"\"\"Add d leaves containing v to each node at every depth d. \"\"\" def helper(t, v, depth): # base case if t.is_leaf(): for i in range(depth): t.branches.append(Tree(v)) return # check every branch for b in t.branches: helper(b, v, depth + 1) # check current node for i in range(depth): t.branches.append(Tree(v)) helper(t, v, 0) ","date":"2022-02-24","objectID":"/zh-cn/lab08-cs61a-of-ucb/:1:3","series":null,"tags":["Course"],"title":"Lab08 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab08-cs61a-of-ucb/#q6-add-leaves"},{"categories":["Course"],"content":" Optional Questions ","date":"2022-02-24","objectID":"/zh-cn/lab08-cs61a-of-ucb/:2:0","series":null,"tags":["Course"],"title":"Lab08 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab08-cs61a-of-ucb/#optional-questions"},{"categories":["Course"],"content":" Q7: Every Other Implement every_other, which takes a linked list s. It mutates s such that all of the odd-indexed elements (using 0-based indexing) are removed from the list. For example: text \u003e\u003e\u003e s = Link('a', Link('b', Link('c', Link('d')))) \u003e\u003e\u003e every_other(s) \u003e\u003e\u003e s.first 'a' \u003e\u003e\u003e s.rest.first 'c' \u003e\u003e\u003e s.rest.rest is Link.empty True If s contains fewer than two elements, s remains unchanged. Do not return anything! every_other should mutate the original list. 我们可以用迭代的方法来处理这个问题, 首先要处理的是长度的问题, 如果链表的长度小于 2, 那么直接返回. 否则我们就维护两个指针指向当前位置和上一个访问的位置, 当我们要删除索引为奇数(索引从 0 开始)的点的时候就让上一个节点直接指向当前这个节点的下一个节点即可. python def every_other(s): \"\"\"Mutates a linked list so that all the odd-indiced elements are removed \"\"\" # if it contains fewer than 2, do nothing if s is Link.empty or s.rest is Link.empty: return last_pos, pos = s, s.rest current_index = 1 # start from 2nd position while pos is not Link.empty: if current_index % 2 == 1: last_pos.rest = pos.rest last_pos = pos pos = pos.rest current_index += 1 ","date":"2022-02-24","objectID":"/zh-cn/lab08-cs61a-of-ucb/:2:1","series":null,"tags":["Course"],"title":"Lab08 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab08-cs61a-of-ucb/#q7-every-other"},{"categories":["Course"],"content":" Q8: Prune Small Complete the function prune_small that takes in a Tree t and a number n and prunes t mutatively. If t or any of its branches has more than n branches, the n branches with the smallest labels should be kept and any other branches should be pruned, or removed, from the tree. 这一道题要我们裁剪这棵树, 具体要求是才见到每个节点最多 n 个子树, 如果超过了 n 就优先移除 label 比较大的, 其实这一道题已经为我们提供了代码, 只要挖空填写就好了. 不难相处, 我们应该自顶向下(从根节点出发)裁剪, 所以第一个 while 循环要完成的动作是如果分支数 \u003e n, 那么找到最大的删掉 而后面的 for 循环则是要让我们到子树中递归裁减 python def prune_small(t, n): \"\"\"Prune the tree mutatively, keeping only the n branches of each node with the smallest label. \"\"\" while len(t.branches) \u003e n: largest = max(t.branches, key=lambda x: x.label) t.branches.remove(largest) for b in t.branches: prune_small(b, n) ","date":"2022-02-24","objectID":"/zh-cn/lab08-cs61a-of-ucb/:2:2","series":null,"tags":["Course"],"title":"Lab08 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab08-cs61a-of-ucb/#q8-prune-small"},{"categories":["Course"],"content":"the simple solutions for lab07 of CS61A of UCB","date":"2022-02-24","objectID":"/zh-cn/lab07-cs61a-of-ucb/","series":null,"tags":["Course"],"title":"Lab07 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab07-cs61a-of-ucb/"},{"categories":["Course"],"content":" Accounts ","date":"2022-02-24","objectID":"/zh-cn/lab07-cs61a-of-ucb/:1:0","series":null,"tags":["Course"],"title":"Lab07 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab07-cs61a-of-ucb/#accounts"},{"categories":["Course"],"content":" Q2: Retirement Add a time_to_retire method to the Account class. This method takes in an amount and returns how many years the holder would need to wait in order for the current balance to grow to at least amount, assuming that the bank adds balance times the interest rate to the total balance at the end of every year. 问题描述如下: 每一年你的 balance 都会有利息, 问你哪一年你达到了 amount 可以退休了, 用代码模拟这个过程即可 python def time_to_retire(self, amount): \"\"\"Return the number of years until balance would grow to amount.\"\"\" assert self.balance \u003e 0 and amount \u003e 0 and self.interest \u003e 0 year, curAmount = 0, self.balance while True: year += 1 curAmount *= (1 + self.interest) if curAmount \u003e amount: return year ","date":"2022-02-24","objectID":"/zh-cn/lab07-cs61a-of-ucb/:1:1","series":null,"tags":["Course"],"title":"Lab07 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab07-cs61a-of-ucb/#q2-retirement"},{"categories":["Course"],"content":" Q3: FreeChecking Implement the FreeChecking class, which is like the Account class from lecture except that it charges a withdraw fee after 2 withdrawals. If a withdrawal is unsuccessful, it still counts towards the number of free withdrawals remaining, but no fee for the withdrawal will be charged. 和普通的 withdraw 方法相比, 我们要额外检查一个参数 - free_withdrawals, 它表示我们可以在不支付消费的情况下取款的次数. 这里要注意两个点: 取款失败也会扣免费次数 在要支付小费的情况下, 得小费+余额\u003e取款金额才能成功取款 注意好这两个点写出代码就没有什么难度了 python def withdraw(self, amount): if self.free_withdrawals \u003e 0: if amount \u003e self.balance: self.free_withdrawals -= 1 return \"Insufficient funds\" if amount \u003e self.max_withdrawal: self.free_withdrawals -= 1 return \"Can't withdraw that amount\" self.free_withdrawals -= 1 self.balance = self.balance - amount else: if amount + self.withdraw_fee \u003e self.balance: self.free_withdrawals -= 1 return \"Insufficient funds\" if amount + self.withdraw_fee \u003e self.max_withdrawal: self.free_withdrawals -= 1 return \"Can't withdraw that amount\" self.balance = self.balance - amount - self.withdraw_fee ","date":"2022-02-24","objectID":"/zh-cn/lab07-cs61a-of-ucb/:1:2","series":null,"tags":["Course"],"title":"Lab07 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab07-cs61a-of-ucb/#q3-freechecking"},{"categories":["Course"],"content":" Magic: the Lambda-ing ","date":"2022-02-24","objectID":"/zh-cn/lab07-cs61a-of-ucb/:2:0","series":null,"tags":["Course"],"title":"Lab07 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab07-cs61a-of-ucb/#magic-the-lambda-ing"},{"categories":["Course"],"content":" Description下面要实现的是一个卡牌游戏, 两个玩家都有一副卡牌, 并且持有手牌. 双方玩家需要在每个回合中打出一张手牌. 每张手牌都有攻击力和防御力, 能量高的人获胜. 能量计算方式如下 $$(持有手牌的攻击力)-(对方卡牌的防御力)/2$$ 第一个胜利 8 回合以上的人获得游戏的胜利. 同时还有下面几张特殊卡牌: AI 卡: 强制让对手出的卡牌的攻击力减去它的防御力, 然后让它的防御力 * 2 Tutor 卡: 强制让对手弃三张卡牌并重新抽三张牌 TA 卡: 强制交换对手出的卡牌的攻击力和防御力 Instructor 卡: 根据对手出的卡牌来增加自己卡牌堆里面的卡牌的攻击力和防御力, 然后删除对手卡牌堆里所有跟他出的卡身材(攻击力和防御力)一样的 ","date":"2022-02-24","objectID":"/zh-cn/lab07-cs61a-of-ucb/:2:1","series":null,"tags":["Course"],"title":"Lab07 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab07-cs61a-of-ucb/#description"},{"categories":["Course"],"content":" Q4: Making Cards To play a card game, we’re going to need to have cards, so let’s make some! We’re gonna implement the basics of the Card class first. First, implement the Card class constructor in classes.py. This constructor takes three arguments: a string as the name of the card an integer as the attack value of the card an integer as the defense value of the card Each Card instance should keep track of these values using instance attributes called name, attack, and defense. You should also implement the power method in Card, which takes in another card as an input and calculates the current card’s power. Refer to the Rules of the Game if you’d like a refresher on how power is calculated. 在本体中我们要完成构造函数的代码和计算能量的函数, 其实就是把上面的规则翻译成代码, 很简单. python class Card: cardtype = 'Staff' def __init__(self, name, attack, defense): \"\"\" Create a Card object with a name, attack, and defense. \"\"\" self.name = name self.attack = attack self.defense = defense def power(self, opponent_card): \"\"\" Calculate power as: (player card's attack) - (opponent card's defense)/2 \"\"\" return self.attack - opponent_card.defense / 2 ","date":"2022-02-24","objectID":"/zh-cn/lab07-cs61a-of-ucb/:2:2","series":null,"tags":["Course"],"title":"Lab07 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab07-cs61a-of-ucb/#q4-making-cards"},{"categories":["Course"],"content":" Q5: Making a Player Now that we have cards, we can make a deck, but we still need players to actually use them. We’ll now fill in the implementation of the Player class. A Player instance has three instance attributes: name is the player’s name. When you play the game, you can enter your name, which will be converted into a string to be passed to the constructor. deck is an instance of the Deck class. You can draw from it using its .draw() method. hand is a list of Card instances. Each player should start with 5 cards in their hand, drawn from their deck. Each card in the hand can be selected by its index in the list during the game. When a player draws a new card from the deck, it is added to the end of this list. Complete the implementation of the constructor for Player so that self.hand is set to a list of 5 cards drawn from the player’s deck. Next, implement the draw and play methods in the Player class. The draw method draws a card from the deck and adds it to the player’s hand. The play method removes and returns a card from the player’s hand at the given index. Call deck.draw() when implementing Player.__init__ and Player.draw. Don’t worry about how this function works - leave it all to the abstraction! 在这一题中进一步对手牌完善了描述, 我们一开始有 5 张手牌. 我们需要完成下面的功能: 构造函数, 在这里要从 deck 中取出 5 张手牌, 为了代码的简洁我们这里可以在这里使用 List comprehension draw 函数, 从卡牌堆取一张牌到手牌, 这个直接用 deck.draw() 即可 play 函数, 其实就是出牌函数, 我们需要根据索引出牌, 记得把牌删掉, 要区分 python 中的 .remove() 和 .pop() 方法 python def __init__(self, deck, name): \"\"\"Initialize a Player object. \"\"\" self.deck = deck self.name = name self.hand = [deck.draw() for i in range(5)] def draw(self): \"\"\"Draw a card from the player's deck and add it to their hand. \"\"\" assert not self.deck.is_empty(), 'Deck is empty!' self.hand.append(self.deck.draw()) def play(self, card_index): \"\"\"Remove and return a card from the player's hand at the given index. \"\"\" card = self.hand[card_index] self.hand.pop(card_index) return card ","date":"2022-02-24","objectID":"/zh-cn/lab07-cs61a-of-ucb/:2:3","series":null,"tags":["Course"],"title":"Lab07 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab07-cs61a-of-ucb/#q5-making-a-player"},{"categories":["Course"],"content":" Optional Questions","date":"2022-02-24","objectID":"/zh-cn/lab07-cs61a-of-ucb/:3:0","series":null,"tags":["Course"],"title":"Lab07 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab07-cs61a-of-ucb/#optional-questions"},{"categories":["Course"],"content":" Q6: AIs: Defenders Implement the effect method for AIs, which reduces the opponent card’s attack by the opponent card’s defense, and then doubles the opponent card’s defense. Note: The opponent card’s resulting attack value cannot be negative. 这个问题要我们实现前面提到过的 AI 卡的功能, 就按照那个功能写代码即可, 注意如果攻击力算出来小于 0, 我们需要把它设置为 0 python def effect(self, opponent_card, player, opponent): \"\"\" Reduce the opponent's card's attack by its defense, then double its defense. \"\"\" opponent_card.attack -= opponent_card.defense if opponent_card.attack \u003c 0: opponent_card.attack = 0 opponent_card.defense *= 2 ","date":"2022-02-24","objectID":"/zh-cn/lab07-cs61a-of-ucb/:3:1","series":null,"tags":["Course"],"title":"Lab07 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab07-cs61a-of-ucb/#q6-ais-defenders"},{"categories":["Course"],"content":" Q7: Tutors: Flummox Implement the effect method for TAs, which swaps the attack and defense of the opponent’s card. 也就是实现上面的 Tutor 卡, 注意这里我们要如何实现弃牌, 我们不应该破坏封装, 也就是我们要假装不知道内部实现细节, 那么查看 Player 类有什么方法我们可以使用. 显然, 我们可以用 play 把前三张牌打出去, 然后从牌堆里 draw 三张牌出来 python def effect(self, opponent_card, player, opponent): \"\"\" Discard the first 3 cards in the opponent's hand and have them draw the same number of cards from their deck. \"\"\" # discard 3 cards for i in range(3): opponent.play(i) # draw 3 cards for i in range(3): opponent.draw() # You should add your implementation above this. print('{} discarded and re-drew 3 cards!'.format(opponent.name)) ","date":"2022-02-24","objectID":"/zh-cn/lab07-cs61a-of-ucb/:3:2","series":null,"tags":["Course"],"title":"Lab07 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab07-cs61a-of-ucb/#q7-tutors-flummox"},{"categories":["Course"],"content":" Q8: TAs: Shift Implement the effect method for TAs, which swaps the attack and defense of the opponent’s card. TA 卡的功能很简单, 无非就是交换攻击力和防御力而已, 在 python 中要实现这个功能是十分简洁的 python def effect(self, opponent_card, player, opponent): \"\"\" Swap the attack and defense of an opponent's card. \"\"\" opponent_card.attack, opponent_card.defense = opponent_card.defense, opponent_card.attack ","date":"2022-02-24","objectID":"/zh-cn/lab07-cs61a-of-ucb/:3:3","series":null,"tags":["Course"],"title":"Lab07 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab07-cs61a-of-ucb/#q8-tas-shift"},{"categories":["Course"],"content":" Q9: The Instructor Arrives A new challenger has appeared! Implement the effect method for the Instructors, who add the opponent card’s attack and defense to all cards in the player’s deck and then removes all cards in the opponent’s deck that have the same attack or defense as the opponent’s card. Note: If you mutate a list while iterating through it, you may run into trouble. Try iterating through a copy of the list instead. You can use slicing to make a copy of a list: text \u003e\u003e\u003e original = [1, 2, 3, 4] \u003e\u003e\u003e copy = original[:] \u003e\u003e\u003e copy [1, 2, 3, 4] \u003e\u003e\u003e copy is original False 也就是我们要实现上面的 Instructor 卡, 相比于其他三个卡来说, 这个的功能稍微复杂些, 但是也还好. 关键之处在于如何一边遍历列表, 一边删除自己想要的元素. 可以查看这里面的回答知道改怎么做, 知道了这一点之后做这一题就不难了 python def effect(self, opponent_card, player, opponent): \"\"\" Adds the attack and defense of the opponent's card to all cards in the player's deck, then removes all cards in the opponent's deck that share an attack or defense stat with the opponent's card. \"\"\" orig_opponent_deck_length = len(opponent.deck.cards) # add the attack and defense of the opponent's card ... for card in player.deck.cards: card.attack += opponent_card.attack card.defense += opponent_card.defense # remove all cards in the opponent's deck that share ... for card in opponent.deck.cards[:]: if card.attack == opponent_card.attack and card.defense == opponent_card.defense: opponent.deck.cards.remove(card) # You should add your implementation above this. discarded = orig_opponent_deck_length - len(opponent.deck.cards) if discarded: print('{} cards were discarded from {}\\'s deck!'.format(discarded, opponent.name)) return ","date":"2022-02-24","objectID":"/zh-cn/lab07-cs61a-of-ucb/:3:4","series":null,"tags":["Course"],"title":"Lab07 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab07-cs61a-of-ucb/#q9-the-instructor-arrives"},{"categories":["Course"],"content":"The simple solutions of hw05 of CS61A of UCB","date":"2022-02-22","objectID":"/zh-cn/hw05-of-cs61a-of-ucb/","series":null,"tags":["Course"],"title":"Hw05 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/hw05-of-cs61a-of-ucb/"},{"categories":["Course"],"content":" Q1: Generate Permutations Given a sequence of unique elements, a permutation of the sequence is a list containing the elements of the sequence in some arbitrary order. For example, [2, 1, 3], [1, 3, 2], and [3, 2, 1] are some of the permutations of the sequence [1, 2, 3]. Implement gen_perms, a generator function that takes in a sequence seq and returns a generator that yields all permutations of seq. For this question, assume that seq will not be empty. Permutations may be yielded in any order. Note that the doctests test whether you are yielding all possible permutations, but not in any particular order. The built-in sorted function takes in an iterable object and returns a list containing the elements of the iterable in non-decreasing order. Hint: If you had the permutations of all the elements in seq not including the first element, how could you use that to generate the permutations of the full seq? Hint: Remember, it’s possible to loop over generator objects because generators are iterators! 题意就是要我们返回一个 generator, 这个 generator 会一个个返回列表的所有排列组合. 这个 Hint 明摆着我们要用递归的方法解决这个问题. 很容易想到这一道题的 base case, 如下 python def gen_perms(seq): if len(seq) \u003c= 1: yield seq ... 现在的问题就是要如何过渡到子问题, 根据提示我们可以猜: 我们应该递归处理除了第一个位置以外的元素, 再根据题目的另一个提示, 我们应该假定我们的 gen_perms(seq) 就是返回 seq 的全排列, 那我们只要将我们的第一个元素插入到全排列的任意一个位置即可. 举个例子来说, 比如我们处理 [1, 2, 3] 的全排列, 假设我们现在已经得到了 [2, 3] 的全排列——[[2, 3], [3, 2]], 那么我们只要将 1 插入到 [2, 3] 的不同位置, 我们就可以得到 [1, 2, 3], [2, 1, 3], [2, 3, 1], 然后我们对 [3, 2] 进行同样的步骤. 这样我们就得到了所有的全排列, 然后我们可以写出如下的代码 python def gen_perms(seq): \"\"\"Generates all permutations of the given sequence. Each permutation is a list of the elements in SEQ in a different order. The permutations may be yielded in any order. \u003e\u003e\u003e perms = gen_perms([100]) \u003e\u003e\u003e type(perms) \u003cclass 'generator'\u003e \u003e\u003e\u003e next(perms) [100] \u003e\u003e\u003e try: #this piece of code prints \"No more permutations!\" if calling next would cause an error ... next(perms) ... except StopIteration: ... print('No more permutations!') No more permutations! \u003e\u003e\u003e sorted(gen_perms([1, 2, 3])) # Returns a sorted list containing elements of the generator [[1, 2, 3], [1, 3, 2], [2, 1, 3], [2, 3, 1], [3, 1, 2], [3, 2, 1]] \u003e\u003e\u003e sorted(gen_perms((10, 20, 30))) [[10, 20, 30], [10, 30, 20], [20, 10, 30], [20, 30, 10], [30, 10, 20], [30, 20, 10]] \u003e\u003e\u003e sorted(gen_perms(\"ab\")) [['a', 'b'], ['b', 'a']] \"\"\" # This problem requires list type, see example above if type(seq) != list: seq = list(seq) # base case if len(seq) \u003c= 1: yield seq else: # iterate every permutation in the generator for perm in gen_perms(seq[1:]): # enumerate every position for insertation for i in range(len(seq)): yield perm[:i] + seq[:1] + perm[i:] ","date":"2022-02-22","objectID":"/zh-cn/hw05-of-cs61a-of-ucb/:0:1","series":null,"tags":["Course"],"title":"Hw05 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/hw05-of-cs61a-of-ucb/#q1-generate-permutations"},{"categories":["Course"],"content":" Q2: Yield Paths Define a generator function path_yielder which takes in a tree t, a value value, and returns a generator object which yields each path from the root of t to a node that has label value. Each path should be represented as a list of the labels along that path in the tree. You may yield the paths in any order. We have provided a skeleton for you. You do not need to use this skeleton, but if your implementation diverges significantly from it, you might want to think about how you can get it to fit the skeleton. 题目让我们返回从根结点出发到达所有标签为 value 的路径. 注意给我们的提示, 我们要实现的函数应该如下所示: python def path_yielder(t, value): \"*** YOUR CODE HERE ***\" for _______________ in _________________: for _______________ in _________________: \"*** YOUR CODE HERE ***\" 如果你仔细观察, 或许可以发现这一题的代码跟 Q1 竟是如此相似, 现在我们开始思考如何来解决这个问题. 首先要处理什么是 base case, 显然当我们遇到 label 是 value 的结点时候就到达了 base case 可以返回. 而将这个问题分解为更简单的子问题的方式也很简单, 我们要从当前结点出发, 遍历它的每一个子树, 只要路径上有就返回, 注意这里我们返回的是子路径(不包括当前结点), 然后我们加上当前结点的 label 即可. 用一个例子来说, 看下面的 docstring 里面的例子, 假设我们现在要找到所有到达 label 为 3 的所有路径, 我们从根结点 1 出发, 检查的它的每一个子树, 分别是 2 和 5. 然后我们接着对 2 这么处理, 在 2 的第一个子树中我们找到了 3, 此时我们 yield [3]. 当我们回溯到 2 的时候加上 2, 我们又得到了子路径 [2, 3], 最后我们接着回溯到根结点, 得到 [1] + [2, 3] = [1, 2, 3] 代码如下: python def path_yielder(t, value): \"\"\"Yields all possible paths from the root of t to a node with the label value as a list. \u003e\u003e\u003e t1 = tree(1, [tree(2, [tree(3), tree(4, [tree(6)]), tree(5)]), tree(5)]) \u003e\u003e\u003e print_tree(t1) 1 2 3 4 6 5 5 \u003e\u003e\u003e next(path_yielder(t1, 6)) [1, 2, 4, 6] \u003e\u003e\u003e path_to_5 = path_yielder(t1, 5) \u003e\u003e\u003e sorted(list(path_to_5)) [[1, 2, 5], [1, 5]] \u003e\u003e\u003e t2 = tree(0, [tree(2, [t1])]) \u003e\u003e\u003e print_tree(t2) 0 2 1 2 3 4 6 5 5 \u003e\u003e\u003e path_to_2 = path_yielder(t2, 2) \u003e\u003e\u003e sorted(list(path_to_2)) [[0, 2], [0, 2, 1, 2]] \"\"\" if label(t) == value: yield [label(t)] for b in branches(t): for path in path_yielder(b, value): yield [label(t)] + path ","date":"2022-02-22","objectID":"/zh-cn/hw05-of-cs61a-of-ucb/:0:2","series":null,"tags":["Course"],"title":"Hw05 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/hw05-of-cs61a-of-ucb/#q2-yield-paths"},{"categories":["Course"],"content":" Q3: Preorder Define the function preorder, which takes in a tree as an argument and returns a list of all the entries in the tree in the order that print_tree would print them. The following diagram shows the order that the nodes would get printed, with the arrows representing function calls. 又是树的先序遍历问题, 这真的是一个十分经典的问题. 我们要递归访问这一棵树的所有结点, 从根结点出发, 注意我们是先记住根结点的值再去看它的子树, 并递归式处理这样的问题. python def preorder(t): \"\"\"Return a list of the entries in this tree in the order that they would be visited by a preorder traversal (see problem description). \u003e\u003e\u003e numbers = tree(1, [tree(2), tree(3, [tree(4), tree(5)]), tree(6, [tree(7)])]) \u003e\u003e\u003e preorder(numbers) [1, 2, 3, 4, 5, 6, 7] \u003e\u003e\u003e preorder(tree(2, [tree(4, [tree(6)])])) [2, 4, 6] \"\"\" result = [] def helper(t): if t is not None: result.append(label(t)) for b in branches(t): helper(b) helper(t) return result ","date":"2022-02-22","objectID":"/zh-cn/hw05-of-cs61a-of-ucb/:0:3","series":null,"tags":["Course"],"title":"Hw05 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/hw05-of-cs61a-of-ucb/#q3-preorder"},{"categories":["Course"],"content":" Q4: Generate Preorder Similarly to preorder in Question 3, define the function generate_preorder, which takes in a tree as an argument and now instead yields the entries in the tree in the order that print_tree would print them. Hint: How can you modify your implementation of preorder to yield from your recursive calls instead of returning them? 仍旧是先序遍历的问题, 整体解法上很像 Q3, 只是现在我们不需要用一个 result 来存储遍历的序列, 因为我们要返回的是 generator. 但这个算法的逻辑还是一致的, 先看根结点, 然后去看它的子树的结点. 如果想对 yield from 有更深的了解, 我们可以看看这个人的这篇文章 python def generate_preorder(t): \"\"\"Yield the entries in this tree in the order that they would be visited by a preorder traversal (see problem description). \u003e\u003e\u003e numbers = tree(1, [tree(2), tree(3, [tree(4), tree(5)]), tree(6, [tree(7)])]) \u003e\u003e\u003e gen = generate_preorder(numbers) \u003e\u003e\u003e next(gen) 1 \u003e\u003e\u003e list(gen) [2, 3, 4, 5, 6, 7] \"\"\" yield label(t) for b in branches(t): yield from generate_preorder(b) ","date":"2022-02-22","objectID":"/zh-cn/hw05-of-cs61a-of-ucb/:0:4","series":null,"tags":["Course"],"title":"Hw05 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/hw05-of-cs61a-of-ucb/#q4-generate-preorder"},{"categories":["Course"],"content":" Q5: Remainder Generator Like functions, generators can also be higher-order. For this problem, we will be writing remainders_generator, which yields a series of generator objects. remainders_generator takes in an integer m, and yields m different generators. The first generator is a generator of multiples of m, i.e. numbers where the remainder is 0. The second is a generator of natural numbers with remainder 1 when divided by m. The last generator yields natural numbers with remainder m - 1 when divided by m. Hint: To create a generator of infinite natural numbers, you can call the naturals function that’s provided in the starter code. Hint: Consider defining an inner generator function. Each yielded generator varies only in that the elements of each generator have a particular remainder when divided by m. What does that tell you about the argument(s) that the inner function should take in? 这个问题如果你对 python 的 generator 一点都不了解的话, 一时要写出这样的代码是比较困难的, 我会推荐你先阅读这个教程. 在阅读上面的材料之后我们开始以前来想这个问题要怎么解决. 其实它就是要返回 m 个 generator, 第 i 个 generator 里面分别是除以 m 得到余数为 i 的所有数. 注意, 我们要的是所有数, 所以我们可以现象我们要怎么得到第一个 generator, 其他 generator 其实都是类似的. 我们只要用一个 while True 死循环来一直找就行, 因为我们用的是 yield, 它每次找到一个就会暂停执行并返回那个数. 这样我们就得到了这个无限产生我们想要的数的 generator python def helper(i, m): num = 1 # loop variable while True: if num % m == i: yield num num += 1 # you can give it a test \u003e\u003e\u003e it = helper(2, 3) \u003e\u003e\u003e next(it) 2 # 2 % 3 == 2 \u003e\u003e\u003e next(it) 5 # 5 % 3 == 2 \u003e\u003e\u003e next(it) 8 # 8 % 3 == 2 那么我们如何得到一个 generator 的 list 呢, 也很简单, 我们用 for 循环就好了 python def remainders_generator(m): \"\"\" Yields m generators. The ith yielded generator yields natural numbers whose remainder is i when divided by m. \u003e\u003e\u003e import types \u003e\u003e\u003e [isinstance(gen, types.GeneratorType) for gen in remainders_generator(5)] [True, True, True, True, True] \u003e\u003e\u003e remainders_four = remainders_generator(4) \u003e\u003e\u003e for i in range(4): ... print(\"First 3 natural numbers with remainder {0} when divided by 4:\".format(i)) ... gen = next(remainders_four) ... for _ in range(3): ... print(next(gen)) First 3 natural numbers with remainder 0 when divided by 4: 4 8 12 First 3 natural numbers with remainder 1 when divided by 4: 1 5 9 First 3 natural numbers with remainder 2 when divided by 4: 2 6 10 First 3 natural numbers with remainder 3 when divided by 4: 3 7 11 \"\"\" def helper(i, m): num = 1 # loop variable while True: if num % m == i: yield num num += 1 for i in range(m): yield helper(i, m) ","date":"2022-02-22","objectID":"/zh-cn/hw05-of-cs61a-of-ucb/:0:5","series":null,"tags":["Course"],"title":"Hw05 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/hw05-of-cs61a-of-ucb/#q5-remainder-generator"},{"categories":["Course"],"content":"the simple solutions for lab06 of CS61A of UCB","date":"2022-02-20","objectID":"/zh-cn/lab06-cs61a-of-ucb/","series":null,"tags":["Course"],"title":"Lab06 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab06-cs61a-of-ucb/"},{"categories":["Course"],"content":" Mutability Write a function which takes in a list lst, an argument entry, and another argument elem. This function will check through each item in lst to see if it is equal to entry. Upon finding an item equal to entry, the function should modify the list by placing elem into lst right after the item. At the end of the function, the modified list should be returned. See the doctests for examples on how this function is utilized. Important: Use list mutation to modify the original list. No new lists should be created or returned. Note: If the values passed into entry and elem are equivalent, make sure you’re not creating an infinitely long list while iterating through it. If you find that your code is taking more than a few seconds to run, the function may be in a loop of inserting new values. 注意我们不能 for 循环来一边遍历这个 list 一边进行修改, 我记得我之前在《Effective Python》看过这一点. 其实自己 debug 就可以发现, 因为一开始用 for i in range(len(lst)) 的时候就固定了, 但其实你在 for 循环里面会插入新的值, 这个 list 其实是变得更长的(但是 i 还是在原来的范围里), 所以后面超过本来长度的元素就会看不到. 注意下面这个代码是错误的🙅‍♂️ python def insert_items(lst, entry, elem): is_the_same = (entry == elem) while True: no_entry = True for i in range(len(lst)): if lst[i] == entry: if i == len(lst) - 1: lst.append(elem) else: lst.insert(i + 1, elem) no_entry = False # avoid infinite loop if is_the_same: i += 1 if no_entry: return lst 正确的解法应该是用 while 循环搭配 list.index(x[, start[, end]]) 方法, 代码如下: python def insert_items(lst, entry, elem): \"\"\"Inserts elem into lst after each occurence of entry and then returns lst. \u003e\u003e\u003e test_lst = [1, 5, 8, 5, 2, 3] \u003e\u003e\u003e new_lst = insert_items(test_lst, 5, 7) \u003e\u003e\u003e new_lst [1, 5, 7, 8, 5, 7, 2, 3] \u003e\u003e\u003e double_lst = [1, 2, 1, 2, 3, 3] \u003e\u003e\u003e double_lst = insert_items(double_lst, 3, 4) \u003e\u003e\u003e double_lst [1, 2, 1, 2, 3, 4, 3, 4] \u003e\u003e\u003e large_lst = [1, 4, 8] \u003e\u003e\u003e large_lst2 = insert_items(large_lst, 4, 4) \u003e\u003e\u003e large_lst2 [1, 4, 4, 8] \u003e\u003e\u003e large_lst3 = insert_items(large_lst2, 4, 6) \u003e\u003e\u003e large_lst3 [1, 4, 6, 4, 6, 8] \u003e\u003e\u003e large_lst3 is large_lst True \u003e\u003e\u003e # Ban creating new lists \u003e\u003e\u003e from construct_check import check \u003e\u003e\u003e check(HW_SOURCE_FILE, 'insert_items', ... ['List', 'ListComp', 'Slice']) True \"\"\" pos, cnt = 0, 0 for i in lst: if i == entry: cnt += 1 while cnt \u003e 0: idx = lst.index(entry, pos) pos = idx + 1 if idx == len(lst) - 1: lst.append(elem) else: lst.insert(idx + 1, elem) cnt -= 1 return lst ","date":"2022-02-20","objectID":"/zh-cn/lab06-cs61a-of-ucb/:1:0","series":null,"tags":["Course"],"title":"Lab06 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab06-cs61a-of-ucb/#mutability"},{"categories":["Course"],"content":" Iterators ","date":"2022-02-20","objectID":"/zh-cn/lab06-cs61a-of-ucb/:2:0","series":null,"tags":["Course"],"title":"Lab06 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab06-cs61a-of-ucb/#iterators"},{"categories":["Course"],"content":" Q4: Count Occurrences Implement count_occurrences, which takes in an iterator t and returns the number of times the value x appears in the first n elements of t. A value appears in a sequence of elements if it is equal to an entry in the sequence. Note: You can assume that t will have at least n elements. 这一道题主要是要让我们学会使用 iter 和 next 这两个函数. 我们可以用 while n \u003e 0 来控制只访问前 n 个位置, 做一个简单的判读来计数即可 python def count_occurrences(t, n, x): \"\"\"Return the number of times that x appears in the first n elements of iterator t. \u003e\u003e\u003e s = iter([10, 9, 10, 9, 9, 10, 8, 8, 8, 7]) \u003e\u003e\u003e count_occurrences(s, 10, 9) 3 \u003e\u003e\u003e s2 = iter([10, 9, 10, 9, 9, 10, 8, 8, 8, 7]) \u003e\u003e\u003e count_occurrences(s2, 3, 10) 2 \u003e\u003e\u003e s = iter([3, 2, 2, 2, 1, 2, 1, 4, 4, 5, 5, 5]) \u003e\u003e\u003e count_occurrences(s, 1, 3) 1 \u003e\u003e\u003e count_occurrences(s, 4, 2) 3 \u003e\u003e\u003e next(s) 2 \u003e\u003e\u003e s2 = iter([4, 1, 6, 6, 7, 7, 8, 8, 2, 2, 2, 5]) \u003e\u003e\u003e count_occurrences(s2, 6, 6) 2 \"\"\" it = iter(t) cnt = 0 while n \u003e 0: val = next(it) if val == x: cnt += 1 n -= 1 return cnt ","date":"2022-02-20","objectID":"/zh-cn/lab06-cs61a-of-ucb/:2:1","series":null,"tags":["Course"],"title":"Lab06 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab06-cs61a-of-ucb/#q4-count-occurrences"},{"categories":["Course"],"content":" Q5: Repeated Implement repeated, which takes in an iterator t and returns the first value in t that appears k times in a row. Note: You can assume that the iterator t will have a value that appears at least k times in a row. If you are receiving a StopIteration, your repeated function is likely not identifying the correct value. Your implementation should iterate through the items in a way such that if the same iterator is passed into repeated twice, it should continue in the second call at the point it left off in the first. An example of this behavior is in the doctests. 我们在这个问题重要解决两个问题: 如何找到连续的 k 个值 ? 需要设置 last_val 来记住上一个值是什么, 这样才能和当前的值进行对比. 用一个 while True: 来不断找即可(题目保证一定找得到, 所以不用怕死循环) 如何保证下一次调用的时候要从上一次离开的位置开始 ? 如果认真看过课程的人可能记得要怎么做, 我们应该用高阶函数, 在 repeated 里面再定义一个函数, 将变量绑定到这个嵌套的函数上. 这样我们就可以保证每次都可以从上一次的位置开始. 忘了的可以看看这个链接 的 2.4.4 Local state python def repeated(t, k): \"\"\"Return the first value in iterator T that appears K times in a row. Iterate through the items such that if the same iterator is passed into the function twice, it continues in the second call at the point it left off in the first. \u003e\u003e\u003e s = iter([10, 9, 10, 9, 9, 10, 8, 8, 8, 7]) \u003e\u003e\u003e repeated(s, 2) 9 \u003e\u003e\u003e s2 = iter([10, 9, 10, 9, 9, 10, 8, 8, 8, 7]) \u003e\u003e\u003e repeated(s2, 3) 8 \u003e\u003e\u003e s = iter([3, 2, 2, 2, 1, 2, 1, 4, 4, 5, 5, 5]) \u003e\u003e\u003e repeated(s, 3) 2 \u003e\u003e\u003e repeated(s, 3) 5 \u003e\u003e\u003e s2 = iter([4, 1, 6, 6, 7, 7, 8, 8, 2, 2, 2, 5]) \u003e\u003e\u003e repeated(s2, 3) 2 \"\"\" assert k \u003e 1 last_val, it = None, iter(t) def helper(k): nonlocal last_val nonlocal it cnt = 0 while True: val = next(it) if last_val is None or val != last_val: last_val, cnt = val, 1 else: cnt += 1 if cnt == k: return val return helper(k) ","date":"2022-02-20","objectID":"/zh-cn/lab06-cs61a-of-ucb/:2:2","series":null,"tags":["Course"],"title":"Lab06 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab06-cs61a-of-ucb/#q5-repeated"},{"categories":["Course"],"content":"The simple solutions of hw04 of CS61A of UCB","date":"2022-02-20","objectID":"/zh-cn/hw04-of-cs61a-of-ucb/","series":null,"tags":["Course"],"title":"Hw04 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/hw04-of-cs61a-of-ucb/"},{"categories":["Course"],"content":" Mobiles ","date":"2022-02-20","objectID":"/zh-cn/hw04-of-cs61a-of-ucb/:1:0","series":null,"tags":["Course"],"title":"Hw04 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/hw04-of-cs61a-of-ucb/#mobiles"},{"categories":["Course"],"content":" Q2: Weights Implement the planet data abstraction by completing the planet constructor and the size selector so that a planet is represented using a two-element list where the first element is the string 'planet' and the second element is its size. 从问题的描述中我们可以知道什么是 planet. 就是一个长度为 2 的 list, 内容是 ['planet', size]. 可以参考 mobile 函数, 这两个函数的代码是很类似的 python def planet(size): \"\"\"Construct a planet of some size.\"\"\" assert size \u003e 0 return ['planet', size] def size(w): \"\"\"Select the size of a planet.\"\"\" assert is_planet(w), 'must call size on a planet' return w[1] ","date":"2022-02-20","objectID":"/zh-cn/hw04-of-cs61a-of-ucb/:1:1","series":null,"tags":["Course"],"title":"Hw04 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/hw04-of-cs61a-of-ucb/#q2-weights"},{"categories":["Course"],"content":" Q3: Balanced Implement the balanced function, which returns whether m is a balanced mobile. A mobile is balanced if both of the following conditions are met: The torque applied by its left arm is equal to that applied by its right arm. The torque of the left arm is the length of the left rod multiplied by the total weight hanging from that rod. Likewise for the right. For example, if the left arm has a length of 5, and there is a mobile hanging at the end of the left arm of weight 10, the torque on the left side of our mobile is 50. Each of the mobiles hanging at the end of its arms is balanced. Planets themselves are balanced, as there is nothing hanging off of them. 这个问题需要用递归的方法来解决. 我们判断一个 mobile 平衡的条件如下 它是 planet, 根据描述可以知道本身是平衡的 它是 arm, 并且 total_weight(left_arm) == total_weight(right_arm). 并且它的所有子树都要符合这个平衡的条件. 注意不要漏掉对子树的判断 写出代码的关键: 要区分开 arm, planet, mobile 这三个概念并且要能够知道用什么对应的函数来处理. 😢 python def balanced(m): \"\"\"Return whether m is balanced. \u003e\u003e\u003e t, u, v = examples() \u003e\u003e\u003e balanced(t) True \u003e\u003e\u003e balanced(v) True \u003e\u003e\u003e w = mobile(arm(3, t), arm(2, u)) \u003e\u003e\u003e balanced(w) False \u003e\u003e\u003e balanced(mobile(arm(1, v), arm(1, w))) False \u003e\u003e\u003e balanced(mobile(arm(1, w), arm(1, v))) False \u003e\u003e\u003e from construct_check import check \u003e\u003e\u003e # checking for abstraction barrier violations by banning indexing \u003e\u003e\u003e check(HW_SOURCE_FILE, 'balanced', ['Index']) True \"\"\" # planet is balanced if is_planet(m): return True left_arm, right_arm = left(m), right(m) # end(...arm) will is a mobile or a planet left_val = length(left_arm) * total_weight(end(left_arm)) right_val = length(right_arm) * total_weight(end(right_arm)) return left_val == right_val and balanced(end(left_arm)) and balanced(end(right_arm)) ","date":"2022-02-20","objectID":"/zh-cn/hw04-of-cs61a-of-ucb/:1:2","series":null,"tags":["Course"],"title":"Hw04 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/hw04-of-cs61a-of-ucb/#q3-balanced"},{"categories":["Course"],"content":" Q4: Totals Implement totals_tree, which takes in a mobile or planet and returns a tree whose root is the total weight of the input. For a planet, totals_tree should return a leaf. For a mobile, totals_tree should return a tree whose label is that mobile’s total weight, and whose branches are totals_trees for the ends of its arms. As a reminder, the description of the tree data abstraction can be found here. 我们在这个问题中想要把 mobile 转换为 tree. 递归解法的 base case 是当我们遇到叶子结点而且是 planet 的时候. 否则我们就递归分析它的子树 python def totals_tree(m): \"\"\"Return a tree representing the mobile with its total weight at the root. \u003e\u003e\u003e t, u, v = examples() \u003e\u003e\u003e print_tree(totals_tree(t)) 3 2 1 \u003e\u003e\u003e print_tree(totals_tree(u)) 6 1 5 3 2 \u003e\u003e\u003e print_tree(totals_tree(v)) 9 3 2 1 6 1 5 3 2 \u003e\u003e\u003e from construct_check import check \u003e\u003e\u003e # checking for abstraction barrier violations by banning indexing \u003e\u003e\u003e check(HW_SOURCE_FILE, 'totals_tree', ['Index']) True \"\"\" if is_planet(m): return tree(size(m)) return tree(total_weight(m), [totals_tree(i) for i in [end(left(m)), end(right(m))]]) ","date":"2022-02-20","objectID":"/zh-cn/hw04-of-cs61a-of-ucb/:1:3","series":null,"tags":["Course"],"title":"Hw04 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/hw04-of-cs61a-of-ucb/#q4-totals"},{"categories":["Course"],"content":" More trees ","date":"2022-02-20","objectID":"/zh-cn/hw04-of-cs61a-of-ucb/:2:0","series":null,"tags":["Course"],"title":"Hw04 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/hw04-of-cs61a-of-ucb/#more-trees"},{"categories":["Course"],"content":" Q5: Replace Loki at Leaf Define replace_loki_at_leaf, which takes a tree t and a value lokis_replacement. replace_loki_at_leaf returns a new tree that’s the same as t except that every leaf label equal to \"loki\" has been replaced with lokis_replacement. If you want to learn about the Norse mythology referenced in this problem, you can read about it here. 递归解法的 base case 仍然是叶子结点, 我们要检查它的 label 是否为 ’loki’. 如果是的话, 我们就创建一个新的叶子结点并返回. 否则我们返回本来的叶子结点即可. python def replace_loki_at_leaf(t, lokis_replacement): \"\"\"Returns a new tree where every leaf value equal to \"loki\" has been replaced with lokis_replacement. \u003e\u003e\u003e yggdrasil = tree('odin', ... [tree('balder', ... [tree('loki'), ... tree('freya')]), ... tree('frigg', ... [tree('loki')]), ... tree('loki', ... [tree('sif'), ... tree('loki')]), ... tree('loki')]) \u003e\u003e\u003e laerad = copy_tree(yggdrasil) # copy yggdrasil for testing purposes \u003e\u003e\u003e print_tree(replace_loki_at_leaf(yggdrasil, 'freya')) odin balder freya freya frigg freya loki sif freya freya \u003e\u003e\u003e laerad == yggdrasil # Make sure original tree is unmodified True \"\"\" if is_leaf(t): if label(t) == 'loki': return tree(lokis_replacement) return t return tree(label(t), [replace_loki_at_leaf(b, lokis_replacement) for b in branches(t)]) ","date":"2022-02-20","objectID":"/zh-cn/hw04-of-cs61a-of-ucb/:2:1","series":null,"tags":["Course"],"title":"Hw04 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/hw04-of-cs61a-of-ucb/#q5-replace-loki-at-leaf"},{"categories":["Course"],"content":" Q6: Has Path Write a function has_path that takes in a tree t and a string word. It returns True if there is a path that starts from the root where the entries along the path spell out the word, and False otherwise. (This data structure is called a trie, and it has a lot of cool applications, such as autocomplete). You may assume that every node’s labelis exactly one character. 什么是这道题的 base case ? 我们要记住从根结点出发到当前所在结点一路经过的结点拼起来的字符串是什么. 举例来说, 在一开始的时候我们在根结点, 我们的字符串是 label(t). 也就是 h. 当我们到了根结点的第一个子结点的时候, 我们就得到了 h + i = hi. 为了实现这样的功能我们可以另外写个递归函数. 然后在 has_path 里面调用即可. 一个提高效率的方法是如果我们当前得到的字符串不是目标字符串的一部分(开头位置), 那么我们显然没有必要继续到更深的子树里面寻找. 这也是递归的剪枝操作. 怎么把问题分解为更简单的子问题 ? 我们可以使用 python 提供的 any 函数, 只要任意一个子树上存在这样的路径即可. python def has_path(t, word): \"\"\"Return whether there is a path in a tree where the entries along the path spell out a particular word. \u003e\u003e\u003e greetings = tree('h', [tree('i'), ... tree('e', [tree('l', [tree('l', [tree('o')])]), ... tree('y')])]) \u003e\u003e\u003e print_tree(greetings) h i e l l o y \u003e\u003e\u003e has_path(greetings, 'h') True \u003e\u003e\u003e has_path(greetings, 'i') False \u003e\u003e\u003e has_path(greetings, 'hi') True \u003e\u003e\u003e has_path(greetings, 'hello') True \u003e\u003e\u003e has_path(greetings, 'hey') True \u003e\u003e\u003e has_path(greetings, 'bye') False \u003e\u003e\u003e has_path(greetings, 'hint') False \"\"\" assert len(word) \u003e 0, 'no path for empty word.' def helper(t, cur): if cur == word: return True if cur not in word: return False return any([helper(b, cur + label(b)) for b in branches(t)]) return helper(t, label(t)) ","date":"2022-02-20","objectID":"/zh-cn/hw04-of-cs61a-of-ucb/:2:2","series":null,"tags":["Course"],"title":"Hw04 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/hw04-of-cs61a-of-ucb/#q6-has-path"},{"categories":["Course"],"content":" Trees ","date":"2022-02-20","objectID":"/zh-cn/hw04-of-cs61a-of-ucb/:3:0","series":null,"tags":["Course"],"title":"Hw04 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/hw04-of-cs61a-of-ucb/#trees"},{"categories":["Course"],"content":" Q7: Preorder Define the function preorder, which takes in a tree as an argument and returns a list of all the entries in the tree in the order that print_tree would print them. The following diagram shows the order that the nodes would get printed, with the arrows representing function calls. 先序遍历是遍历树的一个基本方法. 我们要先记住根结点的值再去访问它的子树上的结点. python def preorder(t): \"\"\"Return a list of the entries in this tree in the order that they would be visited by a preorder traversal (see problem description). \u003e\u003e\u003e numbers = tree(1, [tree(2), tree(3, [tree(4), tree(5)]), tree(6, [tree(7)])]) \u003e\u003e\u003e preorder(numbers) [1, 2, 3, 4, 5, 6, 7] \u003e\u003e\u003e preorder(tree(2, [tree(4, [tree(6)])])) [2, 4, 6] \"\"\" result = [] def helper(t): if t is not None: result.append(label(t)) for b in branches(t): helper(b) helper(t) return result ","date":"2022-02-20","objectID":"/zh-cn/hw04-of-cs61a-of-ucb/:3:1","series":null,"tags":["Course"],"title":"Hw04 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/hw04-of-cs61a-of-ucb/#q7-preorder"},{"categories":["Course"],"content":" Data Abstraction ","date":"2022-02-20","objectID":"/zh-cn/hw04-of-cs61a-of-ucb/:4:0","series":null,"tags":["Course"],"title":"Hw04 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/hw04-of-cs61a-of-ucb/#data-abstraction"},{"categories":["Course"],"content":" Q8: Interval Abstraction Acknowledgements. This interval arithmetic example is based on a classic problem from Structure and Interpretation of Computer Programs, Section 2.1.4. Introduction. Alyssa P. Hacker is designing a system to help people solve engineering problems. One feature she wants to provide in her system is the ability to manipulate inexact quantities (such as measurements from physical devices) with known precision, so that when computations are done with such approximate quantities the results will be numbers of known precision. For example, if a measured quantity x lies between two numbers a and b, Alyssa would like her system to use this range in computations involving x. Alyssa’s idea is to implement interval arithmetic as a set of arithmetic operations for combining “intervals” (objects that represent the range of possible values of an inexact quantity). The result of adding, subracting, multiplying, or dividing two intervals is also an interval, one that represents the range of the result. Alyssa suggests the existence of an abstraction called an “interval” that has two endpoints: a lower bound and an upper bound. She also presumes that, given the endpoints of an interval, she can create the interval using data abstraction. Using this constructor and the appropriate selectors, she defines the following operations: Alyssa’s program is incomplete because she has not specified the implementation of the interval abstraction. She has implemented the constructor for you; fill in the implementation of the selectors. 这道题的计算系统其实是用来计算电阻的. 我们知道电阻会存在误差(比如 $\\pm5%$), 所以真正的电阻值应该是在一个区间里面的. 这就是这个所谓的的 interval 表示的. 所以 interval 其实也就是一个长度为 2 的 list 而已. 要得到它两侧的范围我们只要根据索引返回 x[0] 或 x[1] 即可. python def interval(a, b): \"\"\"Construct an interval from a to b.\"\"\" assert a \u003c= b, 'Lower bound cannot be greater than upper bound' return [a, b] def lower_bound(x): \"\"\"Return the lower bound of interval x.\"\"\" return x[0] def upper_bound(x): \"\"\"Return the upper bound of interval x.\"\"\" return x[1] ","date":"2022-02-20","objectID":"/zh-cn/hw04-of-cs61a-of-ucb/:4:1","series":null,"tags":["Course"],"title":"Hw04 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/hw04-of-cs61a-of-ucb/#q8-interval-abstraction"},{"categories":["Course"],"content":" Q9: Interval Arithmetic After implementing the abstraction, Alyssa decided to implement a few interval arithmetic functions. This is her current implementation for interval multiplication. Unfortunately there are some data abstraction violations, so your task is to fix this code before someone sets it on fire. python def mul_interval(x, y): \"\"\"Return the interval that contains the product of any value in x and any value in y.\"\"\" p1 = x[0] * y[0] p2 = x[0] * y[1] p3 = x[1] * y[0] p4 = x[1] * y[1] return [min(p1, p2, p3, p4), max(p1, p2, p3, p4)] 这里面有很多违反了数据抽象原则的操作, 比如我们访问电阻的上下界的时候不应该直接用 x[0] 或 x[1]. ⚠️ 这其实是破坏了封装性, 万一以后我们换个一个实现电阻的方式, 这个代码就用不了了. 所以正确的方法应该是用前面实现的 lower_bound() 和 upper_bound() 这两个函数. 除此之外, 我们在创建一个 interval 的时候也应该用 interval 这个构造函数. python def mul_interval(x, y): \"\"\"Return the interval that contains the product of any value in x and any value in y.\"\"\" p1 = lower_bound(x) * lower_bound(y) p2 = lower_bound(x) * upper_bound(y) p3 = upper_bound(x) * lower_bound(y) p4 = upper_bound(x) * upper_bound(y) return interval(min(p1, p2, p3, p4), max(p1, p2, p3, p4)) Interval Subtraction Using a similar approach as mul_interval and add_interval, define a subtraction function for intervals. If you find yourself repeating code, see if you can reuse functions that have already been implemented. 这个代码如果和 mul_interval 的几乎一模一样, 只是换了个操作符而已. 如果你跟我一样用的是 vim 作为编辑器, 那么用 \u003cctrl-v\u003e 选中四个 * 之后我们用 r- 就可以快速替换掉了. python def sub_interval(x, y): \"\"\"Return the interval that contains the difference between any value in x and any value in y.\"\"\" p1 = lower_bound(x) - lower_bound(y) p2 = lower_bound(x) - upper_bound(y) p3 = upper_bound(x) - lower_bound(y) p4 = upper_bound(x) - upper_bound(y) return interval(min(p1, p2, p3, p4), max(p1, p2, p3, p4)) Interval Division Alyssa implements division below by multiplying by the reciprocal of y. A systems programmer looks over Alyssa’s shoulder and comments that it is not clear what it means to divide by an interval that spans zero. Add an assertstatement to Alyssa’s code to ensure that no such interval is used as a divisor: 检查是否除数 \u003e 0 python def div_interval(x, y): \"\"\"Return the interval that contains the quotient of any value in x divided by any value in y. Division is implemented as the multiplication of x by the reciprocal of y.\"\"\" assert lower_bound(y) \u003e 0, \"AssertionError!\" reciprocal_y = interval(1 / upper_bound(y), 1 / lower_bound(y)) return mul_interval(x, reciprocal_y) ","date":"2022-02-20","objectID":"/zh-cn/hw04-of-cs61a-of-ucb/:4:2","series":null,"tags":["Course"],"title":"Hw04 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/hw04-of-cs61a-of-ucb/#q9-interval-arithmetic"},{"categories":["Course"],"content":" Q9: Interval Arithmetic After implementing the abstraction, Alyssa decided to implement a few interval arithmetic functions. This is her current implementation for interval multiplication. Unfortunately there are some data abstraction violations, so your task is to fix this code before someone sets it on fire. python def mul_interval(x, y): \"\"\"Return the interval that contains the product of any value in x and any value in y.\"\"\" p1 = x[0] * y[0] p2 = x[0] * y[1] p3 = x[1] * y[0] p4 = x[1] * y[1] return [min(p1, p2, p3, p4), max(p1, p2, p3, p4)] 这里面有很多违反了数据抽象原则的操作, 比如我们访问电阻的上下界的时候不应该直接用 x[0] 或 x[1]. ⚠️ 这其实是破坏了封装性, 万一以后我们换个一个实现电阻的方式, 这个代码就用不了了. 所以正确的方法应该是用前面实现的 lower_bound() 和 upper_bound() 这两个函数. 除此之外, 我们在创建一个 interval 的时候也应该用 interval 这个构造函数. python def mul_interval(x, y): \"\"\"Return the interval that contains the product of any value in x and any value in y.\"\"\" p1 = lower_bound(x) * lower_bound(y) p2 = lower_bound(x) * upper_bound(y) p3 = upper_bound(x) * lower_bound(y) p4 = upper_bound(x) * upper_bound(y) return interval(min(p1, p2, p3, p4), max(p1, p2, p3, p4)) Interval Subtraction Using a similar approach as mul_interval and add_interval, define a subtraction function for intervals. If you find yourself repeating code, see if you can reuse functions that have already been implemented. 这个代码如果和 mul_interval 的几乎一模一样, 只是换了个操作符而已. 如果你跟我一样用的是 vim 作为编辑器, 那么用 选中四个 * 之后我们用 r- 就可以快速替换掉了. python def sub_interval(x, y): \"\"\"Return the interval that contains the difference between any value in x and any value in y.\"\"\" p1 = lower_bound(x) - lower_bound(y) p2 = lower_bound(x) - upper_bound(y) p3 = upper_bound(x) - lower_bound(y) p4 = upper_bound(x) - upper_bound(y) return interval(min(p1, p2, p3, p4), max(p1, p2, p3, p4)) Interval Division Alyssa implements division below by multiplying by the reciprocal of y. A systems programmer looks over Alyssa’s shoulder and comments that it is not clear what it means to divide by an interval that spans zero. Add an assertstatement to Alyssa’s code to ensure that no such interval is used as a divisor: 检查是否除数 \u003e 0 python def div_interval(x, y): \"\"\"Return the interval that contains the quotient of any value in x divided by any value in y. Division is implemented as the multiplication of x by the reciprocal of y.\"\"\" assert lower_bound(y) \u003e 0, \"AssertionError!\" reciprocal_y = interval(1 / upper_bound(y), 1 / lower_bound(y)) return mul_interval(x, reciprocal_y) ","date":"2022-02-20","objectID":"/zh-cn/hw04-of-cs61a-of-ucb/:4:2","series":null,"tags":["Course"],"title":"Hw04 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/hw04-of-cs61a-of-ucb/#interval-subtraction"},{"categories":["Course"],"content":" Q9: Interval Arithmetic After implementing the abstraction, Alyssa decided to implement a few interval arithmetic functions. This is her current implementation for interval multiplication. Unfortunately there are some data abstraction violations, so your task is to fix this code before someone sets it on fire. python def mul_interval(x, y): \"\"\"Return the interval that contains the product of any value in x and any value in y.\"\"\" p1 = x[0] * y[0] p2 = x[0] * y[1] p3 = x[1] * y[0] p4 = x[1] * y[1] return [min(p1, p2, p3, p4), max(p1, p2, p3, p4)] 这里面有很多违反了数据抽象原则的操作, 比如我们访问电阻的上下界的时候不应该直接用 x[0] 或 x[1]. ⚠️ 这其实是破坏了封装性, 万一以后我们换个一个实现电阻的方式, 这个代码就用不了了. 所以正确的方法应该是用前面实现的 lower_bound() 和 upper_bound() 这两个函数. 除此之外, 我们在创建一个 interval 的时候也应该用 interval 这个构造函数. python def mul_interval(x, y): \"\"\"Return the interval that contains the product of any value in x and any value in y.\"\"\" p1 = lower_bound(x) * lower_bound(y) p2 = lower_bound(x) * upper_bound(y) p3 = upper_bound(x) * lower_bound(y) p4 = upper_bound(x) * upper_bound(y) return interval(min(p1, p2, p3, p4), max(p1, p2, p3, p4)) Interval Subtraction Using a similar approach as mul_interval and add_interval, define a subtraction function for intervals. If you find yourself repeating code, see if you can reuse functions that have already been implemented. 这个代码如果和 mul_interval 的几乎一模一样, 只是换了个操作符而已. 如果你跟我一样用的是 vim 作为编辑器, 那么用 选中四个 * 之后我们用 r- 就可以快速替换掉了. python def sub_interval(x, y): \"\"\"Return the interval that contains the difference between any value in x and any value in y.\"\"\" p1 = lower_bound(x) - lower_bound(y) p2 = lower_bound(x) - upper_bound(y) p3 = upper_bound(x) - lower_bound(y) p4 = upper_bound(x) - upper_bound(y) return interval(min(p1, p2, p3, p4), max(p1, p2, p3, p4)) Interval Division Alyssa implements division below by multiplying by the reciprocal of y. A systems programmer looks over Alyssa’s shoulder and comments that it is not clear what it means to divide by an interval that spans zero. Add an assertstatement to Alyssa’s code to ensure that no such interval is used as a divisor: 检查是否除数 \u003e 0 python def div_interval(x, y): \"\"\"Return the interval that contains the quotient of any value in x divided by any value in y. Division is implemented as the multiplication of x by the reciprocal of y.\"\"\" assert lower_bound(y) \u003e 0, \"AssertionError!\" reciprocal_y = interval(1 / upper_bound(y), 1 / lower_bound(y)) return mul_interval(x, reciprocal_y) ","date":"2022-02-20","objectID":"/zh-cn/hw04-of-cs61a-of-ucb/:4:2","series":null,"tags":["Course"],"title":"Hw04 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/hw04-of-cs61a-of-ucb/#interval-division"},{"categories":["Course"],"content":" Q10: Par Diff After considerable work, Alyssa P. Hacker delivers her finished system. Several years later, after she has forgotten all about it, she gets a frenzied call from an irate user, Lem E. Tweakit. It seems that Lem has noticed that theformula for parallel resistors can be written in two algebraically equivalent ways: text par1(r1, r2) = (r1 * r2) / (r1 + r2) or text par2(r1, r2) = 1 / (1/r1 + 1/r2) He has written the following two programs, each of which computes the parallel_resistors formula differently: python def par2(r1, r2): one = interval(1, 1) rep_r1 = div_interval(one, r1) rep_r2 = div_interval(one, r2) return div_interval(one, add_interval(rep_r1, rep_r2)) Lem points out that Alyssa’s program gives different answers for the two ways of computing. Find two intervals r1 and r2 that demonstrate the difference in behavior between par1 and par2 when passed into each of the two functions. Demonstrate that Lem is right. Investigate the behavior of the system on a variety of arithmetic expressions. Make some intervals r1 and r2, and show that par1 and par2 can give different results. 如果你想知道这个的详细解释的话, 可以看一下这个 链接 python def check_par(): \"\"\"Return two intervals that give different results for parallel resistors. \u003e\u003e\u003e r1, r2 = check_par() \u003e\u003e\u003e x = par1(r1, r2) \u003e\u003e\u003e y = par2(r1, r2) \u003e\u003e\u003e lower_bound(x) != lower_bound(y) or upper_bound(x) != upper_bound(y) True \"\"\" r1 = interval(5, 7) r2 = interval(5, 7) return r1, r2 ","date":"2022-02-20","objectID":"/zh-cn/hw04-of-cs61a-of-ucb/:4:3","series":null,"tags":["Course"],"title":"Hw04 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/hw04-of-cs61a-of-ucb/#q10-par-diff"},{"categories":["Course"],"content":"the simple solutions for lab05 of CS61A of UCB","date":"2022-02-19","objectID":"/zh-cn/lab05-cs61a-of-ucb/","series":null,"tags":["Course"],"title":"Lab05 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab05-cs61a-of-ucb/"},{"categories":["Course"],"content":" Lists ","date":"2022-02-19","objectID":"/zh-cn/lab05-cs61a-of-ucb/:1:0","series":null,"tags":["Course"],"title":"Lab05 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab05-cs61a-of-ucb/#lists"},{"categories":["Course"],"content":" Q1: Factors List Write factors_list, which takes a number n and returns a list of its factors in ascending order. 我们可以知道这么一个基本的数学事实: 一个数字的因子最大仅可能为它的一半(当这个数字是偶数的时候). 所以我们的 for 循环只要遍历到 n // 2 + 1 即可 python def factors_list(n): \"\"\"Return a list containing all the numbers that divide `n` evenly, except for the number itself. Make sure the list is in ascending order. \u003e\u003e\u003e factors_list(6) [1, 2, 3] \u003e\u003e\u003e factors_list(8) [1, 2, 4] \u003e\u003e\u003e factors_list(28) [1, 2, 4, 7, 14] \"\"\" all_factors = [] # the biggest number which can divide `n` evenly will be `n // 2` for i in range(1, n // 2 + 1): if n % i == 0: all_factors.append(i) return all_factors ","date":"2022-02-19","objectID":"/zh-cn/lab05-cs61a-of-ucb/:1:1","series":null,"tags":["Course"],"title":"Lab05 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab05-cs61a-of-ucb/#q1-factors-list"},{"categories":["Course"],"content":" Q2: Flatten Write a function flatten that takes a list and “flattens” it. The list could be a deep list, meaning that there could be a multiple layers of nesting within the list. For example, one use case of flatten could be the following: text \u003e\u003e\u003e lst = [1, [[2], 3], 4, [5, 6]] \u003e\u003e\u003e flatten(lst) [1, 2, 3, 4, 5, 6] Make sure your solution does not mutate the input list. 显然这个问题天然复合递归求解的性质, 对于嵌套的 list, 我们需要递归分解它. 那么这又回到了怎么处理递归分解的问题: 什么是 base case ? 如果是空的 list 就返回 [] 怎么递归分解为更简单的子问题 ? 也就是我们要如何缩小问题的规模, 我们可以每次尝试处理嵌套 list 的第一个位置的元素, 根据它们是不是 list 可以分解出两种情况. 最后我们可以写出如下的代码: python def flatten(s): \"\"\"Returns a flattened version of list s. \u003e\u003e\u003e flatten([1, 2, 3]) # normal list [1, 2, 3] \u003e\u003e\u003e x = [1, [2, 3], 4] # deep list \u003e\u003e\u003e flatten(x) [1, 2, 3, 4] \u003e\u003e\u003e x # Ensure x is not mutated [1, [2, 3], 4] \u003e\u003e\u003e x = [[1, [1, 1]], 1, [1, 1]] # deep list \u003e\u003e\u003e flatten(x) [1, 1, 1, 1, 1, 1] \u003e\u003e\u003e x [[1, [1, 1]], 1, [1, 1]] \"\"\" if s == []: return [] elif type(s[0]) == list: return flatten(s[0]) + flatten(s[1:]) else: return s[:1] + flatten(s[1:]) ","date":"2022-02-19","objectID":"/zh-cn/lab05-cs61a-of-ucb/:1:2","series":null,"tags":["Course"],"title":"Lab05 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab05-cs61a-of-ucb/#q2-flatten"},{"categories":["Course"],"content":" Data Abstraction ","date":"2022-02-19","objectID":"/zh-cn/lab05-cs61a-of-ucb/:2:0","series":null,"tags":["Course"],"title":"Lab05 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab05-cs61a-of-ucb/#data-abstraction"},{"categories":["Course"],"content":" Q3: Distance We will now implement the function distance, which computes the distance between two city objects. Recall that the distance between two coordinate pairs (x1, y1) and (x2, y2) can be found by calculating the sqrt of (x1 - x2)**2 + (y1 - y2)**2. We have already imported sqrt for your convenience. Use the latitude and longitude of a city as its coordinates; you’ll need to use the selectors to access this info! 我们只要分别对传进来的参数调用 get_lat 和 get_lon 得到值然后计算即可 python def distance(city_a, city_b): \"\"\" \u003e\u003e\u003e city_a = make_city('city_a', 0, 1) \u003e\u003e\u003e city_b = make_city('city_b', 0, 2) \u003e\u003e\u003e distance(city_a, city_b) 1.0 \u003e\u003e\u003e city_c = make_city('city_c', 6.5, 12) \u003e\u003e\u003e city_d = make_city('city_d', 2.5, 15) \u003e\u003e\u003e distance(city_c, city_d) 5.0 \"\"\" x = (get_lat(city_a) - get_lat(city_b)) ** 2 y = (get_lon(city_a) - get_lon(city_b)) ** 2 return sqrt(x + y) ","date":"2022-02-19","objectID":"/zh-cn/lab05-cs61a-of-ucb/:2:1","series":null,"tags":["Course"],"title":"Lab05 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab05-cs61a-of-ucb/#q3-distance"},{"categories":["Course"],"content":" Q4: Closer city Next, implement closer_city, a function that takes a latitude, longitude, and two cities, and returns the name of the city that is relatively closer to the provided latitude and longitude. You may only use the selectors and constructors introduced above and the distance function you just defined for this question. Hint: How can you use your distance function to find the distance between the given location and each of the given cities? 根据提示和我们在 Q3 中的 distance 函数, 我们知道我们应该根据 lat 和 lon 建立一个虚拟的城市, 然后使用 distance 函数来计算距离. 这样才不用写大量重复的代码 python def closer_city(lat, lon, city_a, city_b): \"\"\" Returns the name of either city_a or city_b, whichever is closest to coordinate (lat, lon). If the two cities are the same distance away from the coordinate, consider city_b to be the closer city. \u003e\u003e\u003e berkeley = make_city('Berkeley', 37.87, 112.26) \u003e\u003e\u003e stanford = make_city('Stanford', 34.05, 118.25) \u003e\u003e\u003e closer_city(38.33, 121.44, berkeley, stanford) 'Stanford' \u003e\u003e\u003e bucharest = make_city('Bucharest', 44.43, 26.10) \u003e\u003e\u003e vienna = make_city('Vienna', 48.20, 16.37) \u003e\u003e\u003e closer_city(41.29, 174.78, bucharest, vienna) 'Bucharest' \"\"\" tmp = make_city('tmp', lat, lon) if distance(tmp, city_a) \u003c distance(tmp, city_b): return get_name(city_a) else: return get_name(city_b) ","date":"2022-02-19","objectID":"/zh-cn/lab05-cs61a-of-ucb/:2:2","series":null,"tags":["Course"],"title":"Lab05 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab05-cs61a-of-ucb/#q4-closer-city"},{"categories":["Course"],"content":" Trees ","date":"2022-02-19","objectID":"/zh-cn/lab05-cs61a-of-ucb/:3:0","series":null,"tags":["Course"],"title":"Lab05 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab05-cs61a-of-ucb/#trees"},{"categories":["Course"],"content":" Q6: Finding Berries! The squirrels on campus need your help! There are a lot of trees on campus and the squirrels would like to know which ones contain berries. Define the function berry_finder, which takes in a tree and returns True if the tree contains a node with the value 'berry' and False otherwise. Hint: To iterate through each of the branches of a particular tree, you can consider using a for loop to get each branch. 这是一道很经典的树的递归题目. 我们要在所有的节点中找到 label 为 berry 的点, 用递归的思路如下: 什么是 base case ? 显然为叶子结点的时候是 base case, 这个时候我们看它的 label 是不是 怎么分解为更简单的子问题 ? 容易想到, 我们只要有任何一个分支的某个节点存在 berry 即可, 或者说我们当前分支的 label 为 berry. python def berry_finder(t): \"\"\"Returns True if t contains a node with the value 'berry' and False otherwise. \u003e\u003e\u003e scrat = tree('berry') \u003e\u003e\u003e berry_finder(scrat) True \u003e\u003e\u003e sproul = tree('roots', [tree('branch1', [tree('leaf'), tree('berry')]), tree('branch2')]) \u003e\u003e\u003e berry_finder(sproul) True \u003e\u003e\u003e numbers = tree(1, [tree(2), tree(3, [tree(4), tree(5)]), tree(6, [tree(7)])]) \u003e\u003e\u003e berry_finder(numbers) False \u003e\u003e\u003e t = tree(1, [tree('berry',[tree('not berry')])]) \u003e\u003e\u003e berry_finder(t) True \"\"\" if is_leaf(t): return label(t) == 'berry' return any([berry_finder(b) for b in branches(t)]) or label(t) == 'berry' ","date":"2022-02-19","objectID":"/zh-cn/lab05-cs61a-of-ucb/:3:1","series":null,"tags":["Course"],"title":"Lab05 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab05-cs61a-of-ucb/#q6-finding-berries"},{"categories":["Course"],"content":" Q7: Sprout leaves Define a function sprout_leaves that takes in a tree, t, and a list of leaves, leaves. It produces a new tree that is identical to t, but where each old leaf node has new branches, one for each leaf in leaves. For example, say we have the tree t = tree(1, [tree(2), tree(3, [tree(4)])]): text 1 / \\ 2 3 | 4 If we call sprout_leaves(t, [5, 6]), the result is the following tree: text 1 / \\ 2 3 / \\ | 5 6 4 / \\ 5 6 这同样是要用递归解决的题目, 显然 base case 就是叶子结点, 当我们遇到叶子结点的时候要把 leaves 添加上去. 如果是分支, 那么我们就要检查它的每一个子树. python def sprout_leaves(t, leaves): \"\"\"Sprout new leaves containing the data in leaves at each leaf in the original tree t and return the resulting tree. \u003e\u003e\u003e t1 = tree(1, [tree(2), tree(3)]) \u003e\u003e\u003e print_tree(t1) 1 2 3 \u003e\u003e\u003e new1 = sprout_leaves(t1, [4, 5]) \u003e\u003e\u003e print_tree(new1) 1 2 4 5 3 4 5 \u003e\u003e\u003e t2 = tree(1, [tree(2, [tree(3)])]) \u003e\u003e\u003e print_tree(t2) 1 2 3 \u003e\u003e\u003e new2 = sprout_leaves(t2, [6, 1, 2]) \u003e\u003e\u003e print_tree(new2) 1 2 3 6 1 2 \"\"\" if is_leaf(t): return tree(label(t), [tree(leaf) for leaf in leaves]) return tree(label(t), [sprout_leaves(b, leaves) for b in branches(t)]) ","date":"2022-02-19","objectID":"/zh-cn/lab05-cs61a-of-ucb/:3:2","series":null,"tags":["Course"],"title":"Lab05 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab05-cs61a-of-ucb/#q7-sprout-leaves"},{"categories":["Course"],"content":"the simple solutions for lab04 of CS61A of UCB","date":"2022-02-03","objectID":"/zh-cn/lab04-cs61a-of-ucb/","series":null,"tags":["Course"],"title":"Lab04 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab04-cs61a-of-ucb/"},{"categories":["Course"],"content":" Intro 我发现解决递归的问题真的很有意思, 我喜欢这种解决问题的方式, 代码足够简洁而且做出来很直观, 这也是我写下这篇文章的原因. 📒 如何解决好递归的问题 ? 想清楚什么是 base case ? 怎么把当前的问题分解为更简单的问题 ? 时刻要记住我们定义的函数的定义 后面我也会按照这个思路来解决这个 lab 中的递归问题 ","date":"2022-02-03","objectID":"/zh-cn/lab04-cs61a-of-ucb/:1:0","series":null,"tags":["Course"],"title":"Lab04 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab04-cs61a-of-ucb/#intro"},{"categories":["Course"],"content":" Recursion ","date":"2022-02-03","objectID":"/zh-cn/lab04-cs61a-of-ucb/:2:0","series":null,"tags":["Course"],"title":"Lab04 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab04-cs61a-of-ucb/#recursion"},{"categories":["Course"],"content":" Q2: Summation Write a recursive implementation of summation, which takes a positive integer n and a function term. It applies term to every number from 1 to n including n and returns the sum. Important: Use recursion; the tests will fail if you use any loops (for, while). 什么是这一题的 base case ? 这个很容易想到, 因为我们要处理从 1 到 n, 显然当 n = 1 的时候就是我们的 base case, 此时返回 term(n) 怎么把当前的问题分解为更简单的问题 ? 因为是从 1 到 n, 我们每次让 n - 1 来缩小问题的规模, 就会一直到达 base case python def summation(n, term): \"\"\"Return the sum of numbers 1 through n (including n) wíth term applied to each number. Implement using recursion! \u003e\u003e\u003e summation(5, lambda x: x * x * x) # 1^3 + 2^3 + 3^3 + 4^3 + 5^3 225 \u003e\u003e\u003e summation(9, lambda x: x + 1) # 2 + 3 + 4 + 5 + 6 + 7 + 8 + 9 + 10 54 \u003e\u003e\u003e summation(5, lambda x: 2**x) # 2^1 + 2^2 + 2^3 + 2^4 + 2^5 62 \u003e\u003e\u003e # Do not use while/for loops! \u003e\u003e\u003e from construct_check import check \u003e\u003e\u003e # ban iteration \u003e\u003e\u003e check(HW_SOURCE_FILE, 'summation', ... ['While', 'For']) True \"\"\" assert n \u003e= 1 # base case: n = 1 if n == 1: return term(n) else: return term(n) + summation(n - 1, term) ","date":"2022-02-03","objectID":"/zh-cn/lab04-cs61a-of-ucb/:2:1","series":null,"tags":["Course"],"title":"Lab04 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab04-cs61a-of-ucb/#q2-summation"},{"categories":["Course"],"content":" Tree Recursion ","date":"2022-02-03","objectID":"/zh-cn/lab04-cs61a-of-ucb/:3:0","series":null,"tags":["Course"],"title":"Lab04 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab04-cs61a-of-ucb/#tree-recursion"},{"categories":["Course"],"content":" Q3: Pascal’s Triangle Here’s a part of the Pascal’s trangle: text 1 1 1 1 2 1 1 3 3 1 1 4 6 4 1 Every number in Pascal’s triangle is defined as the sum of the item above it and the item above and to the left of it. Use 0 if the item does not exist. Define the procedure pascal(row, column) which takes a row and a column, and finds the value of the item at that position in Pascal’s triangle. Rows and columns are zero-indexed; that is, the first row is row 0 instead of 1 and the first column is column 0 instead of column 1. For example, the item at row 2, column 1 in Pascal’s triangle is 2. 这个问题是很经典的帕斯卡三角形问题了, 根据定义我们可以知道在 Pascal(i, j) 这个位置, 要得到它的值我们可以用 Pascal(i - 1, j) + Pascal(i - 1, j - 1) 来计算, 显然这个定义式天然给出了递归分解子问题的方式. 那么我们剩下要解决的就是「什么是 base case ?」, 显然只要是在第一列(j = 0)或者说行号和列号(i == j)相等, 那么就是 1. 再看看上面的帕斯卡三角形示例, 你会发现这两个 base case + 递归分解子问题的方式我们就可以计算出所有的情况. 注意我们还要考虑到索引非法的情况(j \u003e i) python def pascal(row, column): \"\"\"returns the value of the item in pascal's triangle whose position is specified by row and column. \u003e\u003e\u003e pascal(0, 0) 1 \u003e\u003e\u003e pascal(0, 5) # empty entry; outside of pascal's triangle 0 \u003e\u003e\u003e pascal(3, 2) # row 3 (1 3 3 1), column 2 3 \u003e\u003e\u003e pascal(4, 2) # row 4 (1 4 6 4 1), column 2 6 \"\"\" # in pascal's triangle, \\ # pascal(i, j) = pascal(i - 1, j - 1) + pascal(i - 1, j) # base case 1. empty entry if column \u003e row: return 0 # base case 2. pascal(i, 0) if column == 0: return 1 # base case 3. pascal(i, i) elif row == column: return 1 return pascal(row - 1, column) + pascal(row - 1, column - 1) ","date":"2022-02-03","objectID":"/zh-cn/lab04-cs61a-of-ucb/:3:1","series":null,"tags":["Course"],"title":"Lab04 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab04-cs61a-of-ucb/#q3-pascals-triangle"},{"categories":["Course"],"content":" Q4: Insect Combinatorics Consider an insect in an M by N grid. The insect starts at the bottom left corner, (0, 0), and wants to end up at the top right corner, (M-1, N-1). The insect is only capable of moving right or up. Write a function paths that takes a grid length and width and returns the number of different paths the insect can take from the start to the goal. (There is a closed-form solution to this problem, but try to answer it procedurally using recursion.) For example, the 2 by 2 grid has a total of two ways for the insect to move from the start to the goal. For the 3 by 3 grid, the insect has 6 diferent paths (only 3 are shown above). Hint: What happens if we hit the top or rightmost edge? 从题目中我们可以知道我们只能向上走或者向右走, 也就是说假设我们处在 path(i, j) 这个位置, 那么我们只可能是从左边或者是从下边来的, 那么走到 path(i, j) 有几种走法呢 ? 显然, 它等于 path(i, j - 1) + path(i - 1, j). (这里左下角才是 (0, 0)). 那么我们剩下要解决的就是「什么是 base case ?」, 也就是一直往上走和一直往右走这两种, 都只有 1 中走法. 如下面这个表格所示: 1 1 1 1 1 再根据上面的公式可以知道, 完整的应该是这样: 1 3 6 1 2 3 1 1 1 这里为了处理问题方便, 我们让索引从 1 开始 ","date":"2022-02-03","objectID":"/zh-cn/lab04-cs61a-of-ucb/:3:2","series":null,"tags":["Course"],"title":"Lab04 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab04-cs61a-of-ucb/#q4-insect-combinatorics"},{"categories":["Course"],"content":" List Comprehensions ","date":"2022-02-03","objectID":"/zh-cn/lab04-cs61a-of-ucb/:4:0","series":null,"tags":["Course"],"title":"Lab04 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab04-cs61a-of-ucb/#list-comprehensions"},{"categories":["Course"],"content":" Q5: Couple Implement the function couple, which takes in two lists and returns a list that contains lists with i-th elements of two sequences coupled together. You can assume the lengths of two sequences are the same. Try using a list comprehension. Hint: You may find the built in range function helpful. 这个问题简单, 因为两个是等长的 list, 所以我们只要用同一个索引从两个 list 中取数即可 python def couple(s, t): \"\"\"Return a list of two-element lists in which the i-th element is [s[i], t[i]]. \u003e\u003e\u003e a = [1, 2, 3] \u003e\u003e\u003e b = [4, 5, 6] \u003e\u003e\u003e couple(a, b) [[1, 4], [2, 5], [3, 6]] \u003e\u003e\u003e c = ['c', 6] \u003e\u003e\u003e d = ['s', '1'] \u003e\u003e\u003e couple(c, d) [['c', 's'], [6, '1']] \"\"\" assert len(s) == len(t) return [[s[i], t[i]] for i in range(len(s))] ","date":"2022-02-03","objectID":"/zh-cn/lab04-cs61a-of-ucb/:4:1","series":null,"tags":["Course"],"title":"Lab04 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab04-cs61a-of-ucb/#q5-couple"},{"categories":["Course"],"content":" Q6: Coordinates Implement a function coords that takes a function fn, a sequence seq, and a lower and upper bound on the output of the function. coords then returns a list of coordinate pairs (lists) such that: Each (x, y) pair is represented as [x, fn(x)] The x-coordinates are elements in the sequence The result contains only pairs whose y-coordinate is within the upper and lower bounds (inclusive) See the doctest for examples. Note: your answer can only be one line long. You should make use of list comprehensions! 这个其实也容易, 就是多了一个 if 语句来过滤掉不符合条件的结果而已 python def coords(fn, seq, lower, upper): \"\"\" \u003e\u003e\u003e seq = [-4, -2, 0, 1, 3] \u003e\u003e\u003e fn = lambda x: x**2 \u003e\u003e\u003e coords(fn, seq, 1, 9) [[-2, 4], [1, 1], [3, 9]] \"\"\" \"*** YOUR CODE HERE ***\" return [[i, fn(i)] for i in seq if lower \u003c= fn(i) \u003c= upper] ","date":"2022-02-03","objectID":"/zh-cn/lab04-cs61a-of-ucb/:4:2","series":null,"tags":["Course"],"title":"Lab04 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab04-cs61a-of-ucb/#q6-coordinates"},{"categories":["Course"],"content":" Q7: Riffle Shuffle A common way of shuffling cards is known as the riffle shuffle. The shuffle produces a new configuration of cards in which the top card is followed by the middle card, then by the second card, then the card after the middle, and so forth. Write a list comprehension that riffle shuffles a sequence of items. You can assume the sequence contains an even number of items. Hint: There are two ways you can write this as a single list comprension: 1) You may find the expression k%2, which evaluates to 0 on even numbers and 1 on odd numbers, to be alternatively access the beginning and middle of the deck. 2) You can utilize an if expression in your comprehension for the odd and even numbers respectively. 这一个问题会稍微难一点, 我们其实是要想办法得到正确的索引, 显然索引为奇数和偶数的时候情况并不相同. 我们可以看如下的表格找一下规律⬇️: Origin index 0 1 2 3 Real index for deck[…] 0 2 1 3 Guess ? (M = 2) 0 M 2 // 2 ? M + 1 = M + 3 // 2 ? 奇数: 0, 1, 2, … 偶数: M+0, M+1, M+2, … 通过上面的观察我们就可以写出如下的代码⬇️: python def riffle(deck): \"\"\"Produces a single, perfect riffle shuffle of DECK, consisting of DECK[0], DECK[M], DECK[1], DECK[M+1], ... where M is position of the second half of the deck. Assume that len(DECK) is even. \u003e\u003e\u003e riffle([3, 4, 5, 6]) [3, 5, 4, 6] \u003e\u003e\u003e riffle(range(20)) [0, 10, 1, 11, 2, 12, 3, 13, 4, 14, 5, 15, 6, 16, 7, 17, 8, 18, 9, 19] \"\"\" return [deck[i // 2 + (i % 2) * (len(deck) // 2)] for i in range(len(deck))] ","date":"2022-02-03","objectID":"/zh-cn/lab04-cs61a-of-ucb/:4:3","series":null,"tags":["Course"],"title":"Lab04 题解 (UCB CS61A@2021 Fall)","uri":"/zh-cn/lab04-cs61a-of-ucb/#q7-riffle-shuffle"},{"categories":["Tool"],"content":"Explain how to use hammerspoon to manage windows","date":"2022-01-21","objectID":"/zh-cn/how-to-manage-windows-using-hammerspoon/","series":null,"tags":["Tool"],"title":"How to Manage Windows Using Hammerspoon","uri":"/zh-cn/how-to-manage-windows-using-hammerspoon/"},{"categories":["Tool"],"content":" 引言 虽然 macOS 自带窗口管理这个功能, 但是实际上是用下来发现还是很难受的. 功能不足以满足自己的需求. 所以我常常发现自己在用鼠标拖动窗口和重新调整窗口大小. 长此以往, 我觉得这样效率实在太低, 恰好前阵子在看 MIT-Missing-Semester 的课, 里面提到了 hammerspoon 这个工具. 我去稍微了解了一下发现这工具真的不错. ","date":"2022-01-21","objectID":"/zh-cn/how-to-manage-windows-using-hammerspoon/:1:0","series":null,"tags":["Tool"],"title":"How to Manage Windows Using Hammerspoon","uri":"/zh-cn/how-to-manage-windows-using-hammerspoon/#引言"},{"categories":["Tool"],"content":" 什么是 hammerspoon ? 根据官方文档介绍, hammerspoon 是 macOS 上一个用于自动化的工具, 充当了 Lua 语言和操作系统的系统调用之间的桥梁. 也就是说我们可以使用 Lua 语言和 hammerspoon 提供的 API 来来完成很多自动化操作. 目前我还只看了窗口管理相关的. 因为要用到 Lua 语言, 但是我又根本没有接触过这个语言, 所以我大概跟着 Learn Lua in Y minutes 稍微学习了一下. ","date":"2022-01-21","objectID":"/zh-cn/how-to-manage-windows-using-hammerspoon/:2:0","series":null,"tags":["Tool"],"title":"How to Manage Windows Using Hammerspoon","uri":"/zh-cn/how-to-manage-windows-using-hammerspoon/#什么是-hammerspoon-"},{"categories":["Tool"],"content":" 怎么管理窗口? 我主要想要有下面的几个功能 可以把窗口移动到屏幕的左边或者是右边(1 / 2 屏幕) 可以把窗口弄成全屏的 可以把窗口移动到左上角/右上角/左下角/右下角(1 / 4 屏幕) 把当前的窗口移动到屏幕中央 我的方案主要是写了三个 *.lua file(我放在了我的 github 仓库 dotfiles 里) 👉config.lua lua MACBOOK_MONITOR = 'Built-in Retina Display' -- disable animations, default value = 0.2 hs.window.animationDuration = 0 👉init.lua lua require('config') require('window') 👉window.lua 这个是主要的代码 lua -- half of screen -- {frame.x, frame.y, window.w, window.h} -- First two elements: we decide the position of frame -- Last two elements: we decide the size of frame hs.hotkey.bind({'alt', 'cmd'}, 'left', function() hs.window.focusedWindow():moveToUnit({0, 0, 0.5, 1}) end) hs.hotkey.bind({'alt', 'cmd'}, 'right', function() hs.window.focusedWindow():moveToUnit({0.5, 0, 0.5, 1}) end) hs.hotkey.bind({'alt', 'cmd'}, 'up', function() hs.window.focusedWindow():moveToUnit({0, 0, 1, 0.5}) end) hs.hotkey.bind({'alt', 'cmd'}, 'down', function() hs.window.focusedWindow():moveToUnit({0, 0.5, 1, 0.5}) end) -- quarter of screen --[[ u i j k --]] hs.hotkey.bind({'ctrl', 'alt', 'cmd'}, 'u', function() hs.window.focusedWindow():moveToUnit({0, 0, 0.5, 0.5}) end) hs.hotkey.bind({'ctrl', 'alt', 'cmd'}, 'k', function() hs.window.focusedWindow():moveToUnit({0.5, 0.5, 0.5, 0.5}) end) hs.hotkey.bind({'ctrl', 'alt', 'cmd'}, 'i', function() hs.window.focusedWindow():moveToUnit({0.5, 0, 0.5, 0.5}) end) hs.hotkey.bind({'ctrl', 'alt', 'cmd'}, 'j', function() hs.window.focusedWindow():moveToUnit({0, 0.5, 0.5, 0.5}) end) -- full screen hs.hotkey.bind({'alt', 'cmd'}, 'f', function() hs.window.focusedWindow():moveToUnit({0, 0, 1, 1}) end) -- center screen hs.hotkey.bind({'alt', 'cmd'}, 'c', function() hs.window.focusedWindow():centerOnScreen() end) 你应该把上面三个文件放在 ~/.hammerspoon/ 这个路径下然后在 hammerspoon 里面点击 Reload config 就可以正常使用了🤗 ","date":"2022-01-21","objectID":"/zh-cn/how-to-manage-windows-using-hammerspoon/:3:0","series":null,"tags":["Tool"],"title":"How to Manage Windows Using Hammerspoon","uri":"/zh-cn/how-to-manage-windows-using-hammerspoon/#怎么管理窗口"},{"categories":["Tool"],"content":" 代码解释 hs.hotkey.bind(mods, key, pressedfn) 这个主要是把按键 mods 和 key 绑定到 pressedfn 这个函数上. 在使用的时候先按下 mods 对应的按键组合并保持, 然后再按下 key 对应的按键. 比如我们要让窗口全屏, 我们首先按下并保持 alt(option) 和 cmd, 再按下 f. 就可以让窗口全屏了 pressedfn 这个就是用 Lua 语言写的一个函数 函数的关键在于 hs.window.focusedWindow():moveToUnit({...}) 这个方法. 他的主要功能是获得当前被激活的窗口然后做一些位置和大小上的修改. 参数是 Lua 语言里的 table, 我已经把参数的具体含义写在了注释里, 可以结合下面我画的图来进行理解. ","date":"2022-01-21","objectID":"/zh-cn/how-to-manage-windows-using-hammerspoon/:4:0","series":null,"tags":["Tool"],"title":"How to Manage Windows Using Hammerspoon","uri":"/zh-cn/how-to-manage-windows-using-hammerspoon/#代码解释"},{"categories":["Tool"],"content":" 参考 Anish’s Hammerspoon config ","date":"2022-01-21","objectID":"/zh-cn/how-to-manage-windows-using-hammerspoon/:5:0","series":null,"tags":["Tool"],"title":"How to Manage Windows Using Hammerspoon","uri":"/zh-cn/how-to-manage-windows-using-hammerspoon/#参考"},{"categories":["macOS"],"content":"简单介绍怎么用 homebrew 安装本地安装包","date":"2022-01-04","objectID":"/zh-cn/how-to-use-local-file-in-homebrew/","series":null,"tags":["macOS","Homebrew"],"title":"怎么在 homebrew 里面安装本地安装包","uri":"/zh-cn/how-to-use-local-file-in-homebrew/"},{"categories":["macOS"],"content":" 引言 最近想要在 homebrew 上面下载 qbittorent, 发现我即使用的是中科大的源也下载不下来, 终端显示如下内容⬇️ bash ==\u003e Downloading https://downloads.sourceforge.net/qbittorrent/qbittorrent-mac/qbittorrent-4.3.9/qbittorrent-4.3.9.dmg curl: (35) error:06FFF089:digital envelope routines:CRYPTO_internal:bad key length=# # # Error: Download failed on Cask 'qbittorrent' with message: Download failed: https://downloads.sourceforge.net/qbittorrent/qbittorrent-mac/qbittorrent-4.3.9/qbittorrent-4.3.9.dmg 此时我就想到要不干脆把这个文件下载下来, 然后用 homebrew 本地安装(应该是有这个功能的), 做了一番检索之后, 终于知道要怎么弄了, 下面我将以 qbittorrent-4.3.9.dmg 为例 ","date":"2022-01-04","objectID":"/zh-cn/how-to-use-local-file-in-homebrew/:1:0","series":null,"tags":["macOS","Homebrew"],"title":"怎么在 homebrew 里面安装本地安装包","uri":"/zh-cn/how-to-use-local-file-in-homebrew/#引言"},{"categories":["macOS"],"content":" Step 1. 获取路径文件名 可以先运行 brew --cache 查看 homebrew 的缓存路径, 一般来说应该是在 ~/Library/Caches/Homebrew 下. homebrew 会把安装包下载到里面的 downloads 文件夹里面, 也就是在 ~/Library/Caches/Homebrew/downloads 下, 进入这个文件夹可以发现里面的文件名的格式都是 \u003curl-hash\u003e--\u003cformula\u003e-\u003cversion\u003e, 显然, 我们也要把我们的安装包弄成这种格式放在里面. 📒 使用 brew --cache -s \u003cformula\u003e 来获取对应的路径文件名 对应我们这篇文章的例子就是 brew --cache -s qbittorrent, 可以看到输出内容是 /Users/\u003c对应你的用户名\u003e/Library/Caches/Homebrew/downloads/7ee479ba2a19cf904e4c415805a6adaead76e7c191d595c016c86b72044c22fa--qbittorrent-4.3.9.dmg ","date":"2022-01-04","objectID":"/zh-cn/how-to-use-local-file-in-homebrew/:2:0","series":null,"tags":["macOS","Homebrew"],"title":"怎么在 homebrew 里面安装本地安装包","uri":"/zh-cn/how-to-use-local-file-in-homebrew/#step-1-获取路径文件名"},{"categories":["macOS"],"content":" Step 2. 移动本地安装包到对应的目录下 在 Step 1. 中我们已经可以知道该把文件放到什么地方, 接下来要做的无非就是移动文件可以, 如果打开文件浏览器移动那就慢了, 直接在命令行输入对应命令即可 📒 使用 mv \u003clocal-file\u003e \"$(brew --cache -s \u003cformula\u003e)\" 移动本地安装包到对应目录下 对应我们的例子就是 mv qbittorrent-4.3.9.dmg \"$(brew --cache -s qbittorrent)\" ","date":"2022-01-04","objectID":"/zh-cn/how-to-use-local-file-in-homebrew/:3:0","series":null,"tags":["macOS","Homebrew"],"title":"怎么在 homebrew 里面安装本地安装包","uri":"/zh-cn/how-to-use-local-file-in-homebrew/#step-2-移动本地安装包到对应的目录下"},{"categories":["macOS"],"content":" Step 3. 再次运行 brew install 此时再次运行 brew install qbittorrent 即可, 可以看到命令行找到了缓存文件🤗, 而且安装成功了 📒 再次运行 brew install \u003cformula\u003e bash ==\u003e Downloading https://downloads.sourceforge.net/qbittorrent/qbittorrent-mac/qbittorrent-4.3.9/qbittorrent-4.3.9.dmg Already downloaded: /Users/\u003c对应你的用户名\u003e/Library/Caches/Homebrew/downloads/7ee479ba2a19cf904e4c415805a6adaead76e7c191d595c016c86b72044c22fa--qbittorrent-4.3.9.dmg ==\u003e Installing Cask qbittorrent ==\u003e Moving App 'qbittorrent.app' to '/Applications/qBittorrent.app' 🍺 qbittorrent was successfully installed! ","date":"2022-01-04","objectID":"/zh-cn/how-to-use-local-file-in-homebrew/:4:0","series":null,"tags":["macOS","Homebrew"],"title":"怎么在 homebrew 里面安装本地安装包","uri":"/zh-cn/how-to-use-local-file-in-homebrew/#step-3-再次运行-brew-install"},{"categories":["macOS"],"content":" 参考 homebrew 文档 ","date":"2022-01-04","objectID":"/zh-cn/how-to-use-local-file-in-homebrew/:5:0","series":null,"tags":["macOS","Homebrew"],"title":"怎么在 homebrew 里面安装本地安装包","uri":"/zh-cn/how-to-use-local-file-in-homebrew/#参考"},{"categories":["Python"],"content":"简单介绍了用 ipdb 对 Python 文件进行 debug","date":"2021-12-28","objectID":"/zh-cn/how-to-debug-in-python/","series":null,"tags":["Python"],"title":"怎么 debug Python 代码","uri":"/zh-cn/how-to-debug-in-python/"},{"categories":["Python"],"content":" 引言 PS. 有兴趣的可以查看我翻译的一个项目 - pdb 教程 🙌 很长一段时间内我写代码都是用最简单的 debug 方法, 手动在程序里面插入 print 代码来看具体的变量的值, 然后自己推断程序到底是在哪里出问题。根据 print 的结果可能还要到别的地方重复这个步骤。debug 完之后还得去把这些 print 语句注释掉，即我是一名 print debugger 😢 最近在看 MIT.Missing semester 的课讲到 debug, 顿时感到应该系统学习一下在 Python 里面如何 debug, 虽然用 print 也凑合, 学完之后只恨自己没有早点了解😢 ","date":"2021-12-28","objectID":"/zh-cn/how-to-debug-in-python/:1:0","series":null,"tags":["Python"],"title":"怎么 debug Python 代码","uri":"/zh-cn/how-to-debug-in-python/#引言"},{"categories":["Python"],"content":" 快速上手","date":"2021-12-28","objectID":"/zh-cn/how-to-debug-in-python/:2:0","series":null,"tags":["Python"],"title":"怎么 debug Python 代码","uri":"/zh-cn/how-to-debug-in-python/#快速上手"},{"categories":["Python"],"content":" 安装虽然 Python 有自带的 pdb, 但是 ipdb 的跟它大差不差, 还带颜色输出, 当然用这个了(其实就跟你在命令行要用 python 还是 ipython 一样, 肯定是选择 UI 比较好的 bash $ pip install ipdb ","date":"2021-12-28","objectID":"/zh-cn/how-to-debug-in-python/:2:1","series":null,"tags":["Python"],"title":"怎么 debug Python 代码","uri":"/zh-cn/how-to-debug-in-python/#安装"},{"categories":["Python"],"content":" 开始 debug直接在命令行输入以下内容即可, 其中 \u003cfilename\u003e 表示你要 debug 的文件 bash $ python -m ipdb \u003cfilename\u003e ","date":"2021-12-28","objectID":"/zh-cn/how-to-debug-in-python/:2:2","series":null,"tags":["Python"],"title":"怎么 debug Python 代码","uri":"/zh-cn/how-to-debug-in-python/#开始-debug"},{"categories":["Python"],"content":" ipdb 📒 [ ] 表示是可选参数, 如果没有 [ ] 表示一定要给这个参数 📒 ( ) 表示括号里面的可以不写, 简写命令 ","date":"2021-12-28","objectID":"/zh-cn/how-to-debug-in-python/:3:0","series":null,"tags":["Python"],"title":"怎么 debug Python 代码","uri":"/zh-cn/how-to-debug-in-python/#ipdb"},{"categories":["Python"],"content":" 常用 Debug 指令 l(ist) 显示当前行附近的代码, 具体来说是附近的 11 行, 但是记这个具体的数字好像也没啥意义 也可以使用 ll 命令, 会显示当前所在函数或者是堆栈帧的源代码 可以传入参数, 比如要看 1 到 12 行的内容可以用 l 1,12 s(tep) 单步执行下一步, 如果是函数调用, 会进到函数里一步步执行 n(ext) 单步执行下一步, 如果是函数调用, 不会进去函数里一步步执行, 它会一直跳到函数调用执行完成的后一行 c(ontinue) 继续执行, 直到程序发生错误或者正常退出 如果程序是正常退出的, 那么就会输出 The program finished and will be restarted q(uit) 退出 r(eturn) 继续运行到当前函数返回结果为止 w(here) 打印 Stack trace, 看调用轨迹, 从上到下分别是从最内层到最外层的调用入口 可以根据这个调用栈, 用 d(own) [count] 和 u(up) [count] 来在不同的层次间移动 ","date":"2021-12-28","objectID":"/zh-cn/how-to-debug-in-python/:3:1","series":null,"tags":["Python"],"title":"怎么 debug Python 代码","uri":"/zh-cn/how-to-debug-in-python/#常用-debug-指令"},{"categories":["Python"],"content":" 程序断点专题每次设置程序断点的时候都会输出你当前这个程序断点的序号 📒 序号默认从 1 开始, 也就是后面提到的 breakpoint [count] b(reak) [line_number] 在 line_number 这一行设置断点 不提供参数的话就是查看我们设置的所有程序断点 高级用法, 你还可以指定文件! 比如你想停在 util.py 文件的第 10 行, 你可以用 b util:10 高级用法, 你在指定文件的同时, 可以指定函数, 还是刚才那个例子, 比如 util.py 文件里面有个 get_result 函数, 你可以用 b util.get_result 高级用法: 你还可以指定满足某些条件才会设置程序断点, 用法如下: b ..., condition tbreak [line_number] 暂时的程序断点, 第一次命中之后就会自己取消 disable [breakpoint count] 暂时不用这个程序断点, 和 clear 不同, 你后面可以通过 enable 重新激活这个程序断点 enable [breakpoint count] 激活程序断点 cl(ear) [breakpoint count | line_number] 通过程序断点的序号或者是对应的行来清除程序断点 unt(il) [line_number] 运行大于等于 line_number 的地方 当然你也可以不提供参数, 此时 unt(il) 命令会继续运行程序到行数比当前行大的那一行(有点绕口, 但意思其实就是下一行🧐), 此时它的功能类似于 n(ext) unt(il) 命令默认会停在当前函数(或者是堆栈帧) return 的地方, 而 c(ontinue) 会一直运行到下去 restart [args...] - 可以给定不同的参数再次重新运行 debug ","date":"2021-12-28","objectID":"/zh-cn/how-to-debug-in-python/:3:2","series":null,"tags":["Python"],"title":"怎么 debug Python 代码","uri":"/zh-cn/how-to-debug-in-python/#程序断点专题"},{"categories":["Python"],"content":" 查看各种信息 h(elp) [command] 不知道命令可以查询一下 p expression 相当于 print expression, 也可以使用 pp(对应 pprint) 一个比较特殊的 expression 是 locals(), 可以查看当前所在位置的 context 要深刻理解这里是 expression 的好处, 如果本来的 expression 不对, 其实你可以直接在这里想要怎么改, 然后直接进行测试 a(rgs) - 打印当前所有的变量的值 whatis expression 相当于 type(expression) source expression 查看 expression 的源码。 常用的 expression 是函数名 ","date":"2021-12-28","objectID":"/zh-cn/how-to-debug-in-python/:3:3","series":null,"tags":["Python"],"title":"怎么 debug Python 代码","uri":"/zh-cn/how-to-debug-in-python/#查看各种信息"},{"categories":["Python"],"content":" 常见问题Q: 我的变量名跟命令重复了怎么办, 比如变量名是 p ? A: 这个其实不影响, 你还是可以通过 p p 来获取变量名的值. 如果你直接输入 p 显示 p 对应的值的话, 你可以使用 !p, 用 ! 来告诉 ipdb 在它后面的是 python 语句 Q: 每次单步执行之后都要用 p expression 的方式来看变量的值, 有没有更为简便的方法? A: 可以用 display expression, 那么在 expression 的值发生变动的时候, 它就会输出对应的值. 如果要取消就用 undisplay expression Q: 觉得命令有点少不满足自己的需要 ? A: 可以在 ipdb 里面直接写 python 的代码 🤗 Q: 不想使用 python -m ipdb \u003cfilename\u003e 想直接在代码里插入程序断点 ? A: 这也是可以的, 你可以在要插入的行之前设置, 像这样: python ... import ipdb; ipdb.set_trace(); ... 📒 如果你是用是 Python 3.7+ 的版本, 可以插入 breakpoint() 而不是 import ipdb; ipdb.set_trace();, 这样设置的好处是你可以一次性取消所有的程序断点，你就可以区分开正常运行的模式和调试程序的模式 Q: -\u003e 指向的行运行了吗 ? A: 没有 Q: 如果我一直在调用 step 命令, 难道我每一次都要输入 s 吗, 有没有更快捷的方法 ? A: 可以直接使用回车键(ENTER), 会自动重复上一次的命令 ","date":"2021-12-28","objectID":"/zh-cn/how-to-debug-in-python/:4:0","series":null,"tags":["Python"],"title":"怎么 debug Python 代码","uri":"/zh-cn/how-to-debug-in-python/#常见问题"},{"categories":["Python"],"content":" 参考 pdb 的官方文档 ","date":"2021-12-28","objectID":"/zh-cn/how-to-debug-in-python/:5:0","series":null,"tags":["Python"],"title":"怎么 debug Python 代码","uri":"/zh-cn/how-to-debug-in-python/#参考"},{"categories":["Git"],"content":"简单介绍 Git LFS 的使用方法和使用场景","date":"2021-12-06","objectID":"/zh-cn/gitlfs/","series":null,"tags":["Git"],"title":"Git LFS 使用指南","uri":"/zh-cn/gitlfs/"},{"categories":["Git"],"content":" 什么时候需要 Git LFS如果你在命令行用 git push 添加或更新 $\u003e$ 50MB 的文件，你会收到一个 warning，不过你仍然可以正常 push。但如果 $\u003e$ 100MB 的时候就无法 push 了。如果你是在浏览器要上传文件的话，这个限制更为严重，不能超过 25MB，这是 GitHub 对仓库的限制。Git LFS 就是用于解决这个问题1 ","date":"2021-12-06","objectID":"/zh-cn/gitlfs/:1:0","series":null,"tags":["Git"],"title":"Git LFS 使用指南","uri":"/zh-cn/gitlfs/#什么时候需要-git-lfs"},{"categories":["Git"],"content":" 什么时候不需要用 Git LFS下面几个场景不需要用 文件大小没有超过限制当然就没有必要用了 如果是要分发二进制文件（比如 *.exe）等，此时直接用 GitHub 提供的 release 功能就好了 ","date":"2021-12-06","objectID":"/zh-cn/gitlfs/:2:0","series":null,"tags":["Git"],"title":"Git LFS 使用指南","uri":"/zh-cn/gitlfs/#什么时候不需要用-git-lfs"},{"categories":["Git"],"content":" Git LFS 原理使用 Git LFS 之后，在仓库中存储的其实是对大文件的引用，可以理解为指针。而真正的大文件托管在 Git LFS 的服务器上。GitHub 给不同用户的提供的存储空间不一样，免费用户和 Pro 用户都是 2 GB，而如果是企业用户则会高点2 当我们用 Git LFS 追踪某个大文件（比如 foo.zip）之后，可以看到 .gitattributes 发生了改变 text foo.zip filter=lfs diff=lfs merge=lfs -text 这一行体现了很多信息 foo.zip，这是 Git LFS 正在追踪的大文件符合的模式，说是模式是因为用 Git LFS 追踪大文件的时候可以用通配符，那么这里就会是通配符的形式 filter=lfs：用 Git LFS 的方式对待被追踪的大文件 diff=lfs：用 Git LFS 的方式对待被追踪的大文件 -text，表示不会将这个大文件看成是文本文件 ","date":"2021-12-06","objectID":"/zh-cn/gitlfs/:3:0","series":null,"tags":["Git"],"title":"Git LFS 使用指南","uri":"/zh-cn/gitlfs/#git-lfs-原理"},{"categories":["Git"],"content":" 使用 Git LFS","date":"2021-12-06","objectID":"/zh-cn/gitlfs/:4:0","series":null,"tags":["Git"],"title":"Git LFS 使用指南","uri":"/zh-cn/gitlfs/#使用-git-lfs"},{"categories":["Git"],"content":" 安装 Git LFS如果用的是 Mac，那么用 Homebrew 就可以很方便安装 sh $ brew install git-lfs $ git lfs install # 如果输出为 Git LFS initialized. 就是正常安装好了 ","date":"2021-12-06","objectID":"/zh-cn/gitlfs/:4:1","series":null,"tags":["Git"],"title":"Git LFS 使用指南","uri":"/zh-cn/gitlfs/#安装-git-lfs"},{"categories":["Git"],"content":" Case 1. 从 0 开始配置使用 Git LFS我们可以通过如下的不同方式让 Git LFS 追踪一个大文件或者是一堆大文件 指定大文件后缀名——git lfs track \"*.filetype\"，即批量追踪 *.filetype 文件 指定某个目录下的所有文件——git lfs track \"directory/*\"，即批量追踪 directory 里面的文件 指定某个具体大文件——git lfs track \"path/to/file\" sh $ mkdir \u003crepo\u003e $ cd \u003crepo\u003e $ git init $ git lfs track \"*.zip\" # 比如 *.zip # git lfs track 会修改 .gitattributes 文件的内容，可以验证一下 # \u003e cat .gitattributes # *.zip filter=lfs diff=lfs merge=lfs -text 下面假定有一个远程仓库供我们使用 sh $ git add . $ git commit -m \"\u003cmsg\u003e\" $ git push -u origin main 此时命令行会显示 text uploading LFS objects ","date":"2021-12-06","objectID":"/zh-cn/gitlfs/:4:2","series":null,"tags":["Git"],"title":"Git LFS 使用指南","uri":"/zh-cn/gitlfs/#case-1-从-0-开始配置使用-git-lfs"},{"categories":["Git"],"content":" Case 2. 要追踪的大文件之前不小心加到 Git 仓库里了此时只是简单使用 git lfs track ... 追踪大文件是不够的，因为这个大文件已经存在 Git 仓库的历史记录里，这会导致 Git 仓库无法变小。正确的方法是使用 git lfs migrate，将 Git 历史的大文件变成 Git LFS 追踪的对象3 比如可以用 --include=，Git LFS 会自动根据我们指定的模式进行选择。下面的 --include=\"*.txt 的意思就是选中 Git 仓库历史的 txt 文件 技巧 可以用 man git-lfs-migrate 查看更多信息 bash $ git lfs migrate import --include=\"*.txt\" # 让远程仓库也改过来 $ git push --force ","date":"2021-12-06","objectID":"/zh-cn/gitlfs/:4:3","series":null,"tags":["Git"],"title":"Git LFS 使用指南","uri":"/zh-cn/gitlfs/#case-2-要追踪的大文件之前不小心加到-git-仓库里了"},{"categories":["Git"],"content":" Case 3. 不再跟踪某些文件 bash $ git lfs untrack \"*.filetype\" $ git rm --cached \"*.filetype\" ","date":"2021-12-06","objectID":"/zh-cn/gitlfs/:4:4","series":null,"tags":["Git"],"title":"Git LFS 使用指南","uri":"/zh-cn/gitlfs/#case-3-不再跟踪某些文件"},{"categories":["Git"],"content":" 其他常用命令 查看当前 Git LFS 正在追踪的文件类型——git lfs track 查看当前 Git LFS 正在追踪哪些文件——git lfs ls-file ","date":"2021-12-06","objectID":"/zh-cn/gitlfs/:5:0","series":null,"tags":["Git"],"title":"Git LFS 使用指南","uri":"/zh-cn/gitlfs/#其他常用命令"},{"categories":["Git"],"content":" 参考 About large files on GitHub ↩︎ About Git Large File Storage ↩︎ Migrating existing repository data to LFS ↩︎ ","date":"2021-12-06","objectID":"/zh-cn/gitlfs/:6:0","series":null,"tags":["Git"],"title":"Git LFS 使用指南","uri":"/zh-cn/gitlfs/#参考"},{"categories":["Machine-Learning"],"content":"简单介绍 Precision 和 Recall 以及 F1 score 的计算方式","date":"2021-12-05","objectID":"/zh-cn/f1score/","series":null,"tags":["Machine-Learning"],"title":"从混淆矩阵到 F1 score","uri":"/zh-cn/f1score/"},{"categories":["Machine-Learning"],"content":" 什么是混淆矩阵 每一列表示实际情况，每一行表示我们的预测，这样组合起来就得到了一个混淆矩阵，比如一个二分类的任务，可以画出如下的混淆矩阵⬇️ Positive Negative True TP = True Positive FP = False Positive False FN = False Negative TN = True Negative ","date":"2021-12-05","objectID":"/zh-cn/f1score/:1:0","series":null,"tags":["Machine-Learning"],"title":"从混淆矩阵到 F1 score","uri":"/zh-cn/f1score/#什么是混淆矩阵"},{"categories":["Machine-Learning"],"content":" accuracy 有多少样本我们预测正确了 预测正确的其实有下面两种情形⬇️ TP：本来是 positive，你也认为是 positive 的 TN：本来是 negative，你也认为是 negative 的 那么用 TP + TN（其实就是主对角线）除以总的样本数就可以得到 accuracy， 📒或者直接看表格，其实就是 $\\frac{主对角线}{四个单元格} =\\frac{TP+TN}{TP+TN+FN+FP}$ 一般来说 accuracy 是好用的评估指标，但是在某些情况下不是这样子的，比如样本数据不均衡的时候 类别 A 类别 B 判断是类别 A 0 0 判断是类别 B 1 99 假设类别 A 有 1 个，类别 B 有 99 个，如果不管输入的是什么都返回类别 B 的正确率是多少呢？ 答案是 $\\frac{0+99}{0+0+1+99}=99%$，我们可以说这个分类器效果很好吗，这显然是很荒谬的😂 ","date":"2021-12-05","objectID":"/zh-cn/f1score/:1:1","series":null,"tags":["Machine-Learning"],"title":"从混淆矩阵到 F1 score","uri":"/zh-cn/f1score/#accuracy"},{"categories":["Machine-Learning"],"content":" Precision 所有预测为 True 的样本里面，有多少是真的 positive 的 从定义出发可以知道，其实就是表格中判断为 True 的这一行中 positive 的比例，那么就是 $\\frac{TP}{TP+FP}$ ","date":"2021-12-05","objectID":"/zh-cn/f1score/:1:2","series":null,"tags":["Machine-Learning"],"title":"从混淆矩阵到 F1 score","uri":"/zh-cn/f1score/#precision"},{"categories":["Machine-Learning"],"content":" Recall 所有本来是 positive 的，有多少被我们成功预测了出来 从定义出发，所有本来是 positive 的就是 Positive 这一列之和，我们成功预测的是 TP，那么就是 $\\frac{TP}{TP+FN}$ 📒我们常常要在 Precision 和 Recall 中进行 tradeoff，因为其中一个升高，另一个就会降低 ","date":"2021-12-05","objectID":"/zh-cn/f1score/:1:3","series":null,"tags":["Machine-Learning"],"title":"从混淆矩阵到 F1 score","uri":"/zh-cn/f1score/#recall"},{"categories":["Machine-Learning"],"content":" F1 score 正是因为 Precision 和 Recall 的互斥特性，在衡量分类器好坏的时候会给我们带来困扰，特别是两者相差不多的情况下，于是就需要将这两个指标合并起来用另一个指标表示，也就是 F1 score F1 score 的计算方式如下： $$F1\\ score = \\frac{2PR}{P+R}$$ 其中 Precision = $P$； Recall = $R$ ","date":"2021-12-05","objectID":"/zh-cn/f1score/:2:0","series":null,"tags":["Machine-Learning"],"title":"从混淆矩阵到 F1 score","uri":"/zh-cn/f1score/#f1-score"},{"categories":["Machine-Learning"],"content":" F1 score 的不同计算方法 Macro：分别计算每个类别的 $P$ 和 $R$，再计算总的平均的 $P$ 和 $R$，最后用这个计算 F1 score Micro：合并多个类别的统计结果到一个表格里面，在分别算 $P$ 和 $R$ 和 F1 score 配合后面的例子🌰食用 ","date":"2021-12-05","objectID":"/zh-cn/f1score/:2:1","series":null,"tags":["Machine-Learning"],"title":"从混淆矩阵到 F1 score","uri":"/zh-cn/f1score/#f1-score-的不同计算方法"},{"categories":["Machine-Learning"],"content":" F1 score 的几个规律 F1 score 永远在 precision 和 recall 之间， F1 score 会给低的部分（$P\\ or\\ R$）更多的权重，所以如果算术平均值是一样的情况下，哪个分类器的短板更短，它的 F1 就会越差 情况一：比如 $P$ 和 $R$ 分别是 $60%$ 和 $60%$，可以算他们的 F1 score = $60%$ 情况二：比如 $P$ 和 $R$ 分别是 $50%$ 和 $70%$，可以看到他们和上一种情况的平均值是一样的，但是他们的 F1 score = $58.3%$ 由 1. 可知：📒 高 F1 score 不意味着分类器更好或更适合你的任务，有时候你可能更关注 Precision 或者 Recall 这两个中的一个 ","date":"2021-12-05","objectID":"/zh-cn/f1score/:2:2","series":null,"tags":["Machine-Learning"],"title":"从混淆矩阵到 F1 score","uri":"/zh-cn/f1score/#f1-score-的几个规律"},{"categories":["Machine-Learning"],"content":" 一个完整的例子🌰 class 0 class 1 class 2 predict_class0 2 0 0 predict_class1 1 0 1 predict_class2 0 2 0 ","date":"2021-12-05","objectID":"/zh-cn/f1score/:3:0","series":null,"tags":["Machine-Learning"],"title":"从混淆矩阵到 F1 score","uri":"/zh-cn/f1score/#一个完整的例子"},{"categories":["Machine-Learning"],"content":" Macro 的计算方式要先得到每一个类别的 Precision 和 Recall，先画出表格⬇️ class 0 Not class 0 predict_class0 2 1 predict_not_class0 0 3 class 1 Not class 1 predict_class1 0 2 predict_not_class1 2 2 class 2 Not class 2 predict_class2 0 1 predict_not_class2 2 3 可以得到如下的结果 class 0：Precision = $\\frac{2}{3}$；Recall = $1$ class 1：Precision = $0$；Recall = $0$ class 2：Precision = $0$；Recall = $0$ 那么平均的 Precision 就是 $\\frac{2}{3} * \\frac{1}{3} = \\frac{2}{9}$；平均的 Recall 是 $\\frac{1}{3}$，代入 F1 score 的计算公式可以得到 $\\frac{4}{15}=0.26666$ ","date":"2021-12-05","objectID":"/zh-cn/f1score/:3:1","series":null,"tags":["Machine-Learning"],"title":"从混淆矩阵到 F1 score","uri":"/zh-cn/f1score/#macro-的计算方式"},{"categories":["Machine-Learning"],"content":" Micro 的计算方式将三个表格叠起来（对应位置相加），可以得到如下的表格 class ? Not class ? predict_class? 2 4 predict_not_class? 4 8 代入公式算得 F1 score = $1/3=0.333333$ ","date":"2021-12-05","objectID":"/zh-cn/f1score/:3:2","series":null,"tags":["Machine-Learning"],"title":"从混淆矩阵到 F1 score","uri":"/zh-cn/f1score/#micro-的计算方式"},{"categories":["Machine-Learning"],"content":" 代码验证 Python from sklearn.metrics import f1_score, confusion_matrix y_true = [0, 1, 2, 0, 1, 2] y_pred = [0, 2, 1, 0, 0, 1] print(confusion_matrix(y_true, y_pred)) # confusion matrix # [[2 0 0] # [1 0 1] # [0 2 0]] print(f1_score(y_true, y_pred, average='macro')) # 0.26666 print(f1_score(y_true, y_pred, average='micro')) # 0.33333 ","date":"2021-12-05","objectID":"/zh-cn/f1score/:4:0","series":null,"tags":["Machine-Learning"],"title":"从混淆矩阵到 F1 score","uri":"/zh-cn/f1score/#代码验证"},{"categories":["Machine-Learning"],"content":" 参考 sklearn 的 f1_score 介绍 ","date":"2021-12-05","objectID":"/zh-cn/f1score/:5:0","series":null,"tags":["Machine-Learning"],"title":"从混淆矩阵到 F1 score","uri":"/zh-cn/f1score/#参考"}]