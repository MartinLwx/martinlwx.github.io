<!DOCTYPE html>
<html lang="zh-CN">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="robots" content="noodp" /><title>线性回归模型指南 - 理论部分 - MartinLwx&#39;s Blog</title><meta name="Description" content="机器学习中的线性回归模型指南，包括梯度下降算法推导等"><meta property="og:url" content="https://martinlwx.github.io/zh-cn/linear-regression-model-guide-theory/">
  <meta property="og:site_name" content="MartinLwx&#39;s Blog">
  <meta property="og:title" content="线性回归模型指南 - 理论部分">
  <meta property="og:description" content="机器学习中的线性回归模型指南，包括梯度下降算法推导等">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2023-03-15T12:27:40+08:00">
    <meta property="article:modified_time" content="2023-03-15T12:27:40+08:00">
    <meta property="article:tag" content="Machine-Learning">
    <meta property="og:image" content="https://martinlwx.github.io/logo.png">

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:image" content="https://martinlwx.github.io/logo.png">
  <meta name="twitter:title" content="线性回归模型指南 - 理论部分">
  <meta name="twitter:description" content="机器学习中的线性回归模型指南，包括梯度下降算法推导等">
<meta name="application-name" content="MartinLwx&#39;s blog">
<meta name="apple-mobile-web-app-title" content="MartinLwx&#39;s blog">

<meta name="theme-color" content="#f8f8f8"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">

<link rel="canonical" href="https://martinlwx.github.io/zh-cn/linear-regression-model-guide-theory/" /><link rel="prev" href="https://martinlwx.github.io/zh-cn/config-neovim-from-scratch/" /><link rel="next" href="https://martinlwx.github.io/zh-cn/backpropagation-tutorial/" />
<link rel="stylesheet" href="/css/main.min.css"><link rel="stylesheet" href="/css/style.min.css"><script type="application/ld+json">{"@context": "https://schema.org","@type": "BlogPosting",
        "headline": "线性回归模型指南 - 理论部分",
        "inLanguage": "zh-CN",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https://martinlwx.github.io/zh-cn/linear-regression-model-guide-theory/"
        },"genre": "posts","keywords":["Linear regresison","machine learning","beginner guide"],"wordcount":  4566 ,
        "url": "https://martinlwx.github.io/zh-cn/linear-regression-model-guide-theory/","datePublished": "2023-03-15T12:27:40+08:00","dateModified": "2023-03-15T12:27:40+08:00","license": "\u003ca rel=\"license noopener\" href=\"https://creativecommons.org/licenses/by-nc-nd/4.0/\" target=\"_blank\"\u003eCC BY-NC-ND 4.0\u003c/a\u003e","publisher": {
            "@type": "Organization",
            "name": ""},"author": {
                "@type": "Person",
                "name": "MartinLwx",
                "url": "https://github.com/MartinLwx"
            },"description": "机器学习中的线性回归模型指南，包括梯度下降算法推导等"
    }</script></head>


<body data-instant-intensity="viewport" ><script type="text/javascript">
        function setTheme(theme) {
          document.body.setAttribute('theme', theme); 
          document.documentElement.className = theme;
          document.documentElement.style.setProperty('color-scheme', theme === 'light' ? 'light' : 'dark');
          if (theme === 'light') {
            document.documentElement.classList.remove('tw-dark')
          } else {
            document.documentElement.classList.add('tw-dark')
          }
          window.theme = theme;   
          window.isDark = window.theme !== 'light' 
        }
        function saveTheme(theme) {window.localStorage && localStorage.setItem('theme', theme);}
        function getMeta(metaName) {const metas = document.getElementsByTagName('meta'); for (let i = 0; i < metas.length; i++) if (metas[i].getAttribute('name') === metaName) return metas[i]; return '';}
        if (window.localStorage && localStorage.getItem('theme')) {
            let theme = localStorage.getItem('theme');
            if (theme === 'light' || theme === 'dark') {
            setTheme(theme);
            } else {
                if ((window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches)) {
                    setTheme('dark');
                } else {
                    setTheme('light');
                }
            }
         } else { 
            if ('auto' === 'light' || 'auto' === 'dark') 
                setTheme('auto'), saveTheme('auto'); 
            else saveTheme('auto'), window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches ? setTheme('dark') : setTheme('light');
        }
        let metaColors = {'light': '#f8f8f8','dark': '#161b22'}
        getMeta('theme-color').content = metaColors[document.body.getAttribute('theme')];
        window.switchThemeEventSet = new Set()
    </script>
    <div id="back-to-top"></div>
    <div id="mask"></div><div class="wrapper"><header class="desktop print:!tw-hidden" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/zh-cn/" title="MartinLwx&#39;s Blog"><span id="desktop-header-typeit" class="typeit"></span></a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item"
                    href="/zh-cn/posts/" > 所有文章 </a><a class="menu-item"
                    href="/zh-cn/tags/" > 标签 </a><a class="menu-item"
                    href="/zh-cn/categories/" > 分类 </a><a class="menu-item"
                    href="https://github.com/MartinLwx"  title="GitHub" 
                    rel="noopener noreferrer" target="_blank" ><svg class='icon' xmlns='http://www.w3.org/2000/svg' viewBox='0 0 496 512'><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d='M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z'/></svg>  </a><span class="menu-item delimiter"></span><button class="menu-item language" aria-label="选择语言">简体中文<svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M285.476 272.971L91.132 467.314c-9.373 9.373-24.569 9.373-33.941 0l-22.667-22.667c-9.357-9.357-9.375-24.522-.04-33.901L188.505 256 34.484 101.255c-9.335-9.379-9.317-24.544.04-33.901l22.667-22.667c9.373-9.373 24.569-9.373 33.941 0L285.475 239.03c9.373 9.372 9.373 24.568.001 33.941z"/></svg>
                    <select class="language-select" aria-label="选择语言" id="language-select-desktop"
                        onchange="location = this.value;"><option value="/en/linear-regression-model-guide-theory/" >English</option><option value="/zh-cn/linear-regression-model-guide-theory/"  selected>简体中文</option></select>
                </button><span class="menu-item search" id="search-desktop">
                    <input type="text"
                        placeholder="搜索文章标题或内容..."
                        id="search-input-desktop">
                    <button class="search-button search-toggle" id="search-toggle-desktop" title="搜索">
                        <svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
                    </button>
                    <button class="search-button search-clear" id="search-clear-desktop" title="清空">
                        <svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M256 8C119 8 8 119 8 256s111 248 248 248 248-111 248-248S393 8 256 8zm121.6 313.1c4.7 4.7 4.7 12.3 0 17L338 377.6c-4.7 4.7-12.3 4.7-17 0L256 312l-65.1 65.6c-4.7 4.7-12.3 4.7-17 0L134.4 338c-4.7-4.7-4.7-12.3 0-17l65.6-65-65.6-65.1c-4.7-4.7-4.7-12.3 0-17l39.6-39.6c4.7-4.7 12.3-4.7 17 0l65 65.7 65.1-65.6c4.7-4.7 12.3-4.7 17 0l39.6 39.6c4.7 4.7 4.7 12.3 0 17L312 256l65.6 65.1z"/></svg>
                    </button>
                    <span class="search-button search-loading tw-animate-spin" id="search-loading-desktop">
                        <svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M304 48c0 26.51-21.49 48-48 48s-48-21.49-48-48 21.49-48 48-48 48 21.49 48 48zm-48 368c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48zm208-208c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48zM96 256c0-26.51-21.49-48-48-48S0 229.49 0 256s21.49 48 48 48 48-21.49 48-48zm12.922 99.078c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48c0-26.509-21.491-48-48-48zm294.156 0c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48c0-26.509-21.49-48-48-48zM108.922 60.922c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.491-48-48-48z"/></svg>
                    </span>
                </span><button class="menu-item theme-select" aria-label="切换主题">
                    <svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M8 256c0 136.966 111.033 248 248 248s248-111.034 248-248S392.966 8 256 8 8 119.033 8 256zm248 184V72c101.705 0 184 82.311 184 184 0 101.705-82.311 184-184 184z"/></svg>
                    <select class="color-theme-select" id="theme-select-desktop" aria-label="切换主题">
                        <option value="light">浅色</option>
                        <option value="dark">深色</option>
                        <option value="auto">跟随系统</option>
                    </select>
                </button></div>
        </div>
    </div>
</header><header class="mobile print:!tw-hidden" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/zh-cn/" title="MartinLwx&#39;s Blog"><span id="mobile-header-typeit" class="typeit"></span></a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><div class="search-wrapper">
                <div class="search mobile" id="search-mobile">
                    <input type="text"
                        placeholder="搜索文章标题或内容..."
                        id="search-input-mobile">
                    <button class="search-button search-toggle tw-h-10" id="search-toggle-mobile" title="搜索">
                        <svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
                    </button>
                    <button class="search-button search-clear" id="search-clear-mobile" title="清空">
                        <svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M256 8C119 8 8 119 8 256s111 248 248 248 248-111 248-248S393 8 256 8zm121.6 313.1c4.7 4.7 4.7 12.3 0 17L338 377.6c-4.7 4.7-12.3 4.7-17 0L256 312l-65.1 65.6c-4.7 4.7-12.3 4.7-17 0L134.4 338c-4.7-4.7-4.7-12.3 0-17l65.6-65-65.6-65.1c-4.7-4.7-4.7-12.3 0-17l39.6-39.6c4.7-4.7 12.3-4.7 17 0l65 65.7 65.1-65.6c4.7-4.7 12.3-4.7 17 0l39.6 39.6c4.7 4.7 4.7 12.3 0 17L312 256l65.6 65.1z"/></svg>
                    </button>
                    <span class="search-button search-loading tw-animate-spin" id="search-loading-mobile">
                        <svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M304 48c0 26.51-21.49 48-48 48s-48-21.49-48-48 21.49-48 48-48 48 21.49 48 48zm-48 368c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48zm208-208c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48zM96 256c0-26.51-21.49-48-48-48S0 229.49 0 256s21.49 48 48 48 48-21.49 48-48zm12.922 99.078c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48c0-26.509-21.491-48-48-48zm294.156 0c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48c0-26.509-21.49-48-48-48zM108.922 60.922c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.491-48-48-48z"/></svg>
                    </span>
                </div>
                <button class="search-cancel" id="search-cancel-mobile">
                    取消
                </button>
            </div><a class="menu-item" href="/zh-cn/posts/" title="" >所有文章</a><a class="menu-item" href="/zh-cn/tags/" title="" >标签</a><a class="menu-item" href="/zh-cn/categories/" title="" >分类</a><a class="menu-item" href="https://github.com/MartinLwx" title="GitHub" 
                rel="noopener noreferrer" target="_blank" ><svg class='icon' xmlns='http://www.w3.org/2000/svg' viewBox='0 0 496 512'><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d='M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z'/></svg></a><button class="menu-item theme-select tw-w-full" aria-label="切换主题">
                <svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M8 256c0 136.966 111.033 248 248 248s248-111.034 248-248S392.966 8 256 8 8 119.033 8 256zm248 184V72c101.705 0 184 82.311 184 184 0 101.705-82.311 184-184 184z"/></svg>
                <select class="color-theme-select" id="theme-select-mobile" aria-label="切换主题">
                    <option value="light">浅色</option>
                    <option value="dark">深色</option>
                    <option value="auto">跟随系统</option>
                </select>
            </button><button class="menu-item tw-w-full" title="">简体中文<svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M285.476 272.971L91.132 467.314c-9.373 9.373-24.569 9.373-33.941 0l-22.667-22.667c-9.357-9.357-9.375-24.522-.04-33.901L188.505 256 34.484 101.255c-9.335-9.379-9.317-24.544.04-33.901l22.667-22.667c9.373-9.373 24.569-9.373 33.941 0L285.475 239.03c9.373 9.372 9.373 24.568.001 33.941z"/></svg>
                <select class="language-select" title="" onchange="location = this.value;"><option value="/en/linear-regression-model-guide-theory/" >English</option><option value="/zh-cn/linear-regression-model-guide-theory/"  selected>简体中文</option></select>
            </button></div>
    </div>
</header>
<div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
</div>
<div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
</div><main class="main">
            <div class="container"><div class="toc print:!tw-hidden" id="toc-auto">
        <h2 class="toc-title">目录</h2>
        <div class="toc-content" id="toc-content-auto"><nav id="TableOfContents">
  <ul>
    <li><a href="#引言">引言</a></li>
    <li><a href="#线性回归模型">线性回归模型</a></li>
    <li><a href="#分类">分类</a>
      <ul>
        <li><a href="#单变量线性回归">单变量线性回归</a></li>
        <li><a href="#多变量线性回归">多变量线性回归</a></li>
      </ul>
    </li>
    <li><a href="#模型如何训练">模型如何训练</a>
      <ul>
        <li><a href="#损失函数">损失函数</a></li>
        <li><a href="#梯度下降训练法">梯度下降训练法</a></li>
      </ul>
    </li>
    <li><a href="#总结">总结</a></li>
  </ul>
</nav></div>
    </div><script>document.getElementsByTagName("main")[0].setAttribute("autoTOC", "true")</script><article class="page single print:!tw-w-full print:!tw-max-w-none print:!tw-m-0 print:!tw-p-0"><h1 class="single-title">线性回归模型指南 - 理论部分</h1><div class="post-meta">
            <div class="post-meta-line">
                <span class="post-author"><svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M248 8C111 8 0 119 0 256s111 248 248 248 248-111 248-248S385 8 248 8zm0 96c48.6 0 88 39.4 88 88s-39.4 88-88 88-88-39.4-88-88 39.4-88 88-88zm0 344c-58.7 0-111.3-26.6-146.5-68.2 18.8-35.4 55.6-59.8 98.5-59.8 2.4 0 4.8.4 7.1 1.1 13 4.2 26.6 6.9 40.9 6.9 14.3 0 28-2.7 40.9-6.9 2.3-.7 4.7-1.1 7.1-1.1 42.9 0 79.7 24.4 98.5 59.8C359.3 421.4 306.7 448 248 448z"/></svg><a href="https://github.com/MartinLwx" title="Author" target="_blank" rel="noopener noreferrer author" class="author">MartinLwx</a>
                </span>&nbsp;<span class="post-category">收录于 </span>&nbsp;<span class="post-category">类别 <a href="/zh-cn/categories/ml-dl/"><svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M464 128H272l-54.63-54.63c-6-6-14.14-9.37-22.63-9.37H48C21.49 64 0 85.49 0 112v288c0 26.51 21.49 48 48 48h416c26.51 0 48-21.49 48-48V176c0-26.51-21.49-48-48-48zm0 272H48V112h140.12l54.63 54.63c6 6 14.14 9.37 22.63 9.37H464v224z"/></svg>ML-DL</a></span></div>
            <div class="post-meta-line"><svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M148 288h-40c-6.6 0-12-5.4-12-12v-40c0-6.6 5.4-12 12-12h40c6.6 0 12 5.4 12 12v40c0 6.6-5.4 12-12 12zm108-12v-40c0-6.6-5.4-12-12-12h-40c-6.6 0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6 0 12-5.4 12-12zm96 0v-40c0-6.6-5.4-12-12-12h-40c-6.6 0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6 0 12-5.4 12-12zm-96 96v-40c0-6.6-5.4-12-12-12h-40c-6.6 0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6 0 12-5.4 12-12zm-96 0v-40c0-6.6-5.4-12-12-12h-40c-6.6 0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6 0 12-5.4 12-12zm192 0v-40c0-6.6-5.4-12-12-12h-40c-6.6 0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6 0 12-5.4 12-12zm96-260v352c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V112c0-26.5 21.5-48 48-48h48V12c0-6.6 5.4-12 12-12h40c6.6 0 12 5.4 12 12v52h128V12c0-6.6 5.4-12 12-12h40c6.6 0 12 5.4 12 12v52h48c26.5 0 48 21.5 48 48zm-48 346V160H48v298c0 3.3 2.7 6 6 6h340c3.3 0 6-2.7 6-6z"/></svg>&nbsp;<time datetime="2023-03-15">2023-03-15</time>&nbsp;<svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M402.3 344.9l32-32c5-5 13.7-1.5 13.7 5.7V464c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V112c0-26.5 21.5-48 48-48h273.5c7.1 0 10.7 8.6 5.7 13.7l-32 32c-1.5 1.5-3.5 2.3-5.7 2.3H48v352h352V350.5c0-2.1.8-4.1 2.3-5.6zm156.6-201.8L296.3 405.7l-90.4 10c-26.2 2.9-48.5-19.2-45.6-45.6l10-90.4L432.9 17.1c22.9-22.9 59.9-22.9 82.7 0l43.2 43.2c22.9 22.9 22.9 60 .1 82.8zM460.1 174L402 115.9 216.2 301.8l-7.3 65.3 65.3-7.3L460.1 174zm64.8-79.7l-43.2-43.2c-4.1-4.1-10.8-4.1-14.8 0L436 82l58.1 58.1 30.9-30.9c4-4.2 4-10.8-.1-14.9z"/></svg>&nbsp;<time datetime="2023-03-15">2023-03-15</time>&nbsp;<svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M497.9 142.1l-46.1 46.1c-4.7 4.7-12.3 4.7-17 0l-111-111c-4.7-4.7-4.7-12.3 0-17l46.1-46.1c18.7-18.7 49.1-18.7 67.9 0l60.1 60.1c18.8 18.7 18.8 49.1 0 67.9zM284.2 99.8L21.6 362.4.4 483.9c-2.9 16.4 11.4 30.6 27.8 27.8l121.5-21.3 262.6-262.6c4.7-4.7 4.7-12.3 0-17l-111-111c-4.8-4.7-12.4-4.7-17.1 0zM124.1 339.9c-5.5-5.5-5.5-14.3 0-19.8l154-154c5.5-5.5 14.3-5.5 19.8 0s5.5 14.3 0 19.8l-154 154c-5.5 5.5-14.3 5.5-19.8 0zM88 424h48v36.3l-64.5 11.3-31.1-31.1L51.7 376H88v48z"/></svg>&nbsp;约 4566 字&nbsp;<svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M256 8C119 8 8 119 8 256s111 248 248 248 248-111 248-248S393 8 256 8zm0 448c-110.5 0-200-89.5-200-200S145.5 56 256 56s200 89.5 200 200-89.5 200-200 200zm61.8-104.4l-84.9-61.7c-3.1-2.3-4.9-5.9-4.9-9.7V116c0-6.6 5.4-12 12-12h32c6.6 0 12 5.4 12 12v141.7l66.8 48.6c5.4 3.9 6.5 11.4 2.6 16.8L334.6 349c-3.9 5.3-11.4 6.5-16.8 2.6z"/></svg>&nbsp;预计阅读 10 分钟&nbsp;</div>
        </div><div class="details toc print:!tw-block" id="toc-static"  kept="">
                <div class="details-summary toc-title">
                    <span>目录</span>
                    <span class="details-icon"><svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#引言">引言</a></li>
    <li><a href="#线性回归模型">线性回归模型</a></li>
    <li><a href="#分类">分类</a>
      <ul>
        <li><a href="#单变量线性回归">单变量线性回归</a></li>
        <li><a href="#多变量线性回归">多变量线性回归</a></li>
      </ul>
    </li>
    <li><a href="#模型如何训练">模型如何训练</a>
      <ul>
        <li><a href="#损失函数">损失函数</a></li>
        <li><a href="#梯度下降训练法">梯度下降训练法</a></li>
      </ul>
    </li>
    <li><a href="#总结">总结</a></li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><h2 id="引言" class="headerLink">
    <a href="#%e5%bc%95%e8%a8%80" class="header-mark" aria-label="Header mark for '引言'"></a>引言</h2><p>最近，重新刷起了吴恩达的机器学习课程，系统性复习了之前学过的知识，发现又有不少收获，打算仔细整理一番👍</p>
<p>要谈论什么是线性回归首先要对什么是机器学习有一个基本的认识，什么是机器学习？抽象来说机器学习就是学习一个函数
$$
f(input) = output
$$
其中 $f$ 指的就是具体的机器学习模型。<strong>机器学习就是自动拟合输入 - 输出之间的关系</strong>的一套方法论。有时候我们会发现一些问题很难定义出一个具体的算法来解决，这时就是机器学习发光发热的地方了，我们可以让它从数据中自己学习、总结一些模式，做出相关的预测。这也是它和传统的算法（二分、递归等）区别的地方。不得不承认，机器学习从定义上来说就很迷人，它<em>似乎</em>为所有难以解决的问题提供了一套可行的解决框架。恰恰现实生活中的一些问题就是很难用传统算法解决的</p>
<blockquote>
  <p>📒 为此，我总觉得<strong>每个程序员都应该懂点机器学习/深度学习</strong>，它也是我们解决问题的一大工具💪</p>

</blockquote><p>线性回归就是经典的机器学习入门模型之一，可以说是机器学习界的 <a href="https://en.wikipedia.org/wiki/%22Hello,_World!%22_program" target="_blank" rel="noopener noreferrer">“Hello world”</a>，<em>经典的比如波士顿房价预测项目（虽然说现在已经是烂大街的项目了）</em></p>
<p>前面的公式中，$input$ 为机器学习中所谓的特征（Feature），常用记号 $x$ 表示。而 $output$ 可以根据是预测值还是预测类别可以大致划分为回归问题（Regression problem）和分类问题（Classification problem）两大类</p>
<blockquote>
  <p>📒 如何理解特征？所谓<strong>特征就是，跟要预测的东西高度相关的东西</strong>。<em>还是用预测房价作为例子，房价显然跟占地面积、绿化条件等相关，这里的占地面积等就是特征</em>。机器学习中可以对特征分析，看哪些跟输出的关联程度高，或者运用我们的领域知识（Domain knowledge），自己选择好的特征。但总的来说，<strong>机器学习还是要求我们花费大量精力在提取好的特征上</strong>，这也是机器学习被人诟病的地方，而这个缺点在深度学习中被大大缓解，当然那是后话了</p>

</blockquote><blockquote>
  <p>📒 机器学习<strong>无法魔法般地理解</strong>你提供的各种格式的 $input$，<em>比如图片、文本、视频等</em>。在机器学习中，<strong>$input$ 常常被处理为数字</strong>，才能用各种机器学习方法学习。有些特征本身就是数字，<em>比如预测房价，房子的占地面积这个特征本身就是一个数字</em>。当输入不是数字的时候，就需要别的手段将输入转化为数字，<em>比如用词嵌入向量模型表示文本等</em>，这里不展开细讲。<strong>我们暂时假设已经将输入处理为了数字的形式</strong></p>

</blockquote><p>今天要提到的线性回归模型就属于<strong>监督学习分类下的回归模型</strong>，它足够简单，但是又可以阐述很多机器学习的思想，用来入门是再适合不过了。话不多说，让我们开始吧 :)</p>
<blockquote>
  <p>📒 本文假定你对基本的微积分和线性代数有所了解，<em>比如你需要知道行向量乘列向量如何进行以及对应的记号表示，矩阵乘法的定义，函数如何求导等</em></p>

</blockquote><h2 id="线性回归模型" class="headerLink">
    <a href="#%e7%ba%bf%e6%80%a7%e5%9b%9e%e5%bd%92%e6%a8%a1%e5%9e%8b" class="header-mark" aria-label="Header mark for '线性回归模型'"></a>线性回归模型</h2><p>线性回归的英文是 Linear regression。顾名思义，由两部分组成：</p>
<ul>
<li>Linear 的含义就是它<strong>是线性的</strong>。<em>以二维平面为例，$y=kx+b$ 这种就是线性，画出来是一条直线，而 $y=x^2$ 这种就不是，因为它画出来为曲线</em></li>
<li>Regression 是因为它符合<strong>机器学习中对回归问题的定义</strong>——预测一个<strong>不限制范围</strong>的值</li>
</ul>
<h2 id="分类" class="headerLink">
    <a href="#%e5%88%86%e7%b1%bb" class="header-mark" aria-label="Header mark for '分类'"></a>分类</h2><blockquote>
  <p>📒 为了形式的简洁下面的记号 $f(x)$ 其实省略了下标 $w,b$。$f(x)=f_{w,b}(x)$</p>

</blockquote><blockquote>
  <p>📒 有时候会看到有的书或者博客用 $h_\theta$ 表示模型，我认为 $f(x)$ 比较简洁就用了这个记法</p>

</blockquote><p>如果要进一步对线性回归模型进行细分，又可以分成如下几类</p>
<h3 id="单变量线性回归" class="headerLink">
    <a href="#%e5%8d%95%e5%8f%98%e9%87%8f%e7%ba%bf%e6%80%a7%e5%9b%9e%e5%bd%92" class="header-mark" aria-label="Header mark for '单变量线性回归'"></a>单变量线性回归</h3><p>如果模型的输入特征只有一个，就叫做单变量线性回归（Univariate linear regression），此时达到了最简单的形式
$$
f(x)=wx+b
$$
在机器学习中，分别称 $w$ 和 $b$ 为权重（Weight）和偏置项（Bias）</p>
<blockquote>
  <p>📒 注意：$\theta$ 为一个向量，按道理应该用 $\vec \theta$ 表示，但是下面为了简洁，我都省略了箭头</p>

</blockquote><blockquote>
  <p>📒 也可以用向量的形式写，用 $\theta=[b, w]$ 表示模型的参数，令 $\vec x=[1, x]^T$。那么根据向量乘法的知识我们可以知道 $\theta^T\vec x=wx+b$</p>

</blockquote><h3 id="多变量线性回归" class="headerLink">
    <a href="#%e5%a4%9a%e5%8f%98%e9%87%8f%e7%ba%bf%e6%80%a7%e5%9b%9e%e5%bd%92" class="header-mark" aria-label="Header mark for '多变量线性回归'"></a>多变量线性回归</h3><p>如果模型有多个输入的特征，就叫做多变量线性回归（Multiple linear regresseion）
$$
f(x)=w_1x_1+w_1x_2+&hellip;w_nx_n+b
$$
其中 $x_i$ 是不同的特征，一共有 $n$ 个特征，为此我们需要每个特征学习一个权重 $w_i$</p>
<blockquote>
  <p>📒 同理，可以选择用向量的形式来写，令 $\theta=[b, w_1, w_2, &hellip;, w_n]$，$\vec x=[1, x_1, x_2, &hellip;, x_n]^T$，向量乘法之后也可以得到上面的形式。你会惊讶地发现，<strong>单变量线性回归和多变量线性回归有了统一的形式——$f(\vec x)=\theta^T\vec x$</strong>。<strong>这在后面求解梯度的时候会带来很大的方便</strong></p>

</blockquote><h2 id="模型如何训练" class="headerLink">
    <a href="#%e6%a8%a1%e5%9e%8b%e5%a6%82%e4%bd%95%e8%ae%ad%e7%bb%83" class="header-mark" aria-label="Header mark for '模型如何训练'"></a>模型如何训练</h2><h3 id="损失函数" class="headerLink">
    <a href="#%e6%8d%9f%e5%a4%b1%e5%87%bd%e6%95%b0" class="header-mark" aria-label="Header mark for '损失函数'"></a>损失函数</h3><p>定义了线性回归模型之后，我们需要衡量它的预测好坏，显然，我们<strong>希望预测的值跟实际上的值的“距离”越接近越好</strong>。在机器学习中，我们会规定一个损失函数（Cost function）衡量“距离”，<strong>损失自然是越低越好</strong>。当模型在验证集上的损失降到最低不再明显变化的时候，我们认为模型收敛了，此时得到了最好的模型</p>
<blockquote>
  <p>📒 在机器学习中，通常将数据划分为训练集/验证集/测试集，模型用训练集上的数据学习，在验证集上验证、调参，最后在测试集上进行泛化性验证（<strong>测试集包含没有见过的数据</strong>）。只用训练集/测试集这种划分方法，直接在测试集上调参<strong>是不正确的做法</strong>。测试集<strong>当且仅当</strong>最后你训练和调参结束，选出你认为的最好模型的的时候，在论文里面是报告结果的时候采用的</p>

</blockquote><p>线性回归模型的损失函数最常用的是均平方误差，我更经常直接用英文的缩写 MSE（Mean square error）代指。其公式如下：</p>
<p>$$
MSE=\frac{1}{2m}\sum^m_{i=1}(\hat y^{(i)} - y^{(i)})^2
$$</p>
<p>其中</p>
<ul>
<li>$m$ 表示样本个数</li>
<li>上角标 ${(i)}$ 加了括号，和指数的记号进行区分，表示第 $i$ 个样本的预测/真实值</li>
<li>$\hat y$ 这个记号表示线性回归模型的预测，$y$ 表示本来的真实值</li>
</ul>
<blockquote>
  <p>📒 我采用了符合机器学习惯例的记号，推荐记住～</p>

</blockquote><blockquote>
  <p>📒 线性回归模型<strong>不是非要</strong>用 MSE，也可以用绝对值误差 MAE，MAE 适用于：当数据集中的异常值（Outlier）比较多的时候，降低对这种样本的敏感度</p>

</blockquote><h3 id="梯度下降训练法" class="headerLink">
    <a href="#%e6%a2%af%e5%ba%a6%e4%b8%8b%e9%99%8d%e8%ae%ad%e7%bb%83%e6%b3%95" class="header-mark" aria-label="Header mark for '梯度下降训练法'"></a>梯度下降训练法</h3><p>前面提到当模型在验证集上的损失降到最低而且不再变化的时候，我们得到最好的模型。但是要如何让模型不断改进预测，降低损失呢？🤔 梯度下降（Gradient descent）算法是一种通用的做法</p>
<p>不要被这个名字所迷惑，梯度下降算法其实没有那么神秘。先整理我们目前学到了什么：</p>
<ul>
<li>模型的预测 $\hat y$ 跟它参数，<em>如果是单变量线性回归模型，就是和 $w$ 和 $b$ 有关</em></li>
<li>损失函数跟模型的预测有关系，因为数据本身真实的值这个我们是无法改变的</li>
</ul>
<p>所以<strong>损失函数实际上是一个关于模型参数的函数</strong>，在机器学习中，常用记号 $J$ 表示</p>
<p>先考虑简单的单变量线性回归，当它采用 MSE 作为损失函数的时候：
$$
J(w, b) = \frac{1}{2m}\sum^m_{i=1}(f(x^{(i)})-y^{(i)})^2 = \frac{1}{2m}\sum^m_{i=1}(wx^{(i)} + b - y^{(i)})^2
$$</p>
<p><strong>根据 $w$ 和 $b$ 的取值不同，$J(w,b)$ 也不同</strong>，因此<strong>改进线性回归模型其实就是一直在调整这两个参数让 $J(w,b)$ 的值更小</strong>。用数学的语言来说，求解最优模型其实就是求解函数 $J(w,b)$ 的最小点</p>
<blockquote>
  <p>📒 回忆 $m$ 为训练集的样本个数。更为严格来说，上面的梯度下降式子是批梯度下降（Batch gradient descent），即<strong>每个计算梯度的时候用的是整个训练集上的样本</strong>。当数据集很大的时候这个方法就无法很好 Scale，此时我们就需要使用随机梯度下降（Stochastic gradient descent）</p>

</blockquote><blockquote>
  <p>📒 只要学过导数、最小值，我们不难求解出上面公式的最小值，但<strong>这是因为线性回归模型比较简单</strong>，当模型更加复杂的时候，用数学方法求解也会更加困难，因此<strong>在实践中采用的都是梯度下降算法</strong>（不考虑强化学习，因为强化学习优化的目标一般不是一个可微的函数）</p>

</blockquote><p>让我们<strong>暂时不考虑 $b$ 只考虑 $w$</strong>，那么此时 $J$ 是一个关于 $w$ 的函数，我们可以以 $w$ 为横轴，$J(w)$ 为纵轴画出如下的图：</p>
<figure><img src="/img/linear_regression_tagent.png" width="70%">
</figure>

<blockquote>
  <p>📒 注意，上面的图并不严格遵循 $J(w)$ 的定义，为了方便我这里直接画了 $y=\frac{1}{2}x^2$。但是<strong>形状应该差不多</strong>，可以用来理解梯度下降算法</p>

</blockquote><p>从图中不难看出，当 $w=0$ 的时候 $J(w)$ 取到了最小值。假设模型当前的参数 $w=5$，计算得到损失 $J(5)=12.5$，我们要如何更新 $w$ 让模型更好呢？<strong>答案是让 $w$ 沿着梯度的</strong>反方向<strong>更新（图中红色的线为在 $w=5$ 这个点的切线）</strong>，不难求出这一点的梯度（导数）是 $5$，$w$ 应该减小，因此应该是减去这个梯度（所以说是反方向），同时引入<strong>学习率 $\alpha$ 控制更新的幅度</strong>，得到更新式子 $w \leftarrow w - \alpha \cdot 5$</p>
<blockquote>
  <p>📒 想象你自己站在 $w=5$ 这个点要前进到 $w=0$ 这个最小值在的点，如果学习率 $\alpha$ 太大，你新得到的 $w$ 可能会小于 $0$，一下子越过了 $w=0$ 这个点。虽然你可以通过梯度下降再次尝试更新，但此时往往你会发现你的模型的损失一直在变化无法收敛。<strong>学习率和梯度共同控制了每次参数更新的幅度</strong></p>

</blockquote><blockquote>
  <p>📒 我们在只考虑 $w$ 的时候得出了该如何更新的结论——沿着梯度的反方向，<strong>考虑更多的参数的时候这个结论仍然适用</strong>，不过那就要涉及到求解偏导数乃至向量求导的知识，而且此时的 $J$ 的可视化也更为困难，所以这里不细讲。<strong>只需要记住模型的更新总是沿着梯度的反方向前进，从直觉上进行把握</strong>👻</p>

</blockquote><p>在单变量线性回归中，梯度更新的式子如下：
$$
w \leftarrow w - \alpha \cdot \frac{\partial}{\partial w}J(w,b)
$$</p>
<p>别忘了还有 $b$，它也要更新
$$
b \leftarrow b - \alpha \cdot \frac{\partial}{\partial b}J(w,b)
$$</p>
<p>我们来对其中的梯度计算进行推导
$$
\begin{aligned}
\frac{\partial}{\partial w}J(w,b)&amp;=\frac{\partial}{\partial w}\frac{1}{2m}\sum_{i=1}^m(f(x^{(i)})-y^{(i)})^2 \\\
&amp;= \frac{\partial}{\partial w}\frac{1}{2m}(wx^{(i)}+b-y^{(i)})^2 \\\
&amp;= \frac{\partial}{\partial w}\frac{1}{m}\sum_{i=1}^m(f(x^{(i)})-y^{(i)})x^{(i)}
\end{aligned}
$$
$$
\begin{aligned}
\frac{\partial}{\partial b}J(w,b)&amp;=\frac{\partial}{\partial w}\frac{1}{2m}\sum_{i=1}^m(f(x^{(i)})-y^{(i)})^2 \\\
&amp;= \frac{\partial}{\partial b}\frac{1}{2m}(wx^{(i)}+b-y^{(i)})^2 \\\
&amp;= \frac{\partial}{\partial b}\frac{1}{m}\sum_{i=1}^m(f(x^{(i)})-y^{(i)})
\end{aligned}
$$</p>
<p>如果是多变量线性回归，我们要求解每个 $\frac{\partial }{w_i}J(w_1,w_2, &hellip;,b)$ 显然很不方便，<strong>此时用向量形式推导梯度是最好的</strong></p>
<p>在向量的形式下，损失函数 MSE 写作：</p>
<p>$$
J(\theta) = \frac{1}{2m}(X\theta - \vec{y})^T(X\theta - \vec{y})
$$</p>
<p>其中</p>
<ul>
<li>$X$ 为输入的矩阵，<strong>常用大写字母表示矩阵</strong>，它的每一行为一个样本的特征值 $(x^{(i)})^T$，大小为 $(m, n+1)$
<ul>
<li>前面提到我们有 $n$ 个特征，这里为 $n+1$ 维是因为在第一个位置插入了一个 $1$，这样相乘的时候 $1$ 会和 $b$ 做计算</li>
<li>$x^{(i)}$ 需要转置因为本来它本是列向量</li>
<li>对于单个样本是 $\theta^T\vec x$，对于 $m$ 个样本的计算就要用矩阵乘法 $X\theta$</li>
</ul>
</li>
<li>$\theta$ 正如我们前面说的是 $[b, w_1, w_2, &hellip;, w_n]$，长为 $n + 1$</li>
<li>因此 $X\theta$ 就是模型的预测值，根据矩阵乘法的知识，我们会得到长为 $m$ 的向量，表示对每个样本的预测</li>
<li>$X\theta - \vec y$ 就是每个预测的误差</li>
<li>顺带一提，假设 $\vec a$ 为列向量，<strong>$\vec a^T\vec a$ 得到的总是一个标量，为每个元素的平方和</strong>。如果让 $\vec a=X\theta -\vec y$ 就得到了上面右边的部分，这也解释了为什么会是这个形式</li>
</ul>
<blockquote>
  <p>🤔️ 更新：在 <a href="https://martinlwx.github.io/zh-cn/a-trick-to-calculating-partial-derivatives-in-ml/" rel="">维度分析</a> 这篇博客中，我展示了如何用维度分析技巧<strong>快速</strong>推导出这个公式的解，感兴趣的话可以看下</p>

</blockquote><p>下面我们开始尝试推导这个公式的梯度，<strong>这需要你有一定的向量/矩阵求导知识，可以选择跳过🔮</strong>。<del>不过我建议还是看看，因为机器学习里面还挺多公式推导的</del></p>
<p>$$
\begin{aligned}
\frac{\partial}{\partial \theta}\ J(w,b)
&amp;= \frac{\partial}{\partial \theta}\ \frac{1}{2m}(X\theta - \vec{y})^T(X\theta - \vec{y}) \\\
&amp;= \frac{1}{2m}\frac{\partial}{\partial \theta}\ (\theta^TX^T - \vec{y}^T)(X\theta - \vec{y}) \\\
&amp;= \frac{1}{2m}\frac{\partial}{\partial \theta}\ (\theta^TX^TX\theta - \theta^TX^T\vec y - \vec y^TX\theta + \vec y^T\vec y) \\\
&amp;= \frac{1}{2m}\frac{\partial}{\partial \theta}\ (\theta^TX^TX\theta - \theta^T(X^T\vec y) - (X^T\vec y)^T\theta + \vec y^T\vec y) \\\
&amp;= \frac{1}{2m}\frac{\partial}{\partial \theta}\ (\theta^TX^TX\theta - 2\theta^T(X^T\vec y) + \vec y^T\vec y) \\\
&amp;= \frac{1}{2m}(\frac{\partial}{\partial \theta}\ (\theta^TX^TX\theta) - 2\frac{\partial}{\partial \theta}(\theta^TX^T\vec y))) \\\
&amp;= \frac{1}{2m}(2X^TX\theta - 2X^T\vec y)) \\\
&amp;= \frac{1}{m}(X^TX\theta - X^T\vec y)) \\\
&amp;= \frac{1}{m}X^T(X\theta-\vec y)
\end{aligned}
$$</p>
<p>几个解释：</p>
<ul>
<li>$X^T$ 的大小是 $(n+1, m)$，$\vec y$ 是 $(m, 1)$，因此 $X^T\vec y$ 其实是一个维度为 $(n+1, 1)$ 的列向量，<strong>注意在线性代数中，当 $\vec a$ 和 $\vec b$ 都为列向量的时候，有 $\vec a^T\vec b=\vec b^T\vec a$ 成立</strong>。所以 $\theta^T(X^T\vec y) = (X^T\vec y)^T\theta$</li>
<li>其他几个地方的推导我推荐直接代向量/矩阵求导公式，可以参考这个 <a href="http://www.gatsby.ucl.ac.uk/teaching/courses/sntn/sntn-2017/resources/Matrix_derivatives_cribsheet.pdf" target="_blank" rel="noopener noreferrer">Cheatsheet</a>。当然如果对这方面很感兴趣更推荐直接去看原理证明
<ul>
<li>比如上面的 $\frac{\partial}{\partial \theta}(\theta^TX^T\vec y))$，其实就是换元法，令 $\vec b=X^T\vec y$，刚好对应 Cheatsheet 里面的 $\frac{\partial }{\partial \theta}\theta^T\vec b=\vec b$</li>
</ul>
</li>
</ul>
<blockquote>
  <p>📒 向量形式在实现代码的时候也带来了很大方便，我们可以利用成熟的 <a href="https://numpy.org/" target="_blank" rel="noopener noreferrer">Numpy</a> <strong>高效</strong>进行计算，而不是自己写一个 for 循环一个个样本计算</p>

</blockquote><h2 id="总结" class="headerLink">
    <a href="#%e6%80%bb%e7%bb%93" class="header-mark" aria-label="Header mark for '总结'"></a>总结</h2><p>线性回归模型的理论部分就是以上的内容，本文介绍了单变量线性回归，多变量线性回归，前者可以看成是后者的一个特例。最后我们将其都用向量的形式统一了写法，并给出了向量形式下采用 MSE 作为损失函数的时候的梯度计算公式</p>
<p>本来还想放一下代码在这里，结果写着写着发现这一篇博客已经很长了，看来只好将线性回归模型的算法放在另一篇了🙌</p>
</div>

        <div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>更新于 2023-03-15</span>
            </div>
            <div class="post-info-license"></div>
        </div>
        <div class="post-info-line print:!tw-hidden">
            <div class="post-info-md"></div>
            <div class="post-info-share"><button title="分享到 Twitter" data-sharer="twitter" data-url="https://martinlwx.github.io/zh-cn/linear-regression-model-guide-theory/" data-title="线性回归模型指南 - 理论部分" data-hashtags="Machine-Learning"><svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></button><button title="分享到 Facebook" data-sharer="facebook" data-url="https://martinlwx.github.io/zh-cn/linear-regression-model-guide-theory/" data-hashtag="Machine-Learning"><svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M504 256C504 119 393 8 256 8S8 119 8 256c0 123.78 90.69 226.38 209.25 245V327.69h-63V256h63v-54.64c0-62.15 37-96.48 93.67-96.48 27.14 0 55.52 4.84 55.52 4.84v61h-31.28c-30.8 0-40.41 19.12-40.41 38.73V256h68.78l-11 71.69h-57.78V501C413.31 482.38 504 379.78 504 256z"/></svg></button><button title="分享到 Hacker News" data-sharer="hackernews" data-url="https://martinlwx.github.io/zh-cn/linear-regression-model-guide-theory/" data-title="线性回归模型指南 - 理论部分"><svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M0 32v448h448V32H0zm21.2 197.2H21c.1-.1.2-.3.3-.4 0 .1 0 .3-.1.4zm218 53.9V384h-31.4V281.3L128 128h37.3c52.5 98.3 49.2 101.2 59.3 125.6 12.3-27 5.8-24.4 60.6-125.6H320l-80.8 155.1z"/></svg></button><button title="分享到 Line" data-sharer="line" data-url="https://martinlwx.github.io/zh-cn/linear-regression-model-guide-theory/" data-title="线性回归模型指南 - 理论部分"><svg class="icon" role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>LINE</title><path d="M19.365 9.863c.349 0 .63.285.63.631 0 .345-.281.63-.63.63H17.61v1.125h1.755c.349 0 .63.283.63.63 0 .344-.281.629-.63.629h-2.386c-.345 0-.627-.285-.627-.629V8.108c0-.345.282-.63.63-.63h2.386c.346 0 .627.285.627.63 0 .349-.281.63-.63.63H17.61v1.125h1.755zm-3.855 3.016c0 .27-.174.51-.432.596-.064.021-.133.031-.199.031-.211 0-.391-.09-.51-.25l-2.443-3.317v2.94c0 .344-.279.629-.631.629-.346 0-.626-.285-.626-.629V8.108c0-.27.173-.51.43-.595.06-.023.136-.033.194-.033.195 0 .375.104.495.254l2.462 3.33V8.108c0-.345.282-.63.63-.63.345 0 .63.285.63.63v4.771zm-5.741 0c0 .344-.282.629-.631.629-.345 0-.627-.285-.627-.629V8.108c0-.345.282-.63.63-.63.346 0 .628.285.628.63v4.771zm-2.466.629H4.917c-.345 0-.63-.285-.63-.629V8.108c0-.345.285-.63.63-.63.348 0 .63.285.63.63v4.141h1.756c.348 0 .629.283.629.63 0 .344-.282.629-.629.629M24 10.314C24 4.943 18.615.572 12 .572S0 4.943 0 10.314c0 4.811 4.27 8.842 10.035 9.608.391.082.923.258 1.058.59.12.301.079.766.038 1.08l-.164 1.02c-.045.301-.24 1.186 1.049.645 1.291-.539 6.916-4.078 9.436-6.975C23.176 14.393 24 12.458 24 10.314"/></svg></button><button title="分享到 微博" data-sharer="weibo" data-url="https://martinlwx.github.io/zh-cn/linear-regression-model-guide-theory/" data-title="线性回归模型指南 - 理论部分"><svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M407 177.6c7.6-24-13.4-46.8-37.4-41.7-22 4.8-28.8-28.1-7.1-32.8 50.1-10.9 92.3 37.1 76.5 84.8-6.8 21.2-38.8 10.8-32-10.3zM214.8 446.7C108.5 446.7 0 395.3 0 310.4c0-44.3 28-95.4 76.3-143.7C176 67 279.5 65.8 249.9 161c-4 13.1 12.3 5.7 12.3 6 79.5-33.6 140.5-16.8 114 51.4-3.7 9.4 1.1 10.9 8.3 13.1 135.7 42.3 34.8 215.2-169.7 215.2zm143.7-146.3c-5.4-55.7-78.5-94-163.4-85.7-84.8 8.6-148.8 60.3-143.4 116s78.5 94 163.4 85.7c84.8-8.6 148.8-60.3 143.4-116zM347.9 35.1c-25.9 5.6-16.8 43.7 8.3 38.3 72.3-15.2 134.8 52.8 111.7 124-7.4 24.2 29.1 37 37.4 12 31.9-99.8-55.1-195.9-157.4-174.3zm-78.5 311c-17.1 38.8-66.8 60-109.1 46.3-40.8-13.1-58-53.4-40.3-89.7 17.7-35.4 63.1-55.4 103.4-45.1 42 10.8 63.1 50.2 46 88.5zm-86.3-30c-12.9-5.4-30 .3-38 12.9-8.3 12.9-4.3 28 8.6 34 13.1 6 30.8.3 39.1-12.9 8-13.1 3.7-28.3-9.7-34zm32.6-13.4c-5.1-1.7-11.4.6-14.3 5.4-2.9 5.1-1.4 10.6 3.7 12.9 5.1 2 11.7-.3 14.6-5.4 2.8-5.2 1.1-10.9-4-12.9z"/></svg></button><button title="分享到 Telegram" data-sharer="telegram" data-url="https://martinlwx.github.io/zh-cn/linear-regression-model-guide-theory/" data-title="线性回归模型指南 - 理论部分" data-web><svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M446.7 98.6l-67.6 318.8c-5.1 22.5-18.4 28.1-37.3 17.5l-103-75.9-49.7 47.8c-5.5 5.5-10.1 10.1-20.7 10.1l7.4-104.9 190.9-172.5c8.3-7.4-1.8-11.5-12.9-4.1L117.8 284 16.2 252.2c-22.1-6.9-22.5-22.1 4.6-32.7L418.2 66.4c18.4-6.9 34.5 4.1 28.5 32.2z"/></svg></button><script>
        function shareOnMastodon(title, link) {
            const SHARE_MASTODON_DOMAIN = "share_mastodon_domain"
            const savedDomain = localStorage.getItem(SHARE_MASTODON_DOMAIN) ?? "mastodon.social";
            const domain = prompt("Enter your Mastodon domain", savedDomain);
            if (domain === null) {
                return;
            }
            localStorage.setItem(SHARE_MASTODON_DOMAIN, domain)
            const text = title + "\n\n" + link;
            const url = new URL("https://" + domain)
            url.pathname = "share"
            url.searchParams.append('text', text)
            window.open(url, '_blank', "width=500,height=500,left=500,toolbar=0,status=0");
        }
    </script>
    <button title="分享到 Mastodon"onclick="javascript:shareOnMastodon(&#34;线性回归模型指南 - 理论部分&#34;, &#34;https://martinlwx.github.io/zh-cn/linear-regression-model-guide-theory/&#34;)"><svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M433 179.11c0-97.2-63.71-125.7-63.71-125.7-62.52-28.7-228.56-28.4-290.48 0 0 0-63.72 28.5-63.72 125.7 0 115.7-6.6 259.4 105.63 289.1 40.51 10.7 75.32 13 103.33 11.4 50.81-2.8 79.32-18.1 79.32-18.1l-1.7-36.9s-36.31 11.4-77.12 10.1c-40.41-1.4-83-4.4-89.63-54a102.54 102.54 0 0 1-.9-13.9c85.63 20.9 158.65 9.1 178.75 6.7 56.12-6.7 105-41.3 111.23-72.9 9.8-49.8 9-121.5 9-121.5zm-75.12 125.2h-46.63v-114.2c0-49.7-64-51.6-64 6.9v62.5h-46.33V197c0-58.5-64-56.6-64-6.9v114.2H90.19c0-122.1-5.2-147.9 18.41-175 25.9-28.9 79.82-30.8 103.83 6.1l11.6 19.5 11.6-19.5c24.11-37.1 78.12-34.8 103.83-6.1 23.71 27.3 18.4 53 18.4 175z"/></svg></button></div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"><svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M497.941 225.941L286.059 14.059A48 48 0 0 0 252.118 0H48C21.49 0 0 21.49 0 48v204.118a48 48 0 0 0 14.059 33.941l211.882 211.882c18.744 18.745 49.136 18.746 67.882 0l204.118-204.118c18.745-18.745 18.745-49.137 0-67.882zM112 160c-26.51 0-48-21.49-48-48s21.49-48 48-48 48 21.49 48 48-21.49 48-48 48zm513.941 133.823L421.823 497.941c-18.745 18.745-49.137 18.745-67.882 0l-.36-.36L527.64 323.522c16.999-16.999 26.36-39.6 26.36-63.64s-9.362-46.641-26.36-63.64L331.397 0h48.721a48 48 0 0 1 33.941 14.059l211.882 211.882c18.745 18.745 18.745 49.137 0 67.882z"/></svg>&nbsp;<a href="/zh-cn/tags/machine-learning/">Machine-Learning</a></section>
        <section class="print:!tw-hidden">
            <span><button class="tw-text-fgColor-link-muted hover:tw-text-fgColor-link-muted-hover" onclick="window.history.back();">返回</button></span>&nbsp;|&nbsp;<span><a href="/zh-cn/">主页</a></span>
        </section>
    </div>

    <div class="post-nav print:tw-hidden"><a href="/zh-cn/config-neovim-from-scratch/" class="prev" rel="prev" title="从零开始配置 Neovim(Nvim)"><svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M31.7 239l136-136c9.4-9.4 24.6-9.4 33.9 0l22.6 22.6c9.4 9.4 9.4 24.6 0 33.9L127.9 256l96.4 96.4c9.4 9.4 9.4 24.6 0 33.9L201.7 409c-9.4 9.4-24.6 9.4-33.9 0l-136-136c-9.5-9.4-9.5-24.6-.1-34z"/></svg>从零开始配置 Neovim(Nvim)</a>
            <a href="/zh-cn/backpropagation-tutorial/" class="next" rel="next" title="反向传播公式推导和理解">反向传播公式推导和理解<svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a></div>
</div>
<div id="comments" class="print:!tw-hidden tw-pt-32 tw-pb-8"><div id="giscus"></div><noscript>
                Please enable JavaScript to view the comments powered by <a href="https://giscus.app/">giscus</a>.
            </noscript></div></article></div>
        </main><footer class="footer">
        <div class="footer-container"><div class="footer-line">
                    由 <a href="https://gohugo.io/" target="_blank" rel="noopener noreferrer" title="Hugo 0.139.4">Hugo</a> 强力驱动&nbsp;|&nbsp;主题 - <a href="https://github.com/HEIGE-PCloud/DoIt" target="_blank" rel="noopener noreferrer" title="DoIt 0.4.0"><svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M402.3 344.9l32-32c5-5 13.7-1.5 13.7 5.7V464c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V112c0-26.5 21.5-48 48-48h273.5c7.1 0 10.7 8.6 5.7 13.7l-32 32c-1.5 1.5-3.5 2.3-5.7 2.3H48v352h352V350.5c0-2.1.8-4.1 2.3-5.6zm156.6-201.8L296.3 405.7l-90.4 10c-26.2 2.9-48.5-19.2-45.6-45.6l10-90.4L432.9 17.1c22.9-22.9 59.9-22.9 82.7 0l43.2 43.2c22.9 22.9 22.9 60 .1 82.8zM460.1 174L402 115.9 216.2 301.8l-7.3 65.3 65.3-7.3L460.1 174zm64.8-79.7l-43.2-43.2c-4.1-4.1-10.8-4.1-14.8 0L436 82l58.1 58.1 30.9-30.9c4-4.2 4-10.8-.1-14.9z"/></svg> DoIt</a>
                </div><div class="footer-line"><svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M256 8C119.033 8 8 119.033 8 256s111.033 248 248 248 248-111.033 248-248S392.967 8 256 8zm0 448c-110.532 0-200-89.451-200-200 0-110.531 89.451-200 200-200 110.532 0 200 89.451 200 200 0 110.532-89.451 200-200 200zm107.351-101.064c-9.614 9.712-45.53 41.396-104.065 41.396-82.43 0-140.484-61.425-140.484-141.567 0-79.152 60.275-139.401 139.762-139.401 55.531 0 88.738 26.62 97.593 34.779a11.965 11.965 0 0 1 1.936 15.322l-18.155 28.113c-3.841 5.95-11.966 7.282-17.499 2.921-8.595-6.776-31.814-22.538-61.708-22.538-48.303 0-77.916 35.33-77.916 80.082 0 41.589 26.888 83.692 78.277 83.692 32.657 0 56.843-19.039 65.726-27.225 5.27-4.857 13.596-4.039 17.82 1.738l19.865 27.17a11.947 11.947 0 0 1-1.152 15.518z"/></svg>2019 - 2025<span class="author">&nbsp;<a href="https://github.com/MartinLwx" target="_blank" rel="noopener noreferrer">MartinLwx</a></span>&nbsp;|&nbsp;<span class="license"><a rel="license external nofollow noopener noreffer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span></div>
            <div class="footer-line"></div>
            <div class="footer-line">
            </div>
        </div></footer></div>

    <div id="fixed-buttons" class="print:!tw-hidden"><a href="#back-to-top" id="back-to-top-button" class="fixed-button tw-transition-opacity tw-opacity-0" title="回到顶部">
            <svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M34.9 289.5l-22.2-22.2c-9.4-9.4-9.4-24.6 0-33.9L207 39c9.4-9.4 24.6-9.4 33.9 0l194.3 194.3c9.4 9.4 9.4 24.6 0 33.9L413 289.4c-9.5 9.5-25 9.3-34.3-.4L264 168.6V456c0 13.3-10.7 24-24 24h-32c-13.3 0-24-10.7-24-24V168.6L69.2 289.1c-9.3 9.8-24.8 10-34.3.4z"/></svg>
        </a><a href="#comments" id="view-comments" class="fixed-button" title="查看评论">
            <svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M256 32C114.6 32 0 125.1 0 240c0 49.6 21.4 95 57 130.7C44.5 421.1 2.7 466 2.2 466.5c-2.2 2.3-2.8 5.7-1.5 8.7S4.8 480 8 480c66.3 0 116-31.8 140.6-51.4 32.7 12.3 69 19.4 107.4 19.4 141.4 0 256-93.1 256-208S397.4 32 256 32z"/></svg>
        </a></div><link rel="stylesheet" href="/lib/katex/katex.min.css"><link rel="preload" as="style" onload="this.onload=null;this.rel='stylesheet'" href="/lib/katex/copy-tex.min.css">
        <noscript><link rel="stylesheet" href="/lib/katex/copy-tex.min.css"></noscript>
<script>window.config={"algoliasearch.min.js":"/lib/algoliasearch/algoliasearch-lite.umd.min.js","autocomplete.min.js":"/lib/autocomplete/autocomplete.min.js","comment":{"giscus":{"darkTheme":"dark","dataCategory":"Announcements","dataCategoryId":"DIC_kwDOGfB5nc4Ccjd0","dataEmitMetadata":"0","dataInputPosition":"bottom","dataLang":"en","dataLoading":"lazy","dataMapping":"pathname","dataReactionsEnabled":"1","dataRepo":"MartinLwx/martinlwx.github.io","dataRepoId":"R_kgDOGfB5nQ","dataStrict":"0","lightTheme":"preferred_color_scheme"}},"data":{"desktop-header-typeit":"MartinLwx's blog","mobile-header-typeit":"MartinLwx's blog"},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"algoliaAppID":"O4EMEES3VS","algoliaIndex":"index.zh-cn","algoliaSearchKey":"36fdaa364fae083332d0c8709026bd62","highlightTag":"em","maxResultLength":10,"noResultsFound":"没有找到结果","snippetLength":30,"type":"algolia"},"sharerjs":true,"table":{"sort":true},"typeit":{"cursorChar":"|","cursorSpeed":1000,"data":{"desktop-header-typeit":["desktop-header-typeit"],"mobile-header-typeit":["mobile-header-typeit"]},"duration":-1,"speed":100}};</script><script
    src="/lib/tablesort/tablesort.min.js"
    
  ></script><script
    src="/lib/sharer/sharer.min.js"
    
  ></script><script
    src="/lib/typeit/typeit.min.js"
    
  ></script><script
    src="/lib/katex/katex.min.js"
    
      defer
    
  ></script><script
    src="/lib/katex/auto-render.min.js"
    
      defer
    
  ></script><script
    src="/lib/katex/copy-tex.min.js"
    
      defer
    
  ></script><script
    src="/lib/katex/mhchem.min.js"
    
      defer
    
  ></script><script
    src="/js/katex.min.js"
    
      defer
    
  ></script><script
    src="/js/theme.min.js"
    
      defer
    
  ></script><script
    src="/js/giscus.min.js"
    
      defer
    
  ></script><script type="text/javascript">
            window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}gtag('js', new Date());
            gtag('config', 'G-7RY6742J2F', { 'anonymize_ip': true });
        </script><script
    src="https://www.googletagmanager.com/gtag/js?id=G-7RY6742J2F"
    async
  ></script>
    
    <script type="speculationrules">
        {
          "prerender": [
            {
              "where": { "href_matches": "/*" },
              "eagerness": "moderate"
            }
          ]
        }
    </script>
      
</body>

</html>
