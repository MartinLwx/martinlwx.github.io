# ç”¨ MPNN æ¡†æ¶è§£è¯» GAT


## ä»€ä¹ˆæ˜¯ MPNN æ¡†æ¶

Justin Gilmer æå‡ºäº† MPNNï¼ˆMessage Passing Neural Networkï¼‰æ¡†æ¶[^1] ï¼Œç”¨äºæè¿°è¢«ç”¨æ¥åšå›¾ä¸Šçš„ç›‘ç£å­¦ä¹ çš„å›¾ç¥ç»ç½‘ç»œæ¨¡å‹ã€‚æˆ‘å‘ç°è¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½ç”¨çš„æ¡†æ¶ï¼Œå¯ä»¥å¾ˆå¥½ç†è§£ä¸åŒçš„ GNN æ¨¡å‹æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Œæ–¹ä¾¿å¿«é€Ÿå¼„æ¸…æ¥šä¸åŒçš„ GNN æ¨¡å‹ä¹‹é—´çš„å·®åˆ«ã€‚æˆ‘ä»¬è€ƒè™‘å›¾ $G$ ä¸Šçš„ä¸€ä¸ªèŠ‚ç‚¹ $v$ï¼Œå®ƒçš„å‘é‡è¡¨ç¤º $h_v$ çš„æ›´æ–°æ–¹å¼å¦‚ä¸‹ï¼š
$$m_v^{t+1}=\sum_{u\in \mathcal{N}(v)}M_t(h_v^t,h_u^t,e_{vu})$$
$$h_v^{t+1}=U_t(h_v^t,m_v^{t+1})$$

å…¶ä¸­
- $u$ ä¸º $v$ çš„é‚»å±…èŠ‚ç‚¹ï¼Œ$\mathcal{N}(v)$ åˆ™è¡¨ç¤ºèŠ‚ç‚¹ $v$ çš„æ‰€æœ‰é‚»å±…
- $e_{vu}$ æ˜¯å¯é€‰é¡¹ï¼Œè¡¨ç¤ºè¾¹ä¸Šçš„ç‰¹å¾ï¼ˆè‹¥æœ‰ï¼‰
- $M_t$ æ˜¯æ¶ˆæ¯å‡½æ•°ï¼Œ$m_v^{t+1}$ å°±æ˜¯æ‰€æœ‰é‚»å±…èŠ‚ç‚¹çš„æ¶ˆæ¯èšåˆä¹‹åçš„ç»“æœ
- $U_t$ æ˜¯èŠ‚ç‚¹æ›´æ–°å‡½æ•°

åœ¨æ›´æ–°å®Œå›¾ä¸Šæ‰€æœ‰èŠ‚ç‚¹çš„å‘é‡è¡¨ç¤ºä¹‹åï¼Œæˆ‘ä»¬å¯èƒ½éœ€è¦è¦åšå›¾çº§åˆ«çš„åˆ†ç±»ä»»åŠ¡ï¼Œåœ¨ MPNN æ¡†æ¶ä¸­å¯¹åº”ä¸ºï¼š
$$\hat y=R(\{h_v^T|v\in G\})$$

å…¶ä¸­ï¼š
- $R$ ä¸ºå›¾è¯»å‡ºå‡½æ•°ï¼Œè¾“å…¥æ˜¯å›¾ä¸Šæ‰€æœ‰èŠ‚ç‚¹çš„å‘é‡è¡¨ç¤ºï¼Œè¾“å‡ºä¸ºä¸€ä¸ªç‰¹å¾å‘é‡ç”¨äºå›¾çº§åˆ«çš„åˆ†ç±»ä»»åŠ¡


## ä»€ä¹ˆæ˜¯ GAT
> ğŸ§ æˆ‘å‘ç°å°†è®ºæ–‡çš„å…¬å¼å’Œå…·ä½“çš„ä»£ç è”ç³»èµ·æ¥æ€»æ˜¯èƒ½å¤Ÿå¸®åŠ©ç†è§£ï¼Œå› æ­¤ä¸‹é¢å…³äº GAT å…¬å¼çš„è®²è§£æˆ‘ä¼šåœ¨ç”¨ MPNN æ¡†æ¶çš„åŸºç¡€ä¸Šï¼ŒåŒæ—¶é™„ä¸Šç›¸å…³çš„ä»£ç ï¼ˆç”¨ `...` è¡¨ç¤ºå…¶ä»–çœç•¥çš„éƒ¨åˆ†ï¼‰ã€‚ä»£ç æ¥è‡ªäº DGL å®˜æ–¹æä¾›çš„ GAT æ¨¡å—çš„[æºç ](https://docs.dgl.ai/en/latest/_modules/dgl/nn/pytorch/conv/gatconv.html#GATConv)

> ğŸ§ GAT å¯ä»¥æ–¹ä¾¿å †å å¤šå±‚ï¼Œä¸‹é¢çš„è®¨è®ºéƒ½æ˜¯ä»**æŸä¸€å±‚ $l$**çš„**æŸä¸ª**èŠ‚ç‚¹ $v$ çš„è§’åº¦æ¥è°ˆçš„

#### Step 1. å¯¹èŠ‚ç‚¹åšçº¿æ€§å˜æ¢
$$h_v^{l}=W^lh_v^{l}$$

è®¾æ¯ä¸ªèŠ‚ç‚¹çš„å‘é‡è¡¨ç¤ºçš„é•¿åº¦ä¸º $F$ï¼Œåœ¨ç¬¬ä¸€æ­¥ä¸­ï¼Œ**å¯¹å›¾ä¸Šæ¯ä¸ªç»“ç‚¹**çš„å‘é‡å…ˆåšä¸€ä¸ªçº¿æ€§å˜æ¢ï¼Œå…¶ä¸­ $W\in\mathcal{R}^{F'\times F}$, å› æ­¤æ¯ä¸ªèŠ‚ç‚¹çš„å‘é‡éƒ½æ›´æ–°é•¿åº¦ä¸º $F'$ã€‚ä¸ºäº†åŒºåˆ†ä¸åŒå±‚çš„å‘é‡ï¼Œç”¨ä¸Šè§’æ ‡ $l$ è¡¨ç¤ºè¿™æ˜¯ç¬¬ $l$ å±‚çš„ã€‚æ³¨æ„**åœ¨ç¬¬ $l$ å±‚ä¸­ï¼Œæ‰€æœ‰èŠ‚ç‚¹å…±ç”¨åŒä¸€ä¸ªæƒé‡çŸ©é˜µ $W$**

> ğŸ“’ **æ³¨æ„åé¢çš„ $h_v^l$ æˆ–è€… $h_u^l$ éƒ½æ˜¯ç»è¿‡çº¿æ€§å˜æ¢ä¹‹åçš„**

```python
class GATConv(nn.Module):
    def __init__(self, ...):
        ...
        self.fc = nn.Linear(
            self._in_src_feats, out_feats * num_heads, bias=False
        )
        ...
    def forward(self, graph, feat, ...):
        """
        Args
        ----
            feat: (N, *, D_in) where D_in is the size of input feature

        Returns
        -------
            torch.Tensor
                (N, *, num_heads, D_out)

        """
        ...
        src_prefix_shape = dst_prefix_shape = feat.shape[:-1]
        h_src = h_dst = self.feat_drop(feat)
        # h_src: (N, *, D_in)
        feat_src = feat_dst = self.fc(h_src).view(
            *src_prefix_shape, self._num_heads, self._out_feats
        )
        # feat_src/feat_dst: (N, *, num_heads, out_feat)
        ...
```

æ³¨æ„ï¼Œä¸Šé¢ä»£ç ä¸­çš„ `h_src` ä¼šå‡ºæ¥ä¸¤ä¸ªä¸€æ ·çš„ `feat_src` å’Œ `feat_dst` æ˜¯å› ä¸º DGL é‡‡ç”¨äº†æ•°å­¦ä¸Šç­‰ä»·ä½†æ˜¯è®¡ç®—æ•ˆç‡ä¼šæ›´é«˜çš„å®ç°ã€‚åé¢ä¼šè§£é‡Š

#### Step 2. è®¡ç®—æ³¨æ„åŠ›
$$e_{vu}^l=LeakyReLU\Big((a^l)^T[h_v^{l}||h_u^{l}]\Big)$$

$$\alpha_{vu}^l=Softmax_u(e_{vu}^l)$$

ç¬¬äºŒæ­¥å°±æ˜¯è¦è®¡ç®—ä¸­å¿ƒèŠ‚ç‚¹ $v$ å’Œå®ƒçš„æ‰€æœ‰é‚»å±…èŠ‚ç‚¹ä¹‹é—´çš„æ³¨æ„åŠ›äº†ã€‚åœ¨ä¸Šé¢çš„å…¬å¼ä¸­ï¼š
- $e_{vu}^l$ è¡¨ç¤ºæ³¨æ„åŠ›ç³»æ•°ï¼ˆattention coefficientï¼‰ã€‚è®ºæ–‡ä¸­æåˆ°å®Œå…¨å¯ä»¥é‡‡ç”¨ä¸åŒçš„æ³¨æ„åŠ›è®¡ç®—æ–¹å¼ï¼Œåœ¨ GAT çš„è®ºæ–‡ä¸­ï¼Œä½œè€…é€‰æ‹©ç”¨ä¸€å±‚å‰é¦ˆç¥ç»ç½‘ç»œè®¡ç®—æ³¨æ„åŠ›[^2]ã€‚**æ³¨æ„è¿™é‡Œçš„ $e_{vu}^l$ è·Ÿ MPNN çš„ $e_{vu}$ æ˜¯æ²¡æœ‰å…³ç³»çš„ï¼Œåªæ˜¯æ°å¥½è®°å·ä¸€æ ·äº†è€Œå·²**
- $||$ è¡¨ç¤ºæ‹¼æ¥æ“ä½œï¼Œå³æˆ‘ä»¬ä¼šå°†ä¸­å¿ƒèŠ‚ç‚¹å’Œå®ƒå¯¹åº”çš„é‚»å±…ç»“ç‚¹çš„å‘é‡è¡¨ç¤ºæ‹¼æ¥èµ·æ¥ï¼Œå¾—åˆ°ä¸€ä¸ªé•¿åº¦ä¸º $2F'$ çš„å‘é‡ï¼Œå¯¹åº”å…¬å¼ä¸­çš„ $[h_v^{l}||h_u^{l}]$ï¼Œç„¶åæŠŠå®ƒé€å…¥åˆ°å‰é¢æåˆ°çš„ä¸€å±‚å‰é¦ˆç¥ç»ç½‘ç»œä¸­ï¼Œå¯¹åº”å…¬å¼ä¸­çš„ $(a^l)^T[h_v^{l}||h_u^{l}]$ï¼Œå…¶ä¸­ $(a^l)^T$ æŒ‡çš„æ˜¯ç¬¬ $l$ å±‚çš„å•å±‚å‰é¦ˆç¥ç»ç½‘ç»œçš„å‚æ•°
- æ¿€æ´»å‡½æ•°é€‰ç”¨çš„æ˜¯ $LeakyReLU$
- æœ€ååœ¨èŠ‚ç‚¹ $v$ çš„æ‰€æœ‰é‚»å±…èŠ‚ç‚¹ä¹‹é—´ç”¨ Softmax åšå½’ä¸€åŒ–

> ğŸ¤”ï¸ æ­¥éª¤ä¸€å’Œæ­¥éª¤äºŒå¯¹åº” MPNN æ¡†æ¶çš„ $m_v^{t+1}$ çš„è®¡ç®—
##### å¤šå¤´æ³¨æ„åŠ›
æ­£å¦‚ Transformer ä¸­æœ‰å¤šå¤´æ³¨æ„åŠ›ä¸€æ ·ï¼ŒGAT çš„ä½œè€…åŒæ ·åœ¨èŠ‚ç‚¹æ›´æ–°çš„æ—¶å€™é‡‡ç”¨äº†å¤šå¤´æ³¨æ„åŠ›çš„æœºåˆ¶ï¼š
$$h_v^{l+1}= ||^{K^l} \sigma(\sum_{u\in\mathcal{N}(i)}\alpha_{vu}^{(k,l)}W^{(k,l)}h_u^{l})$$

è®°å·è¶Šæ¥è¶Šå¤æ‚äº†ï¼Œä½†æ˜¯ä»”ç»†æ€ç´¢ä¸€ç•ªè¿˜æ˜¯å¯ä»¥ç†æ¸…æ¥šçš„ï¼Œä¸Šè§’æ ‡ $(k,l)$ çš„æ„æ€æ˜¯ç¬¬ $l$ å±‚çš„ç¬¬ $k$ ä¸ªå¤´ã€‚å…¶ä¸­ $K^l$ ä¸ºç¬¬ $l$ å±‚â€œå¤´â€çš„æ•°é‡ã€‚ä¸Šé¢çš„å…¬å¼çš„æ„æ€å°±æ˜¯æ¯ä¸ªâ€œå¤´â€ä¼šè®¡ç®—å‡ºä¸€ä¸ªå‘é‡è¡¨ç¤ºï¼Œç„¶åä¸åŒâ€œå¤´â€ä¹‹é—´çš„ä¼šæ‹¼æ¥èµ·æ¥


```python
class GATConv(nn.Module):
    def __init__(self, ...):
        ...
        self.attn_l = nn.Parameter(
            th.FloatTensor(size=(1, num_heads, out_feats))
        )
        self.attn_r = nn.Parameter(
            th.FloatTensor(size=(1, num_heads, out_feats))
        )
        self.leaky_relu = nn.LeakyReLU(negative_slope)
        ...

    def forward(self, graph, feat, ...):
        """
        Args
        ----
            feat: (N, *, D_in) where D_in is the size of input feature

        Returns
        -------
            torch.Tensor
                (N, *, num_heads, D_out)

        """
        # feat_src/feat_dst: (N, *, num_heads, out_feat)
        el = (feat_src * self.attn_l).sum(dim=-1).unsqueeze(-1)
        er = (feat_dst * self.attn_r).sum(dim=-1).unsqueeze(-1)
        # el/er: (N, *, num_heads, 1)
        graph.srcdata.update({"ft": feat_src, "el": el})
        graph.dstdata.update({"er": er})
        graph.apply_edges(fn.u_add_v("el", "er", "e"))
        e = self.leaky_relu(graph.edata.pop("e"))
        # e: (N, *, num_heads, 1)

        # normalization
        graph.edata["a"] = self.attn_drop(edge_softmax(graph, e))
        # a: (N, *, num_heads, 1)

        # weighted sum
        graph.update_all(
            # ft: (N, *, num_heads, out_feat)
            # a: (N, *, num_heads, 1)
            # m: (N, *, num_heads, out_feat)
            fn.u_mul_e("ft", "a", "m"), 
            fn.sum("m", "ft")
        )
        rst = graph.dstdata["ft"]
        # rst: (N, *, num_heads, out_feat)
        ...
```
DGL çš„å®ç°åŸºäºä¸‹é¢è¿™ä¸ªäº‹å®ï¼š
$$a^T[h_v||h_u]=a_l^Th_v+a_r^Th_u$$
ä¸ºä»€ä¹ˆä¼šæ›´ä¸ºé«˜æ•ˆå‘¢ï¼Ÿ
- ä¸éœ€è¦å­˜å‚¨ $[h_v||h_u]$ è¿™ä¸ªä¸­é—´å˜é‡äº†ï¼ˆDGL ä¼šå°†æ¶ˆæ¯å­˜å‚¨ä¸ºè¾¹çš„å±æ€§ï¼‰
- åŠ æ³•å¯ä»¥ç”¨ DGL ä¼˜åŒ–è¿‡çš„ `fn.u_add_v` å‡½æ•°
#### Step 3. èšåˆé‚»å±…æ¶ˆæ¯

æœ€åèŠ‚ç‚¹æ›´æ–°çš„æ–¹å¼å°±æ˜¯è®¡ç®—é‚»å±…çš„å‘é‡è¡¨ç¤ºçš„åŠ æƒå’Œï¼ˆåŸºäºå‰é¢ç®—å¥½çš„æ³¨æ„åŠ›ï¼‰ï¼š
$$h_v^{l+1}=\sigma(\sum_{u\in \mathcal{N}(i)}\alpha_{vu}W^{l}h_u^{l})$$

> ğŸ¤”ï¸ ä¸Šé¢å°±å¯¹åº” MPNN æ¡†æ¶ä¸­çš„ $h_v^{t+1}$ çš„è®¡ç®—ï¼Œæ³¨æ„ GAT ç®— $h_t^{l+1}$ çš„æ—¶å€™å¹¶ä¸ä¼šç”¨åˆ°è‡ªå·±ä¸Šä¸€å±‚è¡¨ç¤º $h_t^l$ã€‚åŒæ—¶ GAT çš„æå‡ºæ˜¯ç”¨äºè§£å†³å›¾ä¸Šçš„èŠ‚ç‚¹åˆ†ç±»é—®é¢˜ï¼Œå› æ­¤ä¹Ÿæ²¡æœ‰å›¾è¯»å‡ºçš„æ“ä½œã€‚

åœ¨ GAT çš„è®ºæ–‡ä¸­ï¼Œä½œè€…æ˜¯è¦å°† GAT ç”¨äºèŠ‚ç‚¹çº§åˆ«çš„åˆ†ç±»ä»»åŠ¡[^2]ã€‚å‡è®¾æˆ‘ä»¬å †å äº† $L$ å±‚çš„ GAT ä¹‹åï¼Œåœ¨æœ€åä¸€å±‚å¦‚æœè¿˜é‡‡ç”¨æ‹¼æ¥çš„æ–¹å¼æ˜¾ç„¶æ˜¯ä¸åˆç†çš„ã€‚å› æ­¤ä½œè€…åœ¨æœ€åä¸€å±‚ GAT ä¸­ï¼Œæ˜¯å–å¤šä¸ªå¤´çš„å¹³å‡å€¼**ä¹‹åæ‰**åº”ç”¨äº†æ¿€æ´»å‡½æ•°ï¼Œè¿™é‡Œçš„æ¿€æ´»å‡½æ•°å¦‚æœé‡‡ç”¨ Softmaxï¼Œå°±å¯ä»¥ç›´æ¥åšèŠ‚ç‚¹åˆ†ç±»äº†[^2]ã€‚å…¬å¼å¦‚ä¸‹æ‰€ç¤º:
$$final\ embedding\ of\ h_v= \sigma\Big(\frac{1}{K^L}\sum_{k=1}^{K^L}\sum_{u\in\mathcal{N}(i)}\alpha_{vu}^{(k,L)}W^{(k,L)}h_u^{L}\Big)$$


## å®ç°

> ğŸ¤”ï¸ å›¾ç¥ç»ç½‘ç»œçš„æµè¡Œæ¡†æ¶ä¹‹ä¸€ [DGL](https://www.dgl.ai/) çš„è®¾è®¡å°±æ˜¯åŸºäº MPNN æ¡†æ¶ï¼Œä¸è¿‡ä»–ä»¬çš„å…¬å¼ä¼šç¨æœ‰ä¸åŒï¼Œä»–ä»¬è¿˜æœ‰ä¸€ä¸ªèšåˆå‡½æ•° $\rho$ï¼Œç”¨äºå†³å®šä¸€ä¸ªèŠ‚ç‚¹å¦‚ä½•èšåˆä»é‚»å±…é‚£è¾¹æ”¶åˆ°çš„æ‰€æœ‰ä¿¡æ¯ã€‚**æˆ‘è®¤ä¸ºä»–ä»¬çš„å…¬å¼æ›´å…·æœ‰æ³›åŒ–æ€§ï¼Œèƒ½å¤Ÿé€‚ç”¨äºæ›´å¤šç§æƒ…å†µ**ã€‚ä»–ä»¬è¿˜è´´å¿ƒåœ°å†™äº†å…³äºå¦‚ä½•ä½¿ç”¨ DGL çš„ MPNN ç›¸å…³å‡½æ•°çš„[æ•™ç¨‹](https://docs.dgl.ai/en/latest/guide/message.html)ï¼Œæ¨èä¸€çœ‹ğŸ‘ğŸ‘ğŸ‘

è‡³äº GAT çš„å®ç°ï¼ŒDGL ä¸ä»…æä¾›äº† [GAT æ¨¡å—](https://docs.dgl.ai/en/latest/generated/dgl.nn.pytorch.conv.GATConv.html#dgl.nn.pytorch.conv.GATConv)ï¼Œè€Œä¸”è¿˜å†™äº†ä¸€ç¯‡ä¸é”™çš„ç”¨è‡ªå¸¦çš„ `message_func` å’Œ `reduce_func` æ‰‹åŠ¨å®ç° GAT çš„[æ•™ç¨‹](https://docs.dgl.ai/en/latest/tutorials/models/1_gnn/9_gat.html)ã€‚ä¸€ä¸ªå®Œæ•´çš„ GAT ä»»åŠ¡è®­ç»ƒè„šæœ¬å¯ä»¥çœ‹[è¿™é‡Œ](https://github.com/dmlc/dgl/blob/master/examples/core/gat/train.py)

## æ€»ç»“
ä»¥ä¸Šå°±æ˜¯å¦‚ä½•ç”¨ MPNN æ¡†æ¶è§£é‡Š GAT çš„æ–¹æ³•ï¼Œå…¶ä¸­åŠ ä¸Šäº† DGL çš„æºç åˆ†æè¿›è¡Œè§£é‡Šï¼Œç”¨æ³¨æ„åŠ›è®¡ç®—èŠ‚ç‚¹ä¹‹é—´çš„å…³ç³»çœ‹èµ·æ¥æ˜¯ä¸€ä¸ªå¾ˆè‡ªç„¶çš„æ€è·¯ï¼Œå¯ä»¥çœ‹æˆæ˜¯å¯¹ GCN çš„ä¸€ç§æ³›åŒ–ã€‚GAT èƒ½å¤Ÿå¾ˆå¥½å­¦ä¹ åˆ°å›¾çš„å±€éƒ¨ç»“æ„è¡¨ç¤ºï¼Œè€Œä¸”è®¡ç®—æ³¨æ„åŠ›çš„æ–¹å¼å¯ä»¥å¹¶è¡Œï¼Œæ˜¯ååˆ†é«˜æ•ˆçš„ğŸ»ğŸ»ğŸ»

## å‚è€ƒ

[^1]: Gilmer J, Schoenholz S S, Riley P F, et al. Neural message passing for quantum chemistry[C]//International conference on machine learning. PMLR, 2017: 1263-1272. [arXiv](https://arxiv.org/abs/1704.01212)
[^2]: VeliÄkoviÄ‡ P, Cucurull G, Casanova A, et al. Graph attention networks[J]. arXiv preprint arXiv:1710.10903, 2017. [arXiv](https://arxiv.org/abs/1710.10903)

