<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>MartinLwx&#39;s Blog</title>
        <link>https://martinlwx.github.io/zh-cn/</link>
        <description>Welcome to my blog :)</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>martinlwx@163.com (MartinLwx)</managingEditor>
            <webMaster>martinlwx@163.com (MartinLwx)</webMaster><copyright>&lt;a rel=&#34;license noopener&#34; href=&#34;https://creativecommons.org/licenses/by-nc-nd/4.0/&#34; target=&#34;_blank&#34;&gt;CC BY-NC-ND 4.0&lt;/a&gt;</copyright><lastBuildDate>Wed, 18 Jun 2025 23:07:55 &#43;0800</lastBuildDate>
            <atom:link href="https://martinlwx.github.io/zh-cn/index.xml" rel="self" type="application/rss+xml" />
        <item>
    <title>异步编程&#43;漏桶算法：批量调用 LLM API</title>
    <link>https://martinlwx.github.io/zh-cn/async-and-leaky-bucket-algorithm-batch-llm-api-call/</link>
    <pubDate>Wed, 18 Jun 2025 23:07:55 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/zh-cn/async-and-leaky-bucket-algorithm-batch-llm-api-call/</guid>
    <description><![CDATA[<h2 id="背景" class="headerLink">
    <a href="#%e8%83%8c%e6%99%af" class="header-mark"></a>背景</h2><p>最近在工作中着手模型评测平台的搭建，其中有这么一个场景：需要调用其他部门提供的 LLM API 进行在评测集上跑模型评测，但这个 LLM API 有请求速率限制 - 最多 1 秒调用 2 次（2 RPS）。所以我的任务概括来说就是：<em>如何在严格遵守 API 速率请求的情况下，最大提高并发度加快模型评测速度</em>。本文的内容主要记录了对这个任务的尝试，以及最后的解决方案</p>]]></description>
</item><item>
    <title>范畴论与编程：Functor 是什么</title>
    <link>https://martinlwx.github.io/zh-cn/why-functor/</link>
    <pubDate>Sun, 01 Jun 2025 22:50:47 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/zh-cn/why-functor/</guid>
    <description><![CDATA[<h2 id="引言" class="headerLink">
    <a href="#%e5%bc%95%e8%a8%80" class="header-mark"></a>引言</h2><p>你可能每天都在使用 Functor 但你并没有意识到这一点：当你每次使用各种容器类型的 <code>map</code> 方法的时候，其实就是在利用 Functor 的性质</p>
<p>本篇文章会分别从范畴论的视角、编程语言视角讲解 Functor，希望能对你有所帮助 :)</p>]]></description>
</item><item>
    <title>Transformer 架构变化：旋转位置编码 (RoPE)</title>
    <link>https://martinlwx.github.io/zh-cn/rotary-position-embedding/</link>
    <pubDate>Sat, 24 May 2025 16:28:13 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/zh-cn/rotary-position-embedding/</guid>
    <description><![CDATA[<h2 id="自注意力机制回顾" class="headerLink">
    <a href="#%e8%87%aa%e6%b3%a8%e6%84%8f%e5%8a%9b%e6%9c%ba%e5%88%b6%e5%9b%9e%e9%a1%be" class="header-mark"></a>自注意力机制回顾</h2><p>用 $\mathbf x_i$ 表示没有位置编码的 token embedding，那么 $\mathbf q_m,\mathbf k_n,\mathbf v_n$ 的计算如下</p>
<p>$$
\begin{aligned}
\mathbf q_m&amp;=f_q(\mathbf x_m,m)\\
\mathbf k_n&amp;=f_k(\mathbf x_n,n)\\
\mathbf v_n&amp;=f_v(\mathbf x_n,n)
\end{aligned}
$$</p>
<p>这里的 $n, m$ 表示的是不同的位置，这里假设 $\mathbf k$ 和 $\mathbf v$ 是都是位置 $n$ 的，而 $\mathbf q$ 是位置 $m$ 的，并且 $m &gt; n$</p>]]></description>
</item><item>
    <title>Transformer 架构变化：RMSNorm 指南</title>
    <link>https://martinlwx.github.io/zh-cn/rmsnorm-in-a-nutshell/</link>
    <pubDate>Sun, 11 May 2025 14:01:26 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/zh-cn/rmsnorm-in-a-nutshell/</guid>
    <description><![CDATA[<h2 id="引言" class="headerLink">
    <a href="#%e5%bc%95%e8%a8%80" class="header-mark"></a>引言</h2><p>从 2017 年 Transformer 架构被提出以来，到现在 2025 已经 8 年过去了，Transformer 架构已经发生了很多变化。比如，现如今越来越多的大模型采用的是 RMSNorm<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> 而不是 LayerNorm。今天这篇文章就是对 RMSNorm 的一个简单介绍，在了解 RMSNorm 之前，我们不妨先回顾一下什么是 LayerNorm</p>]]></description>
</item><item>
    <title>Kosaraju 算法：求解有向图的强连通分量</title>
    <link>https://martinlwx.github.io/zh-cn/kosaraju-algorithm-explained/</link>
    <pubDate>Sat, 26 Apr 2025 17:23:49 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/zh-cn/kosaraju-algorithm-explained/</guid>
    <description><![CDATA[<h2 id="intro" class="headerLink">
    <a href="#intro" class="header-mark"></a>Intro</h2><p>在做算法题练习的时候遇到了一道有趣的题目 - <a href="https://cses.fi/problemset/task/1682/" target="_blank" rel="noopener noreferrer">1682. Flight Routes Check</a>。要解决这一道题需要<em>高效</em>确定一个有向图上有多少强连通分量。在看了一下题解之后，我发现 Kosaruju 算法可以用于解决这个问题，它可以在<em>线性时间内</em>找到有向图的所有强连通分量。这里说的线性时间是</p>]]></description>
</item><item>
    <title>神奇的 torch.einsum API</title>
    <link>https://martinlwx.github.io/zh-cn/the-magic-torch-einsum-api/</link>
    <pubDate>Mon, 14 Apr 2025 20:44:01 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/zh-cn/the-magic-torch-einsum-api/</guid>
    <description><![CDATA[<h2 id="motivations" class="headerLink">
    <a href="#motivations" class="header-mark"></a>Motivations</h2><p>在 PyTorch 里面存在着<em>很多</em>跟矩阵乘法、矩阵向量乘法等操作相关的 API，这对记忆来说是一种负担。并且，在使用这些 API 的过程中<em>经常</em>需要对矩阵进行 reshape 等操作，确保维度信息对得上</p>]]></description>
</item><item>
    <title>Python 的 2 个进程池相关 API</title>
    <link>https://martinlwx.github.io/zh-cn/data-parallel-with-two-different-api/</link>
    <pubDate>Sun, 30 Mar 2025 21:36:18 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/zh-cn/data-parallel-with-two-different-api/</guid>
    <description><![CDATA[<h2 id="intro" class="headerLink">
    <a href="#intro" class="header-mark"></a>Intro</h2><p>作为一名算法工程师，在我的工作中经常都会写各种 Python 脚本来处理大量数据，做数据清洗、信息提取等。通常情况下，这些数据的处理并不涉及竞争条件（Race Condition），而是简单的数据并行（Data Parallel），属于 <em>CPU 密集型任务</em>。通常情况下，这样的任务可以被抽象为 <code>map(fn, data)</code> 的模式</p>]]></description>
</item><item>
    <title>Class Hierarchy Analysis 算法: 快速生成调用图</title>
    <link>https://martinlwx.github.io/zh-cn/call-graph-generation-using-class-hierarchy-analysis/</link>
    <pubDate>Wed, 19 Mar 2025 22:27:38 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/zh-cn/call-graph-generation-using-class-hierarchy-analysis/</guid>
    <description><![CDATA[<h2 id="调用图生成的核心问题" class="headerLink">
    <a href="#%e8%b0%83%e7%94%a8%e5%9b%be%e7%94%9f%e6%88%90%e7%9a%84%e6%a0%b8%e5%bf%83%e9%97%ae%e9%a2%98" class="header-mark"></a>调用图生成的核心问题</h2><p>对于 OOP 语言来说，搭建调用图的核心问题是<em>有多态的场景下</em>如何确定到底是哪一个方法被调用了，下面是 Java 的一些可能的函数调用 <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>
<table>
  <thead>
      <tr>
          <th></th>
          <th>Static Call</th>
          <th>Special Call</th>
          <th>Virtual Call</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Instruction</td>
          <td><code>invokestatic</code></td>
          <td><code>invokespecial</code></td>
          <td><code>invokeinterface, invokevirtual</code></td>
      </tr>
      <tr>
          <td>Receiver Objects</td>
          <td>❌</td>
          <td>✅</td>
          <td>✅</td>
      </tr>
      <tr>
          <td>Target Methods</td>
          <td>Static Method</td>
          <td>Constructor, Private Instance Method, Superclass Instance Method</td>
          <td>Other Instance Method</td>
      </tr>
      <tr>
          <td>Count of Possible Target Methods</td>
          <td>1</td>
          <td>1</td>
          <td>$\ge 1$ (polymorphism)</td>
      </tr>
      <tr>
          <td>Determinancy</td>
          <td>Compile-time</td>
          <td>Compile-time</td>
          <td>Run-time</td>
      </tr>
  </tbody>
</table>
<p>其中 Virtual Call 因为包含了多态，方法调用存在<em>多个</em>可能的目标方法</p>]]></description>
</item><item>
    <title>前缀和数组: 快速计算数组区间和</title>
    <link>https://martinlwx.github.io/zh-cn/ds-prefixsum-array/</link>
    <pubDate>Sat, 15 Mar 2025 19:11:43 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/zh-cn/ds-prefixsum-array/</guid>
    <description><![CDATA[<h2 id="motivations" class="headerLink">
    <a href="#motivations" class="header-mark"></a>Motivations</h2><p>有这么一类问题——给定一个数组 $arr$ 和 $Q$ 个查询，每一个查询的格式是 $query(l, r)$，意思是计算区间和 $arr[l] + arr[l + 1] + &hellip; + arr[r]$</p>
<p>如果采用暴力求解，那么查询区间和的时间复杂度是 $O(N)$，处理 $Q$ 个查询就需要 $O(NQ)$，<em>有没有</em>什么数据结构或者是算法可以优化这个时间复杂度呢？</p>]]></description>
</item><item>
    <title>语言模型中的 Weight Tying 技术</title>
    <link>https://martinlwx.github.io/zh-cn/an-explanation-of-weight-tying/</link>
    <pubDate>Tue, 11 Mar 2025 19:05:30 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/zh-cn/an-explanation-of-weight-tying/</guid>
    <description><![CDATA[<h2 id="引言" class="headerLink">
    <a href="#%e5%bc%95%e8%a8%80" class="header-mark"></a>引言</h2><div class="details admonition quote open">
    <div class="details-summary admonition-title">
        <span class="icon"><svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M464 32H336c-26.5 0-48 21.5-48 48v128c0 26.5 21.5 48 48 48h80v64c0 35.3-28.7 64-64 64h-8c-13.3 0-24 10.7-24 24v48c0 13.3 10.7 24 24 24h8c88.4 0 160-71.6 160-160V80c0-26.5-21.5-48-48-48zm-288 0H48C21.5 32 0 53.5 0 80v128c0 26.5 21.5 48 48 48h80v64c0 35.3-28.7 64-64 64h-8c-13.3 0-24 10.7-24 24v48c0 13.3 10.7 24 24 24h8c88.4 0 160-71.6 160-160V80c0-26.5-21.5-48-48-48z"/></svg></span>Quote<span class="details-icon"><svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></span>
    </div>
    <div class="details-content">
        <div class="admonition-content"><p><em>In our model, we share the same weight matrix between the two embedding layers and the pre-softmax linear transformation</em> - <em>Attention is All You Need</em>, Section 3.4. Embeddings and Softmax<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>]]></description>
</item></channel>
</rss>
